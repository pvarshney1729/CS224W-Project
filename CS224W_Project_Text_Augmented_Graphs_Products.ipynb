{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS 224W Project: Text Augmented Graphs (OGBN-Products)\n",
        "\n",
        "### This Colab contains code for experiments using various techniques for combining textual and graph information, tested on the OGBN-Products dataset"
      ],
      "metadata": {
        "id": "iCdg3xHL2iC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install PyG and other required libraries"
      ],
      "metadata": {
        "id": "V2VKKHTawc7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q68cWlLkvbxp",
        "outputId": "059967c7-17d6-476e-99d7-67e80fced6b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cu121)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.10/dist-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src\n",
        "!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric\n",
        "!pip install ogb\n",
        "!pip install faiss-gpu\n",
        "import torch_geometric\n",
        "import torch_geometric.transforms as T\n",
        "from torch_sparse.tensor import SparseTensor\n",
        "from torch_geometric.nn import GCNConv, SAGEConv\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "import numpy as np\n",
        "import pickle\n",
        "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link the Colab to your Google Drive\n",
        "\n",
        "We use Google Drive to load the dataset, pre trained LM embeddings and logits. Instructions to download these embeddings are provided later in the Colab\n"
      ],
      "metadata": {
        "id": "_YUCOZKlHqPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubd42LTCHpy8",
        "outputId": "c890e0da-994b-45d9-b05a-0b294e7a852a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add code to load the OGBN Products dataset\n",
        "\n",
        "Due to the large size of the dataset, and the limited computation available on Colab, we use a sampled version of the OGBN-Products dataset.\n",
        "\n",
        "The sampled dataset is available at https://github.com/XiaoxinHe/TAPE/blob/main/dataset/ogbn_products/ogbn-products_subset.pt, please create a copy of this file in your Google Drive account and update the filepath in the code accordingly\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "10BSGFn4xAau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = \"ogbn-products\"\n",
        "data_filepath=f'/content/drive/Shareddrives/CS224W Project/ogbn-products_subset.pt'\n",
        "class LoadData:\n",
        "    \"\"\"\n",
        "    A class used to load and process graph data using the PyTorch Geometric (PyG) library.\n",
        "    \"\"\"\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Loads the graph dataset, applies necessary transformations, and retrieves split indices.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        data: PyG data object\n",
        "            The transformed graph data.\n",
        "        split_idx: dict\n",
        "            A dictionary containing the train, validation, and test split indices.\n",
        "        num_classes: int\n",
        "            The number of classes in the dataset.\n",
        "        \"\"\"\n",
        "        num_classes = 47\n",
        "        data = torch.load(data_filepath)\n",
        "        data.edge_index = data.adj_t.to_symmetric()\n",
        "        split_idx={}\n",
        "        split_idx['train'] = data.train_mask\n",
        "        split_idx['valid'] = data.val_mask\n",
        "        split_idx['test'] = data.test_mask\n",
        "        return data, split_idx, num_classes"
      ],
      "metadata": {
        "id": "-HO3dfR6xJYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model training and loss function\n",
        "\n"
      ],
      "metadata": {
        "id": "XqzkxMDZ0-QG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss:\n",
        "    \"\"\"\n",
        "    A class for defining loss computation in neural network training.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def get_loss(self, out, labels, train_idx):\n",
        "        \"\"\"\n",
        "        Computes the cross-entropy loss between the output predictions and the true labels.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        out : torch.Tensor\n",
        "            The output predictions from the neural network model, typically the logits.\n",
        "        labels : torch.Tensor\n",
        "            The true labels for the training data.\n",
        "        train_idx : torch.Tensor or list\n",
        "            The indices of the training data samples.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        torch.Tensor\n",
        "            The computed cross-entropy loss.\n",
        "        \"\"\"\n",
        "        return F.cross_entropy(out, labels[train_idx])\n",
        "\n",
        "\n",
        "def train(model, data, train_idx, optimizer, loss_obj):\n",
        "    \"\"\"\n",
        "    Trains a neural network model for one epoch.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : torch.nn.Module\n",
        "        The neural network model to be trained.\n",
        "    data : object\n",
        "        The data object containing features and adjacency information.\n",
        "    train_idx : torch.Tensor or list\n",
        "        The indices of the training data.\n",
        "    optimizer : torch.optim.Optimizer\n",
        "        The optimizer used for updating model weights.\n",
        "    loss_obj : Loss\n",
        "        An instance of the Loss class to compute the loss.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float\n",
        "        The loss value computed for this training epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index, train_idx)[train_idx]\n",
        "    loss = loss_obj.get_loss(out, data.y.squeeze(1), train_idx)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "yYWYuh_W1F5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model testing function\n"
      ],
      "metadata": {
        "id": "naBo4IQ01pmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator):\n",
        "    \"\"\"\n",
        "    Evaluates the performance of a trained model on training, validation, and test datasets.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : torch.nn.Module\n",
        "        The neural network model to be evaluated.\n",
        "    data : object\n",
        "        The data object containing features, adjacency information, and labels.\n",
        "    split_idx : dict\n",
        "        A dictionary with keys 'train', 'valid', and 'test' mapping to the respective data indices.\n",
        "    evaluator : object\n",
        "        An object used to evaluate the model's predictions. It must have an 'eval' method.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (train_acc, valid_acc, test_acc)\n",
        "        A tuple containing the accuracy on the training, validation, and test sets.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    out = model(data.x, data.edge_index)\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True).cpu()\n",
        "\n",
        "    # Evaluate accuracy on training, validation, and test sets\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc\n"
      ],
      "metadata": {
        "id": "oPdpg7lm1WYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Hyperparameters\n",
        "\n",
        "Our code support two models\n",
        "\n",
        "\n",
        "1.   GraphSAGE (torch_geometric.nn.models.GraphSAGE)\n",
        "2.   GCN (torch_geometric.nn.models.GCN)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3kAJ-BLv5d8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = {'model' : 'GraphSAGE', 'hidden_layer_size' : 128, 'num_layers' : 3, 'dropout' : 0.5, 'learning_rate' : 1e-3, 'epochs' : 1000}"
      ],
      "metadata": {
        "id": "dCZ9Sgsd5cv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an end-to-end training loop\n",
        "\n"
      ],
      "metadata": {
        "id": "QCXVcxlI4AX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(load_data_obj, loss_obj, hyperparams):\n",
        "  \"\"\"\n",
        "    Executes the training loop for a graph neural network using specified hyperparameters.\n",
        "\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    load_data_obj : LoadData\n",
        "        An instance of the LoadData class that is used to load the dataset.\n",
        "    loss_obj : Loss\n",
        "        An instance of the Loss class that defines the loss function to be used during training.\n",
        "    hyperparams : dict\n",
        "        A dictionary containing hyperparameters for the model. Expected keys are:\n",
        "        'model' (str), 'hidden_layer_size' (int), 'num_layers' (int), 'out_channels' (int),\n",
        "        'dropout' (float), 'learning_rate' (float), 'epochs' (int).\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple:\n",
        "        best_test_acc (float): The highest test accuracy achieved during training.\n",
        "        model: The trained model instance.\n",
        "  \"\"\"\n",
        "  data, split_idx, num_classes = load_data_obj.load_data()\n",
        "  if hyperparams['model'] == 'GraphSAGE':\n",
        "    model = torch_geometric.nn.models.GraphSAGE(data.x.shape[1], hidden_channels=hyperparams['hidden_layer_size'],\n",
        "                                              num_layers=hyperparams['num_layers'], out_channels=num_classes, dropout=hyperparams['dropout']).to(device)\n",
        "  else:\n",
        "    model = torch_geometric.nn.models.GCN(data.x.shape[1], hidden_channels=hyperparams['hidden_layer_size'],\n",
        "                                              num_layers=hyperparams['num_layers'], out_channels=num_classes, dropout=hyperparams['dropout']).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n",
        "  evaluator = Evaluator(name=DATASET)\n",
        "  train_idx = split_idx['train']\n",
        "  model.to(device)\n",
        "  data.to(device)\n",
        "  valid_accs=[]\n",
        "  test_accs=[]\n",
        "  for epoch in range(hyperparams['epochs']):\n",
        "    loss = train(model, data, train_idx, optimizer, loss_obj)\n",
        "    result = test(model, data, split_idx, evaluator)\n",
        "    train_acc, valid_acc, test_acc = result\n",
        "    valid_accs.append(valid_acc)\n",
        "    test_accs.append(test_acc)\n",
        "    print(f'Epoch: {epoch:02d}, '\n",
        "          f'Loss: {loss:.4f}, '\n",
        "          f'Train: {100 * train_acc:.2f}%, '\n",
        "          f'Valid: {100 * valid_acc:.2f}% '\n",
        "          f'Test: {100 * test_acc:.2f}%')\n",
        "  best_test_acc = test_accs[np.argmax(valid_accs)]\n",
        "  print(f'Best Test accuracy is {best_test_acc}')\n",
        "  return best_test_acc, model"
      ],
      "metadata": {
        "id": "YHNzhwxC4GYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the training loop using the Base Model"
      ],
      "metadata": {
        "id": "yWbO32opnrBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_data=LoadData()\n",
        "loss_obj=Loss()\n",
        "standard_acc, base_model = train_loop(load_data, loss_obj, hyperparams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoPDc6jW956G",
        "outputId": "9bd537d4-d059-4889-bb2e-d19cd626463c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00, Loss: 3.8940, Train: 15.74%, Valid: 14.95% Test: 9.70%\n",
            "Epoch: 01, Loss: 3.7362, Train: 28.39%, Valid: 25.51% Test: 17.91%\n",
            "Epoch: 02, Loss: 3.5971, Train: 29.33%, Valid: 26.46% Test: 18.44%\n",
            "Epoch: 03, Loss: 3.4508, Train: 28.30%, Valid: 25.19% Test: 17.81%\n",
            "Epoch: 04, Loss: 3.3230, Train: 27.65%, Valid: 24.49% Test: 17.50%\n",
            "Epoch: 05, Loss: 3.1815, Train: 27.45%, Valid: 24.36% Test: 17.41%\n",
            "Epoch: 06, Loss: 3.0695, Train: 27.36%, Valid: 24.36% Test: 17.39%\n",
            "Epoch: 07, Loss: 2.9579, Train: 27.35%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 08, Loss: 2.8536, Train: 27.36%, Valid: 24.36% Test: 17.39%\n",
            "Epoch: 09, Loss: 2.7652, Train: 27.47%, Valid: 24.43% Test: 17.44%\n",
            "Epoch: 10, Loss: 2.6899, Train: 28.05%, Valid: 24.94% Test: 17.64%\n",
            "Epoch: 11, Loss: 2.6173, Train: 29.47%, Valid: 26.02% Test: 18.16%\n",
            "Epoch: 12, Loss: 2.5642, Train: 31.15%, Valid: 27.67% Test: 18.90%\n",
            "Epoch: 13, Loss: 2.4942, Train: 32.54%, Valid: 29.77% Test: 19.60%\n",
            "Epoch: 14, Loss: 2.4255, Train: 34.11%, Valid: 31.36% Test: 20.95%\n",
            "Epoch: 15, Loss: 2.3701, Train: 36.63%, Valid: 34.54% Test: 23.43%\n",
            "Epoch: 16, Loss: 2.3181, Train: 40.14%, Valid: 38.61% Test: 26.27%\n",
            "Epoch: 17, Loss: 2.2727, Train: 43.18%, Valid: 42.43% Test: 28.68%\n",
            "Epoch: 18, Loss: 2.2253, Train: 45.47%, Valid: 44.40% Test: 30.54%\n",
            "Epoch: 19, Loss: 2.1811, Train: 47.36%, Valid: 45.61% Test: 31.99%\n",
            "Epoch: 20, Loss: 2.1394, Train: 48.62%, Valid: 47.33% Test: 33.23%\n",
            "Epoch: 21, Loss: 2.1035, Train: 49.69%, Valid: 47.84% Test: 34.09%\n",
            "Epoch: 22, Loss: 2.0635, Train: 50.80%, Valid: 48.98% Test: 34.87%\n",
            "Epoch: 23, Loss: 2.0172, Train: 51.69%, Valid: 49.94% Test: 35.62%\n",
            "Epoch: 24, Loss: 1.9661, Train: 52.70%, Valid: 50.89% Test: 36.35%\n",
            "Epoch: 25, Loss: 1.9322, Train: 53.72%, Valid: 52.04% Test: 37.24%\n",
            "Epoch: 26, Loss: 1.8974, Train: 54.66%, Valid: 52.93% Test: 38.11%\n",
            "Epoch: 27, Loss: 1.8499, Train: 56.03%, Valid: 54.07% Test: 39.19%\n",
            "Epoch: 28, Loss: 1.8104, Train: 57.21%, Valid: 55.73% Test: 40.44%\n",
            "Epoch: 29, Loss: 1.7808, Train: 58.66%, Valid: 56.93% Test: 41.97%\n",
            "Epoch: 30, Loss: 1.7375, Train: 60.42%, Valid: 58.72% Test: 43.40%\n",
            "Epoch: 31, Loss: 1.7066, Train: 62.13%, Valid: 60.37% Test: 44.72%\n",
            "Epoch: 32, Loss: 1.6695, Train: 63.71%, Valid: 62.34% Test: 46.01%\n",
            "Epoch: 33, Loss: 1.6459, Train: 65.01%, Valid: 63.68% Test: 47.31%\n",
            "Epoch: 34, Loss: 1.6061, Train: 66.41%, Valid: 65.46% Test: 48.61%\n",
            "Epoch: 35, Loss: 1.5759, Train: 67.62%, Valid: 66.54% Test: 49.58%\n",
            "Epoch: 36, Loss: 1.5440, Train: 68.47%, Valid: 67.68% Test: 50.34%\n",
            "Epoch: 37, Loss: 1.5102, Train: 69.45%, Valid: 68.83% Test: 51.02%\n",
            "Epoch: 38, Loss: 1.4792, Train: 70.04%, Valid: 69.66% Test: 51.59%\n",
            "Epoch: 39, Loss: 1.4596, Train: 70.65%, Valid: 70.42% Test: 52.10%\n",
            "Epoch: 40, Loss: 1.4292, Train: 71.06%, Valid: 71.12% Test: 52.50%\n",
            "Epoch: 41, Loss: 1.4038, Train: 71.48%, Valid: 71.95% Test: 52.97%\n",
            "Epoch: 42, Loss: 1.3852, Train: 71.97%, Valid: 72.33% Test: 53.45%\n",
            "Epoch: 43, Loss: 1.3619, Train: 72.50%, Valid: 72.90% Test: 54.02%\n",
            "Epoch: 44, Loss: 1.3408, Train: 72.91%, Valid: 73.28% Test: 54.51%\n",
            "Epoch: 45, Loss: 1.3236, Train: 73.38%, Valid: 73.98% Test: 55.04%\n",
            "Epoch: 46, Loss: 1.2972, Train: 73.91%, Valid: 74.17% Test: 55.59%\n",
            "Epoch: 47, Loss: 1.2849, Train: 74.24%, Valid: 74.55% Test: 56.04%\n",
            "Epoch: 48, Loss: 1.2576, Train: 74.61%, Valid: 75.13% Test: 56.50%\n",
            "Epoch: 49, Loss: 1.2443, Train: 74.96%, Valid: 75.70% Test: 56.87%\n",
            "Epoch: 50, Loss: 1.2256, Train: 75.31%, Valid: 75.89% Test: 57.18%\n",
            "Epoch: 51, Loss: 1.2178, Train: 75.61%, Valid: 75.95% Test: 57.47%\n",
            "Epoch: 52, Loss: 1.1910, Train: 75.90%, Valid: 76.34% Test: 57.74%\n",
            "Epoch: 53, Loss: 1.1892, Train: 76.09%, Valid: 76.65% Test: 58.01%\n",
            "Epoch: 54, Loss: 1.1597, Train: 76.26%, Valid: 77.04% Test: 58.16%\n",
            "Epoch: 55, Loss: 1.1602, Train: 76.45%, Valid: 77.23% Test: 58.31%\n",
            "Epoch: 56, Loss: 1.1491, Train: 76.57%, Valid: 77.48% Test: 58.44%\n",
            "Epoch: 57, Loss: 1.1426, Train: 76.82%, Valid: 77.67% Test: 58.61%\n",
            "Epoch: 58, Loss: 1.1116, Train: 77.10%, Valid: 77.93% Test: 58.72%\n",
            "Epoch: 59, Loss: 1.1105, Train: 77.18%, Valid: 78.18% Test: 58.97%\n",
            "Epoch: 60, Loss: 1.0883, Train: 77.39%, Valid: 78.37% Test: 59.20%\n",
            "Epoch: 61, Loss: 1.1009, Train: 77.64%, Valid: 78.50% Test: 59.46%\n",
            "Epoch: 62, Loss: 1.0822, Train: 77.79%, Valid: 78.69% Test: 59.71%\n",
            "Epoch: 63, Loss: 1.0677, Train: 77.90%, Valid: 79.01% Test: 59.95%\n",
            "Epoch: 64, Loss: 1.0579, Train: 78.01%, Valid: 78.94% Test: 60.17%\n",
            "Epoch: 65, Loss: 1.0597, Train: 78.16%, Valid: 78.94% Test: 60.32%\n",
            "Epoch: 66, Loss: 1.0437, Train: 78.34%, Valid: 78.88% Test: 60.51%\n",
            "Epoch: 67, Loss: 1.0420, Train: 78.49%, Valid: 79.01% Test: 60.67%\n",
            "Epoch: 68, Loss: 1.0332, Train: 78.56%, Valid: 79.01% Test: 60.82%\n",
            "Epoch: 69, Loss: 1.0257, Train: 78.69%, Valid: 79.13% Test: 60.99%\n",
            "Epoch: 70, Loss: 1.0174, Train: 78.90%, Valid: 79.20% Test: 61.13%\n",
            "Epoch: 71, Loss: 1.0051, Train: 79.03%, Valid: 79.52% Test: 61.32%\n",
            "Epoch: 72, Loss: 1.0083, Train: 79.18%, Valid: 79.64% Test: 61.51%\n",
            "Epoch: 73, Loss: 1.0030, Train: 79.32%, Valid: 79.77% Test: 61.68%\n",
            "Epoch: 74, Loss: 0.9882, Train: 79.38%, Valid: 80.09% Test: 61.88%\n",
            "Epoch: 75, Loss: 0.9959, Train: 79.47%, Valid: 80.03% Test: 62.05%\n",
            "Epoch: 76, Loss: 0.9800, Train: 79.56%, Valid: 80.03% Test: 62.25%\n",
            "Epoch: 77, Loss: 0.9664, Train: 79.65%, Valid: 80.09% Test: 62.37%\n",
            "Epoch: 78, Loss: 0.9733, Train: 79.71%, Valid: 80.03% Test: 62.50%\n",
            "Epoch: 79, Loss: 0.9556, Train: 79.84%, Valid: 80.28% Test: 62.58%\n",
            "Epoch: 80, Loss: 0.9557, Train: 79.94%, Valid: 80.28% Test: 62.70%\n",
            "Epoch: 81, Loss: 0.9542, Train: 80.02%, Valid: 80.34% Test: 62.85%\n",
            "Epoch: 82, Loss: 0.9486, Train: 80.16%, Valid: 80.34% Test: 62.94%\n",
            "Epoch: 83, Loss: 0.9293, Train: 80.21%, Valid: 80.47% Test: 63.03%\n",
            "Epoch: 84, Loss: 0.9377, Train: 80.29%, Valid: 80.53% Test: 63.15%\n",
            "Epoch: 85, Loss: 0.9333, Train: 80.36%, Valid: 80.66% Test: 63.26%\n",
            "Epoch: 86, Loss: 0.9329, Train: 80.52%, Valid: 80.85% Test: 63.40%\n",
            "Epoch: 87, Loss: 0.9197, Train: 80.57%, Valid: 81.04% Test: 63.52%\n",
            "Epoch: 88, Loss: 0.9129, Train: 80.66%, Valid: 80.98% Test: 63.61%\n",
            "Epoch: 89, Loss: 0.9225, Train: 80.69%, Valid: 81.11% Test: 63.69%\n",
            "Epoch: 90, Loss: 0.9221, Train: 80.72%, Valid: 81.11% Test: 63.79%\n",
            "Epoch: 91, Loss: 0.9129, Train: 80.79%, Valid: 81.17% Test: 63.91%\n",
            "Epoch: 92, Loss: 0.9163, Train: 80.85%, Valid: 81.17% Test: 63.99%\n",
            "Epoch: 93, Loss: 0.9018, Train: 80.89%, Valid: 81.11% Test: 64.06%\n",
            "Epoch: 94, Loss: 0.9019, Train: 80.96%, Valid: 81.30% Test: 64.16%\n",
            "Epoch: 95, Loss: 0.8977, Train: 81.04%, Valid: 81.30% Test: 64.25%\n",
            "Epoch: 96, Loss: 0.8920, Train: 81.09%, Valid: 81.42% Test: 64.35%\n",
            "Epoch: 97, Loss: 0.8931, Train: 81.17%, Valid: 81.55% Test: 64.42%\n",
            "Epoch: 98, Loss: 0.8805, Train: 81.20%, Valid: 81.62% Test: 64.49%\n",
            "Epoch: 99, Loss: 0.8762, Train: 81.27%, Valid: 81.81% Test: 64.60%\n",
            "Epoch: 100, Loss: 0.8792, Train: 81.33%, Valid: 81.74% Test: 64.65%\n",
            "Epoch: 101, Loss: 0.8706, Train: 81.38%, Valid: 81.74% Test: 64.73%\n",
            "Epoch: 102, Loss: 0.8786, Train: 81.43%, Valid: 81.87% Test: 64.80%\n",
            "Epoch: 103, Loss: 0.8652, Train: 81.55%, Valid: 81.81% Test: 64.87%\n",
            "Epoch: 104, Loss: 0.8602, Train: 81.62%, Valid: 81.74% Test: 64.94%\n",
            "Epoch: 105, Loss: 0.8573, Train: 81.67%, Valid: 82.00% Test: 64.98%\n",
            "Epoch: 106, Loss: 0.8541, Train: 81.76%, Valid: 82.00% Test: 65.03%\n",
            "Epoch: 107, Loss: 0.8513, Train: 81.73%, Valid: 82.12% Test: 65.08%\n",
            "Epoch: 108, Loss: 0.8510, Train: 81.81%, Valid: 82.12% Test: 65.17%\n",
            "Epoch: 109, Loss: 0.8440, Train: 81.81%, Valid: 82.12% Test: 65.24%\n",
            "Epoch: 110, Loss: 0.8465, Train: 81.85%, Valid: 82.19% Test: 65.31%\n",
            "Epoch: 111, Loss: 0.8402, Train: 81.89%, Valid: 82.32% Test: 65.37%\n",
            "Epoch: 112, Loss: 0.8337, Train: 81.91%, Valid: 82.38% Test: 65.43%\n",
            "Epoch: 113, Loss: 0.8405, Train: 82.00%, Valid: 82.38% Test: 65.47%\n",
            "Epoch: 114, Loss: 0.8333, Train: 82.03%, Valid: 82.38% Test: 65.51%\n",
            "Epoch: 115, Loss: 0.8280, Train: 82.07%, Valid: 82.44% Test: 65.58%\n",
            "Epoch: 116, Loss: 0.8344, Train: 82.10%, Valid: 82.38% Test: 65.63%\n",
            "Epoch: 117, Loss: 0.8261, Train: 82.12%, Valid: 82.63% Test: 65.65%\n",
            "Epoch: 118, Loss: 0.8295, Train: 82.13%, Valid: 82.57% Test: 65.72%\n",
            "Epoch: 119, Loss: 0.8230, Train: 82.17%, Valid: 82.70% Test: 65.77%\n",
            "Epoch: 120, Loss: 0.8142, Train: 82.20%, Valid: 82.76% Test: 65.82%\n",
            "Epoch: 121, Loss: 0.8201, Train: 82.27%, Valid: 82.76% Test: 65.84%\n",
            "Epoch: 122, Loss: 0.8116, Train: 82.34%, Valid: 82.82% Test: 65.86%\n",
            "Epoch: 123, Loss: 0.8171, Train: 82.40%, Valid: 82.82% Test: 65.93%\n",
            "Epoch: 124, Loss: 0.8063, Train: 82.41%, Valid: 82.70% Test: 66.00%\n",
            "Epoch: 125, Loss: 0.8001, Train: 82.45%, Valid: 82.57% Test: 66.06%\n",
            "Epoch: 126, Loss: 0.8095, Train: 82.51%, Valid: 82.57% Test: 66.11%\n",
            "Epoch: 127, Loss: 0.8097, Train: 82.54%, Valid: 82.63% Test: 66.15%\n",
            "Epoch: 128, Loss: 0.7990, Train: 82.58%, Valid: 82.63% Test: 66.15%\n",
            "Epoch: 129, Loss: 0.7959, Train: 82.57%, Valid: 82.63% Test: 66.16%\n",
            "Epoch: 130, Loss: 0.7935, Train: 82.64%, Valid: 82.76% Test: 66.18%\n",
            "Epoch: 131, Loss: 0.8061, Train: 82.72%, Valid: 82.82% Test: 66.20%\n",
            "Epoch: 132, Loss: 0.7994, Train: 82.78%, Valid: 82.95% Test: 66.22%\n",
            "Epoch: 133, Loss: 0.7962, Train: 82.81%, Valid: 82.89% Test: 66.20%\n",
            "Epoch: 134, Loss: 0.7988, Train: 82.82%, Valid: 83.08% Test: 66.24%\n",
            "Epoch: 135, Loss: 0.7886, Train: 82.85%, Valid: 82.95% Test: 66.29%\n",
            "Epoch: 136, Loss: 0.7840, Train: 82.87%, Valid: 82.82% Test: 66.35%\n",
            "Epoch: 137, Loss: 0.7825, Train: 82.89%, Valid: 82.82% Test: 66.40%\n",
            "Epoch: 138, Loss: 0.7802, Train: 82.93%, Valid: 82.89% Test: 66.50%\n",
            "Epoch: 139, Loss: 0.7781, Train: 82.98%, Valid: 83.02% Test: 66.55%\n",
            "Epoch: 140, Loss: 0.7712, Train: 83.03%, Valid: 83.02% Test: 66.67%\n",
            "Epoch: 141, Loss: 0.7803, Train: 83.10%, Valid: 83.08% Test: 66.73%\n",
            "Epoch: 142, Loss: 0.7683, Train: 83.16%, Valid: 83.14% Test: 66.79%\n",
            "Epoch: 143, Loss: 0.7736, Train: 83.17%, Valid: 83.14% Test: 66.84%\n",
            "Epoch: 144, Loss: 0.7726, Train: 83.21%, Valid: 83.14% Test: 66.84%\n",
            "Epoch: 145, Loss: 0.7679, Train: 83.24%, Valid: 83.21% Test: 66.85%\n",
            "Epoch: 146, Loss: 0.7709, Train: 83.32%, Valid: 83.21% Test: 66.88%\n",
            "Epoch: 147, Loss: 0.7583, Train: 83.32%, Valid: 83.21% Test: 66.90%\n",
            "Epoch: 148, Loss: 0.7733, Train: 83.37%, Valid: 83.27% Test: 66.89%\n",
            "Epoch: 149, Loss: 0.7575, Train: 83.40%, Valid: 83.27% Test: 66.92%\n",
            "Epoch: 150, Loss: 0.7621, Train: 83.41%, Valid: 83.27% Test: 66.94%\n",
            "Epoch: 151, Loss: 0.7658, Train: 83.43%, Valid: 83.33% Test: 66.95%\n",
            "Epoch: 152, Loss: 0.7643, Train: 83.43%, Valid: 83.40% Test: 66.94%\n",
            "Epoch: 153, Loss: 0.7543, Train: 83.49%, Valid: 83.40% Test: 66.97%\n",
            "Epoch: 154, Loss: 0.7448, Train: 83.50%, Valid: 83.40% Test: 67.07%\n",
            "Epoch: 155, Loss: 0.7525, Train: 83.53%, Valid: 83.27% Test: 67.15%\n",
            "Epoch: 156, Loss: 0.7424, Train: 83.59%, Valid: 83.21% Test: 67.21%\n",
            "Epoch: 157, Loss: 0.7519, Train: 83.64%, Valid: 83.33% Test: 67.32%\n",
            "Epoch: 158, Loss: 0.7484, Train: 83.70%, Valid: 83.33% Test: 67.42%\n",
            "Epoch: 159, Loss: 0.7464, Train: 83.74%, Valid: 83.21% Test: 67.45%\n",
            "Epoch: 160, Loss: 0.7431, Train: 83.76%, Valid: 83.27% Test: 67.47%\n",
            "Epoch: 161, Loss: 0.7342, Train: 83.80%, Valid: 83.27% Test: 67.47%\n",
            "Epoch: 162, Loss: 0.7405, Train: 83.87%, Valid: 83.21% Test: 67.49%\n",
            "Epoch: 163, Loss: 0.7367, Train: 83.93%, Valid: 83.27% Test: 67.49%\n",
            "Epoch: 164, Loss: 0.7285, Train: 83.94%, Valid: 83.21% Test: 67.50%\n",
            "Epoch: 165, Loss: 0.7468, Train: 83.97%, Valid: 83.21% Test: 67.47%\n",
            "Epoch: 166, Loss: 0.7297, Train: 84.02%, Valid: 83.21% Test: 67.47%\n",
            "Epoch: 167, Loss: 0.7420, Train: 84.04%, Valid: 83.27% Test: 67.48%\n",
            "Epoch: 168, Loss: 0.7436, Train: 84.04%, Valid: 83.27% Test: 67.49%\n",
            "Epoch: 169, Loss: 0.7270, Train: 84.10%, Valid: 83.40% Test: 67.53%\n",
            "Epoch: 170, Loss: 0.7323, Train: 84.10%, Valid: 83.33% Test: 67.58%\n",
            "Epoch: 171, Loss: 0.7213, Train: 84.17%, Valid: 83.33% Test: 67.59%\n",
            "Epoch: 172, Loss: 0.7213, Train: 84.17%, Valid: 83.27% Test: 67.61%\n",
            "Epoch: 173, Loss: 0.7291, Train: 84.19%, Valid: 83.33% Test: 67.65%\n",
            "Epoch: 174, Loss: 0.7213, Train: 84.25%, Valid: 83.33% Test: 67.68%\n",
            "Epoch: 175, Loss: 0.7218, Train: 84.28%, Valid: 83.46% Test: 67.73%\n",
            "Epoch: 176, Loss: 0.7317, Train: 84.27%, Valid: 83.40% Test: 67.83%\n",
            "Epoch: 177, Loss: 0.7138, Train: 84.32%, Valid: 83.40% Test: 67.84%\n",
            "Epoch: 178, Loss: 0.7166, Train: 84.36%, Valid: 83.46% Test: 67.86%\n",
            "Epoch: 179, Loss: 0.7236, Train: 84.38%, Valid: 83.46% Test: 67.93%\n",
            "Epoch: 180, Loss: 0.7171, Train: 84.41%, Valid: 83.59% Test: 67.97%\n",
            "Epoch: 181, Loss: 0.7101, Train: 84.46%, Valid: 83.59% Test: 68.01%\n",
            "Epoch: 182, Loss: 0.7097, Train: 84.49%, Valid: 83.72% Test: 68.06%\n",
            "Epoch: 183, Loss: 0.7080, Train: 84.53%, Valid: 83.65% Test: 68.10%\n",
            "Epoch: 184, Loss: 0.7037, Train: 84.57%, Valid: 83.46% Test: 68.10%\n",
            "Epoch: 185, Loss: 0.7076, Train: 84.61%, Valid: 83.52% Test: 68.09%\n",
            "Epoch: 186, Loss: 0.7073, Train: 84.65%, Valid: 83.52% Test: 68.12%\n",
            "Epoch: 187, Loss: 0.7026, Train: 84.72%, Valid: 83.59% Test: 68.11%\n",
            "Epoch: 188, Loss: 0.7014, Train: 84.76%, Valid: 83.65% Test: 68.12%\n",
            "Epoch: 189, Loss: 0.7037, Train: 84.78%, Valid: 83.65% Test: 68.13%\n",
            "Epoch: 190, Loss: 0.7087, Train: 84.78%, Valid: 83.72% Test: 68.17%\n",
            "Epoch: 191, Loss: 0.6964, Train: 84.80%, Valid: 83.72% Test: 68.19%\n",
            "Epoch: 192, Loss: 0.6968, Train: 84.80%, Valid: 83.78% Test: 68.25%\n",
            "Epoch: 193, Loss: 0.6958, Train: 84.81%, Valid: 83.72% Test: 68.25%\n",
            "Epoch: 194, Loss: 0.6932, Train: 84.87%, Valid: 83.78% Test: 68.28%\n",
            "Epoch: 195, Loss: 0.6890, Train: 84.87%, Valid: 83.78% Test: 68.29%\n",
            "Epoch: 196, Loss: 0.6965, Train: 84.90%, Valid: 83.78% Test: 68.31%\n",
            "Epoch: 197, Loss: 0.6894, Train: 84.91%, Valid: 83.72% Test: 68.31%\n",
            "Epoch: 198, Loss: 0.6901, Train: 84.99%, Valid: 83.78% Test: 68.31%\n",
            "Epoch: 199, Loss: 0.6857, Train: 85.02%, Valid: 83.72% Test: 68.32%\n",
            "Epoch: 200, Loss: 0.6870, Train: 85.05%, Valid: 83.59% Test: 68.29%\n",
            "Epoch: 201, Loss: 0.6864, Train: 85.09%, Valid: 83.78% Test: 68.24%\n",
            "Epoch: 202, Loss: 0.6880, Train: 85.07%, Valid: 83.65% Test: 68.22%\n",
            "Epoch: 203, Loss: 0.6890, Train: 85.13%, Valid: 83.65% Test: 68.22%\n",
            "Epoch: 204, Loss: 0.6839, Train: 85.16%, Valid: 83.78% Test: 68.26%\n",
            "Epoch: 205, Loss: 0.6866, Train: 85.21%, Valid: 83.78% Test: 68.30%\n",
            "Epoch: 206, Loss: 0.6897, Train: 85.24%, Valid: 83.78% Test: 68.33%\n",
            "Epoch: 207, Loss: 0.6828, Train: 85.25%, Valid: 83.78% Test: 68.33%\n",
            "Epoch: 208, Loss: 0.6703, Train: 85.25%, Valid: 83.78% Test: 68.36%\n",
            "Epoch: 209, Loss: 0.6783, Train: 85.27%, Valid: 83.65% Test: 68.38%\n",
            "Epoch: 210, Loss: 0.6713, Train: 85.35%, Valid: 83.65% Test: 68.40%\n",
            "Epoch: 211, Loss: 0.6788, Train: 85.35%, Valid: 83.72% Test: 68.40%\n",
            "Epoch: 212, Loss: 0.6776, Train: 85.38%, Valid: 83.78% Test: 68.42%\n",
            "Epoch: 213, Loss: 0.6687, Train: 85.44%, Valid: 83.78% Test: 68.42%\n",
            "Epoch: 214, Loss: 0.6752, Train: 85.49%, Valid: 83.78% Test: 68.42%\n",
            "Epoch: 215, Loss: 0.6630, Train: 85.52%, Valid: 83.91% Test: 68.43%\n",
            "Epoch: 216, Loss: 0.6709, Train: 85.56%, Valid: 83.91% Test: 68.49%\n",
            "Epoch: 217, Loss: 0.6708, Train: 85.58%, Valid: 83.97% Test: 68.56%\n",
            "Epoch: 218, Loss: 0.6679, Train: 85.59%, Valid: 84.03% Test: 68.63%\n",
            "Epoch: 219, Loss: 0.6743, Train: 85.64%, Valid: 83.97% Test: 68.68%\n",
            "Epoch: 220, Loss: 0.6634, Train: 85.69%, Valid: 83.97% Test: 68.69%\n",
            "Epoch: 221, Loss: 0.6700, Train: 85.71%, Valid: 84.16% Test: 68.69%\n",
            "Epoch: 222, Loss: 0.6620, Train: 85.74%, Valid: 84.22% Test: 68.70%\n",
            "Epoch: 223, Loss: 0.6617, Train: 85.74%, Valid: 84.22% Test: 68.71%\n",
            "Epoch: 224, Loss: 0.6593, Train: 85.75%, Valid: 84.10% Test: 68.73%\n",
            "Epoch: 225, Loss: 0.6612, Train: 85.77%, Valid: 84.03% Test: 68.77%\n",
            "Epoch: 226, Loss: 0.6599, Train: 85.78%, Valid: 83.91% Test: 68.81%\n",
            "Epoch: 227, Loss: 0.6601, Train: 85.80%, Valid: 84.03% Test: 68.85%\n",
            "Epoch: 228, Loss: 0.6574, Train: 85.82%, Valid: 84.03% Test: 68.91%\n",
            "Epoch: 229, Loss: 0.6517, Train: 85.89%, Valid: 84.10% Test: 68.94%\n",
            "Epoch: 230, Loss: 0.6501, Train: 85.89%, Valid: 84.10% Test: 68.97%\n",
            "Epoch: 231, Loss: 0.6534, Train: 85.95%, Valid: 84.29% Test: 68.97%\n",
            "Epoch: 232, Loss: 0.6498, Train: 85.96%, Valid: 84.35% Test: 68.94%\n",
            "Epoch: 233, Loss: 0.6431, Train: 85.95%, Valid: 84.41% Test: 68.90%\n",
            "Epoch: 234, Loss: 0.6496, Train: 85.96%, Valid: 84.35% Test: 68.85%\n",
            "Epoch: 235, Loss: 0.6447, Train: 85.99%, Valid: 84.29% Test: 68.84%\n",
            "Epoch: 236, Loss: 0.6452, Train: 85.97%, Valid: 84.41% Test: 68.84%\n",
            "Epoch: 237, Loss: 0.6427, Train: 85.99%, Valid: 84.41% Test: 68.83%\n",
            "Epoch: 238, Loss: 0.6494, Train: 86.02%, Valid: 84.35% Test: 68.89%\n",
            "Epoch: 239, Loss: 0.6471, Train: 86.00%, Valid: 84.29% Test: 68.95%\n",
            "Epoch: 240, Loss: 0.6401, Train: 86.01%, Valid: 84.35% Test: 68.94%\n",
            "Epoch: 241, Loss: 0.6444, Train: 86.05%, Valid: 84.35% Test: 68.99%\n",
            "Epoch: 242, Loss: 0.6420, Train: 86.06%, Valid: 84.41% Test: 69.04%\n",
            "Epoch: 243, Loss: 0.6489, Train: 86.07%, Valid: 84.48% Test: 69.06%\n",
            "Epoch: 244, Loss: 0.6431, Train: 86.10%, Valid: 84.48% Test: 69.07%\n",
            "Epoch: 245, Loss: 0.6391, Train: 86.18%, Valid: 84.41% Test: 69.10%\n",
            "Epoch: 246, Loss: 0.6386, Train: 86.23%, Valid: 84.41% Test: 69.14%\n",
            "Epoch: 247, Loss: 0.6354, Train: 86.24%, Valid: 84.48% Test: 69.14%\n",
            "Epoch: 248, Loss: 0.6365, Train: 86.26%, Valid: 84.41% Test: 69.17%\n",
            "Epoch: 249, Loss: 0.6381, Train: 86.28%, Valid: 84.41% Test: 69.14%\n",
            "Epoch: 250, Loss: 0.6320, Train: 86.29%, Valid: 84.35% Test: 69.15%\n",
            "Epoch: 251, Loss: 0.6370, Train: 86.31%, Valid: 84.35% Test: 69.17%\n",
            "Epoch: 252, Loss: 0.6412, Train: 86.33%, Valid: 84.35% Test: 69.20%\n",
            "Epoch: 253, Loss: 0.6302, Train: 86.37%, Valid: 84.48% Test: 69.21%\n",
            "Epoch: 254, Loss: 0.6287, Train: 86.33%, Valid: 84.54% Test: 69.18%\n",
            "Epoch: 255, Loss: 0.6308, Train: 86.37%, Valid: 84.54% Test: 69.16%\n",
            "Epoch: 256, Loss: 0.6278, Train: 86.40%, Valid: 84.48% Test: 69.16%\n",
            "Epoch: 257, Loss: 0.6199, Train: 86.38%, Valid: 84.54% Test: 69.18%\n",
            "Epoch: 258, Loss: 0.6314, Train: 86.42%, Valid: 84.61% Test: 69.19%\n",
            "Epoch: 259, Loss: 0.6249, Train: 86.44%, Valid: 84.61% Test: 69.19%\n",
            "Epoch: 260, Loss: 0.6256, Train: 86.46%, Valid: 84.48% Test: 69.22%\n",
            "Epoch: 261, Loss: 0.6320, Train: 86.49%, Valid: 84.61% Test: 69.22%\n",
            "Epoch: 262, Loss: 0.6179, Train: 86.51%, Valid: 84.61% Test: 69.25%\n",
            "Epoch: 263, Loss: 0.6271, Train: 86.54%, Valid: 84.61% Test: 69.28%\n",
            "Epoch: 264, Loss: 0.6174, Train: 86.57%, Valid: 84.67% Test: 69.26%\n",
            "Epoch: 265, Loss: 0.6251, Train: 86.59%, Valid: 84.67% Test: 69.29%\n",
            "Epoch: 266, Loss: 0.6238, Train: 86.63%, Valid: 84.61% Test: 69.29%\n",
            "Epoch: 267, Loss: 0.6174, Train: 86.67%, Valid: 84.67% Test: 69.29%\n",
            "Epoch: 268, Loss: 0.6172, Train: 86.70%, Valid: 84.73% Test: 69.34%\n",
            "Epoch: 269, Loss: 0.6154, Train: 86.70%, Valid: 84.73% Test: 69.41%\n",
            "Epoch: 270, Loss: 0.6136, Train: 86.69%, Valid: 84.80% Test: 69.41%\n",
            "Epoch: 271, Loss: 0.6189, Train: 86.69%, Valid: 84.92% Test: 69.41%\n",
            "Epoch: 272, Loss: 0.6112, Train: 86.71%, Valid: 84.92% Test: 69.39%\n",
            "Epoch: 273, Loss: 0.6208, Train: 86.69%, Valid: 84.86% Test: 69.33%\n",
            "Epoch: 274, Loss: 0.6150, Train: 86.71%, Valid: 84.80% Test: 69.26%\n",
            "Epoch: 275, Loss: 0.6187, Train: 86.74%, Valid: 84.86% Test: 69.24%\n",
            "Epoch: 276, Loss: 0.6095, Train: 86.77%, Valid: 84.86% Test: 69.24%\n",
            "Epoch: 277, Loss: 0.6079, Train: 86.81%, Valid: 84.86% Test: 69.29%\n",
            "Epoch: 278, Loss: 0.6019, Train: 86.82%, Valid: 84.92% Test: 69.33%\n",
            "Epoch: 279, Loss: 0.6135, Train: 86.81%, Valid: 84.99% Test: 69.37%\n",
            "Epoch: 280, Loss: 0.6077, Train: 86.82%, Valid: 85.18% Test: 69.41%\n",
            "Epoch: 281, Loss: 0.6082, Train: 86.88%, Valid: 85.18% Test: 69.41%\n",
            "Epoch: 282, Loss: 0.6065, Train: 86.85%, Valid: 85.05% Test: 69.41%\n",
            "Epoch: 283, Loss: 0.6118, Train: 86.89%, Valid: 85.05% Test: 69.43%\n",
            "Epoch: 284, Loss: 0.6070, Train: 86.94%, Valid: 85.05% Test: 69.46%\n",
            "Epoch: 285, Loss: 0.6035, Train: 86.95%, Valid: 84.99% Test: 69.48%\n",
            "Epoch: 286, Loss: 0.6052, Train: 86.91%, Valid: 84.92% Test: 69.47%\n",
            "Epoch: 287, Loss: 0.6022, Train: 86.89%, Valid: 84.99% Test: 69.46%\n",
            "Epoch: 288, Loss: 0.5986, Train: 86.98%, Valid: 85.11% Test: 69.46%\n",
            "Epoch: 289, Loss: 0.5939, Train: 86.95%, Valid: 85.18% Test: 69.46%\n",
            "Epoch: 290, Loss: 0.5987, Train: 86.95%, Valid: 85.24% Test: 69.47%\n",
            "Epoch: 291, Loss: 0.5967, Train: 86.99%, Valid: 85.24% Test: 69.46%\n",
            "Epoch: 292, Loss: 0.6015, Train: 86.99%, Valid: 85.31% Test: 69.46%\n",
            "Epoch: 293, Loss: 0.6011, Train: 87.01%, Valid: 85.24% Test: 69.45%\n",
            "Epoch: 294, Loss: 0.5978, Train: 87.01%, Valid: 85.24% Test: 69.42%\n",
            "Epoch: 295, Loss: 0.5912, Train: 87.04%, Valid: 85.18% Test: 69.44%\n",
            "Epoch: 296, Loss: 0.5960, Train: 87.07%, Valid: 85.05% Test: 69.45%\n",
            "Epoch: 297, Loss: 0.5908, Train: 87.08%, Valid: 85.05% Test: 69.43%\n",
            "Epoch: 298, Loss: 0.5848, Train: 87.14%, Valid: 85.05% Test: 69.44%\n",
            "Epoch: 299, Loss: 0.5840, Train: 87.20%, Valid: 85.05% Test: 69.45%\n",
            "Epoch: 300, Loss: 0.5907, Train: 87.19%, Valid: 85.11% Test: 69.46%\n",
            "Epoch: 301, Loss: 0.5903, Train: 87.18%, Valid: 85.11% Test: 69.48%\n",
            "Epoch: 302, Loss: 0.5899, Train: 87.22%, Valid: 85.18% Test: 69.58%\n",
            "Epoch: 303, Loss: 0.5890, Train: 87.23%, Valid: 85.18% Test: 69.64%\n",
            "Epoch: 304, Loss: 0.5890, Train: 87.25%, Valid: 85.18% Test: 69.65%\n",
            "Epoch: 305, Loss: 0.5942, Train: 87.29%, Valid: 85.05% Test: 69.65%\n",
            "Epoch: 306, Loss: 0.5891, Train: 87.29%, Valid: 84.99% Test: 69.70%\n",
            "Epoch: 307, Loss: 0.5935, Train: 87.29%, Valid: 84.99% Test: 69.69%\n",
            "Epoch: 308, Loss: 0.5835, Train: 87.28%, Valid: 84.99% Test: 69.68%\n",
            "Epoch: 309, Loss: 0.5800, Train: 87.31%, Valid: 84.92% Test: 69.70%\n",
            "Epoch: 310, Loss: 0.5849, Train: 87.36%, Valid: 84.86% Test: 69.68%\n",
            "Epoch: 311, Loss: 0.5777, Train: 87.39%, Valid: 84.92% Test: 69.68%\n",
            "Epoch: 312, Loss: 0.5939, Train: 87.44%, Valid: 85.05% Test: 69.71%\n",
            "Epoch: 313, Loss: 0.5777, Train: 87.48%, Valid: 85.11% Test: 69.71%\n",
            "Epoch: 314, Loss: 0.5855, Train: 87.48%, Valid: 85.05% Test: 69.68%\n",
            "Epoch: 315, Loss: 0.5781, Train: 87.53%, Valid: 85.05% Test: 69.65%\n",
            "Epoch: 316, Loss: 0.5750, Train: 87.56%, Valid: 85.05% Test: 69.67%\n",
            "Epoch: 317, Loss: 0.5775, Train: 87.54%, Valid: 85.05% Test: 69.66%\n",
            "Epoch: 318, Loss: 0.5881, Train: 87.55%, Valid: 85.05% Test: 69.67%\n",
            "Epoch: 319, Loss: 0.5735, Train: 87.57%, Valid: 84.92% Test: 69.65%\n",
            "Epoch: 320, Loss: 0.5751, Train: 87.58%, Valid: 84.99% Test: 69.65%\n",
            "Epoch: 321, Loss: 0.5796, Train: 87.60%, Valid: 85.05% Test: 69.71%\n",
            "Epoch: 322, Loss: 0.5758, Train: 87.62%, Valid: 85.11% Test: 69.71%\n",
            "Epoch: 323, Loss: 0.5713, Train: 87.61%, Valid: 85.37% Test: 69.73%\n",
            "Epoch: 324, Loss: 0.5708, Train: 87.63%, Valid: 85.31% Test: 69.74%\n",
            "Epoch: 325, Loss: 0.5807, Train: 87.64%, Valid: 85.37% Test: 69.80%\n",
            "Epoch: 326, Loss: 0.5690, Train: 87.67%, Valid: 85.37% Test: 69.87%\n",
            "Epoch: 327, Loss: 0.5762, Train: 87.73%, Valid: 85.37% Test: 69.88%\n",
            "Epoch: 328, Loss: 0.5713, Train: 87.76%, Valid: 85.37% Test: 69.91%\n",
            "Epoch: 329, Loss: 0.5639, Train: 87.77%, Valid: 85.37% Test: 69.92%\n",
            "Epoch: 330, Loss: 0.5680, Train: 87.78%, Valid: 85.24% Test: 69.94%\n",
            "Epoch: 331, Loss: 0.5619, Train: 87.79%, Valid: 85.05% Test: 69.94%\n",
            "Epoch: 332, Loss: 0.5678, Train: 87.83%, Valid: 85.05% Test: 69.96%\n",
            "Epoch: 333, Loss: 0.5733, Train: 87.84%, Valid: 85.05% Test: 69.95%\n",
            "Epoch: 334, Loss: 0.5616, Train: 87.84%, Valid: 85.05% Test: 69.95%\n",
            "Epoch: 335, Loss: 0.5675, Train: 87.82%, Valid: 85.11% Test: 69.92%\n",
            "Epoch: 336, Loss: 0.5652, Train: 87.86%, Valid: 85.31% Test: 69.91%\n",
            "Epoch: 337, Loss: 0.5660, Train: 87.89%, Valid: 85.43% Test: 69.84%\n",
            "Epoch: 338, Loss: 0.5587, Train: 87.94%, Valid: 85.37% Test: 69.79%\n",
            "Epoch: 339, Loss: 0.5646, Train: 87.94%, Valid: 85.24% Test: 69.77%\n",
            "Epoch: 340, Loss: 0.5664, Train: 87.93%, Valid: 85.31% Test: 69.76%\n",
            "Epoch: 341, Loss: 0.5578, Train: 87.97%, Valid: 85.31% Test: 69.75%\n",
            "Epoch: 342, Loss: 0.5663, Train: 88.01%, Valid: 85.31% Test: 69.77%\n",
            "Epoch: 343, Loss: 0.5557, Train: 88.01%, Valid: 85.37% Test: 69.79%\n",
            "Epoch: 344, Loss: 0.5572, Train: 88.06%, Valid: 85.37% Test: 69.80%\n",
            "Epoch: 345, Loss: 0.5618, Train: 88.05%, Valid: 85.18% Test: 69.78%\n",
            "Epoch: 346, Loss: 0.5681, Train: 88.06%, Valid: 85.05% Test: 69.82%\n",
            "Epoch: 347, Loss: 0.5543, Train: 88.09%, Valid: 85.11% Test: 69.80%\n",
            "Epoch: 348, Loss: 0.5519, Train: 88.09%, Valid: 85.18% Test: 69.84%\n",
            "Epoch: 349, Loss: 0.5589, Train: 88.11%, Valid: 85.31% Test: 69.86%\n",
            "Epoch: 350, Loss: 0.5500, Train: 88.14%, Valid: 85.24% Test: 69.91%\n",
            "Epoch: 351, Loss: 0.5555, Train: 88.19%, Valid: 85.31% Test: 69.97%\n",
            "Epoch: 352, Loss: 0.5543, Train: 88.21%, Valid: 85.31% Test: 70.00%\n",
            "Epoch: 353, Loss: 0.5551, Train: 88.23%, Valid: 85.31% Test: 70.00%\n",
            "Epoch: 354, Loss: 0.5543, Train: 88.24%, Valid: 85.37% Test: 70.01%\n",
            "Epoch: 355, Loss: 0.5457, Train: 88.27%, Valid: 85.43% Test: 70.02%\n",
            "Epoch: 356, Loss: 0.5509, Train: 88.28%, Valid: 85.50% Test: 70.03%\n",
            "Epoch: 357, Loss: 0.5533, Train: 88.20%, Valid: 85.37% Test: 69.97%\n",
            "Epoch: 358, Loss: 0.5401, Train: 88.20%, Valid: 85.24% Test: 69.96%\n",
            "Epoch: 359, Loss: 0.5493, Train: 88.22%, Valid: 85.31% Test: 69.94%\n",
            "Epoch: 360, Loss: 0.5566, Train: 88.29%, Valid: 85.24% Test: 69.90%\n",
            "Epoch: 361, Loss: 0.5500, Train: 88.29%, Valid: 85.43% Test: 69.91%\n",
            "Epoch: 362, Loss: 0.5468, Train: 88.35%, Valid: 85.43% Test: 69.94%\n",
            "Epoch: 363, Loss: 0.5463, Train: 88.33%, Valid: 85.43% Test: 69.96%\n",
            "Epoch: 364, Loss: 0.5515, Train: 88.40%, Valid: 85.37% Test: 70.00%\n",
            "Epoch: 365, Loss: 0.5478, Train: 88.47%, Valid: 85.24% Test: 70.05%\n",
            "Epoch: 366, Loss: 0.5425, Train: 88.46%, Valid: 85.24% Test: 70.09%\n",
            "Epoch: 367, Loss: 0.5470, Train: 88.45%, Valid: 85.31% Test: 70.13%\n",
            "Epoch: 368, Loss: 0.5522, Train: 88.51%, Valid: 85.24% Test: 70.15%\n",
            "Epoch: 369, Loss: 0.5408, Train: 88.49%, Valid: 85.24% Test: 70.13%\n",
            "Epoch: 370, Loss: 0.5463, Train: 88.52%, Valid: 85.24% Test: 70.11%\n",
            "Epoch: 371, Loss: 0.5386, Train: 88.50%, Valid: 85.37% Test: 70.13%\n",
            "Epoch: 372, Loss: 0.5391, Train: 88.50%, Valid: 85.24% Test: 70.08%\n",
            "Epoch: 373, Loss: 0.5480, Train: 88.48%, Valid: 85.31% Test: 70.06%\n",
            "Epoch: 374, Loss: 0.5387, Train: 88.50%, Valid: 85.43% Test: 70.10%\n",
            "Epoch: 375, Loss: 0.5415, Train: 88.54%, Valid: 85.50% Test: 70.09%\n",
            "Epoch: 376, Loss: 0.5432, Train: 88.54%, Valid: 85.37% Test: 70.08%\n",
            "Epoch: 377, Loss: 0.5413, Train: 88.54%, Valid: 85.24% Test: 70.09%\n",
            "Epoch: 378, Loss: 0.5433, Train: 88.55%, Valid: 85.43% Test: 70.13%\n",
            "Epoch: 379, Loss: 0.5402, Train: 88.62%, Valid: 85.43% Test: 70.19%\n",
            "Epoch: 380, Loss: 0.5399, Train: 88.65%, Valid: 85.37% Test: 70.19%\n",
            "Epoch: 381, Loss: 0.5302, Train: 88.62%, Valid: 85.31% Test: 70.19%\n",
            "Epoch: 382, Loss: 0.5348, Train: 88.65%, Valid: 85.31% Test: 70.19%\n",
            "Epoch: 383, Loss: 0.5355, Train: 88.67%, Valid: 85.24% Test: 70.18%\n",
            "Epoch: 384, Loss: 0.5368, Train: 88.64%, Valid: 85.24% Test: 70.22%\n",
            "Epoch: 385, Loss: 0.5237, Train: 88.67%, Valid: 85.37% Test: 70.22%\n",
            "Epoch: 386, Loss: 0.5313, Train: 88.69%, Valid: 85.43% Test: 70.21%\n",
            "Epoch: 387, Loss: 0.5336, Train: 88.69%, Valid: 85.37% Test: 70.21%\n",
            "Epoch: 388, Loss: 0.5311, Train: 88.69%, Valid: 85.37% Test: 70.20%\n",
            "Epoch: 389, Loss: 0.5346, Train: 88.71%, Valid: 85.43% Test: 70.21%\n",
            "Epoch: 390, Loss: 0.5293, Train: 88.74%, Valid: 85.37% Test: 70.17%\n",
            "Epoch: 391, Loss: 0.5250, Train: 88.75%, Valid: 85.11% Test: 70.17%\n",
            "Epoch: 392, Loss: 0.5280, Train: 88.81%, Valid: 85.24% Test: 70.21%\n",
            "Epoch: 393, Loss: 0.5267, Train: 88.76%, Valid: 85.24% Test: 70.22%\n",
            "Epoch: 394, Loss: 0.5324, Train: 88.83%, Valid: 85.31% Test: 70.22%\n",
            "Epoch: 395, Loss: 0.5191, Train: 88.87%, Valid: 85.50% Test: 70.26%\n",
            "Epoch: 396, Loss: 0.5262, Train: 88.86%, Valid: 85.43% Test: 70.26%\n",
            "Epoch: 397, Loss: 0.5230, Train: 88.84%, Valid: 85.37% Test: 70.27%\n",
            "Epoch: 398, Loss: 0.5253, Train: 88.89%, Valid: 85.37% Test: 70.28%\n",
            "Epoch: 399, Loss: 0.5287, Train: 88.88%, Valid: 85.37% Test: 70.27%\n",
            "Epoch: 400, Loss: 0.5312, Train: 88.91%, Valid: 85.37% Test: 70.25%\n",
            "Epoch: 401, Loss: 0.5221, Train: 88.94%, Valid: 85.24% Test: 70.27%\n",
            "Epoch: 402, Loss: 0.5235, Train: 88.94%, Valid: 85.18% Test: 70.26%\n",
            "Epoch: 403, Loss: 0.5200, Train: 88.97%, Valid: 85.24% Test: 70.23%\n",
            "Epoch: 404, Loss: 0.5183, Train: 88.99%, Valid: 85.24% Test: 70.24%\n",
            "Epoch: 405, Loss: 0.5247, Train: 89.01%, Valid: 85.18% Test: 70.29%\n",
            "Epoch: 406, Loss: 0.5193, Train: 89.01%, Valid: 85.18% Test: 70.30%\n",
            "Epoch: 407, Loss: 0.5233, Train: 89.05%, Valid: 85.24% Test: 70.34%\n",
            "Epoch: 408, Loss: 0.5248, Train: 89.03%, Valid: 85.31% Test: 70.36%\n",
            "Epoch: 409, Loss: 0.5096, Train: 89.07%, Valid: 85.31% Test: 70.38%\n",
            "Epoch: 410, Loss: 0.5131, Train: 89.09%, Valid: 85.43% Test: 70.40%\n",
            "Epoch: 411, Loss: 0.5168, Train: 89.10%, Valid: 85.43% Test: 70.38%\n",
            "Epoch: 412, Loss: 0.5257, Train: 89.11%, Valid: 85.50% Test: 70.38%\n",
            "Epoch: 413, Loss: 0.5214, Train: 89.10%, Valid: 85.43% Test: 70.37%\n",
            "Epoch: 414, Loss: 0.5202, Train: 89.14%, Valid: 85.50% Test: 70.34%\n",
            "Epoch: 415, Loss: 0.5233, Train: 89.16%, Valid: 85.56% Test: 70.32%\n",
            "Epoch: 416, Loss: 0.5150, Train: 89.16%, Valid: 85.50% Test: 70.30%\n",
            "Epoch: 417, Loss: 0.5149, Train: 89.17%, Valid: 85.56% Test: 70.27%\n",
            "Epoch: 418, Loss: 0.5096, Train: 89.22%, Valid: 85.50% Test: 70.28%\n",
            "Epoch: 419, Loss: 0.5118, Train: 89.30%, Valid: 85.31% Test: 70.26%\n",
            "Epoch: 420, Loss: 0.5159, Train: 89.30%, Valid: 85.37% Test: 70.28%\n",
            "Epoch: 421, Loss: 0.5059, Train: 89.30%, Valid: 85.24% Test: 70.32%\n",
            "Epoch: 422, Loss: 0.5173, Train: 89.33%, Valid: 85.18% Test: 70.32%\n",
            "Epoch: 423, Loss: 0.5135, Train: 89.35%, Valid: 85.18% Test: 70.31%\n",
            "Epoch: 424, Loss: 0.5123, Train: 89.35%, Valid: 85.11% Test: 70.30%\n",
            "Epoch: 425, Loss: 0.5183, Train: 89.36%, Valid: 85.11% Test: 70.27%\n",
            "Epoch: 426, Loss: 0.5175, Train: 89.38%, Valid: 85.11% Test: 70.30%\n",
            "Epoch: 427, Loss: 0.5065, Train: 89.43%, Valid: 85.18% Test: 70.36%\n",
            "Epoch: 428, Loss: 0.5132, Train: 89.44%, Valid: 85.37% Test: 70.36%\n",
            "Epoch: 429, Loss: 0.5131, Train: 89.45%, Valid: 85.37% Test: 70.37%\n",
            "Epoch: 430, Loss: 0.5155, Train: 89.50%, Valid: 85.37% Test: 70.39%\n",
            "Epoch: 431, Loss: 0.5051, Train: 89.48%, Valid: 85.43% Test: 70.40%\n",
            "Epoch: 432, Loss: 0.5139, Train: 89.46%, Valid: 85.43% Test: 70.44%\n",
            "Epoch: 433, Loss: 0.5151, Train: 89.42%, Valid: 85.37% Test: 70.44%\n",
            "Epoch: 434, Loss: 0.5037, Train: 89.43%, Valid: 85.31% Test: 70.44%\n",
            "Epoch: 435, Loss: 0.5053, Train: 89.48%, Valid: 85.18% Test: 70.45%\n",
            "Epoch: 436, Loss: 0.5116, Train: 89.52%, Valid: 85.31% Test: 70.45%\n",
            "Epoch: 437, Loss: 0.4977, Train: 89.53%, Valid: 85.43% Test: 70.41%\n",
            "Epoch: 438, Loss: 0.5032, Train: 89.51%, Valid: 85.37% Test: 70.41%\n",
            "Epoch: 439, Loss: 0.5070, Train: 89.50%, Valid: 85.31% Test: 70.38%\n",
            "Epoch: 440, Loss: 0.5021, Train: 89.50%, Valid: 85.31% Test: 70.38%\n",
            "Epoch: 441, Loss: 0.5008, Train: 89.52%, Valid: 85.56% Test: 70.36%\n",
            "Epoch: 442, Loss: 0.5050, Train: 89.54%, Valid: 85.43% Test: 70.32%\n",
            "Epoch: 443, Loss: 0.5072, Train: 89.59%, Valid: 85.43% Test: 70.31%\n",
            "Epoch: 444, Loss: 0.5056, Train: 89.60%, Valid: 85.50% Test: 70.30%\n",
            "Epoch: 445, Loss: 0.5051, Train: 89.63%, Valid: 85.37% Test: 70.34%\n",
            "Epoch: 446, Loss: 0.4980, Train: 89.62%, Valid: 85.24% Test: 70.40%\n",
            "Epoch: 447, Loss: 0.4972, Train: 89.61%, Valid: 85.24% Test: 70.48%\n",
            "Epoch: 448, Loss: 0.4994, Train: 89.65%, Valid: 85.11% Test: 70.52%\n",
            "Epoch: 449, Loss: 0.4956, Train: 89.69%, Valid: 85.18% Test: 70.57%\n",
            "Epoch: 450, Loss: 0.4970, Train: 89.65%, Valid: 85.18% Test: 70.61%\n",
            "Epoch: 451, Loss: 0.4965, Train: 89.64%, Valid: 85.24% Test: 70.63%\n",
            "Epoch: 452, Loss: 0.4927, Train: 89.64%, Valid: 85.31% Test: 70.64%\n",
            "Epoch: 453, Loss: 0.4963, Train: 89.71%, Valid: 85.43% Test: 70.63%\n",
            "Epoch: 454, Loss: 0.4960, Train: 89.69%, Valid: 85.50% Test: 70.59%\n",
            "Epoch: 455, Loss: 0.4972, Train: 89.75%, Valid: 85.50% Test: 70.56%\n",
            "Epoch: 456, Loss: 0.4967, Train: 89.74%, Valid: 85.56% Test: 70.50%\n",
            "Epoch: 457, Loss: 0.5010, Train: 89.74%, Valid: 85.62% Test: 70.48%\n",
            "Epoch: 458, Loss: 0.5030, Train: 89.77%, Valid: 85.50% Test: 70.42%\n",
            "Epoch: 459, Loss: 0.4975, Train: 89.78%, Valid: 85.50% Test: 70.40%\n",
            "Epoch: 460, Loss: 0.4929, Train: 89.82%, Valid: 85.50% Test: 70.41%\n",
            "Epoch: 461, Loss: 0.4958, Train: 89.82%, Valid: 85.50% Test: 70.46%\n",
            "Epoch: 462, Loss: 0.4928, Train: 89.84%, Valid: 85.62% Test: 70.47%\n",
            "Epoch: 463, Loss: 0.4955, Train: 89.84%, Valid: 85.62% Test: 70.50%\n",
            "Epoch: 464, Loss: 0.4946, Train: 89.88%, Valid: 85.62% Test: 70.53%\n",
            "Epoch: 465, Loss: 0.4867, Train: 89.87%, Valid: 85.62% Test: 70.55%\n",
            "Epoch: 466, Loss: 0.4952, Train: 89.84%, Valid: 85.50% Test: 70.57%\n",
            "Epoch: 467, Loss: 0.4950, Train: 89.88%, Valid: 85.62% Test: 70.57%\n",
            "Epoch: 468, Loss: 0.4919, Train: 89.88%, Valid: 85.56% Test: 70.53%\n",
            "Epoch: 469, Loss: 0.5006, Train: 89.90%, Valid: 85.56% Test: 70.52%\n",
            "Epoch: 470, Loss: 0.4913, Train: 89.91%, Valid: 85.56% Test: 70.51%\n",
            "Epoch: 471, Loss: 0.4902, Train: 89.92%, Valid: 85.50% Test: 70.48%\n",
            "Epoch: 472, Loss: 0.4913, Train: 89.88%, Valid: 85.50% Test: 70.49%\n",
            "Epoch: 473, Loss: 0.4927, Train: 89.92%, Valid: 85.50% Test: 70.45%\n",
            "Epoch: 474, Loss: 0.4839, Train: 89.94%, Valid: 85.50% Test: 70.43%\n",
            "Epoch: 475, Loss: 0.4853, Train: 89.99%, Valid: 85.43% Test: 70.44%\n",
            "Epoch: 476, Loss: 0.4849, Train: 89.98%, Valid: 85.50% Test: 70.44%\n",
            "Epoch: 477, Loss: 0.4887, Train: 89.99%, Valid: 85.43% Test: 70.46%\n",
            "Epoch: 478, Loss: 0.4828, Train: 90.02%, Valid: 85.43% Test: 70.44%\n",
            "Epoch: 479, Loss: 0.4847, Train: 90.03%, Valid: 85.43% Test: 70.47%\n",
            "Epoch: 480, Loss: 0.4880, Train: 90.04%, Valid: 85.62% Test: 70.52%\n",
            "Epoch: 481, Loss: 0.4795, Train: 90.03%, Valid: 85.56% Test: 70.57%\n",
            "Epoch: 482, Loss: 0.4803, Train: 90.05%, Valid: 85.69% Test: 70.59%\n",
            "Epoch: 483, Loss: 0.4867, Train: 90.05%, Valid: 85.62% Test: 70.61%\n",
            "Epoch: 484, Loss: 0.4792, Train: 90.07%, Valid: 85.50% Test: 70.65%\n",
            "Epoch: 485, Loss: 0.4819, Train: 90.07%, Valid: 85.37% Test: 70.67%\n",
            "Epoch: 486, Loss: 0.4751, Train: 90.09%, Valid: 85.37% Test: 70.71%\n",
            "Epoch: 487, Loss: 0.4861, Train: 90.11%, Valid: 85.43% Test: 70.76%\n",
            "Epoch: 488, Loss: 0.4852, Train: 90.09%, Valid: 85.43% Test: 70.75%\n",
            "Epoch: 489, Loss: 0.4809, Train: 90.10%, Valid: 85.43% Test: 70.72%\n",
            "Epoch: 490, Loss: 0.4822, Train: 90.11%, Valid: 85.56% Test: 70.70%\n",
            "Epoch: 491, Loss: 0.4779, Train: 90.11%, Valid: 85.56% Test: 70.65%\n",
            "Epoch: 492, Loss: 0.4717, Train: 90.11%, Valid: 85.50% Test: 70.61%\n",
            "Epoch: 493, Loss: 0.4748, Train: 90.17%, Valid: 85.50% Test: 70.59%\n",
            "Epoch: 494, Loss: 0.4770, Train: 90.18%, Valid: 85.43% Test: 70.61%\n",
            "Epoch: 495, Loss: 0.4786, Train: 90.20%, Valid: 85.37% Test: 70.60%\n",
            "Epoch: 496, Loss: 0.4782, Train: 90.20%, Valid: 85.50% Test: 70.62%\n",
            "Epoch: 497, Loss: 0.4767, Train: 90.24%, Valid: 85.50% Test: 70.61%\n",
            "Epoch: 498, Loss: 0.4764, Train: 90.25%, Valid: 85.43% Test: 70.58%\n",
            "Epoch: 499, Loss: 0.4761, Train: 90.24%, Valid: 85.50% Test: 70.58%\n",
            "Epoch: 500, Loss: 0.4840, Train: 90.24%, Valid: 85.50% Test: 70.58%\n",
            "Epoch: 501, Loss: 0.4747, Train: 90.34%, Valid: 85.62% Test: 70.59%\n",
            "Epoch: 502, Loss: 0.4796, Train: 90.35%, Valid: 85.56% Test: 70.61%\n",
            "Epoch: 503, Loss: 0.4797, Train: 90.33%, Valid: 85.62% Test: 70.61%\n",
            "Epoch: 504, Loss: 0.4710, Train: 90.32%, Valid: 85.56% Test: 70.61%\n",
            "Epoch: 505, Loss: 0.4767, Train: 90.31%, Valid: 85.50% Test: 70.57%\n",
            "Epoch: 506, Loss: 0.4692, Train: 90.34%, Valid: 85.56% Test: 70.56%\n",
            "Epoch: 507, Loss: 0.4721, Train: 90.33%, Valid: 85.62% Test: 70.59%\n",
            "Epoch: 508, Loss: 0.4800, Train: 90.32%, Valid: 85.56% Test: 70.58%\n",
            "Epoch: 509, Loss: 0.4704, Train: 90.33%, Valid: 85.50% Test: 70.56%\n",
            "Epoch: 510, Loss: 0.4758, Train: 90.32%, Valid: 85.50% Test: 70.58%\n",
            "Epoch: 511, Loss: 0.4697, Train: 90.33%, Valid: 85.56% Test: 70.58%\n",
            "Epoch: 512, Loss: 0.4640, Train: 90.38%, Valid: 85.43% Test: 70.62%\n",
            "Epoch: 513, Loss: 0.4724, Train: 90.38%, Valid: 85.43% Test: 70.68%\n",
            "Epoch: 514, Loss: 0.4722, Train: 90.39%, Valid: 85.43% Test: 70.73%\n",
            "Epoch: 515, Loss: 0.4633, Train: 90.37%, Valid: 85.50% Test: 70.72%\n",
            "Epoch: 516, Loss: 0.4682, Train: 90.40%, Valid: 85.50% Test: 70.74%\n",
            "Epoch: 517, Loss: 0.4755, Train: 90.47%, Valid: 85.50% Test: 70.76%\n",
            "Epoch: 518, Loss: 0.4678, Train: 90.49%, Valid: 85.50% Test: 70.77%\n",
            "Epoch: 519, Loss: 0.4683, Train: 90.50%, Valid: 85.37% Test: 70.76%\n",
            "Epoch: 520, Loss: 0.4668, Train: 90.49%, Valid: 85.31% Test: 70.75%\n",
            "Epoch: 521, Loss: 0.4727, Train: 90.48%, Valid: 85.11% Test: 70.71%\n",
            "Epoch: 522, Loss: 0.4666, Train: 90.49%, Valid: 85.18% Test: 70.68%\n",
            "Epoch: 523, Loss: 0.4624, Train: 90.48%, Valid: 85.31% Test: 70.64%\n",
            "Epoch: 524, Loss: 0.4666, Train: 90.52%, Valid: 85.37% Test: 70.59%\n",
            "Epoch: 525, Loss: 0.4681, Train: 90.51%, Valid: 85.37% Test: 70.53%\n",
            "Epoch: 526, Loss: 0.4677, Train: 90.53%, Valid: 85.43% Test: 70.49%\n",
            "Epoch: 527, Loss: 0.4666, Train: 90.55%, Valid: 85.50% Test: 70.51%\n",
            "Epoch: 528, Loss: 0.4617, Train: 90.54%, Valid: 85.50% Test: 70.55%\n",
            "Epoch: 529, Loss: 0.4684, Train: 90.57%, Valid: 85.43% Test: 70.57%\n",
            "Epoch: 530, Loss: 0.4592, Train: 90.56%, Valid: 85.56% Test: 70.59%\n",
            "Epoch: 531, Loss: 0.4611, Train: 90.58%, Valid: 85.69% Test: 70.61%\n",
            "Epoch: 532, Loss: 0.4596, Train: 90.55%, Valid: 85.50% Test: 70.65%\n",
            "Epoch: 533, Loss: 0.4699, Train: 90.57%, Valid: 85.50% Test: 70.69%\n",
            "Epoch: 534, Loss: 0.4706, Train: 90.53%, Valid: 85.50% Test: 70.73%\n",
            "Epoch: 535, Loss: 0.4675, Train: 90.57%, Valid: 85.43% Test: 70.74%\n",
            "Epoch: 536, Loss: 0.4553, Train: 90.57%, Valid: 85.56% Test: 70.73%\n",
            "Epoch: 537, Loss: 0.4580, Train: 90.61%, Valid: 85.50% Test: 70.67%\n",
            "Epoch: 538, Loss: 0.4597, Train: 90.57%, Valid: 85.43% Test: 70.64%\n",
            "Epoch: 539, Loss: 0.4617, Train: 90.57%, Valid: 85.31% Test: 70.60%\n",
            "Epoch: 540, Loss: 0.4557, Train: 90.57%, Valid: 85.37% Test: 70.58%\n",
            "Epoch: 541, Loss: 0.4601, Train: 90.60%, Valid: 85.43% Test: 70.53%\n",
            "Epoch: 542, Loss: 0.4592, Train: 90.62%, Valid: 85.31% Test: 70.54%\n",
            "Epoch: 543, Loss: 0.4567, Train: 90.64%, Valid: 85.37% Test: 70.51%\n",
            "Epoch: 544, Loss: 0.4503, Train: 90.69%, Valid: 85.43% Test: 70.52%\n",
            "Epoch: 545, Loss: 0.4549, Train: 90.71%, Valid: 85.50% Test: 70.55%\n",
            "Epoch: 546, Loss: 0.4595, Train: 90.77%, Valid: 85.43% Test: 70.61%\n",
            "Epoch: 547, Loss: 0.4622, Train: 90.75%, Valid: 85.62% Test: 70.63%\n",
            "Epoch: 548, Loss: 0.4491, Train: 90.76%, Valid: 85.62% Test: 70.63%\n",
            "Epoch: 549, Loss: 0.4540, Train: 90.80%, Valid: 85.56% Test: 70.65%\n",
            "Epoch: 550, Loss: 0.4543, Train: 90.81%, Valid: 85.43% Test: 70.71%\n",
            "Epoch: 551, Loss: 0.4467, Train: 90.81%, Valid: 85.43% Test: 70.75%\n",
            "Epoch: 552, Loss: 0.4557, Train: 90.82%, Valid: 85.43% Test: 70.77%\n",
            "Epoch: 553, Loss: 0.4494, Train: 90.84%, Valid: 85.37% Test: 70.75%\n",
            "Epoch: 554, Loss: 0.4570, Train: 90.85%, Valid: 85.37% Test: 70.76%\n",
            "Epoch: 555, Loss: 0.4539, Train: 90.87%, Valid: 85.31% Test: 70.68%\n",
            "Epoch: 556, Loss: 0.4580, Train: 90.90%, Valid: 85.24% Test: 70.67%\n",
            "Epoch: 557, Loss: 0.4501, Train: 90.88%, Valid: 85.24% Test: 70.62%\n",
            "Epoch: 558, Loss: 0.4474, Train: 90.87%, Valid: 85.31% Test: 70.59%\n",
            "Epoch: 559, Loss: 0.4462, Train: 90.89%, Valid: 85.31% Test: 70.57%\n",
            "Epoch: 560, Loss: 0.4567, Train: 90.90%, Valid: 85.11% Test: 70.54%\n",
            "Epoch: 561, Loss: 0.4572, Train: 90.86%, Valid: 85.11% Test: 70.56%\n",
            "Epoch: 562, Loss: 0.4406, Train: 90.88%, Valid: 85.11% Test: 70.54%\n",
            "Epoch: 563, Loss: 0.4505, Train: 90.92%, Valid: 85.31% Test: 70.56%\n",
            "Epoch: 564, Loss: 0.4528, Train: 90.93%, Valid: 85.31% Test: 70.54%\n",
            "Epoch: 565, Loss: 0.4436, Train: 90.94%, Valid: 85.37% Test: 70.58%\n",
            "Epoch: 566, Loss: 0.4479, Train: 90.93%, Valid: 85.43% Test: 70.59%\n",
            "Epoch: 567, Loss: 0.4540, Train: 90.94%, Valid: 85.43% Test: 70.64%\n",
            "Epoch: 568, Loss: 0.4564, Train: 90.98%, Valid: 85.50% Test: 70.69%\n",
            "Epoch: 569, Loss: 0.4523, Train: 90.96%, Valid: 85.43% Test: 70.72%\n",
            "Epoch: 570, Loss: 0.4588, Train: 91.01%, Valid: 85.43% Test: 70.72%\n",
            "Epoch: 571, Loss: 0.4407, Train: 91.05%, Valid: 85.43% Test: 70.70%\n",
            "Epoch: 572, Loss: 0.4472, Train: 91.05%, Valid: 85.43% Test: 70.70%\n",
            "Epoch: 573, Loss: 0.4427, Train: 91.07%, Valid: 85.43% Test: 70.69%\n",
            "Epoch: 574, Loss: 0.4529, Train: 91.04%, Valid: 85.43% Test: 70.67%\n",
            "Epoch: 575, Loss: 0.4534, Train: 91.06%, Valid: 85.43% Test: 70.63%\n",
            "Epoch: 576, Loss: 0.4444, Train: 91.07%, Valid: 85.43% Test: 70.65%\n",
            "Epoch: 577, Loss: 0.4500, Train: 91.11%, Valid: 85.43% Test: 70.61%\n",
            "Epoch: 578, Loss: 0.4479, Train: 91.11%, Valid: 85.31% Test: 70.62%\n",
            "Epoch: 579, Loss: 0.4492, Train: 91.14%, Valid: 85.37% Test: 70.62%\n",
            "Epoch: 580, Loss: 0.4464, Train: 91.14%, Valid: 85.24% Test: 70.63%\n",
            "Epoch: 581, Loss: 0.4520, Train: 91.13%, Valid: 85.18% Test: 70.69%\n",
            "Epoch: 582, Loss: 0.4438, Train: 91.15%, Valid: 85.11% Test: 70.69%\n",
            "Epoch: 583, Loss: 0.4403, Train: 91.17%, Valid: 85.11% Test: 70.70%\n",
            "Epoch: 584, Loss: 0.4445, Train: 91.20%, Valid: 85.11% Test: 70.69%\n",
            "Epoch: 585, Loss: 0.4447, Train: 91.20%, Valid: 85.18% Test: 70.67%\n",
            "Epoch: 586, Loss: 0.4459, Train: 91.23%, Valid: 85.31% Test: 70.66%\n",
            "Epoch: 587, Loss: 0.4485, Train: 91.28%, Valid: 85.37% Test: 70.64%\n",
            "Epoch: 588, Loss: 0.4378, Train: 91.28%, Valid: 85.56% Test: 70.63%\n",
            "Epoch: 589, Loss: 0.4422, Train: 91.28%, Valid: 85.56% Test: 70.63%\n",
            "Epoch: 590, Loss: 0.4523, Train: 91.27%, Valid: 85.62% Test: 70.65%\n",
            "Epoch: 591, Loss: 0.4433, Train: 91.24%, Valid: 85.62% Test: 70.67%\n",
            "Epoch: 592, Loss: 0.4421, Train: 91.25%, Valid: 85.50% Test: 70.65%\n",
            "Epoch: 593, Loss: 0.4423, Train: 91.22%, Valid: 85.24% Test: 70.68%\n",
            "Epoch: 594, Loss: 0.4347, Train: 91.23%, Valid: 85.31% Test: 70.69%\n",
            "Epoch: 595, Loss: 0.4403, Train: 91.20%, Valid: 85.31% Test: 70.70%\n",
            "Epoch: 596, Loss: 0.4373, Train: 91.17%, Valid: 85.37% Test: 70.73%\n",
            "Epoch: 597, Loss: 0.4404, Train: 91.15%, Valid: 85.31% Test: 70.75%\n",
            "Epoch: 598, Loss: 0.4433, Train: 91.19%, Valid: 85.37% Test: 70.75%\n",
            "Epoch: 599, Loss: 0.4410, Train: 91.23%, Valid: 85.24% Test: 70.75%\n",
            "Epoch: 600, Loss: 0.4376, Train: 91.24%, Valid: 85.31% Test: 70.74%\n",
            "Epoch: 601, Loss: 0.4317, Train: 91.30%, Valid: 85.31% Test: 70.72%\n",
            "Epoch: 602, Loss: 0.4419, Train: 91.34%, Valid: 85.31% Test: 70.68%\n",
            "Epoch: 603, Loss: 0.4377, Train: 91.34%, Valid: 85.31% Test: 70.69%\n",
            "Epoch: 604, Loss: 0.4360, Train: 91.33%, Valid: 85.18% Test: 70.72%\n",
            "Epoch: 605, Loss: 0.4352, Train: 91.39%, Valid: 85.18% Test: 70.75%\n",
            "Epoch: 606, Loss: 0.4397, Train: 91.43%, Valid: 85.11% Test: 70.73%\n",
            "Epoch: 607, Loss: 0.4316, Train: 91.43%, Valid: 85.11% Test: 70.74%\n",
            "Epoch: 608, Loss: 0.4397, Train: 91.49%, Valid: 85.18% Test: 70.78%\n",
            "Epoch: 609, Loss: 0.4365, Train: 91.49%, Valid: 85.11% Test: 70.81%\n",
            "Epoch: 610, Loss: 0.4345, Train: 91.47%, Valid: 85.11% Test: 70.82%\n",
            "Epoch: 611, Loss: 0.4333, Train: 91.46%, Valid: 85.11% Test: 70.78%\n",
            "Epoch: 612, Loss: 0.4410, Train: 91.45%, Valid: 85.11% Test: 70.80%\n",
            "Epoch: 613, Loss: 0.4390, Train: 91.45%, Valid: 85.05% Test: 70.81%\n",
            "Epoch: 614, Loss: 0.4261, Train: 91.46%, Valid: 85.05% Test: 70.84%\n",
            "Epoch: 615, Loss: 0.4376, Train: 91.44%, Valid: 85.11% Test: 70.85%\n",
            "Epoch: 616, Loss: 0.4316, Train: 91.45%, Valid: 85.18% Test: 70.88%\n",
            "Epoch: 617, Loss: 0.4306, Train: 91.46%, Valid: 85.24% Test: 70.89%\n",
            "Epoch: 618, Loss: 0.4382, Train: 91.51%, Valid: 85.24% Test: 70.90%\n",
            "Epoch: 619, Loss: 0.4277, Train: 91.54%, Valid: 85.31% Test: 70.92%\n",
            "Epoch: 620, Loss: 0.4230, Train: 91.56%, Valid: 85.31% Test: 70.91%\n",
            "Epoch: 621, Loss: 0.4285, Train: 91.56%, Valid: 85.37% Test: 70.89%\n",
            "Epoch: 622, Loss: 0.4285, Train: 91.56%, Valid: 85.18% Test: 70.82%\n",
            "Epoch: 623, Loss: 0.4339, Train: 91.54%, Valid: 85.18% Test: 70.77%\n",
            "Epoch: 624, Loss: 0.4294, Train: 91.54%, Valid: 85.18% Test: 70.72%\n",
            "Epoch: 625, Loss: 0.4238, Train: 91.51%, Valid: 85.11% Test: 70.67%\n",
            "Epoch: 626, Loss: 0.4262, Train: 91.53%, Valid: 85.05% Test: 70.66%\n",
            "Epoch: 627, Loss: 0.4266, Train: 91.50%, Valid: 84.92% Test: 70.66%\n",
            "Epoch: 628, Loss: 0.4291, Train: 91.51%, Valid: 85.05% Test: 70.65%\n",
            "Epoch: 629, Loss: 0.4324, Train: 91.49%, Valid: 84.99% Test: 70.66%\n",
            "Epoch: 630, Loss: 0.4256, Train: 91.51%, Valid: 85.05% Test: 70.73%\n",
            "Epoch: 631, Loss: 0.4255, Train: 91.54%, Valid: 84.99% Test: 70.74%\n",
            "Epoch: 632, Loss: 0.4256, Train: 91.55%, Valid: 85.05% Test: 70.75%\n",
            "Epoch: 633, Loss: 0.4364, Train: 91.60%, Valid: 84.99% Test: 70.75%\n",
            "Epoch: 634, Loss: 0.4355, Train: 91.61%, Valid: 84.86% Test: 70.78%\n",
            "Epoch: 635, Loss: 0.4257, Train: 91.62%, Valid: 84.99% Test: 70.80%\n",
            "Epoch: 636, Loss: 0.4304, Train: 91.66%, Valid: 85.05% Test: 70.77%\n",
            "Epoch: 637, Loss: 0.4258, Train: 91.67%, Valid: 85.11% Test: 70.76%\n",
            "Epoch: 638, Loss: 0.4303, Train: 91.71%, Valid: 85.11% Test: 70.73%\n",
            "Epoch: 639, Loss: 0.4284, Train: 91.73%, Valid: 85.11% Test: 70.69%\n",
            "Epoch: 640, Loss: 0.4243, Train: 91.76%, Valid: 84.99% Test: 70.68%\n",
            "Epoch: 641, Loss: 0.4326, Train: 91.75%, Valid: 84.92% Test: 70.65%\n",
            "Epoch: 642, Loss: 0.4230, Train: 91.75%, Valid: 85.11% Test: 70.62%\n",
            "Epoch: 643, Loss: 0.4328, Train: 91.79%, Valid: 85.18% Test: 70.62%\n",
            "Epoch: 644, Loss: 0.4244, Train: 91.77%, Valid: 85.11% Test: 70.63%\n",
            "Epoch: 645, Loss: 0.4276, Train: 91.77%, Valid: 85.18% Test: 70.65%\n",
            "Epoch: 646, Loss: 0.4285, Train: 91.79%, Valid: 85.18% Test: 70.63%\n",
            "Epoch: 647, Loss: 0.4278, Train: 91.83%, Valid: 84.99% Test: 70.62%\n",
            "Epoch: 648, Loss: 0.4264, Train: 91.80%, Valid: 84.99% Test: 70.63%\n",
            "Epoch: 649, Loss: 0.4200, Train: 91.77%, Valid: 84.92% Test: 70.64%\n",
            "Epoch: 650, Loss: 0.4237, Train: 91.75%, Valid: 85.18% Test: 70.63%\n",
            "Epoch: 651, Loss: 0.4232, Train: 91.70%, Valid: 85.24% Test: 70.64%\n",
            "Epoch: 652, Loss: 0.4132, Train: 91.73%, Valid: 85.24% Test: 70.66%\n",
            "Epoch: 653, Loss: 0.4252, Train: 91.75%, Valid: 85.31% Test: 70.65%\n",
            "Epoch: 654, Loss: 0.4199, Train: 91.73%, Valid: 85.24% Test: 70.69%\n",
            "Epoch: 655, Loss: 0.4239, Train: 91.73%, Valid: 85.11% Test: 70.74%\n",
            "Epoch: 656, Loss: 0.4156, Train: 91.74%, Valid: 85.05% Test: 70.78%\n",
            "Epoch: 657, Loss: 0.4276, Train: 91.77%, Valid: 84.99% Test: 70.76%\n",
            "Epoch: 658, Loss: 0.4213, Train: 91.80%, Valid: 84.99% Test: 70.77%\n",
            "Epoch: 659, Loss: 0.4172, Train: 91.82%, Valid: 84.99% Test: 70.77%\n",
            "Epoch: 660, Loss: 0.4248, Train: 91.79%, Valid: 84.99% Test: 70.76%\n",
            "Epoch: 661, Loss: 0.4213, Train: 91.77%, Valid: 84.92% Test: 70.77%\n",
            "Epoch: 662, Loss: 0.4220, Train: 91.81%, Valid: 84.92% Test: 70.76%\n",
            "Epoch: 663, Loss: 0.4147, Train: 91.81%, Valid: 85.05% Test: 70.78%\n",
            "Epoch: 664, Loss: 0.4165, Train: 91.83%, Valid: 84.86% Test: 70.81%\n",
            "Epoch: 665, Loss: 0.4207, Train: 91.84%, Valid: 84.86% Test: 70.87%\n",
            "Epoch: 666, Loss: 0.4222, Train: 91.88%, Valid: 84.86% Test: 70.87%\n",
            "Epoch: 667, Loss: 0.4208, Train: 91.90%, Valid: 84.92% Test: 70.86%\n",
            "Epoch: 668, Loss: 0.4177, Train: 91.91%, Valid: 84.92% Test: 70.84%\n",
            "Epoch: 669, Loss: 0.4217, Train: 91.91%, Valid: 84.86% Test: 70.84%\n",
            "Epoch: 670, Loss: 0.4177, Train: 91.89%, Valid: 84.86% Test: 70.81%\n",
            "Epoch: 671, Loss: 0.4197, Train: 91.88%, Valid: 84.92% Test: 70.81%\n",
            "Epoch: 672, Loss: 0.4105, Train: 91.90%, Valid: 84.99% Test: 70.83%\n",
            "Epoch: 673, Loss: 0.4099, Train: 91.93%, Valid: 85.11% Test: 70.81%\n",
            "Epoch: 674, Loss: 0.4231, Train: 91.95%, Valid: 85.11% Test: 70.79%\n",
            "Epoch: 675, Loss: 0.4171, Train: 91.94%, Valid: 85.18% Test: 70.75%\n",
            "Epoch: 676, Loss: 0.4162, Train: 91.94%, Valid: 85.18% Test: 70.72%\n",
            "Epoch: 677, Loss: 0.4167, Train: 92.01%, Valid: 85.05% Test: 70.70%\n",
            "Epoch: 678, Loss: 0.4135, Train: 92.05%, Valid: 84.99% Test: 70.72%\n",
            "Epoch: 679, Loss: 0.4167, Train: 92.02%, Valid: 85.05% Test: 70.72%\n",
            "Epoch: 680, Loss: 0.4103, Train: 92.01%, Valid: 85.05% Test: 70.74%\n",
            "Epoch: 681, Loss: 0.4126, Train: 92.06%, Valid: 85.05% Test: 70.79%\n",
            "Epoch: 682, Loss: 0.4017, Train: 92.09%, Valid: 85.11% Test: 70.80%\n",
            "Epoch: 683, Loss: 0.4109, Train: 92.06%, Valid: 85.24% Test: 70.82%\n",
            "Epoch: 684, Loss: 0.4207, Train: 92.10%, Valid: 85.31% Test: 70.83%\n",
            "Epoch: 685, Loss: 0.4104, Train: 92.08%, Valid: 85.31% Test: 70.83%\n",
            "Epoch: 686, Loss: 0.4151, Train: 92.09%, Valid: 85.31% Test: 70.84%\n",
            "Epoch: 687, Loss: 0.4169, Train: 92.07%, Valid: 85.31% Test: 70.82%\n",
            "Epoch: 688, Loss: 0.4145, Train: 92.09%, Valid: 85.31% Test: 70.83%\n",
            "Epoch: 689, Loss: 0.4151, Train: 92.07%, Valid: 85.24% Test: 70.81%\n",
            "Epoch: 690, Loss: 0.4101, Train: 92.10%, Valid: 85.18% Test: 70.78%\n",
            "Epoch: 691, Loss: 0.4174, Train: 92.09%, Valid: 85.11% Test: 70.82%\n",
            "Epoch: 692, Loss: 0.4165, Train: 92.08%, Valid: 85.11% Test: 70.82%\n",
            "Epoch: 693, Loss: 0.4067, Train: 92.09%, Valid: 84.99% Test: 70.80%\n",
            "Epoch: 694, Loss: 0.4170, Train: 92.09%, Valid: 84.99% Test: 70.80%\n",
            "Epoch: 695, Loss: 0.4065, Train: 92.10%, Valid: 84.99% Test: 70.85%\n",
            "Epoch: 696, Loss: 0.4121, Train: 92.11%, Valid: 85.11% Test: 70.90%\n",
            "Epoch: 697, Loss: 0.4053, Train: 92.13%, Valid: 85.24% Test: 70.91%\n",
            "Epoch: 698, Loss: 0.4089, Train: 92.13%, Valid: 85.31% Test: 70.93%\n",
            "Epoch: 699, Loss: 0.4115, Train: 92.13%, Valid: 85.18% Test: 70.92%\n",
            "Epoch: 700, Loss: 0.4052, Train: 92.14%, Valid: 85.18% Test: 70.94%\n",
            "Epoch: 701, Loss: 0.4077, Train: 92.17%, Valid: 85.24% Test: 70.92%\n",
            "Epoch: 702, Loss: 0.4138, Train: 92.22%, Valid: 85.31% Test: 70.91%\n",
            "Epoch: 703, Loss: 0.4047, Train: 92.23%, Valid: 85.18% Test: 70.91%\n",
            "Epoch: 704, Loss: 0.4097, Train: 92.25%, Valid: 85.05% Test: 70.90%\n",
            "Epoch: 705, Loss: 0.4131, Train: 92.25%, Valid: 84.99% Test: 70.87%\n",
            "Epoch: 706, Loss: 0.4074, Train: 92.28%, Valid: 85.11% Test: 70.82%\n",
            "Epoch: 707, Loss: 0.4099, Train: 92.24%, Valid: 85.11% Test: 70.79%\n",
            "Epoch: 708, Loss: 0.4079, Train: 92.24%, Valid: 85.18% Test: 70.79%\n",
            "Epoch: 709, Loss: 0.4099, Train: 92.22%, Valid: 85.18% Test: 70.78%\n",
            "Epoch: 710, Loss: 0.4060, Train: 92.23%, Valid: 85.31% Test: 70.80%\n",
            "Epoch: 711, Loss: 0.4025, Train: 92.21%, Valid: 85.37% Test: 70.80%\n",
            "Epoch: 712, Loss: 0.4065, Train: 92.19%, Valid: 85.31% Test: 70.85%\n",
            "Epoch: 713, Loss: 0.4040, Train: 92.24%, Valid: 85.24% Test: 70.87%\n",
            "Epoch: 714, Loss: 0.3969, Train: 92.23%, Valid: 85.18% Test: 70.95%\n",
            "Epoch: 715, Loss: 0.4043, Train: 92.22%, Valid: 85.24% Test: 70.98%\n",
            "Epoch: 716, Loss: 0.4073, Train: 92.26%, Valid: 85.11% Test: 70.96%\n",
            "Epoch: 717, Loss: 0.4091, Train: 92.26%, Valid: 85.18% Test: 70.95%\n",
            "Epoch: 718, Loss: 0.4023, Train: 92.26%, Valid: 85.05% Test: 70.94%\n",
            "Epoch: 719, Loss: 0.3989, Train: 92.25%, Valid: 85.11% Test: 70.95%\n",
            "Epoch: 720, Loss: 0.4002, Train: 92.24%, Valid: 85.11% Test: 70.92%\n",
            "Epoch: 721, Loss: 0.4051, Train: 92.26%, Valid: 84.99% Test: 70.91%\n",
            "Epoch: 722, Loss: 0.3990, Train: 92.27%, Valid: 84.92% Test: 70.92%\n",
            "Epoch: 723, Loss: 0.3968, Train: 92.32%, Valid: 84.86% Test: 70.92%\n",
            "Epoch: 724, Loss: 0.4062, Train: 92.30%, Valid: 84.86% Test: 70.90%\n",
            "Epoch: 725, Loss: 0.3985, Train: 92.33%, Valid: 84.99% Test: 70.88%\n",
            "Epoch: 726, Loss: 0.3961, Train: 92.35%, Valid: 84.92% Test: 70.83%\n",
            "Epoch: 727, Loss: 0.4008, Train: 92.32%, Valid: 85.05% Test: 70.83%\n",
            "Epoch: 728, Loss: 0.4021, Train: 92.34%, Valid: 84.99% Test: 70.83%\n",
            "Epoch: 729, Loss: 0.4050, Train: 92.34%, Valid: 85.18% Test: 70.82%\n",
            "Epoch: 730, Loss: 0.3985, Train: 92.32%, Valid: 85.05% Test: 70.85%\n",
            "Epoch: 731, Loss: 0.3964, Train: 92.34%, Valid: 84.86% Test: 70.85%\n",
            "Epoch: 732, Loss: 0.3910, Train: 92.34%, Valid: 84.86% Test: 70.88%\n",
            "Epoch: 733, Loss: 0.4035, Train: 92.34%, Valid: 84.92% Test: 70.90%\n",
            "Epoch: 734, Loss: 0.4018, Train: 92.36%, Valid: 84.86% Test: 70.92%\n",
            "Epoch: 735, Loss: 0.3956, Train: 92.36%, Valid: 84.92% Test: 70.92%\n",
            "Epoch: 736, Loss: 0.4024, Train: 92.35%, Valid: 84.92% Test: 70.91%\n",
            "Epoch: 737, Loss: 0.3984, Train: 92.37%, Valid: 84.99% Test: 70.90%\n",
            "Epoch: 738, Loss: 0.3929, Train: 92.39%, Valid: 84.99% Test: 70.92%\n",
            "Epoch: 739, Loss: 0.4019, Train: 92.40%, Valid: 84.86% Test: 70.87%\n",
            "Epoch: 740, Loss: 0.4014, Train: 92.41%, Valid: 84.86% Test: 70.88%\n",
            "Epoch: 741, Loss: 0.4016, Train: 92.39%, Valid: 84.86% Test: 70.81%\n",
            "Epoch: 742, Loss: 0.3962, Train: 92.41%, Valid: 84.86% Test: 70.77%\n",
            "Epoch: 743, Loss: 0.3977, Train: 92.44%, Valid: 84.92% Test: 70.75%\n",
            "Epoch: 744, Loss: 0.3997, Train: 92.49%, Valid: 84.99% Test: 70.76%\n",
            "Epoch: 745, Loss: 0.4088, Train: 92.49%, Valid: 84.92% Test: 70.78%\n",
            "Epoch: 746, Loss: 0.3997, Train: 92.50%, Valid: 84.92% Test: 70.79%\n",
            "Epoch: 747, Loss: 0.3920, Train: 92.52%, Valid: 84.92% Test: 70.81%\n",
            "Epoch: 748, Loss: 0.3934, Train: 92.53%, Valid: 84.99% Test: 70.81%\n",
            "Epoch: 749, Loss: 0.3934, Train: 92.52%, Valid: 85.05% Test: 70.85%\n",
            "Epoch: 750, Loss: 0.3973, Train: 92.49%, Valid: 85.05% Test: 70.90%\n",
            "Epoch: 751, Loss: 0.3951, Train: 92.49%, Valid: 85.05% Test: 70.93%\n",
            "Epoch: 752, Loss: 0.3920, Train: 92.51%, Valid: 85.05% Test: 70.92%\n",
            "Epoch: 753, Loss: 0.3923, Train: 92.53%, Valid: 85.05% Test: 70.90%\n",
            "Epoch: 754, Loss: 0.3957, Train: 92.51%, Valid: 84.99% Test: 70.88%\n",
            "Epoch: 755, Loss: 0.3972, Train: 92.50%, Valid: 84.99% Test: 70.79%\n",
            "Epoch: 756, Loss: 0.3945, Train: 92.48%, Valid: 84.92% Test: 70.75%\n",
            "Epoch: 757, Loss: 0.3952, Train: 92.47%, Valid: 84.86% Test: 70.73%\n",
            "Epoch: 758, Loss: 0.3918, Train: 92.49%, Valid: 84.80% Test: 70.72%\n",
            "Epoch: 759, Loss: 0.3918, Train: 92.51%, Valid: 84.92% Test: 70.75%\n",
            "Epoch: 760, Loss: 0.3919, Train: 92.51%, Valid: 84.99% Test: 70.76%\n",
            "Epoch: 761, Loss: 0.3945, Train: 92.58%, Valid: 84.99% Test: 70.84%\n",
            "Epoch: 762, Loss: 0.3911, Train: 92.64%, Valid: 84.86% Test: 70.89%\n",
            "Epoch: 763, Loss: 0.3867, Train: 92.62%, Valid: 84.80% Test: 70.95%\n",
            "Epoch: 764, Loss: 0.3918, Train: 92.61%, Valid: 84.80% Test: 71.01%\n",
            "Epoch: 765, Loss: 0.3928, Train: 92.61%, Valid: 84.73% Test: 71.05%\n",
            "Epoch: 766, Loss: 0.3886, Train: 92.64%, Valid: 84.73% Test: 71.05%\n",
            "Epoch: 767, Loss: 0.3887, Train: 92.62%, Valid: 84.80% Test: 71.06%\n",
            "Epoch: 768, Loss: 0.3902, Train: 92.66%, Valid: 84.80% Test: 71.02%\n",
            "Epoch: 769, Loss: 0.4001, Train: 92.66%, Valid: 84.92% Test: 71.03%\n",
            "Epoch: 770, Loss: 0.3891, Train: 92.66%, Valid: 85.05% Test: 70.95%\n",
            "Epoch: 771, Loss: 0.3939, Train: 92.68%, Valid: 85.05% Test: 70.94%\n",
            "Epoch: 772, Loss: 0.3922, Train: 92.72%, Valid: 85.18% Test: 70.85%\n",
            "Epoch: 773, Loss: 0.3947, Train: 92.70%, Valid: 85.18% Test: 70.81%\n",
            "Epoch: 774, Loss: 0.3866, Train: 92.73%, Valid: 85.24% Test: 70.77%\n",
            "Epoch: 775, Loss: 0.3854, Train: 92.75%, Valid: 85.05% Test: 70.77%\n",
            "Epoch: 776, Loss: 0.3860, Train: 92.74%, Valid: 84.92% Test: 70.78%\n",
            "Epoch: 777, Loss: 0.3947, Train: 92.72%, Valid: 84.80% Test: 70.79%\n",
            "Epoch: 778, Loss: 0.3920, Train: 92.72%, Valid: 84.80% Test: 70.81%\n",
            "Epoch: 779, Loss: 0.3918, Train: 92.75%, Valid: 84.67% Test: 70.81%\n",
            "Epoch: 780, Loss: 0.3869, Train: 92.75%, Valid: 84.67% Test: 70.85%\n",
            "Epoch: 781, Loss: 0.3912, Train: 92.76%, Valid: 84.61% Test: 70.92%\n",
            "Epoch: 782, Loss: 0.3838, Train: 92.77%, Valid: 84.61% Test: 70.99%\n",
            "Epoch: 783, Loss: 0.3840, Train: 92.77%, Valid: 84.67% Test: 71.01%\n",
            "Epoch: 784, Loss: 0.3878, Train: 92.74%, Valid: 84.67% Test: 71.03%\n",
            "Epoch: 785, Loss: 0.3932, Train: 92.71%, Valid: 84.67% Test: 70.99%\n",
            "Epoch: 786, Loss: 0.3835, Train: 92.71%, Valid: 84.67% Test: 71.01%\n",
            "Epoch: 787, Loss: 0.3871, Train: 92.73%, Valid: 84.61% Test: 70.96%\n",
            "Epoch: 788, Loss: 0.3835, Train: 92.75%, Valid: 84.67% Test: 70.91%\n",
            "Epoch: 789, Loss: 0.3807, Train: 92.77%, Valid: 84.86% Test: 70.89%\n",
            "Epoch: 790, Loss: 0.3893, Train: 92.79%, Valid: 84.92% Test: 70.85%\n",
            "Epoch: 791, Loss: 0.3876, Train: 92.83%, Valid: 84.99% Test: 70.80%\n",
            "Epoch: 792, Loss: 0.3866, Train: 92.81%, Valid: 84.99% Test: 70.77%\n",
            "Epoch: 793, Loss: 0.3864, Train: 92.85%, Valid: 84.92% Test: 70.73%\n",
            "Epoch: 794, Loss: 0.3891, Train: 92.84%, Valid: 84.92% Test: 70.74%\n",
            "Epoch: 795, Loss: 0.3782, Train: 92.81%, Valid: 84.99% Test: 70.74%\n",
            "Epoch: 796, Loss: 0.3865, Train: 92.81%, Valid: 84.92% Test: 70.74%\n",
            "Epoch: 797, Loss: 0.3880, Train: 92.82%, Valid: 84.80% Test: 70.75%\n",
            "Epoch: 798, Loss: 0.3775, Train: 92.84%, Valid: 84.80% Test: 70.77%\n",
            "Epoch: 799, Loss: 0.3807, Train: 92.87%, Valid: 84.86% Test: 70.87%\n",
            "Epoch: 800, Loss: 0.3803, Train: 92.85%, Valid: 84.80% Test: 70.93%\n",
            "Epoch: 801, Loss: 0.3879, Train: 92.89%, Valid: 84.99% Test: 70.95%\n",
            "Epoch: 802, Loss: 0.3886, Train: 92.91%, Valid: 85.05% Test: 70.97%\n",
            "Epoch: 803, Loss: 0.3894, Train: 92.94%, Valid: 85.05% Test: 70.96%\n",
            "Epoch: 804, Loss: 0.3815, Train: 92.96%, Valid: 85.05% Test: 70.95%\n",
            "Epoch: 805, Loss: 0.3814, Train: 92.92%, Valid: 85.05% Test: 70.95%\n",
            "Epoch: 806, Loss: 0.3810, Train: 92.92%, Valid: 85.05% Test: 70.91%\n",
            "Epoch: 807, Loss: 0.3798, Train: 92.94%, Valid: 84.92% Test: 70.87%\n",
            "Epoch: 808, Loss: 0.3815, Train: 92.99%, Valid: 84.92% Test: 70.84%\n",
            "Epoch: 809, Loss: 0.3849, Train: 93.02%, Valid: 84.92% Test: 70.80%\n",
            "Epoch: 810, Loss: 0.3773, Train: 93.01%, Valid: 84.99% Test: 70.76%\n",
            "Epoch: 811, Loss: 0.3802, Train: 93.04%, Valid: 84.92% Test: 70.77%\n",
            "Epoch: 812, Loss: 0.3813, Train: 93.04%, Valid: 84.92% Test: 70.80%\n",
            "Epoch: 813, Loss: 0.3838, Train: 93.04%, Valid: 84.86% Test: 70.81%\n",
            "Epoch: 814, Loss: 0.3806, Train: 93.04%, Valid: 84.86% Test: 70.85%\n",
            "Epoch: 815, Loss: 0.3786, Train: 93.02%, Valid: 84.92% Test: 70.85%\n",
            "Epoch: 816, Loss: 0.3755, Train: 93.00%, Valid: 84.86% Test: 70.86%\n",
            "Epoch: 817, Loss: 0.3832, Train: 93.02%, Valid: 84.99% Test: 70.88%\n",
            "Epoch: 818, Loss: 0.3834, Train: 93.08%, Valid: 84.99% Test: 70.91%\n",
            "Epoch: 819, Loss: 0.3757, Train: 93.10%, Valid: 85.05% Test: 70.95%\n",
            "Epoch: 820, Loss: 0.3717, Train: 93.16%, Valid: 85.11% Test: 70.99%\n",
            "Epoch: 821, Loss: 0.3711, Train: 93.15%, Valid: 85.05% Test: 71.01%\n",
            "Epoch: 822, Loss: 0.3814, Train: 93.12%, Valid: 85.05% Test: 71.02%\n",
            "Epoch: 823, Loss: 0.3767, Train: 93.13%, Valid: 85.05% Test: 71.01%\n",
            "Epoch: 824, Loss: 0.3738, Train: 93.14%, Valid: 85.24% Test: 71.01%\n",
            "Epoch: 825, Loss: 0.3842, Train: 93.11%, Valid: 85.31% Test: 70.99%\n",
            "Epoch: 826, Loss: 0.3764, Train: 93.13%, Valid: 85.11% Test: 70.92%\n",
            "Epoch: 827, Loss: 0.3776, Train: 93.13%, Valid: 84.99% Test: 70.90%\n",
            "Epoch: 828, Loss: 0.3816, Train: 93.18%, Valid: 84.99% Test: 70.87%\n",
            "Epoch: 829, Loss: 0.3831, Train: 93.15%, Valid: 85.11% Test: 70.83%\n",
            "Epoch: 830, Loss: 0.3724, Train: 93.13%, Valid: 85.05% Test: 70.80%\n",
            "Epoch: 831, Loss: 0.3723, Train: 93.14%, Valid: 85.05% Test: 70.76%\n",
            "Epoch: 832, Loss: 0.3760, Train: 93.14%, Valid: 84.99% Test: 70.72%\n",
            "Epoch: 833, Loss: 0.3700, Train: 93.17%, Valid: 84.99% Test: 70.70%\n",
            "Epoch: 834, Loss: 0.3769, Train: 93.17%, Valid: 84.92% Test: 70.71%\n",
            "Epoch: 835, Loss: 0.3767, Train: 93.19%, Valid: 84.99% Test: 70.74%\n",
            "Epoch: 836, Loss: 0.3733, Train: 93.21%, Valid: 84.99% Test: 70.80%\n",
            "Epoch: 837, Loss: 0.3759, Train: 93.23%, Valid: 84.92% Test: 70.81%\n",
            "Epoch: 838, Loss: 0.3772, Train: 93.23%, Valid: 84.92% Test: 70.80%\n",
            "Epoch: 839, Loss: 0.3771, Train: 93.26%, Valid: 84.86% Test: 70.85%\n",
            "Epoch: 840, Loss: 0.3732, Train: 93.28%, Valid: 84.86% Test: 70.90%\n",
            "Epoch: 841, Loss: 0.3766, Train: 93.30%, Valid: 84.86% Test: 70.92%\n",
            "Epoch: 842, Loss: 0.3673, Train: 93.30%, Valid: 84.99% Test: 70.94%\n",
            "Epoch: 843, Loss: 0.3741, Train: 93.24%, Valid: 85.24% Test: 70.96%\n",
            "Epoch: 844, Loss: 0.3746, Train: 93.26%, Valid: 85.31% Test: 70.93%\n",
            "Epoch: 845, Loss: 0.3753, Train: 93.28%, Valid: 85.24% Test: 70.91%\n",
            "Epoch: 846, Loss: 0.3788, Train: 93.26%, Valid: 85.18% Test: 70.87%\n",
            "Epoch: 847, Loss: 0.3643, Train: 93.27%, Valid: 84.99% Test: 70.83%\n",
            "Epoch: 848, Loss: 0.3735, Train: 93.21%, Valid: 84.92% Test: 70.79%\n",
            "Epoch: 849, Loss: 0.3728, Train: 93.26%, Valid: 84.86% Test: 70.78%\n",
            "Epoch: 850, Loss: 0.3742, Train: 93.30%, Valid: 84.86% Test: 70.78%\n",
            "Epoch: 851, Loss: 0.3757, Train: 93.31%, Valid: 84.92% Test: 70.79%\n",
            "Epoch: 852, Loss: 0.3684, Train: 93.32%, Valid: 84.99% Test: 70.80%\n",
            "Epoch: 853, Loss: 0.3746, Train: 93.33%, Valid: 84.92% Test: 70.83%\n",
            "Epoch: 854, Loss: 0.3732, Train: 93.34%, Valid: 84.92% Test: 70.85%\n",
            "Epoch: 855, Loss: 0.3743, Train: 93.36%, Valid: 85.05% Test: 70.85%\n",
            "Epoch: 856, Loss: 0.3695, Train: 93.35%, Valid: 85.05% Test: 70.89%\n",
            "Epoch: 857, Loss: 0.3663, Train: 93.38%, Valid: 85.11% Test: 70.90%\n",
            "Epoch: 858, Loss: 0.3754, Train: 93.33%, Valid: 84.99% Test: 70.92%\n",
            "Epoch: 859, Loss: 0.3673, Train: 93.34%, Valid: 84.99% Test: 70.92%\n",
            "Epoch: 860, Loss: 0.3697, Train: 93.32%, Valid: 84.92% Test: 70.86%\n",
            "Epoch: 861, Loss: 0.3743, Train: 93.34%, Valid: 84.86% Test: 70.88%\n",
            "Epoch: 862, Loss: 0.3690, Train: 93.32%, Valid: 84.80% Test: 70.88%\n",
            "Epoch: 863, Loss: 0.3721, Train: 93.32%, Valid: 84.86% Test: 70.87%\n",
            "Epoch: 864, Loss: 0.3725, Train: 93.33%, Valid: 84.92% Test: 70.86%\n",
            "Epoch: 865, Loss: 0.3753, Train: 93.34%, Valid: 84.92% Test: 70.85%\n",
            "Epoch: 866, Loss: 0.3689, Train: 93.34%, Valid: 84.92% Test: 70.84%\n",
            "Epoch: 867, Loss: 0.3713, Train: 93.36%, Valid: 84.92% Test: 70.80%\n",
            "Epoch: 868, Loss: 0.3695, Train: 93.35%, Valid: 84.92% Test: 70.81%\n",
            "Epoch: 869, Loss: 0.3697, Train: 93.37%, Valid: 84.92% Test: 70.82%\n",
            "Epoch: 870, Loss: 0.3619, Train: 93.40%, Valid: 84.86% Test: 70.83%\n",
            "Epoch: 871, Loss: 0.3701, Train: 93.45%, Valid: 84.86% Test: 70.86%\n",
            "Epoch: 872, Loss: 0.3669, Train: 93.44%, Valid: 84.86% Test: 70.93%\n",
            "Epoch: 873, Loss: 0.3659, Train: 93.47%, Valid: 84.92% Test: 70.97%\n",
            "Epoch: 874, Loss: 0.3626, Train: 93.50%, Valid: 84.92% Test: 70.99%\n",
            "Epoch: 875, Loss: 0.3673, Train: 93.51%, Valid: 84.86% Test: 71.00%\n",
            "Epoch: 876, Loss: 0.3708, Train: 93.53%, Valid: 84.86% Test: 71.02%\n",
            "Epoch: 877, Loss: 0.3749, Train: 93.53%, Valid: 84.86% Test: 71.05%\n",
            "Epoch: 878, Loss: 0.3564, Train: 93.55%, Valid: 84.80% Test: 71.05%\n",
            "Epoch: 879, Loss: 0.3743, Train: 93.52%, Valid: 84.86% Test: 71.07%\n",
            "Epoch: 880, Loss: 0.3649, Train: 93.50%, Valid: 84.80% Test: 71.06%\n",
            "Epoch: 881, Loss: 0.3629, Train: 93.53%, Valid: 84.80% Test: 71.05%\n",
            "Epoch: 882, Loss: 0.3689, Train: 93.49%, Valid: 84.86% Test: 71.08%\n",
            "Epoch: 883, Loss: 0.3676, Train: 93.45%, Valid: 84.92% Test: 71.05%\n",
            "Epoch: 884, Loss: 0.3663, Train: 93.49%, Valid: 85.05% Test: 71.03%\n",
            "Epoch: 885, Loss: 0.3630, Train: 93.54%, Valid: 85.05% Test: 71.02%\n",
            "Epoch: 886, Loss: 0.3665, Train: 93.51%, Valid: 85.05% Test: 71.02%\n",
            "Epoch: 887, Loss: 0.3624, Train: 93.53%, Valid: 84.92% Test: 71.01%\n",
            "Epoch: 888, Loss: 0.3630, Train: 93.52%, Valid: 84.99% Test: 71.03%\n",
            "Epoch: 889, Loss: 0.3647, Train: 93.53%, Valid: 84.99% Test: 71.07%\n",
            "Epoch: 890, Loss: 0.3673, Train: 93.51%, Valid: 84.86% Test: 71.07%\n",
            "Epoch: 891, Loss: 0.3592, Train: 93.55%, Valid: 84.99% Test: 71.03%\n",
            "Epoch: 892, Loss: 0.3558, Train: 93.51%, Valid: 84.99% Test: 71.03%\n",
            "Epoch: 893, Loss: 0.3571, Train: 93.51%, Valid: 85.05% Test: 70.97%\n",
            "Epoch: 894, Loss: 0.3696, Train: 93.53%, Valid: 85.05% Test: 70.98%\n",
            "Epoch: 895, Loss: 0.3664, Train: 93.58%, Valid: 85.05% Test: 70.94%\n",
            "Epoch: 896, Loss: 0.3649, Train: 93.58%, Valid: 85.05% Test: 70.92%\n",
            "Epoch: 897, Loss: 0.3637, Train: 93.62%, Valid: 85.05% Test: 70.90%\n",
            "Epoch: 898, Loss: 0.3635, Train: 93.62%, Valid: 85.05% Test: 70.93%\n",
            "Epoch: 899, Loss: 0.3615, Train: 93.66%, Valid: 85.11% Test: 70.91%\n",
            "Epoch: 900, Loss: 0.3603, Train: 93.67%, Valid: 85.11% Test: 70.84%\n",
            "Epoch: 901, Loss: 0.3644, Train: 93.67%, Valid: 85.05% Test: 70.80%\n",
            "Epoch: 902, Loss: 0.3664, Train: 93.66%, Valid: 84.92% Test: 70.79%\n",
            "Epoch: 903, Loss: 0.3709, Train: 93.66%, Valid: 84.92% Test: 70.81%\n",
            "Epoch: 904, Loss: 0.3644, Train: 93.65%, Valid: 84.92% Test: 70.81%\n",
            "Epoch: 905, Loss: 0.3649, Train: 93.67%, Valid: 84.92% Test: 70.83%\n",
            "Epoch: 906, Loss: 0.3620, Train: 93.66%, Valid: 84.92% Test: 70.88%\n",
            "Epoch: 907, Loss: 0.3637, Train: 93.68%, Valid: 84.99% Test: 70.89%\n",
            "Epoch: 908, Loss: 0.3550, Train: 93.70%, Valid: 84.99% Test: 70.89%\n",
            "Epoch: 909, Loss: 0.3574, Train: 93.70%, Valid: 84.86% Test: 70.88%\n",
            "Epoch: 910, Loss: 0.3679, Train: 93.70%, Valid: 84.80% Test: 70.92%\n",
            "Epoch: 911, Loss: 0.3642, Train: 93.69%, Valid: 84.80% Test: 70.94%\n",
            "Epoch: 912, Loss: 0.3542, Train: 93.70%, Valid: 84.67% Test: 70.96%\n",
            "Epoch: 913, Loss: 0.3523, Train: 93.77%, Valid: 84.73% Test: 70.97%\n",
            "Epoch: 914, Loss: 0.3580, Train: 93.75%, Valid: 84.86% Test: 70.98%\n",
            "Epoch: 915, Loss: 0.3657, Train: 93.75%, Valid: 84.92% Test: 70.99%\n",
            "Epoch: 916, Loss: 0.3596, Train: 93.78%, Valid: 84.86% Test: 70.97%\n",
            "Epoch: 917, Loss: 0.3588, Train: 93.80%, Valid: 84.86% Test: 70.97%\n",
            "Epoch: 918, Loss: 0.3633, Train: 93.79%, Valid: 84.80% Test: 71.00%\n",
            "Epoch: 919, Loss: 0.3602, Train: 93.80%, Valid: 84.73% Test: 71.01%\n",
            "Epoch: 920, Loss: 0.3505, Train: 93.81%, Valid: 84.80% Test: 71.02%\n",
            "Epoch: 921, Loss: 0.3632, Train: 93.86%, Valid: 84.80% Test: 71.02%\n",
            "Epoch: 922, Loss: 0.3660, Train: 93.90%, Valid: 84.80% Test: 70.99%\n",
            "Epoch: 923, Loss: 0.3519, Train: 93.89%, Valid: 84.67% Test: 71.02%\n",
            "Epoch: 924, Loss: 0.3517, Train: 93.91%, Valid: 84.61% Test: 71.00%\n",
            "Epoch: 925, Loss: 0.3604, Train: 93.93%, Valid: 84.61% Test: 70.95%\n",
            "Epoch: 926, Loss: 0.3501, Train: 93.94%, Valid: 84.67% Test: 70.93%\n",
            "Epoch: 927, Loss: 0.3629, Train: 93.94%, Valid: 84.80% Test: 70.94%\n",
            "Epoch: 928, Loss: 0.3588, Train: 93.91%, Valid: 84.80% Test: 70.96%\n",
            "Epoch: 929, Loss: 0.3601, Train: 93.92%, Valid: 84.80% Test: 70.94%\n",
            "Epoch: 930, Loss: 0.3591, Train: 93.94%, Valid: 84.80% Test: 70.94%\n",
            "Epoch: 931, Loss: 0.3582, Train: 93.91%, Valid: 84.99% Test: 70.91%\n",
            "Epoch: 932, Loss: 0.3578, Train: 93.89%, Valid: 84.99% Test: 70.94%\n",
            "Epoch: 933, Loss: 0.3535, Train: 93.89%, Valid: 84.99% Test: 70.97%\n",
            "Epoch: 934, Loss: 0.3595, Train: 93.87%, Valid: 84.92% Test: 70.97%\n",
            "Epoch: 935, Loss: 0.3500, Train: 93.90%, Valid: 84.92% Test: 70.98%\n",
            "Epoch: 936, Loss: 0.3541, Train: 93.89%, Valid: 84.86% Test: 70.94%\n",
            "Epoch: 937, Loss: 0.3512, Train: 93.95%, Valid: 84.92% Test: 70.93%\n",
            "Epoch: 938, Loss: 0.3545, Train: 93.98%, Valid: 84.86% Test: 70.90%\n",
            "Epoch: 939, Loss: 0.3547, Train: 94.00%, Valid: 84.86% Test: 70.87%\n",
            "Epoch: 940, Loss: 0.3542, Train: 93.97%, Valid: 84.86% Test: 70.87%\n",
            "Epoch: 941, Loss: 0.3568, Train: 94.00%, Valid: 84.86% Test: 70.83%\n",
            "Epoch: 942, Loss: 0.3580, Train: 94.00%, Valid: 84.86% Test: 70.79%\n",
            "Epoch: 943, Loss: 0.3481, Train: 94.00%, Valid: 84.86% Test: 70.79%\n",
            "Epoch: 944, Loss: 0.3478, Train: 94.01%, Valid: 84.92% Test: 70.77%\n",
            "Epoch: 945, Loss: 0.3538, Train: 93.98%, Valid: 84.86% Test: 70.78%\n",
            "Epoch: 946, Loss: 0.3544, Train: 94.03%, Valid: 84.99% Test: 70.79%\n",
            "Epoch: 947, Loss: 0.3466, Train: 94.05%, Valid: 84.99% Test: 70.79%\n",
            "Epoch: 948, Loss: 0.3497, Train: 94.09%, Valid: 84.92% Test: 70.84%\n",
            "Epoch: 949, Loss: 0.3585, Train: 94.11%, Valid: 85.05% Test: 70.90%\n",
            "Epoch: 950, Loss: 0.3512, Train: 94.11%, Valid: 85.05% Test: 70.97%\n",
            "Epoch: 951, Loss: 0.3494, Train: 94.08%, Valid: 85.05% Test: 70.98%\n",
            "Epoch: 952, Loss: 0.3497, Train: 94.06%, Valid: 85.05% Test: 71.05%\n",
            "Epoch: 953, Loss: 0.3522, Train: 94.06%, Valid: 85.11% Test: 71.06%\n",
            "Epoch: 954, Loss: 0.3524, Train: 94.04%, Valid: 85.05% Test: 71.06%\n",
            "Epoch: 955, Loss: 0.3552, Train: 94.03%, Valid: 85.05% Test: 71.08%\n",
            "Epoch: 956, Loss: 0.3497, Train: 94.08%, Valid: 84.99% Test: 71.10%\n",
            "Epoch: 957, Loss: 0.3515, Train: 94.12%, Valid: 85.11% Test: 71.10%\n",
            "Epoch: 958, Loss: 0.3481, Train: 94.11%, Valid: 85.18% Test: 71.10%\n",
            "Epoch: 959, Loss: 0.3507, Train: 94.13%, Valid: 84.99% Test: 71.08%\n",
            "Epoch: 960, Loss: 0.3505, Train: 94.12%, Valid: 84.99% Test: 71.05%\n",
            "Epoch: 961, Loss: 0.3533, Train: 94.10%, Valid: 84.92% Test: 71.04%\n",
            "Epoch: 962, Loss: 0.3506, Train: 94.19%, Valid: 84.86% Test: 71.04%\n",
            "Epoch: 963, Loss: 0.3459, Train: 94.19%, Valid: 84.86% Test: 71.04%\n",
            "Epoch: 964, Loss: 0.3516, Train: 94.19%, Valid: 84.86% Test: 71.04%\n",
            "Epoch: 965, Loss: 0.3538, Train: 94.17%, Valid: 84.86% Test: 71.06%\n",
            "Epoch: 966, Loss: 0.3433, Train: 94.15%, Valid: 84.80% Test: 71.05%\n",
            "Epoch: 967, Loss: 0.3499, Train: 94.16%, Valid: 84.99% Test: 71.04%\n",
            "Epoch: 968, Loss: 0.3526, Train: 94.14%, Valid: 85.11% Test: 70.97%\n",
            "Epoch: 969, Loss: 0.3464, Train: 94.14%, Valid: 85.11% Test: 70.94%\n",
            "Epoch: 970, Loss: 0.3499, Train: 94.19%, Valid: 85.11% Test: 70.97%\n",
            "Epoch: 971, Loss: 0.3491, Train: 94.17%, Valid: 85.11% Test: 70.98%\n",
            "Epoch: 972, Loss: 0.3534, Train: 94.15%, Valid: 85.18% Test: 71.03%\n",
            "Epoch: 973, Loss: 0.3532, Train: 94.16%, Valid: 85.11% Test: 71.02%\n",
            "Epoch: 974, Loss: 0.3463, Train: 94.19%, Valid: 84.99% Test: 71.01%\n",
            "Epoch: 975, Loss: 0.3456, Train: 94.17%, Valid: 84.92% Test: 71.01%\n",
            "Epoch: 976, Loss: 0.3499, Train: 94.15%, Valid: 84.92% Test: 71.05%\n",
            "Epoch: 977, Loss: 0.3447, Train: 94.13%, Valid: 84.99% Test: 71.10%\n",
            "Epoch: 978, Loss: 0.3464, Train: 94.13%, Valid: 85.11% Test: 71.15%\n",
            "Epoch: 979, Loss: 0.3500, Train: 94.14%, Valid: 85.11% Test: 71.19%\n",
            "Epoch: 980, Loss: 0.3508, Train: 94.15%, Valid: 85.11% Test: 71.24%\n",
            "Epoch: 981, Loss: 0.3513, Train: 94.16%, Valid: 85.11% Test: 71.23%\n",
            "Epoch: 982, Loss: 0.3460, Train: 94.16%, Valid: 85.18% Test: 71.21%\n",
            "Epoch: 983, Loss: 0.3488, Train: 94.14%, Valid: 85.11% Test: 71.15%\n",
            "Epoch: 984, Loss: 0.3438, Train: 94.17%, Valid: 85.05% Test: 71.09%\n",
            "Epoch: 985, Loss: 0.3439, Train: 94.13%, Valid: 84.92% Test: 71.06%\n",
            "Epoch: 986, Loss: 0.3517, Train: 94.13%, Valid: 84.92% Test: 70.97%\n",
            "Epoch: 987, Loss: 0.3412, Train: 94.15%, Valid: 84.92% Test: 70.89%\n",
            "Epoch: 988, Loss: 0.3454, Train: 94.16%, Valid: 85.11% Test: 70.85%\n",
            "Epoch: 989, Loss: 0.3437, Train: 94.19%, Valid: 85.11% Test: 70.84%\n",
            "Epoch: 990, Loss: 0.3398, Train: 94.16%, Valid: 85.18% Test: 70.83%\n",
            "Epoch: 991, Loss: 0.3372, Train: 94.20%, Valid: 85.18% Test: 70.83%\n",
            "Epoch: 992, Loss: 0.3459, Train: 94.24%, Valid: 85.24% Test: 70.86%\n",
            "Epoch: 993, Loss: 0.3435, Train: 94.28%, Valid: 85.37% Test: 70.86%\n",
            "Epoch: 994, Loss: 0.3419, Train: 94.27%, Valid: 85.31% Test: 70.89%\n",
            "Epoch: 995, Loss: 0.3501, Train: 94.26%, Valid: 85.31% Test: 70.91%\n",
            "Epoch: 996, Loss: 0.3447, Train: 94.26%, Valid: 85.37% Test: 70.95%\n",
            "Epoch: 997, Loss: 0.3441, Train: 94.32%, Valid: 85.31% Test: 70.98%\n",
            "Epoch: 998, Loss: 0.3421, Train: 94.35%, Valid: 85.24% Test: 70.99%\n",
            "Epoch: 999, Loss: 0.3398, Train: 94.32%, Valid: 85.18% Test: 71.01%\n",
            "Best Test accuracy is 0.7059213140813353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset with LM initialized embeddings\n",
        "\n",
        "We finetune an MPNet model on the ogbn-products task using the web page text as an input feature. We then use the embeddings generated by this model as our initial node features for the GNN.\n",
        "\n",
        "The embeddings are available at https://drive.google.com/file/d/184qquWQuXbSog2PDZMG5xuWZU043hn3u/view?usp=sharing, please create a copy of this file in your Google Drive account and update the filepath in the code accordingly\n",
        "\n"
      ],
      "metadata": {
        "id": "894s0kfsAwTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath= \"/content/drive/Shareddrives/CS224W Project/products_embeddings_logits/mpnet_products.pkl\"\n",
        "embs = pickle.load(open(filepath, \"rb\"))\n"
      ],
      "metadata": {
        "id": "eRBezUs8Hfkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadDataLMInit(LoadData):\n",
        "    \"\"\"\n",
        "    A class extending LoadData to load graph data with initial node embeddings.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    embs : array-like\n",
        "        An array of node embeddings used to initialize the node features in the graph dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embs):\n",
        "        \"\"\"\n",
        "        The constructor for LoadDataLMInit class.\n",
        "\n",
        "        Initializes the LoadDataLMInit instance with the provided node embeddings.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        embs : array-like\n",
        "            An array-like structure containing node embeddings. Each element in the array\n",
        "            represents the embedding of a node in the graph.\n",
        "        \"\"\"\n",
        "        self.embs = embs\n",
        "        super(LoadDataLMInit, self).__init__()\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Loads the graph dataset with initial node embeddings, applies transformations, and retrieves split indices.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        data : PyG data object\n",
        "            The graph data object with initialized node features.\n",
        "        split_idx : dict\n",
        "            A dictionary containing the indices for train, validation, and test splits.\n",
        "        num_classes : int\n",
        "            The number of classes in the dataset.\n",
        "        \"\"\"\n",
        "        num_classes = 47\n",
        "        data = torch.load(data_filepath)\n",
        "        data.edge_index = data.adj_t.to_symmetric()\n",
        "        split_idx={}\n",
        "        split_idx['train'] = data.train_mask\n",
        "        split_idx['valid'] = data.val_mask\n",
        "        split_idx['test'] = data.test_mask\n",
        "        data.x = torch.tensor(self.embs)\n",
        "        return data, split_idx, num_classes"
      ],
      "metadata": {
        "id": "orA5gxchAduL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the pipeline with LM initialized embeddings"
      ],
      "metadata": {
        "id": "GED4eoFrIZY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_data=LoadDataLMInit(embs)\n",
        "lminit_acc, lminit_model = train_loop(load_data, loss_obj, hyperparams)"
      ],
      "metadata": {
        "id": "q__q0nOdIeIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82c7f92-4390-4fed-ff27-fd505d12fb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00, Loss: 3.8677, Train: 53.65%, Valid: 50.57% Test: 40.10%\n",
            "Epoch: 01, Loss: 3.6938, Train: 71.25%, Valid: 70.10% Test: 55.62%\n",
            "Epoch: 02, Loss: 3.5192, Train: 77.94%, Valid: 77.74% Test: 62.01%\n",
            "Epoch: 03, Loss: 3.2925, Train: 80.91%, Valid: 81.11% Test: 63.83%\n",
            "Epoch: 04, Loss: 3.0215, Train: 81.15%, Valid: 81.62% Test: 63.89%\n",
            "Epoch: 05, Loss: 2.7082, Train: 80.61%, Valid: 81.49% Test: 63.71%\n",
            "Epoch: 06, Loss: 2.3675, Train: 79.66%, Valid: 80.03% Test: 63.16%\n",
            "Epoch: 07, Loss: 2.0437, Train: 78.80%, Valid: 78.94% Test: 62.46%\n",
            "Epoch: 08, Loss: 1.7587, Train: 78.35%, Valid: 78.37% Test: 62.09%\n",
            "Epoch: 09, Loss: 1.5318, Train: 78.31%, Valid: 78.37% Test: 62.09%\n",
            "Epoch: 10, Loss: 1.3633, Train: 78.95%, Valid: 79.01% Test: 62.55%\n",
            "Epoch: 11, Loss: 1.2317, Train: 80.24%, Valid: 80.73% Test: 63.57%\n",
            "Epoch: 12, Loss: 1.1388, Train: 82.09%, Valid: 82.89% Test: 64.69%\n",
            "Epoch: 13, Loss: 1.0707, Train: 82.87%, Valid: 83.46% Test: 65.21%\n",
            "Epoch: 14, Loss: 1.0114, Train: 83.33%, Valid: 84.10% Test: 65.62%\n",
            "Epoch: 15, Loss: 0.9753, Train: 83.68%, Valid: 84.22% Test: 65.87%\n",
            "Epoch: 16, Loss: 0.9381, Train: 83.87%, Valid: 84.54% Test: 66.07%\n",
            "Epoch: 17, Loss: 0.8910, Train: 83.95%, Valid: 84.73% Test: 66.17%\n",
            "Epoch: 18, Loss: 0.8590, Train: 84.04%, Valid: 84.80% Test: 66.23%\n",
            "Epoch: 19, Loss: 0.8171, Train: 84.14%, Valid: 84.99% Test: 66.76%\n",
            "Epoch: 20, Loss: 0.8024, Train: 84.64%, Valid: 85.62% Test: 67.90%\n",
            "Epoch: 21, Loss: 0.7989, Train: 85.29%, Valid: 86.13% Test: 68.98%\n",
            "Epoch: 22, Loss: 0.7717, Train: 85.58%, Valid: 86.70% Test: 70.06%\n",
            "Epoch: 23, Loss: 0.7478, Train: 85.83%, Valid: 87.09% Test: 70.56%\n",
            "Epoch: 24, Loss: 0.7321, Train: 85.95%, Valid: 87.21% Test: 70.89%\n",
            "Epoch: 25, Loss: 0.7228, Train: 86.12%, Valid: 87.34% Test: 71.24%\n",
            "Epoch: 26, Loss: 0.7040, Train: 86.25%, Valid: 87.34% Test: 71.54%\n",
            "Epoch: 27, Loss: 0.6826, Train: 86.54%, Valid: 87.47% Test: 71.77%\n",
            "Epoch: 28, Loss: 0.6770, Train: 86.73%, Valid: 87.60% Test: 71.87%\n",
            "Epoch: 29, Loss: 0.6637, Train: 86.96%, Valid: 87.91% Test: 72.02%\n",
            "Epoch: 30, Loss: 0.6538, Train: 87.15%, Valid: 88.04% Test: 72.26%\n",
            "Epoch: 31, Loss: 0.6284, Train: 87.39%, Valid: 88.17% Test: 72.49%\n",
            "Epoch: 32, Loss: 0.6176, Train: 87.61%, Valid: 88.17% Test: 72.68%\n",
            "Epoch: 33, Loss: 0.5949, Train: 87.74%, Valid: 88.30% Test: 72.97%\n",
            "Epoch: 34, Loss: 0.5914, Train: 87.95%, Valid: 88.74% Test: 73.13%\n",
            "Epoch: 35, Loss: 0.5763, Train: 88.13%, Valid: 88.87% Test: 73.19%\n",
            "Epoch: 36, Loss: 0.5648, Train: 88.37%, Valid: 88.87% Test: 73.29%\n",
            "Epoch: 37, Loss: 0.5588, Train: 88.50%, Valid: 88.93% Test: 73.36%\n",
            "Epoch: 38, Loss: 0.5402, Train: 88.70%, Valid: 89.19% Test: 73.37%\n",
            "Epoch: 39, Loss: 0.5346, Train: 89.03%, Valid: 89.31% Test: 73.43%\n",
            "Epoch: 40, Loss: 0.5210, Train: 89.24%, Valid: 89.25% Test: 73.51%\n",
            "Epoch: 41, Loss: 0.5147, Train: 89.45%, Valid: 89.31% Test: 73.54%\n",
            "Epoch: 42, Loss: 0.5013, Train: 89.67%, Valid: 89.25% Test: 73.59%\n",
            "Epoch: 43, Loss: 0.4956, Train: 89.92%, Valid: 89.25% Test: 73.71%\n",
            "Epoch: 44, Loss: 0.4862, Train: 90.15%, Valid: 89.38% Test: 73.74%\n",
            "Epoch: 45, Loss: 0.4806, Train: 90.29%, Valid: 89.38% Test: 73.75%\n",
            "Epoch: 46, Loss: 0.4706, Train: 90.42%, Valid: 89.44% Test: 73.80%\n",
            "Epoch: 47, Loss: 0.4606, Train: 90.63%, Valid: 89.69% Test: 73.85%\n",
            "Epoch: 48, Loss: 0.4498, Train: 90.90%, Valid: 89.63% Test: 73.99%\n",
            "Epoch: 49, Loss: 0.4516, Train: 91.06%, Valid: 89.82% Test: 74.15%\n",
            "Epoch: 50, Loss: 0.4378, Train: 91.23%, Valid: 89.82% Test: 74.20%\n",
            "Epoch: 51, Loss: 0.4302, Train: 91.36%, Valid: 89.95% Test: 74.29%\n",
            "Epoch: 52, Loss: 0.4225, Train: 91.53%, Valid: 89.82% Test: 74.43%\n",
            "Epoch: 53, Loss: 0.4274, Train: 91.66%, Valid: 89.82% Test: 74.61%\n",
            "Epoch: 54, Loss: 0.4169, Train: 91.80%, Valid: 89.76% Test: 74.69%\n",
            "Epoch: 55, Loss: 0.4015, Train: 91.93%, Valid: 89.82% Test: 74.82%\n",
            "Epoch: 56, Loss: 0.3966, Train: 92.05%, Valid: 89.82% Test: 74.95%\n",
            "Epoch: 57, Loss: 0.3971, Train: 92.17%, Valid: 89.76% Test: 75.09%\n",
            "Epoch: 58, Loss: 0.4000, Train: 92.27%, Valid: 89.82% Test: 75.18%\n",
            "Epoch: 59, Loss: 0.3889, Train: 92.38%, Valid: 89.95% Test: 75.30%\n",
            "Epoch: 60, Loss: 0.3788, Train: 92.51%, Valid: 89.95% Test: 75.37%\n",
            "Epoch: 61, Loss: 0.3821, Train: 92.62%, Valid: 90.20% Test: 75.47%\n",
            "Epoch: 62, Loss: 0.3795, Train: 92.68%, Valid: 90.20% Test: 75.56%\n",
            "Epoch: 63, Loss: 0.3771, Train: 92.81%, Valid: 90.14% Test: 75.62%\n",
            "Epoch: 64, Loss: 0.3711, Train: 92.87%, Valid: 90.08% Test: 75.67%\n",
            "Epoch: 65, Loss: 0.3650, Train: 92.97%, Valid: 90.08% Test: 75.72%\n",
            "Epoch: 66, Loss: 0.3612, Train: 93.03%, Valid: 90.08% Test: 75.75%\n",
            "Epoch: 67, Loss: 0.3620, Train: 93.11%, Valid: 90.01% Test: 75.79%\n",
            "Epoch: 68, Loss: 0.3539, Train: 93.20%, Valid: 90.01% Test: 75.80%\n",
            "Epoch: 69, Loss: 0.3510, Train: 93.26%, Valid: 90.01% Test: 75.84%\n",
            "Epoch: 70, Loss: 0.3448, Train: 93.32%, Valid: 90.08% Test: 75.85%\n",
            "Epoch: 71, Loss: 0.3470, Train: 93.40%, Valid: 90.20% Test: 75.91%\n",
            "Epoch: 72, Loss: 0.3482, Train: 93.44%, Valid: 90.14% Test: 75.99%\n",
            "Epoch: 73, Loss: 0.3365, Train: 93.51%, Valid: 90.20% Test: 76.04%\n",
            "Epoch: 74, Loss: 0.3351, Train: 93.62%, Valid: 90.20% Test: 76.10%\n",
            "Epoch: 75, Loss: 0.3352, Train: 93.66%, Valid: 90.33% Test: 76.12%\n",
            "Epoch: 76, Loss: 0.3335, Train: 93.70%, Valid: 90.33% Test: 76.19%\n",
            "Epoch: 77, Loss: 0.3323, Train: 93.73%, Valid: 90.39% Test: 76.26%\n",
            "Epoch: 78, Loss: 0.3292, Train: 93.77%, Valid: 90.39% Test: 76.33%\n",
            "Epoch: 79, Loss: 0.3297, Train: 93.83%, Valid: 90.39% Test: 76.39%\n",
            "Epoch: 80, Loss: 0.3284, Train: 93.86%, Valid: 90.39% Test: 76.47%\n",
            "Epoch: 81, Loss: 0.3263, Train: 93.90%, Valid: 90.46% Test: 76.49%\n",
            "Epoch: 82, Loss: 0.3177, Train: 93.94%, Valid: 90.46% Test: 76.52%\n",
            "Epoch: 83, Loss: 0.3169, Train: 94.01%, Valid: 90.39% Test: 76.51%\n",
            "Epoch: 84, Loss: 0.3141, Train: 94.07%, Valid: 90.39% Test: 76.53%\n",
            "Epoch: 85, Loss: 0.3174, Train: 94.12%, Valid: 90.33% Test: 76.58%\n",
            "Epoch: 86, Loss: 0.3139, Train: 94.17%, Valid: 90.39% Test: 76.61%\n",
            "Epoch: 87, Loss: 0.3097, Train: 94.21%, Valid: 90.46% Test: 76.64%\n",
            "Epoch: 88, Loss: 0.3074, Train: 94.29%, Valid: 90.46% Test: 76.67%\n",
            "Epoch: 89, Loss: 0.3083, Train: 94.34%, Valid: 90.52% Test: 76.70%\n",
            "Epoch: 90, Loss: 0.3004, Train: 94.38%, Valid: 90.52% Test: 76.74%\n",
            "Epoch: 91, Loss: 0.3047, Train: 94.40%, Valid: 90.52% Test: 76.80%\n",
            "Epoch: 92, Loss: 0.2991, Train: 94.47%, Valid: 90.65% Test: 76.83%\n",
            "Epoch: 93, Loss: 0.3000, Train: 94.50%, Valid: 90.65% Test: 76.90%\n",
            "Epoch: 94, Loss: 0.2996, Train: 94.52%, Valid: 90.65% Test: 76.92%\n",
            "Epoch: 95, Loss: 0.2936, Train: 94.54%, Valid: 90.65% Test: 76.93%\n",
            "Epoch: 96, Loss: 0.2969, Train: 94.59%, Valid: 90.71% Test: 76.98%\n",
            "Epoch: 97, Loss: 0.2987, Train: 94.64%, Valid: 90.71% Test: 77.03%\n",
            "Epoch: 98, Loss: 0.2929, Train: 94.67%, Valid: 90.78% Test: 77.07%\n",
            "Epoch: 99, Loss: 0.2913, Train: 94.72%, Valid: 90.78% Test: 77.14%\n",
            "Epoch: 100, Loss: 0.2893, Train: 94.74%, Valid: 90.78% Test: 77.19%\n",
            "Epoch: 101, Loss: 0.2914, Train: 94.80%, Valid: 90.71% Test: 77.21%\n",
            "Epoch: 102, Loss: 0.2837, Train: 94.83%, Valid: 90.78% Test: 77.22%\n",
            "Epoch: 103, Loss: 0.2888, Train: 94.86%, Valid: 90.78% Test: 77.26%\n",
            "Epoch: 104, Loss: 0.2832, Train: 94.90%, Valid: 90.84% Test: 77.30%\n",
            "Epoch: 105, Loss: 0.2847, Train: 94.93%, Valid: 90.84% Test: 77.35%\n",
            "Epoch: 106, Loss: 0.2821, Train: 94.97%, Valid: 90.84% Test: 77.37%\n",
            "Epoch: 107, Loss: 0.2833, Train: 94.98%, Valid: 90.84% Test: 77.38%\n",
            "Epoch: 108, Loss: 0.2760, Train: 95.00%, Valid: 90.84% Test: 77.41%\n",
            "Epoch: 109, Loss: 0.2820, Train: 95.02%, Valid: 90.90% Test: 77.41%\n",
            "Epoch: 110, Loss: 0.2785, Train: 95.03%, Valid: 90.84% Test: 77.41%\n",
            "Epoch: 111, Loss: 0.2805, Train: 95.06%, Valid: 90.84% Test: 77.42%\n",
            "Epoch: 112, Loss: 0.2752, Train: 95.10%, Valid: 90.78% Test: 77.44%\n",
            "Epoch: 113, Loss: 0.2748, Train: 95.11%, Valid: 90.78% Test: 77.46%\n",
            "Epoch: 114, Loss: 0.2731, Train: 95.13%, Valid: 90.78% Test: 77.45%\n",
            "Epoch: 115, Loss: 0.2733, Train: 95.15%, Valid: 90.78% Test: 77.46%\n",
            "Epoch: 116, Loss: 0.2705, Train: 95.16%, Valid: 90.78% Test: 77.47%\n",
            "Epoch: 117, Loss: 0.2688, Train: 95.17%, Valid: 90.71% Test: 77.50%\n",
            "Epoch: 118, Loss: 0.2672, Train: 95.19%, Valid: 90.71% Test: 77.53%\n",
            "Epoch: 119, Loss: 0.2655, Train: 95.21%, Valid: 90.71% Test: 77.57%\n",
            "Epoch: 120, Loss: 0.2680, Train: 95.22%, Valid: 90.71% Test: 77.59%\n",
            "Epoch: 121, Loss: 0.2692, Train: 95.21%, Valid: 90.78% Test: 77.60%\n",
            "Epoch: 122, Loss: 0.2604, Train: 95.23%, Valid: 90.78% Test: 77.63%\n",
            "Epoch: 123, Loss: 0.2652, Train: 95.23%, Valid: 90.78% Test: 77.64%\n",
            "Epoch: 124, Loss: 0.2635, Train: 95.26%, Valid: 90.78% Test: 77.68%\n",
            "Epoch: 125, Loss: 0.2672, Train: 95.27%, Valid: 90.84% Test: 77.67%\n",
            "Epoch: 126, Loss: 0.2564, Train: 95.28%, Valid: 90.84% Test: 77.68%\n",
            "Epoch: 127, Loss: 0.2568, Train: 95.29%, Valid: 90.84% Test: 77.71%\n",
            "Epoch: 128, Loss: 0.2638, Train: 95.33%, Valid: 90.84% Test: 77.75%\n",
            "Epoch: 129, Loss: 0.2573, Train: 95.34%, Valid: 90.84% Test: 77.77%\n",
            "Epoch: 130, Loss: 0.2590, Train: 95.36%, Valid: 90.84% Test: 77.78%\n",
            "Epoch: 131, Loss: 0.2499, Train: 95.36%, Valid: 90.84% Test: 77.79%\n",
            "Epoch: 132, Loss: 0.2577, Train: 95.39%, Valid: 90.84% Test: 77.76%\n",
            "Epoch: 133, Loss: 0.2585, Train: 95.42%, Valid: 90.84% Test: 77.75%\n",
            "Epoch: 134, Loss: 0.2579, Train: 95.44%, Valid: 90.78% Test: 77.77%\n",
            "Epoch: 135, Loss: 0.2512, Train: 95.44%, Valid: 90.78% Test: 77.78%\n",
            "Epoch: 136, Loss: 0.2530, Train: 95.46%, Valid: 90.78% Test: 77.77%\n",
            "Epoch: 137, Loss: 0.2542, Train: 95.49%, Valid: 90.78% Test: 77.78%\n",
            "Epoch: 138, Loss: 0.2546, Train: 95.48%, Valid: 90.84% Test: 77.77%\n",
            "Epoch: 139, Loss: 0.2525, Train: 95.50%, Valid: 90.84% Test: 77.76%\n",
            "Epoch: 140, Loss: 0.2491, Train: 95.51%, Valid: 90.84% Test: 77.75%\n",
            "Epoch: 141, Loss: 0.2472, Train: 95.52%, Valid: 90.84% Test: 77.73%\n",
            "Epoch: 142, Loss: 0.2480, Train: 95.53%, Valid: 90.78% Test: 77.71%\n",
            "Epoch: 143, Loss: 0.2500, Train: 95.55%, Valid: 90.78% Test: 77.70%\n",
            "Epoch: 144, Loss: 0.2499, Train: 95.56%, Valid: 90.78% Test: 77.69%\n",
            "Epoch: 145, Loss: 0.2512, Train: 95.56%, Valid: 90.78% Test: 77.69%\n",
            "Epoch: 146, Loss: 0.2483, Train: 95.57%, Valid: 90.84% Test: 77.72%\n",
            "Epoch: 147, Loss: 0.2480, Train: 95.58%, Valid: 90.84% Test: 77.76%\n",
            "Epoch: 148, Loss: 0.2437, Train: 95.60%, Valid: 90.84% Test: 77.79%\n",
            "Epoch: 149, Loss: 0.2447, Train: 95.61%, Valid: 90.84% Test: 77.81%\n",
            "Epoch: 150, Loss: 0.2440, Train: 95.62%, Valid: 90.78% Test: 77.82%\n",
            "Epoch: 151, Loss: 0.2486, Train: 95.63%, Valid: 90.71% Test: 77.87%\n",
            "Epoch: 152, Loss: 0.2379, Train: 95.64%, Valid: 90.65% Test: 77.90%\n",
            "Epoch: 153, Loss: 0.2399, Train: 95.63%, Valid: 90.65% Test: 77.90%\n",
            "Epoch: 154, Loss: 0.2421, Train: 95.63%, Valid: 90.59% Test: 77.93%\n",
            "Epoch: 155, Loss: 0.2366, Train: 95.65%, Valid: 90.59% Test: 77.94%\n",
            "Epoch: 156, Loss: 0.2440, Train: 95.66%, Valid: 90.59% Test: 77.95%\n",
            "Epoch: 157, Loss: 0.2362, Train: 95.68%, Valid: 90.65% Test: 77.94%\n",
            "Epoch: 158, Loss: 0.2419, Train: 95.67%, Valid: 90.59% Test: 77.92%\n",
            "Epoch: 159, Loss: 0.2437, Train: 95.72%, Valid: 90.59% Test: 77.93%\n",
            "Epoch: 160, Loss: 0.2362, Train: 95.72%, Valid: 90.59% Test: 77.95%\n",
            "Epoch: 161, Loss: 0.2386, Train: 95.73%, Valid: 90.59% Test: 77.95%\n",
            "Epoch: 162, Loss: 0.2366, Train: 95.72%, Valid: 90.65% Test: 77.95%\n",
            "Epoch: 163, Loss: 0.2377, Train: 95.74%, Valid: 90.65% Test: 77.97%\n",
            "Epoch: 164, Loss: 0.2406, Train: 95.74%, Valid: 90.71% Test: 77.96%\n",
            "Epoch: 165, Loss: 0.2393, Train: 95.76%, Valid: 90.71% Test: 77.97%\n",
            "Epoch: 166, Loss: 0.2375, Train: 95.78%, Valid: 90.71% Test: 77.97%\n",
            "Epoch: 167, Loss: 0.2362, Train: 95.79%, Valid: 90.71% Test: 77.97%\n",
            "Epoch: 168, Loss: 0.2334, Train: 95.81%, Valid: 90.84% Test: 77.97%\n",
            "Epoch: 169, Loss: 0.2293, Train: 95.81%, Valid: 90.84% Test: 77.95%\n",
            "Epoch: 170, Loss: 0.2327, Train: 95.83%, Valid: 90.78% Test: 77.94%\n",
            "Epoch: 171, Loss: 0.2328, Train: 95.83%, Valid: 90.78% Test: 77.94%\n",
            "Epoch: 172, Loss: 0.2393, Train: 95.83%, Valid: 90.78% Test: 77.92%\n",
            "Epoch: 173, Loss: 0.2304, Train: 95.82%, Valid: 90.78% Test: 77.92%\n",
            "Epoch: 174, Loss: 0.2297, Train: 95.83%, Valid: 90.71% Test: 77.93%\n",
            "Epoch: 175, Loss: 0.2325, Train: 95.85%, Valid: 90.71% Test: 77.93%\n",
            "Epoch: 176, Loss: 0.2290, Train: 95.85%, Valid: 90.71% Test: 77.91%\n",
            "Epoch: 177, Loss: 0.2249, Train: 95.87%, Valid: 90.71% Test: 77.91%\n",
            "Epoch: 178, Loss: 0.2296, Train: 95.89%, Valid: 90.71% Test: 77.91%\n",
            "Epoch: 179, Loss: 0.2332, Train: 95.89%, Valid: 90.71% Test: 77.93%\n",
            "Epoch: 180, Loss: 0.2293, Train: 95.89%, Valid: 90.78% Test: 77.94%\n",
            "Epoch: 181, Loss: 0.2306, Train: 95.89%, Valid: 90.84% Test: 77.96%\n",
            "Epoch: 182, Loss: 0.2328, Train: 95.90%, Valid: 90.84% Test: 77.98%\n",
            "Epoch: 183, Loss: 0.2263, Train: 95.89%, Valid: 90.78% Test: 77.99%\n",
            "Epoch: 184, Loss: 0.2237, Train: 95.89%, Valid: 90.84% Test: 78.02%\n",
            "Epoch: 185, Loss: 0.2288, Train: 95.89%, Valid: 90.84% Test: 78.02%\n",
            "Epoch: 186, Loss: 0.2307, Train: 95.91%, Valid: 90.71% Test: 77.99%\n",
            "Epoch: 187, Loss: 0.2308, Train: 95.90%, Valid: 90.71% Test: 77.96%\n",
            "Epoch: 188, Loss: 0.2254, Train: 95.90%, Valid: 90.65% Test: 77.93%\n",
            "Epoch: 189, Loss: 0.2263, Train: 95.91%, Valid: 90.71% Test: 77.89%\n",
            "Epoch: 190, Loss: 0.2251, Train: 95.91%, Valid: 90.71% Test: 77.88%\n",
            "Epoch: 191, Loss: 0.2276, Train: 95.91%, Valid: 90.65% Test: 77.89%\n",
            "Epoch: 192, Loss: 0.2249, Train: 95.91%, Valid: 90.65% Test: 77.91%\n",
            "Epoch: 193, Loss: 0.2267, Train: 95.91%, Valid: 90.65% Test: 77.91%\n",
            "Epoch: 194, Loss: 0.2246, Train: 95.93%, Valid: 90.65% Test: 77.94%\n",
            "Epoch: 195, Loss: 0.2231, Train: 95.93%, Valid: 90.65% Test: 77.95%\n",
            "Epoch: 196, Loss: 0.2279, Train: 95.93%, Valid: 90.65% Test: 77.95%\n",
            "Epoch: 197, Loss: 0.2207, Train: 95.93%, Valid: 90.65% Test: 77.94%\n",
            "Epoch: 198, Loss: 0.2252, Train: 95.93%, Valid: 90.65% Test: 77.97%\n",
            "Epoch: 199, Loss: 0.2239, Train: 95.93%, Valid: 90.71% Test: 77.99%\n",
            "Epoch: 200, Loss: 0.2196, Train: 95.95%, Valid: 90.71% Test: 78.02%\n",
            "Epoch: 201, Loss: 0.2191, Train: 95.95%, Valid: 90.71% Test: 78.04%\n",
            "Epoch: 202, Loss: 0.2205, Train: 95.97%, Valid: 90.65% Test: 78.08%\n",
            "Epoch: 203, Loss: 0.2197, Train: 95.96%, Valid: 90.71% Test: 78.08%\n",
            "Epoch: 204, Loss: 0.2245, Train: 95.96%, Valid: 90.71% Test: 78.06%\n",
            "Epoch: 205, Loss: 0.2185, Train: 95.95%, Valid: 90.71% Test: 78.04%\n",
            "Epoch: 206, Loss: 0.2195, Train: 95.95%, Valid: 90.65% Test: 78.04%\n",
            "Epoch: 207, Loss: 0.2250, Train: 95.96%, Valid: 90.71% Test: 78.03%\n",
            "Epoch: 208, Loss: 0.2196, Train: 95.95%, Valid: 90.65% Test: 78.02%\n",
            "Epoch: 209, Loss: 0.2190, Train: 95.95%, Valid: 90.65% Test: 77.99%\n",
            "Epoch: 210, Loss: 0.2133, Train: 95.96%, Valid: 90.65% Test: 77.97%\n",
            "Epoch: 211, Loss: 0.2197, Train: 95.97%, Valid: 90.59% Test: 77.97%\n",
            "Epoch: 212, Loss: 0.2219, Train: 95.97%, Valid: 90.46% Test: 77.97%\n",
            "Epoch: 213, Loss: 0.2194, Train: 95.97%, Valid: 90.46% Test: 78.02%\n",
            "Epoch: 214, Loss: 0.2132, Train: 95.98%, Valid: 90.46% Test: 78.03%\n",
            "Epoch: 215, Loss: 0.2161, Train: 96.00%, Valid: 90.46% Test: 78.06%\n",
            "Epoch: 216, Loss: 0.2154, Train: 95.99%, Valid: 90.46% Test: 78.05%\n",
            "Epoch: 217, Loss: 0.2204, Train: 95.99%, Valid: 90.46% Test: 78.06%\n",
            "Epoch: 218, Loss: 0.2096, Train: 96.00%, Valid: 90.46% Test: 78.04%\n",
            "Epoch: 219, Loss: 0.2161, Train: 95.99%, Valid: 90.65% Test: 78.04%\n",
            "Epoch: 220, Loss: 0.2074, Train: 95.98%, Valid: 90.71% Test: 78.02%\n",
            "Epoch: 221, Loss: 0.2154, Train: 95.97%, Valid: 90.71% Test: 78.01%\n",
            "Epoch: 222, Loss: 0.2182, Train: 95.97%, Valid: 90.71% Test: 78.01%\n",
            "Epoch: 223, Loss: 0.2123, Train: 95.97%, Valid: 90.65% Test: 78.01%\n",
            "Epoch: 224, Loss: 0.2148, Train: 95.97%, Valid: 90.59% Test: 78.02%\n",
            "Epoch: 225, Loss: 0.2107, Train: 95.98%, Valid: 90.46% Test: 78.01%\n",
            "Epoch: 226, Loss: 0.2150, Train: 96.00%, Valid: 90.39% Test: 78.02%\n",
            "Epoch: 227, Loss: 0.2133, Train: 96.00%, Valid: 90.39% Test: 78.02%\n",
            "Epoch: 228, Loss: 0.2106, Train: 96.00%, Valid: 90.27% Test: 78.03%\n",
            "Epoch: 229, Loss: 0.2153, Train: 96.02%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 230, Loss: 0.2134, Train: 96.02%, Valid: 90.27% Test: 78.06%\n",
            "Epoch: 231, Loss: 0.2116, Train: 96.02%, Valid: 90.27% Test: 78.06%\n",
            "Epoch: 232, Loss: 0.2090, Train: 96.03%, Valid: 90.27% Test: 78.05%\n",
            "Epoch: 233, Loss: 0.2151, Train: 96.04%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 234, Loss: 0.2066, Train: 96.04%, Valid: 90.27% Test: 78.03%\n",
            "Epoch: 235, Loss: 0.2138, Train: 96.02%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 236, Loss: 0.2097, Train: 96.03%, Valid: 90.20% Test: 78.04%\n",
            "Epoch: 237, Loss: 0.2050, Train: 96.02%, Valid: 90.14% Test: 78.06%\n",
            "Epoch: 238, Loss: 0.2073, Train: 96.04%, Valid: 90.14% Test: 78.08%\n",
            "Epoch: 239, Loss: 0.2076, Train: 96.04%, Valid: 90.20% Test: 78.10%\n",
            "Epoch: 240, Loss: 0.2098, Train: 96.04%, Valid: 90.20% Test: 78.09%\n",
            "Epoch: 241, Loss: 0.2104, Train: 96.04%, Valid: 90.20% Test: 78.07%\n",
            "Epoch: 242, Loss: 0.2086, Train: 96.04%, Valid: 90.20% Test: 78.07%\n",
            "Epoch: 243, Loss: 0.2066, Train: 96.04%, Valid: 90.14% Test: 78.08%\n",
            "Epoch: 244, Loss: 0.2056, Train: 96.06%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 245, Loss: 0.2090, Train: 96.07%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 246, Loss: 0.2088, Train: 96.08%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 247, Loss: 0.2048, Train: 96.10%, Valid: 90.20% Test: 78.09%\n",
            "Epoch: 248, Loss: 0.2005, Train: 96.10%, Valid: 90.20% Test: 78.08%\n",
            "Epoch: 249, Loss: 0.2090, Train: 96.11%, Valid: 90.20% Test: 78.07%\n",
            "Epoch: 250, Loss: 0.2038, Train: 96.13%, Valid: 90.20% Test: 78.07%\n",
            "Epoch: 251, Loss: 0.2005, Train: 96.14%, Valid: 90.14% Test: 78.08%\n",
            "Epoch: 252, Loss: 0.2049, Train: 96.14%, Valid: 90.27% Test: 78.09%\n",
            "Epoch: 253, Loss: 0.2064, Train: 96.13%, Valid: 90.33% Test: 78.11%\n",
            "Epoch: 254, Loss: 0.2041, Train: 96.14%, Valid: 90.33% Test: 78.13%\n",
            "Epoch: 255, Loss: 0.2056, Train: 96.14%, Valid: 90.33% Test: 78.16%\n",
            "Epoch: 256, Loss: 0.2098, Train: 96.16%, Valid: 90.33% Test: 78.18%\n",
            "Epoch: 257, Loss: 0.2090, Train: 96.16%, Valid: 90.33% Test: 78.18%\n",
            "Epoch: 258, Loss: 0.2077, Train: 96.14%, Valid: 90.27% Test: 78.15%\n",
            "Epoch: 259, Loss: 0.2062, Train: 96.14%, Valid: 90.27% Test: 78.15%\n",
            "Epoch: 260, Loss: 0.2061, Train: 96.14%, Valid: 90.27% Test: 78.13%\n",
            "Epoch: 261, Loss: 0.2041, Train: 96.14%, Valid: 90.20% Test: 78.10%\n",
            "Epoch: 262, Loss: 0.2063, Train: 96.14%, Valid: 90.27% Test: 78.09%\n",
            "Epoch: 263, Loss: 0.2035, Train: 96.17%, Valid: 90.27% Test: 78.09%\n",
            "Epoch: 264, Loss: 0.2039, Train: 96.17%, Valid: 90.20% Test: 78.10%\n",
            "Epoch: 265, Loss: 0.2021, Train: 96.19%, Valid: 90.20% Test: 78.11%\n",
            "Epoch: 266, Loss: 0.1979, Train: 96.18%, Valid: 90.20% Test: 78.11%\n",
            "Epoch: 267, Loss: 0.2035, Train: 96.19%, Valid: 90.20% Test: 78.12%\n",
            "Epoch: 268, Loss: 0.2005, Train: 96.18%, Valid: 90.20% Test: 78.15%\n",
            "Epoch: 269, Loss: 0.2063, Train: 96.18%, Valid: 90.27% Test: 78.17%\n",
            "Epoch: 270, Loss: 0.2016, Train: 96.20%, Valid: 90.27% Test: 78.19%\n",
            "Epoch: 271, Loss: 0.2020, Train: 96.19%, Valid: 90.27% Test: 78.17%\n",
            "Epoch: 272, Loss: 0.2051, Train: 96.19%, Valid: 90.27% Test: 78.17%\n",
            "Epoch: 273, Loss: 0.1984, Train: 96.17%, Valid: 90.27% Test: 78.15%\n",
            "Epoch: 274, Loss: 0.2038, Train: 96.19%, Valid: 90.27% Test: 78.09%\n",
            "Epoch: 275, Loss: 0.2015, Train: 96.21%, Valid: 90.20% Test: 78.05%\n",
            "Epoch: 276, Loss: 0.2056, Train: 96.21%, Valid: 90.14% Test: 78.01%\n",
            "Epoch: 277, Loss: 0.2026, Train: 96.24%, Valid: 90.14% Test: 78.01%\n",
            "Epoch: 278, Loss: 0.2006, Train: 96.23%, Valid: 90.14% Test: 78.00%\n",
            "Epoch: 279, Loss: 0.2010, Train: 96.23%, Valid: 90.14% Test: 78.02%\n",
            "Epoch: 280, Loss: 0.1937, Train: 96.21%, Valid: 90.14% Test: 78.06%\n",
            "Epoch: 281, Loss: 0.1989, Train: 96.21%, Valid: 90.14% Test: 78.06%\n",
            "Epoch: 282, Loss: 0.2009, Train: 96.22%, Valid: 90.01% Test: 78.08%\n",
            "Epoch: 283, Loss: 0.2013, Train: 96.23%, Valid: 89.95% Test: 78.11%\n",
            "Epoch: 284, Loss: 0.1994, Train: 96.23%, Valid: 89.95% Test: 78.10%\n",
            "Epoch: 285, Loss: 0.2024, Train: 96.23%, Valid: 90.01% Test: 78.07%\n",
            "Epoch: 286, Loss: 0.1959, Train: 96.22%, Valid: 90.08% Test: 78.01%\n",
            "Epoch: 287, Loss: 0.2022, Train: 96.23%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 288, Loss: 0.2043, Train: 96.24%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 289, Loss: 0.1980, Train: 96.24%, Valid: 90.14% Test: 77.91%\n",
            "Epoch: 290, Loss: 0.1999, Train: 96.24%, Valid: 90.14% Test: 77.90%\n",
            "Epoch: 291, Loss: 0.1991, Train: 96.26%, Valid: 90.14% Test: 77.92%\n",
            "Epoch: 292, Loss: 0.1961, Train: 96.28%, Valid: 90.27% Test: 77.95%\n",
            "Epoch: 293, Loss: 0.1966, Train: 96.27%, Valid: 90.27% Test: 78.01%\n",
            "Epoch: 294, Loss: 0.2002, Train: 96.27%, Valid: 90.27% Test: 78.06%\n",
            "Epoch: 295, Loss: 0.1993, Train: 96.26%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 296, Loss: 0.1991, Train: 96.26%, Valid: 90.14% Test: 78.12%\n",
            "Epoch: 297, Loss: 0.1949, Train: 96.26%, Valid: 90.14% Test: 78.13%\n",
            "Epoch: 298, Loss: 0.1986, Train: 96.27%, Valid: 90.14% Test: 78.14%\n",
            "Epoch: 299, Loss: 0.2009, Train: 96.28%, Valid: 90.14% Test: 78.13%\n",
            "Epoch: 300, Loss: 0.1997, Train: 96.29%, Valid: 90.14% Test: 78.11%\n",
            "Epoch: 301, Loss: 0.1959, Train: 96.29%, Valid: 90.14% Test: 78.09%\n",
            "Epoch: 302, Loss: 0.1937, Train: 96.29%, Valid: 90.08% Test: 78.07%\n",
            "Epoch: 303, Loss: 0.1968, Train: 96.30%, Valid: 90.14% Test: 78.08%\n",
            "Epoch: 304, Loss: 0.1948, Train: 96.29%, Valid: 90.20% Test: 78.09%\n",
            "Epoch: 305, Loss: 0.1984, Train: 96.29%, Valid: 90.20% Test: 78.08%\n",
            "Epoch: 306, Loss: 0.1900, Train: 96.29%, Valid: 90.20% Test: 78.11%\n",
            "Epoch: 307, Loss: 0.1919, Train: 96.29%, Valid: 90.27% Test: 78.13%\n",
            "Epoch: 308, Loss: 0.1911, Train: 96.30%, Valid: 90.27% Test: 78.17%\n",
            "Epoch: 309, Loss: 0.1942, Train: 96.31%, Valid: 90.27% Test: 78.18%\n",
            "Epoch: 310, Loss: 0.1956, Train: 96.31%, Valid: 90.27% Test: 78.14%\n",
            "Epoch: 311, Loss: 0.1919, Train: 96.31%, Valid: 90.20% Test: 78.10%\n",
            "Epoch: 312, Loss: 0.1936, Train: 96.32%, Valid: 90.08% Test: 78.04%\n",
            "Epoch: 313, Loss: 0.1927, Train: 96.34%, Valid: 90.08% Test: 78.00%\n",
            "Epoch: 314, Loss: 0.1954, Train: 96.35%, Valid: 90.14% Test: 78.01%\n",
            "Epoch: 315, Loss: 0.1978, Train: 96.35%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 316, Loss: 0.1981, Train: 96.35%, Valid: 90.14% Test: 78.01%\n",
            "Epoch: 317, Loss: 0.1939, Train: 96.34%, Valid: 90.08% Test: 78.04%\n",
            "Epoch: 318, Loss: 0.1980, Train: 96.35%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 319, Loss: 0.1988, Train: 96.35%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 320, Loss: 0.1924, Train: 96.34%, Valid: 90.14% Test: 78.14%\n",
            "Epoch: 321, Loss: 0.1947, Train: 96.36%, Valid: 90.14% Test: 78.14%\n",
            "Epoch: 322, Loss: 0.1911, Train: 96.35%, Valid: 90.14% Test: 78.13%\n",
            "Epoch: 323, Loss: 0.1898, Train: 96.33%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 324, Loss: 0.1941, Train: 96.34%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 325, Loss: 0.1936, Train: 96.34%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 326, Loss: 0.1897, Train: 96.34%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 327, Loss: 0.1934, Train: 96.34%, Valid: 90.14% Test: 78.08%\n",
            "Epoch: 328, Loss: 0.1932, Train: 96.35%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 329, Loss: 0.1888, Train: 96.35%, Valid: 90.20% Test: 78.09%\n",
            "Epoch: 330, Loss: 0.1871, Train: 96.35%, Valid: 90.27% Test: 78.10%\n",
            "Epoch: 331, Loss: 0.1866, Train: 96.36%, Valid: 90.20% Test: 78.10%\n",
            "Epoch: 332, Loss: 0.1862, Train: 96.38%, Valid: 90.20% Test: 78.11%\n",
            "Epoch: 333, Loss: 0.1832, Train: 96.38%, Valid: 90.14% Test: 78.13%\n",
            "Epoch: 334, Loss: 0.1923, Train: 96.38%, Valid: 90.14% Test: 78.13%\n",
            "Epoch: 335, Loss: 0.1946, Train: 96.38%, Valid: 90.14% Test: 78.14%\n",
            "Epoch: 336, Loss: 0.1904, Train: 96.39%, Valid: 90.14% Test: 78.15%\n",
            "Epoch: 337, Loss: 0.1933, Train: 96.39%, Valid: 90.14% Test: 78.15%\n",
            "Epoch: 338, Loss: 0.1857, Train: 96.39%, Valid: 90.14% Test: 78.15%\n",
            "Epoch: 339, Loss: 0.1848, Train: 96.39%, Valid: 90.14% Test: 78.12%\n",
            "Epoch: 340, Loss: 0.1892, Train: 96.38%, Valid: 90.20% Test: 78.13%\n",
            "Epoch: 341, Loss: 0.1864, Train: 96.38%, Valid: 90.27% Test: 78.11%\n",
            "Epoch: 342, Loss: 0.1868, Train: 96.38%, Valid: 90.27% Test: 78.09%\n",
            "Epoch: 343, Loss: 0.1878, Train: 96.39%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 344, Loss: 0.1867, Train: 96.39%, Valid: 90.27% Test: 78.03%\n",
            "Epoch: 345, Loss: 0.1865, Train: 96.40%, Valid: 90.20% Test: 78.01%\n",
            "Epoch: 346, Loss: 0.1868, Train: 96.40%, Valid: 90.20% Test: 78.00%\n",
            "Epoch: 347, Loss: 0.1872, Train: 96.40%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 348, Loss: 0.1892, Train: 96.40%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 349, Loss: 0.1902, Train: 96.39%, Valid: 90.14% Test: 77.98%\n",
            "Epoch: 350, Loss: 0.1862, Train: 96.38%, Valid: 90.14% Test: 78.00%\n",
            "Epoch: 351, Loss: 0.1893, Train: 96.40%, Valid: 90.14% Test: 78.00%\n",
            "Epoch: 352, Loss: 0.1874, Train: 96.40%, Valid: 90.14% Test: 78.01%\n",
            "Epoch: 353, Loss: 0.1840, Train: 96.41%, Valid: 90.14% Test: 78.04%\n",
            "Epoch: 354, Loss: 0.1898, Train: 96.41%, Valid: 90.14% Test: 78.06%\n",
            "Epoch: 355, Loss: 0.1857, Train: 96.40%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 356, Loss: 0.1864, Train: 96.41%, Valid: 90.14% Test: 78.10%\n",
            "Epoch: 357, Loss: 0.1846, Train: 96.40%, Valid: 90.14% Test: 78.09%\n",
            "Epoch: 358, Loss: 0.1867, Train: 96.39%, Valid: 90.20% Test: 78.07%\n",
            "Epoch: 359, Loss: 0.1878, Train: 96.39%, Valid: 90.20% Test: 78.06%\n",
            "Epoch: 360, Loss: 0.1874, Train: 96.40%, Valid: 90.20% Test: 78.03%\n",
            "Epoch: 361, Loss: 0.1858, Train: 96.40%, Valid: 90.14% Test: 78.00%\n",
            "Epoch: 362, Loss: 0.1880, Train: 96.42%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 363, Loss: 0.1819, Train: 96.44%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 364, Loss: 0.1801, Train: 96.45%, Valid: 90.14% Test: 78.02%\n",
            "Epoch: 365, Loss: 0.1819, Train: 96.46%, Valid: 90.14% Test: 78.05%\n",
            "Epoch: 366, Loss: 0.1837, Train: 96.47%, Valid: 90.20% Test: 78.06%\n",
            "Epoch: 367, Loss: 0.1859, Train: 96.46%, Valid: 90.14% Test: 78.06%\n",
            "Epoch: 368, Loss: 0.1876, Train: 96.46%, Valid: 90.20% Test: 78.07%\n",
            "Epoch: 369, Loss: 0.1846, Train: 96.46%, Valid: 90.20% Test: 78.08%\n",
            "Epoch: 370, Loss: 0.1854, Train: 96.46%, Valid: 90.20% Test: 78.10%\n",
            "Epoch: 371, Loss: 0.1829, Train: 96.45%, Valid: 90.20% Test: 78.08%\n",
            "Epoch: 372, Loss: 0.1862, Train: 96.44%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 373, Loss: 0.1818, Train: 96.46%, Valid: 90.14% Test: 78.03%\n",
            "Epoch: 374, Loss: 0.1793, Train: 96.46%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 375, Loss: 0.1824, Train: 96.45%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 376, Loss: 0.1838, Train: 96.46%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 377, Loss: 0.1818, Train: 96.46%, Valid: 90.20% Test: 78.01%\n",
            "Epoch: 378, Loss: 0.1850, Train: 96.46%, Valid: 90.20% Test: 78.02%\n",
            "Epoch: 379, Loss: 0.1818, Train: 96.45%, Valid: 90.20% Test: 78.01%\n",
            "Epoch: 380, Loss: 0.1816, Train: 96.45%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 381, Loss: 0.1793, Train: 96.45%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 382, Loss: 0.1811, Train: 96.45%, Valid: 90.20% Test: 77.94%\n",
            "Epoch: 383, Loss: 0.1780, Train: 96.45%, Valid: 90.20% Test: 77.93%\n",
            "Epoch: 384, Loss: 0.1851, Train: 96.46%, Valid: 90.20% Test: 77.91%\n",
            "Epoch: 385, Loss: 0.1802, Train: 96.48%, Valid: 90.20% Test: 77.91%\n",
            "Epoch: 386, Loss: 0.1810, Train: 96.51%, Valid: 90.20% Test: 77.92%\n",
            "Epoch: 387, Loss: 0.1810, Train: 96.53%, Valid: 90.20% Test: 77.94%\n",
            "Epoch: 388, Loss: 0.1800, Train: 96.53%, Valid: 90.20% Test: 78.01%\n",
            "Epoch: 389, Loss: 0.1815, Train: 96.53%, Valid: 90.20% Test: 78.10%\n",
            "Epoch: 390, Loss: 0.1768, Train: 96.51%, Valid: 90.08% Test: 78.16%\n",
            "Epoch: 391, Loss: 0.1810, Train: 96.51%, Valid: 90.14% Test: 78.25%\n",
            "Epoch: 392, Loss: 0.1800, Train: 96.53%, Valid: 90.14% Test: 78.28%\n",
            "Epoch: 393, Loss: 0.1789, Train: 96.55%, Valid: 90.14% Test: 78.29%\n",
            "Epoch: 394, Loss: 0.1794, Train: 96.55%, Valid: 90.20% Test: 78.26%\n",
            "Epoch: 395, Loss: 0.1800, Train: 96.55%, Valid: 90.27% Test: 78.22%\n",
            "Epoch: 396, Loss: 0.1786, Train: 96.55%, Valid: 90.27% Test: 78.17%\n",
            "Epoch: 397, Loss: 0.1813, Train: 96.55%, Valid: 90.20% Test: 78.11%\n",
            "Epoch: 398, Loss: 0.1816, Train: 96.53%, Valid: 90.20% Test: 78.05%\n",
            "Epoch: 399, Loss: 0.1789, Train: 96.53%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 400, Loss: 0.1775, Train: 96.55%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 401, Loss: 0.1805, Train: 96.53%, Valid: 90.27% Test: 77.93%\n",
            "Epoch: 402, Loss: 0.1779, Train: 96.53%, Valid: 90.20% Test: 77.92%\n",
            "Epoch: 403, Loss: 0.1760, Train: 96.53%, Valid: 90.08% Test: 77.95%\n",
            "Epoch: 404, Loss: 0.1781, Train: 96.55%, Valid: 90.08% Test: 77.99%\n",
            "Epoch: 405, Loss: 0.1752, Train: 96.55%, Valid: 90.14% Test: 78.03%\n",
            "Epoch: 406, Loss: 0.1814, Train: 96.55%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 407, Loss: 0.1788, Train: 96.53%, Valid: 90.20% Test: 78.12%\n",
            "Epoch: 408, Loss: 0.1761, Train: 96.57%, Valid: 90.20% Test: 78.13%\n",
            "Epoch: 409, Loss: 0.1768, Train: 96.59%, Valid: 90.14% Test: 78.12%\n",
            "Epoch: 410, Loss: 0.1802, Train: 96.59%, Valid: 90.08% Test: 78.11%\n",
            "Epoch: 411, Loss: 0.1740, Train: 96.59%, Valid: 90.08% Test: 78.11%\n",
            "Epoch: 412, Loss: 0.1762, Train: 96.59%, Valid: 90.08% Test: 78.08%\n",
            "Epoch: 413, Loss: 0.1774, Train: 96.59%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 414, Loss: 0.1773, Train: 96.60%, Valid: 90.14% Test: 78.03%\n",
            "Epoch: 415, Loss: 0.1803, Train: 96.59%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 416, Loss: 0.1792, Train: 96.59%, Valid: 90.20% Test: 77.98%\n",
            "Epoch: 417, Loss: 0.1764, Train: 96.59%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 418, Loss: 0.1778, Train: 96.61%, Valid: 90.27% Test: 77.98%\n",
            "Epoch: 419, Loss: 0.1767, Train: 96.59%, Valid: 90.08% Test: 78.00%\n",
            "Epoch: 420, Loss: 0.1753, Train: 96.59%, Valid: 90.01% Test: 78.03%\n",
            "Epoch: 421, Loss: 0.1748, Train: 96.60%, Valid: 90.08% Test: 78.05%\n",
            "Epoch: 422, Loss: 0.1712, Train: 96.57%, Valid: 90.08% Test: 78.06%\n",
            "Epoch: 423, Loss: 0.1778, Train: 96.57%, Valid: 90.08% Test: 78.07%\n",
            "Epoch: 424, Loss: 0.1738, Train: 96.57%, Valid: 90.08% Test: 78.05%\n",
            "Epoch: 425, Loss: 0.1734, Train: 96.59%, Valid: 90.08% Test: 78.02%\n",
            "Epoch: 426, Loss: 0.1758, Train: 96.58%, Valid: 90.08% Test: 78.01%\n",
            "Epoch: 427, Loss: 0.1788, Train: 96.59%, Valid: 90.20% Test: 78.03%\n",
            "Epoch: 428, Loss: 0.1775, Train: 96.58%, Valid: 90.33% Test: 78.07%\n",
            "Epoch: 429, Loss: 0.1778, Train: 96.60%, Valid: 90.33% Test: 78.05%\n",
            "Epoch: 430, Loss: 0.1723, Train: 96.61%, Valid: 90.33% Test: 78.07%\n",
            "Epoch: 431, Loss: 0.1786, Train: 96.61%, Valid: 90.27% Test: 78.05%\n",
            "Epoch: 432, Loss: 0.1754, Train: 96.63%, Valid: 90.20% Test: 78.06%\n",
            "Epoch: 433, Loss: 0.1789, Train: 96.63%, Valid: 90.20% Test: 78.06%\n",
            "Epoch: 434, Loss: 0.1724, Train: 96.65%, Valid: 90.14% Test: 78.03%\n",
            "Epoch: 435, Loss: 0.1747, Train: 96.63%, Valid: 90.08% Test: 78.02%\n",
            "Epoch: 436, Loss: 0.1721, Train: 96.59%, Valid: 90.08% Test: 78.00%\n",
            "Epoch: 437, Loss: 0.1783, Train: 96.59%, Valid: 90.08% Test: 77.97%\n",
            "Epoch: 438, Loss: 0.1728, Train: 96.59%, Valid: 90.08% Test: 77.96%\n",
            "Epoch: 439, Loss: 0.1734, Train: 96.61%, Valid: 90.01% Test: 77.95%\n",
            "Epoch: 440, Loss: 0.1752, Train: 96.63%, Valid: 90.01% Test: 77.99%\n",
            "Epoch: 441, Loss: 0.1725, Train: 96.66%, Valid: 90.08% Test: 77.99%\n",
            "Epoch: 442, Loss: 0.1693, Train: 96.70%, Valid: 90.20% Test: 78.01%\n",
            "Epoch: 443, Loss: 0.1744, Train: 96.68%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 444, Loss: 0.1773, Train: 96.68%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 445, Loss: 0.1718, Train: 96.68%, Valid: 90.20% Test: 78.04%\n",
            "Epoch: 446, Loss: 0.1703, Train: 96.66%, Valid: 90.20% Test: 78.04%\n",
            "Epoch: 447, Loss: 0.1736, Train: 96.66%, Valid: 90.27% Test: 78.02%\n",
            "Epoch: 448, Loss: 0.1746, Train: 96.67%, Valid: 90.20% Test: 78.01%\n",
            "Epoch: 449, Loss: 0.1696, Train: 96.66%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 450, Loss: 0.1741, Train: 96.66%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 451, Loss: 0.1742, Train: 96.65%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 452, Loss: 0.1679, Train: 96.65%, Valid: 90.14% Test: 77.98%\n",
            "Epoch: 453, Loss: 0.1732, Train: 96.68%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 454, Loss: 0.1737, Train: 96.68%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 455, Loss: 0.1715, Train: 96.68%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 456, Loss: 0.1704, Train: 96.68%, Valid: 90.14% Test: 77.92%\n",
            "Epoch: 457, Loss: 0.1759, Train: 96.68%, Valid: 90.14% Test: 77.88%\n",
            "Epoch: 458, Loss: 0.1701, Train: 96.70%, Valid: 90.14% Test: 77.88%\n",
            "Epoch: 459, Loss: 0.1710, Train: 96.72%, Valid: 90.20% Test: 77.89%\n",
            "Epoch: 460, Loss: 0.1738, Train: 96.71%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 461, Loss: 0.1686, Train: 96.70%, Valid: 90.14% Test: 78.01%\n",
            "Epoch: 462, Loss: 0.1658, Train: 96.70%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 463, Loss: 0.1728, Train: 96.70%, Valid: 90.14% Test: 78.08%\n",
            "Epoch: 464, Loss: 0.1702, Train: 96.70%, Valid: 90.08% Test: 78.15%\n",
            "Epoch: 465, Loss: 0.1695, Train: 96.74%, Valid: 90.14% Test: 78.15%\n",
            "Epoch: 466, Loss: 0.1696, Train: 96.74%, Valid: 90.08% Test: 78.16%\n",
            "Epoch: 467, Loss: 0.1715, Train: 96.74%, Valid: 90.08% Test: 78.15%\n",
            "Epoch: 468, Loss: 0.1706, Train: 96.72%, Valid: 90.08% Test: 78.10%\n",
            "Epoch: 469, Loss: 0.1690, Train: 96.73%, Valid: 90.08% Test: 78.08%\n",
            "Epoch: 470, Loss: 0.1731, Train: 96.75%, Valid: 90.08% Test: 78.03%\n",
            "Epoch: 471, Loss: 0.1680, Train: 96.77%, Valid: 90.08% Test: 78.01%\n",
            "Epoch: 472, Loss: 0.1698, Train: 96.76%, Valid: 90.08% Test: 77.96%\n",
            "Epoch: 473, Loss: 0.1666, Train: 96.75%, Valid: 90.08% Test: 77.93%\n",
            "Epoch: 474, Loss: 0.1682, Train: 96.74%, Valid: 90.01% Test: 77.89%\n",
            "Epoch: 475, Loss: 0.1672, Train: 96.72%, Valid: 90.01% Test: 77.90%\n",
            "Epoch: 476, Loss: 0.1729, Train: 96.73%, Valid: 90.01% Test: 77.88%\n",
            "Epoch: 477, Loss: 0.1698, Train: 96.72%, Valid: 90.08% Test: 77.91%\n",
            "Epoch: 478, Loss: 0.1702, Train: 96.72%, Valid: 90.08% Test: 77.94%\n",
            "Epoch: 479, Loss: 0.1715, Train: 96.72%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 480, Loss: 0.1719, Train: 96.73%, Valid: 90.14% Test: 77.98%\n",
            "Epoch: 481, Loss: 0.1689, Train: 96.74%, Valid: 90.08% Test: 78.00%\n",
            "Epoch: 482, Loss: 0.1677, Train: 96.74%, Valid: 90.08% Test: 77.99%\n",
            "Epoch: 483, Loss: 0.1698, Train: 96.74%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 484, Loss: 0.1632, Train: 96.76%, Valid: 90.01% Test: 77.98%\n",
            "Epoch: 485, Loss: 0.1635, Train: 96.77%, Valid: 90.14% Test: 77.97%\n",
            "Epoch: 486, Loss: 0.1667, Train: 96.76%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 487, Loss: 0.1671, Train: 96.77%, Valid: 90.20% Test: 77.96%\n",
            "Epoch: 488, Loss: 0.1648, Train: 96.76%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 489, Loss: 0.1685, Train: 96.78%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 490, Loss: 0.1625, Train: 96.79%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 491, Loss: 0.1684, Train: 96.80%, Valid: 90.20% Test: 77.93%\n",
            "Epoch: 492, Loss: 0.1674, Train: 96.80%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 493, Loss: 0.1685, Train: 96.80%, Valid: 90.27% Test: 77.97%\n",
            "Epoch: 494, Loss: 0.1656, Train: 96.80%, Valid: 90.33% Test: 77.97%\n",
            "Epoch: 495, Loss: 0.1666, Train: 96.81%, Valid: 90.20% Test: 77.98%\n",
            "Epoch: 496, Loss: 0.1654, Train: 96.82%, Valid: 90.14% Test: 77.98%\n",
            "Epoch: 497, Loss: 0.1645, Train: 96.82%, Valid: 90.14% Test: 77.98%\n",
            "Epoch: 498, Loss: 0.1653, Train: 96.82%, Valid: 90.14% Test: 77.94%\n",
            "Epoch: 499, Loss: 0.1603, Train: 96.81%, Valid: 90.08% Test: 77.95%\n",
            "Epoch: 500, Loss: 0.1639, Train: 96.84%, Valid: 90.14% Test: 77.93%\n",
            "Epoch: 501, Loss: 0.1644, Train: 96.82%, Valid: 90.14% Test: 77.93%\n",
            "Epoch: 502, Loss: 0.1638, Train: 96.82%, Valid: 90.08% Test: 77.92%\n",
            "Epoch: 503, Loss: 0.1641, Train: 96.82%, Valid: 90.08% Test: 77.94%\n",
            "Epoch: 504, Loss: 0.1675, Train: 96.84%, Valid: 90.08% Test: 77.95%\n",
            "Epoch: 505, Loss: 0.1647, Train: 96.85%, Valid: 90.08% Test: 77.97%\n",
            "Epoch: 506, Loss: 0.1648, Train: 96.85%, Valid: 90.08% Test: 78.02%\n",
            "Epoch: 507, Loss: 0.1676, Train: 96.85%, Valid: 90.01% Test: 78.04%\n",
            "Epoch: 508, Loss: 0.1648, Train: 96.87%, Valid: 90.01% Test: 78.04%\n",
            "Epoch: 509, Loss: 0.1649, Train: 96.86%, Valid: 90.01% Test: 78.05%\n",
            "Epoch: 510, Loss: 0.1632, Train: 96.85%, Valid: 90.01% Test: 78.02%\n",
            "Epoch: 511, Loss: 0.1624, Train: 96.85%, Valid: 90.01% Test: 78.00%\n",
            "Epoch: 512, Loss: 0.1668, Train: 96.85%, Valid: 90.08% Test: 78.04%\n",
            "Epoch: 513, Loss: 0.1651, Train: 96.85%, Valid: 90.08% Test: 78.07%\n",
            "Epoch: 514, Loss: 0.1658, Train: 96.86%, Valid: 90.08% Test: 78.08%\n",
            "Epoch: 515, Loss: 0.1637, Train: 96.85%, Valid: 90.20% Test: 78.10%\n",
            "Epoch: 516, Loss: 0.1616, Train: 96.87%, Valid: 90.14% Test: 78.14%\n",
            "Epoch: 517, Loss: 0.1637, Train: 96.87%, Valid: 90.08% Test: 78.17%\n",
            "Epoch: 518, Loss: 0.1652, Train: 96.86%, Valid: 90.20% Test: 78.16%\n",
            "Epoch: 519, Loss: 0.1650, Train: 96.89%, Valid: 90.27% Test: 78.13%\n",
            "Epoch: 520, Loss: 0.1644, Train: 96.89%, Valid: 90.33% Test: 78.12%\n",
            "Epoch: 521, Loss: 0.1618, Train: 96.89%, Valid: 90.33% Test: 78.11%\n",
            "Epoch: 522, Loss: 0.1644, Train: 96.89%, Valid: 90.33% Test: 78.06%\n",
            "Epoch: 523, Loss: 0.1655, Train: 96.87%, Valid: 90.27% Test: 78.03%\n",
            "Epoch: 524, Loss: 0.1624, Train: 96.86%, Valid: 90.20% Test: 78.02%\n",
            "Epoch: 525, Loss: 0.1629, Train: 96.87%, Valid: 90.14% Test: 78.01%\n",
            "Epoch: 526, Loss: 0.1657, Train: 96.87%, Valid: 90.14% Test: 78.03%\n",
            "Epoch: 527, Loss: 0.1628, Train: 96.88%, Valid: 90.20% Test: 78.04%\n",
            "Epoch: 528, Loss: 0.1622, Train: 96.90%, Valid: 90.14% Test: 78.06%\n",
            "Epoch: 529, Loss: 0.1681, Train: 96.89%, Valid: 90.14% Test: 78.08%\n",
            "Epoch: 530, Loss: 0.1676, Train: 96.89%, Valid: 90.20% Test: 78.08%\n",
            "Epoch: 531, Loss: 0.1641, Train: 96.89%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 532, Loss: 0.1663, Train: 96.90%, Valid: 90.14% Test: 78.07%\n",
            "Epoch: 533, Loss: 0.1607, Train: 96.91%, Valid: 90.20% Test: 78.06%\n",
            "Epoch: 534, Loss: 0.1606, Train: 96.91%, Valid: 90.20% Test: 77.98%\n",
            "Epoch: 535, Loss: 0.1593, Train: 96.91%, Valid: 90.14% Test: 77.92%\n",
            "Epoch: 536, Loss: 0.1600, Train: 96.91%, Valid: 90.01% Test: 77.89%\n",
            "Epoch: 537, Loss: 0.1595, Train: 96.89%, Valid: 90.01% Test: 77.85%\n",
            "Epoch: 538, Loss: 0.1618, Train: 96.91%, Valid: 89.95% Test: 77.83%\n",
            "Epoch: 539, Loss: 0.1617, Train: 96.91%, Valid: 90.08% Test: 77.82%\n",
            "Epoch: 540, Loss: 0.1581, Train: 96.92%, Valid: 90.14% Test: 77.84%\n",
            "Epoch: 541, Loss: 0.1633, Train: 96.92%, Valid: 90.14% Test: 77.91%\n",
            "Epoch: 542, Loss: 0.1621, Train: 96.91%, Valid: 90.08% Test: 77.97%\n",
            "Epoch: 543, Loss: 0.1599, Train: 96.90%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 544, Loss: 0.1618, Train: 96.92%, Valid: 90.14% Test: 78.03%\n",
            "Epoch: 545, Loss: 0.1574, Train: 96.92%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 546, Loss: 0.1603, Train: 96.91%, Valid: 90.33% Test: 78.04%\n",
            "Epoch: 547, Loss: 0.1575, Train: 96.91%, Valid: 90.08% Test: 78.01%\n",
            "Epoch: 548, Loss: 0.1606, Train: 96.92%, Valid: 90.08% Test: 77.95%\n",
            "Epoch: 549, Loss: 0.1595, Train: 96.92%, Valid: 90.01% Test: 77.90%\n",
            "Epoch: 550, Loss: 0.1587, Train: 96.91%, Valid: 90.01% Test: 77.85%\n",
            "Epoch: 551, Loss: 0.1595, Train: 96.92%, Valid: 90.08% Test: 77.83%\n",
            "Epoch: 552, Loss: 0.1572, Train: 96.93%, Valid: 90.08% Test: 77.83%\n",
            "Epoch: 553, Loss: 0.1602, Train: 96.90%, Valid: 90.14% Test: 77.83%\n",
            "Epoch: 554, Loss: 0.1555, Train: 96.89%, Valid: 90.01% Test: 77.86%\n",
            "Epoch: 555, Loss: 0.1591, Train: 96.89%, Valid: 90.01% Test: 77.86%\n",
            "Epoch: 556, Loss: 0.1584, Train: 96.92%, Valid: 90.01% Test: 77.89%\n",
            "Epoch: 557, Loss: 0.1621, Train: 96.94%, Valid: 90.01% Test: 77.91%\n",
            "Epoch: 558, Loss: 0.1583, Train: 96.96%, Valid: 90.01% Test: 77.96%\n",
            "Epoch: 559, Loss: 0.1557, Train: 96.97%, Valid: 90.01% Test: 77.97%\n",
            "Epoch: 560, Loss: 0.1590, Train: 96.97%, Valid: 90.14% Test: 78.00%\n",
            "Epoch: 561, Loss: 0.1545, Train: 96.97%, Valid: 90.14% Test: 78.03%\n",
            "Epoch: 562, Loss: 0.1592, Train: 96.98%, Valid: 90.14% Test: 78.02%\n",
            "Epoch: 563, Loss: 0.1605, Train: 96.97%, Valid: 90.14% Test: 78.00%\n",
            "Epoch: 564, Loss: 0.1624, Train: 96.97%, Valid: 90.14% Test: 77.98%\n",
            "Epoch: 565, Loss: 0.1591, Train: 96.97%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 566, Loss: 0.1587, Train: 96.97%, Valid: 90.08% Test: 77.93%\n",
            "Epoch: 567, Loss: 0.1591, Train: 96.99%, Valid: 90.08% Test: 77.93%\n",
            "Epoch: 568, Loss: 0.1576, Train: 96.97%, Valid: 90.01% Test: 77.93%\n",
            "Epoch: 569, Loss: 0.1589, Train: 96.93%, Valid: 90.08% Test: 77.92%\n",
            "Epoch: 570, Loss: 0.1583, Train: 96.92%, Valid: 90.14% Test: 77.93%\n",
            "Epoch: 571, Loss: 0.1562, Train: 96.93%, Valid: 90.14% Test: 77.93%\n",
            "Epoch: 572, Loss: 0.1594, Train: 96.96%, Valid: 90.08% Test: 77.96%\n",
            "Epoch: 573, Loss: 0.1574, Train: 96.97%, Valid: 90.14% Test: 77.97%\n",
            "Epoch: 574, Loss: 0.1592, Train: 97.00%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 575, Loss: 0.1563, Train: 97.01%, Valid: 90.20% Test: 78.03%\n",
            "Epoch: 576, Loss: 0.1531, Train: 97.02%, Valid: 90.20% Test: 78.11%\n",
            "Epoch: 577, Loss: 0.1589, Train: 97.04%, Valid: 90.27% Test: 78.11%\n",
            "Epoch: 578, Loss: 0.1547, Train: 97.03%, Valid: 90.14% Test: 78.11%\n",
            "Epoch: 579, Loss: 0.1578, Train: 97.02%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 580, Loss: 0.1572, Train: 97.02%, Valid: 90.27% Test: 77.99%\n",
            "Epoch: 581, Loss: 0.1588, Train: 97.00%, Valid: 90.20% Test: 77.96%\n",
            "Epoch: 582, Loss: 0.1528, Train: 96.98%, Valid: 90.14% Test: 77.94%\n",
            "Epoch: 583, Loss: 0.1570, Train: 96.97%, Valid: 90.14% Test: 77.91%\n",
            "Epoch: 584, Loss: 0.1487, Train: 96.95%, Valid: 90.20% Test: 77.89%\n",
            "Epoch: 585, Loss: 0.1577, Train: 96.98%, Valid: 90.20% Test: 77.89%\n",
            "Epoch: 586, Loss: 0.1590, Train: 96.99%, Valid: 90.20% Test: 77.91%\n",
            "Epoch: 587, Loss: 0.1565, Train: 96.99%, Valid: 90.20% Test: 77.92%\n",
            "Epoch: 588, Loss: 0.1535, Train: 96.99%, Valid: 90.14% Test: 77.96%\n",
            "Epoch: 589, Loss: 0.1576, Train: 97.00%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 590, Loss: 0.1549, Train: 97.00%, Valid: 90.20% Test: 78.00%\n",
            "Epoch: 591, Loss: 0.1529, Train: 96.99%, Valid: 90.27% Test: 77.99%\n",
            "Epoch: 592, Loss: 0.1513, Train: 96.99%, Valid: 90.33% Test: 77.97%\n",
            "Epoch: 593, Loss: 0.1559, Train: 96.99%, Valid: 90.27% Test: 77.96%\n",
            "Epoch: 594, Loss: 0.1576, Train: 96.97%, Valid: 90.27% Test: 77.95%\n",
            "Epoch: 595, Loss: 0.1546, Train: 96.99%, Valid: 90.27% Test: 77.94%\n",
            "Epoch: 596, Loss: 0.1581, Train: 97.02%, Valid: 90.27% Test: 77.94%\n",
            "Epoch: 597, Loss: 0.1571, Train: 97.03%, Valid: 90.08% Test: 77.92%\n",
            "Epoch: 598, Loss: 0.1524, Train: 97.04%, Valid: 90.01% Test: 77.90%\n",
            "Epoch: 599, Loss: 0.1543, Train: 97.03%, Valid: 90.01% Test: 77.88%\n",
            "Epoch: 600, Loss: 0.1539, Train: 97.04%, Valid: 89.95% Test: 77.90%\n",
            "Epoch: 601, Loss: 0.1529, Train: 97.06%, Valid: 90.14% Test: 77.89%\n",
            "Epoch: 602, Loss: 0.1554, Train: 97.06%, Valid: 90.08% Test: 77.91%\n",
            "Epoch: 603, Loss: 0.1533, Train: 97.07%, Valid: 90.14% Test: 77.92%\n",
            "Epoch: 604, Loss: 0.1509, Train: 97.08%, Valid: 90.14% Test: 77.93%\n",
            "Epoch: 605, Loss: 0.1572, Train: 97.08%, Valid: 90.08% Test: 77.94%\n",
            "Epoch: 606, Loss: 0.1524, Train: 97.08%, Valid: 90.08% Test: 77.93%\n",
            "Epoch: 607, Loss: 0.1527, Train: 97.08%, Valid: 90.08% Test: 77.96%\n",
            "Epoch: 608, Loss: 0.1522, Train: 97.06%, Valid: 90.08% Test: 77.95%\n",
            "Epoch: 609, Loss: 0.1512, Train: 97.06%, Valid: 90.08% Test: 77.93%\n",
            "Epoch: 610, Loss: 0.1513, Train: 97.06%, Valid: 90.08% Test: 77.93%\n",
            "Epoch: 611, Loss: 0.1499, Train: 97.08%, Valid: 90.14% Test: 77.94%\n",
            "Epoch: 612, Loss: 0.1548, Train: 97.08%, Valid: 90.14% Test: 77.96%\n",
            "Epoch: 613, Loss: 0.1549, Train: 97.09%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 614, Loss: 0.1521, Train: 97.08%, Valid: 90.08% Test: 77.94%\n",
            "Epoch: 615, Loss: 0.1541, Train: 97.09%, Valid: 90.14% Test: 77.93%\n",
            "Epoch: 616, Loss: 0.1557, Train: 97.10%, Valid: 90.20% Test: 77.96%\n",
            "Epoch: 617, Loss: 0.1511, Train: 97.12%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 618, Loss: 0.1542, Train: 97.10%, Valid: 90.20% Test: 78.01%\n",
            "Epoch: 619, Loss: 0.1553, Train: 97.12%, Valid: 90.20% Test: 78.00%\n",
            "Epoch: 620, Loss: 0.1492, Train: 97.13%, Valid: 90.27% Test: 78.02%\n",
            "Epoch: 621, Loss: 0.1522, Train: 97.13%, Valid: 90.20% Test: 78.02%\n",
            "Epoch: 622, Loss: 0.1501, Train: 97.13%, Valid: 90.20% Test: 78.04%\n",
            "Epoch: 623, Loss: 0.1515, Train: 97.12%, Valid: 90.20% Test: 78.03%\n",
            "Epoch: 624, Loss: 0.1494, Train: 97.12%, Valid: 90.27% Test: 78.01%\n",
            "Epoch: 625, Loss: 0.1515, Train: 97.11%, Valid: 90.27% Test: 77.98%\n",
            "Epoch: 626, Loss: 0.1546, Train: 97.12%, Valid: 90.33% Test: 77.97%\n",
            "Epoch: 627, Loss: 0.1509, Train: 97.12%, Valid: 90.20% Test: 77.92%\n",
            "Epoch: 628, Loss: 0.1488, Train: 97.10%, Valid: 90.20% Test: 77.92%\n",
            "Epoch: 629, Loss: 0.1522, Train: 97.10%, Valid: 90.27% Test: 77.90%\n",
            "Epoch: 630, Loss: 0.1515, Train: 97.09%, Valid: 90.27% Test: 77.88%\n",
            "Epoch: 631, Loss: 0.1513, Train: 97.09%, Valid: 90.20% Test: 77.87%\n",
            "Epoch: 632, Loss: 0.1500, Train: 97.08%, Valid: 90.20% Test: 77.86%\n",
            "Epoch: 633, Loss: 0.1516, Train: 97.10%, Valid: 90.20% Test: 77.88%\n",
            "Epoch: 634, Loss: 0.1522, Train: 97.12%, Valid: 90.27% Test: 77.88%\n",
            "Epoch: 635, Loss: 0.1487, Train: 97.13%, Valid: 90.33% Test: 77.90%\n",
            "Epoch: 636, Loss: 0.1458, Train: 97.12%, Valid: 90.33% Test: 77.92%\n",
            "Epoch: 637, Loss: 0.1507, Train: 97.12%, Valid: 90.27% Test: 77.91%\n",
            "Epoch: 638, Loss: 0.1495, Train: 97.13%, Valid: 90.27% Test: 77.92%\n",
            "Epoch: 639, Loss: 0.1490, Train: 97.13%, Valid: 90.20% Test: 77.94%\n",
            "Epoch: 640, Loss: 0.1484, Train: 97.14%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 641, Loss: 0.1543, Train: 97.14%, Valid: 90.27% Test: 77.95%\n",
            "Epoch: 642, Loss: 0.1444, Train: 97.16%, Valid: 90.27% Test: 77.95%\n",
            "Epoch: 643, Loss: 0.1520, Train: 97.17%, Valid: 90.33% Test: 77.92%\n",
            "Epoch: 644, Loss: 0.1499, Train: 97.18%, Valid: 90.33% Test: 77.91%\n",
            "Epoch: 645, Loss: 0.1453, Train: 97.18%, Valid: 90.27% Test: 77.92%\n",
            "Epoch: 646, Loss: 0.1501, Train: 97.16%, Valid: 90.27% Test: 77.96%\n",
            "Epoch: 647, Loss: 0.1490, Train: 97.15%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 648, Loss: 0.1481, Train: 97.17%, Valid: 90.27% Test: 77.98%\n",
            "Epoch: 649, Loss: 0.1505, Train: 97.19%, Valid: 90.27% Test: 77.98%\n",
            "Epoch: 650, Loss: 0.1486, Train: 97.19%, Valid: 90.33% Test: 77.95%\n",
            "Epoch: 651, Loss: 0.1481, Train: 97.19%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 652, Loss: 0.1481, Train: 97.19%, Valid: 90.20% Test: 77.91%\n",
            "Epoch: 653, Loss: 0.1487, Train: 97.18%, Valid: 90.20% Test: 77.88%\n",
            "Epoch: 654, Loss: 0.1452, Train: 97.18%, Valid: 90.20% Test: 77.85%\n",
            "Epoch: 655, Loss: 0.1452, Train: 97.19%, Valid: 90.20% Test: 77.84%\n",
            "Epoch: 656, Loss: 0.1478, Train: 97.19%, Valid: 90.20% Test: 77.84%\n",
            "Epoch: 657, Loss: 0.1502, Train: 97.19%, Valid: 90.20% Test: 77.86%\n",
            "Epoch: 658, Loss: 0.1469, Train: 97.21%, Valid: 90.14% Test: 77.88%\n",
            "Epoch: 659, Loss: 0.1426, Train: 97.22%, Valid: 90.20% Test: 77.90%\n",
            "Epoch: 660, Loss: 0.1484, Train: 97.23%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 661, Loss: 0.1455, Train: 97.22%, Valid: 90.27% Test: 77.97%\n",
            "Epoch: 662, Loss: 0.1458, Train: 97.23%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 663, Loss: 0.1465, Train: 97.22%, Valid: 90.27% Test: 77.96%\n",
            "Epoch: 664, Loss: 0.1449, Train: 97.23%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 665, Loss: 0.1476, Train: 97.25%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 666, Loss: 0.1465, Train: 97.23%, Valid: 90.20% Test: 77.93%\n",
            "Epoch: 667, Loss: 0.1450, Train: 97.21%, Valid: 90.14% Test: 77.93%\n",
            "Epoch: 668, Loss: 0.1432, Train: 97.21%, Valid: 90.14% Test: 77.92%\n",
            "Epoch: 669, Loss: 0.1467, Train: 97.22%, Valid: 90.14% Test: 77.92%\n",
            "Epoch: 670, Loss: 0.1466, Train: 97.22%, Valid: 90.14% Test: 77.94%\n",
            "Epoch: 671, Loss: 0.1467, Train: 97.23%, Valid: 90.14% Test: 77.94%\n",
            "Epoch: 672, Loss: 0.1466, Train: 97.23%, Valid: 90.27% Test: 77.94%\n",
            "Epoch: 673, Loss: 0.1485, Train: 97.20%, Valid: 90.33% Test: 77.91%\n",
            "Epoch: 674, Loss: 0.1459, Train: 97.22%, Valid: 90.33% Test: 77.90%\n",
            "Epoch: 675, Loss: 0.1450, Train: 97.23%, Valid: 90.20% Test: 77.88%\n",
            "Epoch: 676, Loss: 0.1492, Train: 97.25%, Valid: 90.14% Test: 77.86%\n",
            "Epoch: 677, Loss: 0.1449, Train: 97.25%, Valid: 90.14% Test: 77.82%\n",
            "Epoch: 678, Loss: 0.1444, Train: 97.25%, Valid: 90.14% Test: 77.79%\n",
            "Epoch: 679, Loss: 0.1431, Train: 97.25%, Valid: 90.14% Test: 77.78%\n",
            "Epoch: 680, Loss: 0.1447, Train: 97.25%, Valid: 90.14% Test: 77.76%\n",
            "Epoch: 681, Loss: 0.1419, Train: 97.24%, Valid: 90.14% Test: 77.77%\n",
            "Epoch: 682, Loss: 0.1454, Train: 97.21%, Valid: 90.14% Test: 77.79%\n",
            "Epoch: 683, Loss: 0.1438, Train: 97.22%, Valid: 90.14% Test: 77.84%\n",
            "Epoch: 684, Loss: 0.1461, Train: 97.22%, Valid: 90.14% Test: 77.87%\n",
            "Epoch: 685, Loss: 0.1423, Train: 97.21%, Valid: 90.14% Test: 77.90%\n",
            "Epoch: 686, Loss: 0.1432, Train: 97.22%, Valid: 90.14% Test: 77.93%\n",
            "Epoch: 687, Loss: 0.1460, Train: 97.22%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 688, Loss: 0.1443, Train: 97.23%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 689, Loss: 0.1419, Train: 97.24%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 690, Loss: 0.1398, Train: 97.24%, Valid: 90.20% Test: 78.01%\n",
            "Epoch: 691, Loss: 0.1414, Train: 97.23%, Valid: 90.33% Test: 77.99%\n",
            "Epoch: 692, Loss: 0.1444, Train: 97.23%, Valid: 90.27% Test: 78.01%\n",
            "Epoch: 693, Loss: 0.1421, Train: 97.21%, Valid: 90.27% Test: 78.02%\n",
            "Epoch: 694, Loss: 0.1435, Train: 97.21%, Valid: 90.27% Test: 78.00%\n",
            "Epoch: 695, Loss: 0.1454, Train: 97.21%, Valid: 90.20% Test: 78.00%\n",
            "Epoch: 696, Loss: 0.1459, Train: 97.23%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 697, Loss: 0.1413, Train: 97.23%, Valid: 90.20% Test: 77.93%\n",
            "Epoch: 698, Loss: 0.1447, Train: 97.25%, Valid: 90.20% Test: 77.89%\n",
            "Epoch: 699, Loss: 0.1413, Train: 97.25%, Valid: 90.20% Test: 77.88%\n",
            "Epoch: 700, Loss: 0.1410, Train: 97.27%, Valid: 90.20% Test: 77.89%\n",
            "Epoch: 701, Loss: 0.1470, Train: 97.26%, Valid: 90.20% Test: 77.91%\n",
            "Epoch: 702, Loss: 0.1453, Train: 97.27%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 703, Loss: 0.1407, Train: 97.29%, Valid: 90.20% Test: 78.02%\n",
            "Epoch: 704, Loss: 0.1459, Train: 97.29%, Valid: 90.20% Test: 78.06%\n",
            "Epoch: 705, Loss: 0.1447, Train: 97.29%, Valid: 90.27% Test: 78.08%\n",
            "Epoch: 706, Loss: 0.1420, Train: 97.27%, Valid: 90.33% Test: 78.11%\n",
            "Epoch: 707, Loss: 0.1471, Train: 97.28%, Valid: 90.33% Test: 78.10%\n",
            "Epoch: 708, Loss: 0.1424, Train: 97.27%, Valid: 90.27% Test: 78.06%\n",
            "Epoch: 709, Loss: 0.1400, Train: 97.29%, Valid: 90.27% Test: 78.02%\n",
            "Epoch: 710, Loss: 0.1378, Train: 97.27%, Valid: 90.27% Test: 77.94%\n",
            "Epoch: 711, Loss: 0.1419, Train: 97.27%, Valid: 90.27% Test: 77.90%\n",
            "Epoch: 712, Loss: 0.1404, Train: 97.28%, Valid: 90.20% Test: 77.86%\n",
            "Epoch: 713, Loss: 0.1400, Train: 97.29%, Valid: 90.20% Test: 77.85%\n",
            "Epoch: 714, Loss: 0.1371, Train: 97.27%, Valid: 90.20% Test: 77.83%\n",
            "Epoch: 715, Loss: 0.1411, Train: 97.27%, Valid: 90.27% Test: 77.86%\n",
            "Epoch: 716, Loss: 0.1432, Train: 97.27%, Valid: 90.27% Test: 77.91%\n",
            "Epoch: 717, Loss: 0.1414, Train: 97.29%, Valid: 90.27% Test: 77.95%\n",
            "Epoch: 718, Loss: 0.1422, Train: 97.33%, Valid: 90.27% Test: 78.00%\n",
            "Epoch: 719, Loss: 0.1402, Train: 97.33%, Valid: 90.27% Test: 78.04%\n",
            "Epoch: 720, Loss: 0.1408, Train: 97.35%, Valid: 90.27% Test: 78.06%\n",
            "Epoch: 721, Loss: 0.1430, Train: 97.34%, Valid: 90.27% Test: 78.03%\n",
            "Epoch: 722, Loss: 0.1437, Train: 97.35%, Valid: 90.27% Test: 78.01%\n",
            "Epoch: 723, Loss: 0.1390, Train: 97.33%, Valid: 90.27% Test: 77.96%\n",
            "Epoch: 724, Loss: 0.1360, Train: 97.34%, Valid: 90.20% Test: 77.98%\n",
            "Epoch: 725, Loss: 0.1391, Train: 97.35%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 726, Loss: 0.1419, Train: 97.35%, Valid: 90.20% Test: 77.94%\n",
            "Epoch: 727, Loss: 0.1370, Train: 97.37%, Valid: 90.20% Test: 77.93%\n",
            "Epoch: 728, Loss: 0.1370, Train: 97.36%, Valid: 90.20% Test: 77.89%\n",
            "Epoch: 729, Loss: 0.1374, Train: 97.35%, Valid: 90.27% Test: 77.85%\n",
            "Epoch: 730, Loss: 0.1375, Train: 97.34%, Valid: 90.14% Test: 77.86%\n",
            "Epoch: 731, Loss: 0.1398, Train: 97.34%, Valid: 90.14% Test: 77.84%\n",
            "Epoch: 732, Loss: 0.1388, Train: 97.35%, Valid: 90.14% Test: 77.80%\n",
            "Epoch: 733, Loss: 0.1386, Train: 97.36%, Valid: 90.14% Test: 77.83%\n",
            "Epoch: 734, Loss: 0.1377, Train: 97.35%, Valid: 90.14% Test: 77.81%\n",
            "Epoch: 735, Loss: 0.1383, Train: 97.35%, Valid: 90.14% Test: 77.82%\n",
            "Epoch: 736, Loss: 0.1411, Train: 97.36%, Valid: 90.14% Test: 77.84%\n",
            "Epoch: 737, Loss: 0.1419, Train: 97.36%, Valid: 90.08% Test: 77.88%\n",
            "Epoch: 738, Loss: 0.1367, Train: 97.38%, Valid: 90.08% Test: 77.89%\n",
            "Epoch: 739, Loss: 0.1381, Train: 97.38%, Valid: 90.08% Test: 77.88%\n",
            "Epoch: 740, Loss: 0.1375, Train: 97.38%, Valid: 90.08% Test: 77.91%\n",
            "Epoch: 741, Loss: 0.1404, Train: 97.38%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 742, Loss: 0.1387, Train: 97.37%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 743, Loss: 0.1397, Train: 97.36%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 744, Loss: 0.1399, Train: 97.36%, Valid: 90.20% Test: 77.94%\n",
            "Epoch: 745, Loss: 0.1376, Train: 97.37%, Valid: 90.27% Test: 77.87%\n",
            "Epoch: 746, Loss: 0.1399, Train: 97.36%, Valid: 90.27% Test: 77.83%\n",
            "Epoch: 747, Loss: 0.1387, Train: 97.37%, Valid: 90.27% Test: 77.77%\n",
            "Epoch: 748, Loss: 0.1341, Train: 97.36%, Valid: 90.27% Test: 77.78%\n",
            "Epoch: 749, Loss: 0.1391, Train: 97.40%, Valid: 90.20% Test: 77.76%\n",
            "Epoch: 750, Loss: 0.1398, Train: 97.40%, Valid: 90.20% Test: 77.79%\n",
            "Epoch: 751, Loss: 0.1348, Train: 97.41%, Valid: 90.20% Test: 77.84%\n",
            "Epoch: 752, Loss: 0.1349, Train: 97.40%, Valid: 90.20% Test: 77.87%\n",
            "Epoch: 753, Loss: 0.1380, Train: 97.41%, Valid: 90.27% Test: 77.90%\n",
            "Epoch: 754, Loss: 0.1371, Train: 97.42%, Valid: 90.27% Test: 77.93%\n",
            "Epoch: 755, Loss: 0.1329, Train: 97.43%, Valid: 90.20% Test: 77.90%\n",
            "Epoch: 756, Loss: 0.1345, Train: 97.44%, Valid: 90.20% Test: 77.90%\n",
            "Epoch: 757, Loss: 0.1384, Train: 97.42%, Valid: 90.20% Test: 77.85%\n",
            "Epoch: 758, Loss: 0.1348, Train: 97.41%, Valid: 90.20% Test: 77.82%\n",
            "Epoch: 759, Loss: 0.1347, Train: 97.41%, Valid: 90.20% Test: 77.79%\n",
            "Epoch: 760, Loss: 0.1326, Train: 97.42%, Valid: 90.20% Test: 77.79%\n",
            "Epoch: 761, Loss: 0.1384, Train: 97.44%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 762, Loss: 0.1364, Train: 97.44%, Valid: 90.20% Test: 77.84%\n",
            "Epoch: 763, Loss: 0.1344, Train: 97.44%, Valid: 90.20% Test: 77.88%\n",
            "Epoch: 764, Loss: 0.1362, Train: 97.45%, Valid: 90.20% Test: 77.89%\n",
            "Epoch: 765, Loss: 0.1385, Train: 97.44%, Valid: 90.14% Test: 77.92%\n",
            "Epoch: 766, Loss: 0.1377, Train: 97.45%, Valid: 90.14% Test: 77.94%\n",
            "Epoch: 767, Loss: 0.1342, Train: 97.45%, Valid: 90.14% Test: 77.99%\n",
            "Epoch: 768, Loss: 0.1320, Train: 97.46%, Valid: 90.14% Test: 78.01%\n",
            "Epoch: 769, Loss: 0.1323, Train: 97.47%, Valid: 90.14% Test: 78.02%\n",
            "Epoch: 770, Loss: 0.1376, Train: 97.48%, Valid: 90.20% Test: 78.05%\n",
            "Epoch: 771, Loss: 0.1351, Train: 97.48%, Valid: 90.20% Test: 78.04%\n",
            "Epoch: 772, Loss: 0.1369, Train: 97.48%, Valid: 90.20% Test: 77.99%\n",
            "Epoch: 773, Loss: 0.1353, Train: 97.47%, Valid: 90.20% Test: 77.94%\n",
            "Epoch: 774, Loss: 0.1358, Train: 97.47%, Valid: 90.27% Test: 77.91%\n",
            "Epoch: 775, Loss: 0.1350, Train: 97.48%, Valid: 90.27% Test: 77.90%\n",
            "Epoch: 776, Loss: 0.1324, Train: 97.48%, Valid: 90.27% Test: 77.92%\n",
            "Epoch: 777, Loss: 0.1372, Train: 97.48%, Valid: 90.27% Test: 77.93%\n",
            "Epoch: 778, Loss: 0.1327, Train: 97.46%, Valid: 90.33% Test: 77.97%\n",
            "Epoch: 779, Loss: 0.1321, Train: 97.46%, Valid: 90.27% Test: 77.99%\n",
            "Epoch: 780, Loss: 0.1334, Train: 97.46%, Valid: 90.27% Test: 77.96%\n",
            "Epoch: 781, Loss: 0.1360, Train: 97.46%, Valid: 90.20% Test: 77.93%\n",
            "Epoch: 782, Loss: 0.1350, Train: 97.47%, Valid: 90.20% Test: 77.87%\n",
            "Epoch: 783, Loss: 0.1343, Train: 97.49%, Valid: 90.20% Test: 77.83%\n",
            "Epoch: 784, Loss: 0.1321, Train: 97.49%, Valid: 90.20% Test: 77.81%\n",
            "Epoch: 785, Loss: 0.1312, Train: 97.49%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 786, Loss: 0.1359, Train: 97.52%, Valid: 90.20% Test: 77.79%\n",
            "Epoch: 787, Loss: 0.1321, Train: 97.51%, Valid: 90.20% Test: 77.82%\n",
            "Epoch: 788, Loss: 0.1333, Train: 97.52%, Valid: 90.20% Test: 77.85%\n",
            "Epoch: 789, Loss: 0.1316, Train: 97.53%, Valid: 90.27% Test: 77.89%\n",
            "Epoch: 790, Loss: 0.1298, Train: 97.53%, Valid: 90.20% Test: 77.92%\n",
            "Epoch: 791, Loss: 0.1357, Train: 97.54%, Valid: 90.20% Test: 77.96%\n",
            "Epoch: 792, Loss: 0.1378, Train: 97.53%, Valid: 90.20% Test: 77.98%\n",
            "Epoch: 793, Loss: 0.1339, Train: 97.53%, Valid: 90.20% Test: 77.98%\n",
            "Epoch: 794, Loss: 0.1293, Train: 97.54%, Valid: 90.14% Test: 77.98%\n",
            "Epoch: 795, Loss: 0.1261, Train: 97.55%, Valid: 90.14% Test: 77.98%\n",
            "Epoch: 796, Loss: 0.1334, Train: 97.56%, Valid: 90.14% Test: 77.97%\n",
            "Epoch: 797, Loss: 0.1351, Train: 97.55%, Valid: 90.20% Test: 77.92%\n",
            "Epoch: 798, Loss: 0.1323, Train: 97.55%, Valid: 90.20% Test: 77.87%\n",
            "Epoch: 799, Loss: 0.1313, Train: 97.55%, Valid: 90.20% Test: 77.85%\n",
            "Epoch: 800, Loss: 0.1350, Train: 97.52%, Valid: 90.20% Test: 77.88%\n",
            "Epoch: 801, Loss: 0.1340, Train: 97.50%, Valid: 90.14% Test: 77.85%\n",
            "Epoch: 802, Loss: 0.1360, Train: 97.50%, Valid: 90.14% Test: 77.79%\n",
            "Epoch: 803, Loss: 0.1317, Train: 97.51%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 804, Loss: 0.1326, Train: 97.54%, Valid: 90.14% Test: 77.78%\n",
            "Epoch: 805, Loss: 0.1313, Train: 97.54%, Valid: 90.14% Test: 77.83%\n",
            "Epoch: 806, Loss: 0.1332, Train: 97.55%, Valid: 90.20% Test: 77.87%\n",
            "Epoch: 807, Loss: 0.1329, Train: 97.55%, Valid: 90.27% Test: 77.85%\n",
            "Epoch: 808, Loss: 0.1305, Train: 97.55%, Valid: 90.27% Test: 77.88%\n",
            "Epoch: 809, Loss: 0.1323, Train: 97.54%, Valid: 90.20% Test: 77.88%\n",
            "Epoch: 810, Loss: 0.1350, Train: 97.54%, Valid: 90.20% Test: 77.85%\n",
            "Epoch: 811, Loss: 0.1321, Train: 97.51%, Valid: 90.20% Test: 77.86%\n",
            "Epoch: 812, Loss: 0.1372, Train: 97.54%, Valid: 90.14% Test: 77.84%\n",
            "Epoch: 813, Loss: 0.1336, Train: 97.55%, Valid: 90.33% Test: 77.79%\n",
            "Epoch: 814, Loss: 0.1282, Train: 97.55%, Valid: 90.27% Test: 77.78%\n",
            "Epoch: 815, Loss: 0.1289, Train: 97.57%, Valid: 90.20% Test: 77.75%\n",
            "Epoch: 816, Loss: 0.1303, Train: 97.57%, Valid: 90.27% Test: 77.77%\n",
            "Epoch: 817, Loss: 0.1302, Train: 97.58%, Valid: 90.20% Test: 77.84%\n",
            "Epoch: 818, Loss: 0.1312, Train: 97.58%, Valid: 90.20% Test: 77.87%\n",
            "Epoch: 819, Loss: 0.1335, Train: 97.57%, Valid: 90.27% Test: 77.93%\n",
            "Epoch: 820, Loss: 0.1329, Train: 97.55%, Valid: 90.20% Test: 77.97%\n",
            "Epoch: 821, Loss: 0.1308, Train: 97.55%, Valid: 90.20% Test: 78.00%\n",
            "Epoch: 822, Loss: 0.1296, Train: 97.57%, Valid: 90.27% Test: 77.99%\n",
            "Epoch: 823, Loss: 0.1296, Train: 97.59%, Valid: 90.14% Test: 77.95%\n",
            "Epoch: 824, Loss: 0.1276, Train: 97.59%, Valid: 90.14% Test: 77.91%\n",
            "Epoch: 825, Loss: 0.1302, Train: 97.58%, Valid: 90.20% Test: 77.87%\n",
            "Epoch: 826, Loss: 0.1291, Train: 97.58%, Valid: 90.27% Test: 77.84%\n",
            "Epoch: 827, Loss: 0.1300, Train: 97.59%, Valid: 90.27% Test: 77.82%\n",
            "Epoch: 828, Loss: 0.1304, Train: 97.55%, Valid: 90.27% Test: 77.81%\n",
            "Epoch: 829, Loss: 0.1299, Train: 97.55%, Valid: 90.27% Test: 77.78%\n",
            "Epoch: 830, Loss: 0.1309, Train: 97.56%, Valid: 90.33% Test: 77.79%\n",
            "Epoch: 831, Loss: 0.1276, Train: 97.58%, Valid: 90.33% Test: 77.81%\n",
            "Epoch: 832, Loss: 0.1302, Train: 97.61%, Valid: 90.20% Test: 77.81%\n",
            "Epoch: 833, Loss: 0.1261, Train: 97.61%, Valid: 90.20% Test: 77.78%\n",
            "Epoch: 834, Loss: 0.1292, Train: 97.62%, Valid: 90.14% Test: 77.74%\n",
            "Epoch: 835, Loss: 0.1294, Train: 97.62%, Valid: 90.14% Test: 77.73%\n",
            "Epoch: 836, Loss: 0.1318, Train: 97.62%, Valid: 90.27% Test: 77.75%\n",
            "Epoch: 837, Loss: 0.1301, Train: 97.63%, Valid: 90.20% Test: 77.78%\n",
            "Epoch: 838, Loss: 0.1302, Train: 97.63%, Valid: 90.20% Test: 77.82%\n",
            "Epoch: 839, Loss: 0.1292, Train: 97.64%, Valid: 90.14% Test: 77.85%\n",
            "Epoch: 840, Loss: 0.1298, Train: 97.64%, Valid: 90.14% Test: 77.87%\n",
            "Epoch: 841, Loss: 0.1276, Train: 97.64%, Valid: 90.14% Test: 77.86%\n",
            "Epoch: 842, Loss: 0.1277, Train: 97.64%, Valid: 90.20% Test: 77.83%\n",
            "Epoch: 843, Loss: 0.1252, Train: 97.65%, Valid: 90.20% Test: 77.83%\n",
            "Epoch: 844, Loss: 0.1268, Train: 97.63%, Valid: 90.20% Test: 77.83%\n",
            "Epoch: 845, Loss: 0.1305, Train: 97.63%, Valid: 90.14% Test: 77.81%\n",
            "Epoch: 846, Loss: 0.1262, Train: 97.64%, Valid: 90.14% Test: 77.81%\n",
            "Epoch: 847, Loss: 0.1271, Train: 97.64%, Valid: 90.20% Test: 77.81%\n",
            "Epoch: 848, Loss: 0.1249, Train: 97.64%, Valid: 90.27% Test: 77.80%\n",
            "Epoch: 849, Loss: 0.1294, Train: 97.65%, Valid: 90.27% Test: 77.83%\n",
            "Epoch: 850, Loss: 0.1275, Train: 97.66%, Valid: 90.27% Test: 77.87%\n",
            "Epoch: 851, Loss: 0.1250, Train: 97.65%, Valid: 90.20% Test: 77.88%\n",
            "Epoch: 852, Loss: 0.1238, Train: 97.63%, Valid: 90.20% Test: 77.90%\n",
            "Epoch: 853, Loss: 0.1307, Train: 97.63%, Valid: 90.27% Test: 77.92%\n",
            "Epoch: 854, Loss: 0.1249, Train: 97.64%, Valid: 90.27% Test: 77.94%\n",
            "Epoch: 855, Loss: 0.1282, Train: 97.67%, Valid: 90.20% Test: 77.95%\n",
            "Epoch: 856, Loss: 0.1244, Train: 97.63%, Valid: 90.20% Test: 77.89%\n",
            "Epoch: 857, Loss: 0.1273, Train: 97.61%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 858, Loss: 0.1288, Train: 97.65%, Valid: 90.20% Test: 77.79%\n",
            "Epoch: 859, Loss: 0.1243, Train: 97.65%, Valid: 90.14% Test: 77.76%\n",
            "Epoch: 860, Loss: 0.1270, Train: 97.64%, Valid: 90.20% Test: 77.73%\n",
            "Epoch: 861, Loss: 0.1252, Train: 97.65%, Valid: 90.14% Test: 77.68%\n",
            "Epoch: 862, Loss: 0.1272, Train: 97.65%, Valid: 90.14% Test: 77.66%\n",
            "Epoch: 863, Loss: 0.1276, Train: 97.65%, Valid: 90.20% Test: 77.67%\n",
            "Epoch: 864, Loss: 0.1227, Train: 97.66%, Valid: 90.20% Test: 77.75%\n",
            "Epoch: 865, Loss: 0.1248, Train: 97.64%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 866, Loss: 0.1246, Train: 97.65%, Valid: 90.20% Test: 77.84%\n",
            "Epoch: 867, Loss: 0.1280, Train: 97.65%, Valid: 90.14% Test: 77.88%\n",
            "Epoch: 868, Loss: 0.1219, Train: 97.70%, Valid: 90.14% Test: 77.90%\n",
            "Epoch: 869, Loss: 0.1228, Train: 97.68%, Valid: 90.14% Test: 77.87%\n",
            "Epoch: 870, Loss: 0.1237, Train: 97.70%, Valid: 90.14% Test: 77.82%\n",
            "Epoch: 871, Loss: 0.1262, Train: 97.70%, Valid: 90.14% Test: 77.79%\n",
            "Epoch: 872, Loss: 0.1257, Train: 97.68%, Valid: 90.14% Test: 77.81%\n",
            "Epoch: 873, Loss: 0.1251, Train: 97.68%, Valid: 90.14% Test: 77.83%\n",
            "Epoch: 874, Loss: 0.1253, Train: 97.67%, Valid: 90.20% Test: 77.84%\n",
            "Epoch: 875, Loss: 0.1240, Train: 97.69%, Valid: 90.20% Test: 77.81%\n",
            "Epoch: 876, Loss: 0.1249, Train: 97.70%, Valid: 90.20% Test: 77.81%\n",
            "Epoch: 877, Loss: 0.1255, Train: 97.74%, Valid: 90.33% Test: 77.83%\n",
            "Epoch: 878, Loss: 0.1272, Train: 97.73%, Valid: 90.33% Test: 77.83%\n",
            "Epoch: 879, Loss: 0.1222, Train: 97.72%, Valid: 90.33% Test: 77.85%\n",
            "Epoch: 880, Loss: 0.1244, Train: 97.70%, Valid: 90.27% Test: 77.87%\n",
            "Epoch: 881, Loss: 0.1235, Train: 97.69%, Valid: 90.27% Test: 77.88%\n",
            "Epoch: 882, Loss: 0.1218, Train: 97.68%, Valid: 90.27% Test: 77.85%\n",
            "Epoch: 883, Loss: 0.1249, Train: 97.70%, Valid: 90.27% Test: 77.82%\n",
            "Epoch: 884, Loss: 0.1225, Train: 97.70%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 885, Loss: 0.1207, Train: 97.73%, Valid: 90.27% Test: 77.80%\n",
            "Epoch: 886, Loss: 0.1235, Train: 97.73%, Valid: 90.27% Test: 77.78%\n",
            "Epoch: 887, Loss: 0.1261, Train: 97.72%, Valid: 90.27% Test: 77.73%\n",
            "Epoch: 888, Loss: 0.1229, Train: 97.72%, Valid: 90.14% Test: 77.71%\n",
            "Epoch: 889, Loss: 0.1182, Train: 97.75%, Valid: 90.20% Test: 77.72%\n",
            "Epoch: 890, Loss: 0.1212, Train: 97.74%, Valid: 90.20% Test: 77.73%\n",
            "Epoch: 891, Loss: 0.1202, Train: 97.74%, Valid: 90.20% Test: 77.73%\n",
            "Epoch: 892, Loss: 0.1212, Train: 97.75%, Valid: 90.20% Test: 77.74%\n",
            "Epoch: 893, Loss: 0.1246, Train: 97.75%, Valid: 90.27% Test: 77.71%\n",
            "Epoch: 894, Loss: 0.1227, Train: 97.73%, Valid: 90.27% Test: 77.71%\n",
            "Epoch: 895, Loss: 0.1229, Train: 97.73%, Valid: 90.27% Test: 77.76%\n",
            "Epoch: 896, Loss: 0.1239, Train: 97.73%, Valid: 90.27% Test: 77.81%\n",
            "Epoch: 897, Loss: 0.1221, Train: 97.74%, Valid: 90.20% Test: 77.85%\n",
            "Epoch: 898, Loss: 0.1200, Train: 97.76%, Valid: 90.20% Test: 77.86%\n",
            "Epoch: 899, Loss: 0.1230, Train: 97.74%, Valid: 90.20% Test: 77.86%\n",
            "Epoch: 900, Loss: 0.1214, Train: 97.73%, Valid: 90.20% Test: 77.82%\n",
            "Epoch: 901, Loss: 0.1217, Train: 97.72%, Valid: 90.27% Test: 77.78%\n",
            "Epoch: 902, Loss: 0.1234, Train: 97.74%, Valid: 90.20% Test: 77.75%\n",
            "Epoch: 903, Loss: 0.1179, Train: 97.76%, Valid: 90.20% Test: 77.73%\n",
            "Epoch: 904, Loss: 0.1207, Train: 97.75%, Valid: 90.20% Test: 77.72%\n",
            "Epoch: 905, Loss: 0.1212, Train: 97.77%, Valid: 90.20% Test: 77.76%\n",
            "Epoch: 906, Loss: 0.1174, Train: 97.77%, Valid: 90.20% Test: 77.79%\n",
            "Epoch: 907, Loss: 0.1243, Train: 97.80%, Valid: 90.14% Test: 77.82%\n",
            "Epoch: 908, Loss: 0.1187, Train: 97.79%, Valid: 90.14% Test: 77.81%\n",
            "Epoch: 909, Loss: 0.1202, Train: 97.79%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 910, Loss: 0.1204, Train: 97.78%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 911, Loss: 0.1192, Train: 97.78%, Valid: 90.20% Test: 77.80%\n",
            "Epoch: 912, Loss: 0.1188, Train: 97.79%, Valid: 90.33% Test: 77.79%\n",
            "Epoch: 913, Loss: 0.1221, Train: 97.77%, Valid: 90.33% Test: 77.76%\n",
            "Epoch: 914, Loss: 0.1207, Train: 97.81%, Valid: 90.14% Test: 77.72%\n",
            "Epoch: 915, Loss: 0.1234, Train: 97.80%, Valid: 90.14% Test: 77.74%\n",
            "Epoch: 916, Loss: 0.1205, Train: 97.83%, Valid: 90.08% Test: 77.78%\n",
            "Epoch: 917, Loss: 0.1198, Train: 97.80%, Valid: 90.14% Test: 77.84%\n",
            "Epoch: 918, Loss: 0.1204, Train: 97.80%, Valid: 90.08% Test: 77.88%\n",
            "Epoch: 919, Loss: 0.1190, Train: 97.84%, Valid: 90.08% Test: 77.91%\n",
            "Epoch: 920, Loss: 0.1201, Train: 97.80%, Valid: 90.14% Test: 77.88%\n",
            "Epoch: 921, Loss: 0.1207, Train: 97.76%, Valid: 90.27% Test: 77.88%\n",
            "Epoch: 922, Loss: 0.1181, Train: 97.78%, Valid: 90.27% Test: 77.82%\n",
            "Epoch: 923, Loss: 0.1200, Train: 97.82%, Valid: 90.27% Test: 77.80%\n",
            "Epoch: 924, Loss: 0.1183, Train: 97.84%, Valid: 90.39% Test: 77.76%\n",
            "Epoch: 925, Loss: 0.1200, Train: 97.84%, Valid: 90.39% Test: 77.71%\n",
            "Epoch: 926, Loss: 0.1194, Train: 97.85%, Valid: 90.39% Test: 77.68%\n",
            "Epoch: 927, Loss: 0.1202, Train: 97.85%, Valid: 90.27% Test: 77.66%\n",
            "Epoch: 928, Loss: 0.1178, Train: 97.86%, Valid: 90.27% Test: 77.66%\n",
            "Epoch: 929, Loss: 0.1197, Train: 97.84%, Valid: 90.14% Test: 77.70%\n",
            "Epoch: 930, Loss: 0.1236, Train: 97.85%, Valid: 90.20% Test: 77.70%\n",
            "Epoch: 931, Loss: 0.1195, Train: 97.85%, Valid: 90.27% Test: 77.75%\n",
            "Epoch: 932, Loss: 0.1199, Train: 97.85%, Valid: 90.27% Test: 77.80%\n",
            "Epoch: 933, Loss: 0.1204, Train: 97.86%, Valid: 90.33% Test: 77.85%\n",
            "Epoch: 934, Loss: 0.1213, Train: 97.84%, Valid: 90.33% Test: 77.86%\n",
            "Epoch: 935, Loss: 0.1151, Train: 97.85%, Valid: 90.27% Test: 77.87%\n",
            "Epoch: 936, Loss: 0.1202, Train: 97.85%, Valid: 90.27% Test: 77.89%\n",
            "Epoch: 937, Loss: 0.1184, Train: 97.87%, Valid: 90.27% Test: 77.87%\n",
            "Epoch: 938, Loss: 0.1198, Train: 97.87%, Valid: 90.27% Test: 77.82%\n",
            "Epoch: 939, Loss: 0.1201, Train: 97.86%, Valid: 90.27% Test: 77.75%\n",
            "Epoch: 940, Loss: 0.1180, Train: 97.87%, Valid: 90.20% Test: 77.74%\n",
            "Epoch: 941, Loss: 0.1189, Train: 97.88%, Valid: 90.20% Test: 77.73%\n",
            "Epoch: 942, Loss: 0.1171, Train: 97.90%, Valid: 90.27% Test: 77.71%\n",
            "Epoch: 943, Loss: 0.1183, Train: 97.89%, Valid: 90.27% Test: 77.73%\n",
            "Epoch: 944, Loss: 0.1154, Train: 97.87%, Valid: 90.27% Test: 77.77%\n",
            "Epoch: 945, Loss: 0.1207, Train: 97.87%, Valid: 90.33% Test: 77.78%\n",
            "Epoch: 946, Loss: 0.1153, Train: 97.87%, Valid: 90.27% Test: 77.76%\n",
            "Epoch: 947, Loss: 0.1161, Train: 97.89%, Valid: 90.27% Test: 77.73%\n",
            "Epoch: 948, Loss: 0.1164, Train: 97.88%, Valid: 90.20% Test: 77.69%\n",
            "Epoch: 949, Loss: 0.1138, Train: 97.88%, Valid: 90.39% Test: 77.66%\n",
            "Epoch: 950, Loss: 0.1151, Train: 97.91%, Valid: 90.39% Test: 77.63%\n",
            "Epoch: 951, Loss: 0.1173, Train: 97.91%, Valid: 90.33% Test: 77.60%\n",
            "Epoch: 952, Loss: 0.1189, Train: 97.91%, Valid: 90.33% Test: 77.61%\n",
            "Epoch: 953, Loss: 0.1133, Train: 97.91%, Valid: 90.33% Test: 77.66%\n",
            "Epoch: 954, Loss: 0.1185, Train: 97.92%, Valid: 90.33% Test: 77.73%\n",
            "Epoch: 955, Loss: 0.1189, Train: 97.91%, Valid: 90.27% Test: 77.77%\n",
            "Epoch: 956, Loss: 0.1163, Train: 97.91%, Valid: 90.33% Test: 77.78%\n",
            "Epoch: 957, Loss: 0.1160, Train: 97.89%, Valid: 90.33% Test: 77.79%\n",
            "Epoch: 958, Loss: 0.1128, Train: 97.90%, Valid: 90.33% Test: 77.80%\n",
            "Epoch: 959, Loss: 0.1154, Train: 97.93%, Valid: 90.33% Test: 77.82%\n",
            "Epoch: 960, Loss: 0.1154, Train: 97.93%, Valid: 90.27% Test: 77.81%\n",
            "Epoch: 961, Loss: 0.1161, Train: 97.93%, Valid: 90.27% Test: 77.77%\n",
            "Epoch: 962, Loss: 0.1150, Train: 97.97%, Valid: 90.27% Test: 77.78%\n",
            "Epoch: 963, Loss: 0.1132, Train: 97.93%, Valid: 90.27% Test: 77.79%\n",
            "Epoch: 964, Loss: 0.1150, Train: 97.93%, Valid: 90.27% Test: 77.75%\n",
            "Epoch: 965, Loss: 0.1152, Train: 97.95%, Valid: 90.27% Test: 77.74%\n",
            "Epoch: 966, Loss: 0.1149, Train: 97.94%, Valid: 90.27% Test: 77.74%\n",
            "Epoch: 967, Loss: 0.1134, Train: 97.92%, Valid: 90.27% Test: 77.74%\n",
            "Epoch: 968, Loss: 0.1159, Train: 97.91%, Valid: 90.27% Test: 77.73%\n",
            "Epoch: 969, Loss: 0.1158, Train: 97.90%, Valid: 90.27% Test: 77.77%\n",
            "Epoch: 970, Loss: 0.1154, Train: 97.90%, Valid: 90.20% Test: 77.77%\n",
            "Epoch: 971, Loss: 0.1178, Train: 97.91%, Valid: 90.27% Test: 77.78%\n",
            "Epoch: 972, Loss: 0.1138, Train: 97.95%, Valid: 90.33% Test: 77.78%\n",
            "Epoch: 973, Loss: 0.1121, Train: 97.97%, Valid: 90.33% Test: 77.78%\n",
            "Epoch: 974, Loss: 0.1156, Train: 97.97%, Valid: 90.33% Test: 77.79%\n",
            "Epoch: 975, Loss: 0.1150, Train: 97.96%, Valid: 90.39% Test: 77.81%\n",
            "Epoch: 976, Loss: 0.1150, Train: 97.95%, Valid: 90.33% Test: 77.82%\n",
            "Epoch: 977, Loss: 0.1141, Train: 97.95%, Valid: 90.33% Test: 77.80%\n",
            "Epoch: 978, Loss: 0.1173, Train: 97.96%, Valid: 90.39% Test: 77.77%\n",
            "Epoch: 979, Loss: 0.1131, Train: 97.96%, Valid: 90.33% Test: 77.71%\n",
            "Epoch: 980, Loss: 0.1118, Train: 97.96%, Valid: 90.39% Test: 77.73%\n",
            "Epoch: 981, Loss: 0.1116, Train: 97.97%, Valid: 90.46% Test: 77.77%\n",
            "Epoch: 982, Loss: 0.1114, Train: 97.96%, Valid: 90.46% Test: 77.78%\n",
            "Epoch: 983, Loss: 0.1136, Train: 97.96%, Valid: 90.33% Test: 77.80%\n",
            "Epoch: 984, Loss: 0.1103, Train: 97.97%, Valid: 90.33% Test: 77.80%\n",
            "Epoch: 985, Loss: 0.1117, Train: 97.98%, Valid: 90.39% Test: 77.77%\n",
            "Epoch: 986, Loss: 0.1099, Train: 97.97%, Valid: 90.46% Test: 77.81%\n",
            "Epoch: 987, Loss: 0.1145, Train: 97.99%, Valid: 90.39% Test: 77.80%\n",
            "Epoch: 988, Loss: 0.1107, Train: 98.00%, Valid: 90.33% Test: 77.79%\n",
            "Epoch: 989, Loss: 0.1139, Train: 98.00%, Valid: 90.33% Test: 77.75%\n",
            "Epoch: 990, Loss: 0.1100, Train: 98.01%, Valid: 90.39% Test: 77.71%\n",
            "Epoch: 991, Loss: 0.1133, Train: 97.99%, Valid: 90.39% Test: 77.70%\n",
            "Epoch: 992, Loss: 0.1111, Train: 97.99%, Valid: 90.33% Test: 77.67%\n",
            "Epoch: 993, Loss: 0.1105, Train: 97.99%, Valid: 90.39% Test: 77.64%\n",
            "Epoch: 994, Loss: 0.1147, Train: 98.01%, Valid: 90.33% Test: 77.61%\n",
            "Epoch: 995, Loss: 0.1130, Train: 98.01%, Valid: 90.33% Test: 77.61%\n",
            "Epoch: 996, Loss: 0.1127, Train: 98.03%, Valid: 90.33% Test: 77.65%\n",
            "Epoch: 997, Loss: 0.1110, Train: 98.01%, Valid: 90.39% Test: 77.65%\n",
            "Epoch: 998, Loss: 0.1120, Train: 98.02%, Valid: 90.33% Test: 77.70%\n",
            "Epoch: 999, Loss: 0.1122, Train: 98.01%, Valid: 90.20% Test: 77.81%\n",
            "Best Test accuracy is 0.7740892833487879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add virtual edges to the Dataset\n",
        "\n",
        "We attempt data augmentation by adding virtual edges, to capture relationships between nodes that have similar titles and abstracts. We add edges between each node and its k nearest neighbours based on the LLM embeddings of the MPNet model explained above. We use the [FAISS](https://github.com/facebookresearch/faiss) library for fast calculation of nearest neighbours."
      ],
      "metadata": {
        "id": "aJab3L_WTQTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "class LoadDataVirtualEdges(LoadData):\n",
        "  \"\"\"\n",
        "    A class extending LoadData to load graph data with additional virtual edges.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    embs : array-like\n",
        "        An array of node embeddings used to find nearest neighbors and create virtual edges.\n",
        "    k : int\n",
        "        The number of nearest neighbors to consider for creating virtual edges.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, embs, k):\n",
        "    self.embs=embs\n",
        "    self.k=k\n",
        "    super(LoadDataVirtualEdges, self).__init__()\n",
        "\n",
        "  def get_nearest_neighbours(self, embs, k):\n",
        "      \"\"\"\n",
        "      Computes the k-nearest neighbors for each node in the graph based on embeddings.\n",
        "\n",
        "      Parameters:\n",
        "      -----------\n",
        "      embs : array-like\n",
        "          An array-like structure containing node embeddings.\n",
        "      k : int\n",
        "          The number of nearest neighbors to find for each node.\n",
        "\n",
        "      Returns:\n",
        "      --------\n",
        "      numpy.ndarray\n",
        "          An array of indices representing the k-nearest neighbors for each node.\n",
        "      \"\"\"\n",
        "      res = faiss.StandardGpuResources()\n",
        "      index = faiss.IndexFlatL2(embs.shape[1])   # build the index\n",
        "      gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "      gpu_index_flat.add(embs)                  # add vectors to the index\n",
        "      D, I = gpu_index_flat.search(embs, k+1)     # actual search\n",
        "      return I\n",
        "\n",
        "  def convert_to_edge_index(self, I, k):\n",
        "    \"\"\"\n",
        "    Converts nearest neighbor information into PyTorch Geometric edge indices.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    I : numpy.ndarray\n",
        "        An array of indices representing the nearest neighbors for each node.\n",
        "    k : int\n",
        "        The number of nearest neighbors for each node.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (src_nodes, dst_nodes)\n",
        "        Two tensors representing the source and destination nodes of each virtual edge.\n",
        "    \"\"\"\n",
        "    num_nodes = I.shape[0]\n",
        "    src_nodes = torch.arange(num_nodes).repeat_interleave(k).to(device)\n",
        "    dst_nodes = torch.tensor(I[:,1:]).flatten().to(device)\n",
        "    return src_nodes, dst_nodes\n",
        "\n",
        "  def load_data(self):\n",
        "    \"\"\"\n",
        "    Loads the graph dataset, adds virtual edges based on nearest neighbors, applies transformations,\n",
        "    and retrieves split indices.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    data : PyG data object\n",
        "        The graph data object with virtual edges added.\n",
        "    split_idx : dict\n",
        "        A dictionary containing the indices for train, validation, and test splits.\n",
        "    num_classes : int\n",
        "        The number of classes in the dataset.\n",
        "    \"\"\"\n",
        "    num_classes = 47\n",
        "    data = torch.load(data_filepath)\n",
        "    row, col, edge_attr = data.adj_t.to_symmetric().t().coo()\n",
        "    data.edge_index = torch.stack([row, col], dim=0)\n",
        "    split_idx={}\n",
        "    split_idx['train'] = data.train_mask\n",
        "    split_idx['valid'] = data.val_mask\n",
        "    split_idx['test'] = data.test_mask\n",
        "    I=self.get_nearest_neighbours(self.embs,self.k)\n",
        "    S,D=self.convert_to_edge_index(I,k)\n",
        "    data.edge_index=torch.cat((data.edge_index,torch.stack((S,D)).to('cpu')),dim=1)\n",
        "    data.edge_index=SparseTensor.from_edge_index(data.edge_index)\n",
        "    return data, split_idx, num_classes"
      ],
      "metadata": {
        "id": "G9XSkQwHUtbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the pipeline with Virtual Edges added"
      ],
      "metadata": {
        "id": "ryrzlxSaWDCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k=10\n",
        "load_data=LoadDataVirtualEdges(embs,k)\n",
        "virtual_edge_acc, virtual_edge_model = train_loop(load_data, loss_obj, hyperparams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkDoMDTHV_9f",
        "outputId": "52166038-72fb-4aca-b09d-de503b49a538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00, Loss: 3.8834, Train: 10.14%, Valid: 10.18% Test: 6.94%\n",
            "Epoch: 01, Loss: 3.7166, Train: 26.49%, Valid: 23.92% Test: 17.03%\n",
            "Epoch: 02, Loss: 3.5556, Train: 27.44%, Valid: 24.36% Test: 17.53%\n",
            "Epoch: 03, Loss: 3.4017, Train: 27.33%, Valid: 24.36% Test: 17.43%\n",
            "Epoch: 04, Loss: 3.2464, Train: 27.31%, Valid: 24.36% Test: 17.39%\n",
            "Epoch: 05, Loss: 3.0988, Train: 27.31%, Valid: 24.36% Test: 17.38%\n",
            "Epoch: 06, Loss: 2.9483, Train: 27.31%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 07, Loss: 2.8056, Train: 27.31%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 08, Loss: 2.6832, Train: 27.31%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 09, Loss: 2.5648, Train: 27.31%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 10, Loss: 2.4675, Train: 27.31%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 11, Loss: 2.3909, Train: 27.44%, Valid: 24.49% Test: 17.46%\n",
            "Epoch: 12, Loss: 2.2997, Train: 29.25%, Valid: 26.21% Test: 18.53%\n",
            "Epoch: 13, Loss: 2.2167, Train: 33.74%, Valid: 30.92% Test: 21.25%\n",
            "Epoch: 14, Loss: 2.1476, Train: 39.45%, Valid: 35.88% Test: 24.81%\n",
            "Epoch: 15, Loss: 2.0844, Train: 44.06%, Valid: 40.97% Test: 28.05%\n",
            "Epoch: 16, Loss: 1.9961, Train: 48.36%, Valid: 45.74% Test: 32.17%\n",
            "Epoch: 17, Loss: 1.9360, Train: 53.62%, Valid: 51.78% Test: 37.03%\n",
            "Epoch: 18, Loss: 1.8740, Train: 58.29%, Valid: 56.11% Test: 41.25%\n",
            "Epoch: 19, Loss: 1.8084, Train: 61.82%, Valid: 60.18% Test: 44.58%\n",
            "Epoch: 20, Loss: 1.7476, Train: 64.20%, Valid: 62.15% Test: 47.06%\n",
            "Epoch: 21, Loss: 1.6830, Train: 66.00%, Valid: 63.10% Test: 48.82%\n",
            "Epoch: 22, Loss: 1.6153, Train: 67.34%, Valid: 65.08% Test: 50.04%\n",
            "Epoch: 23, Loss: 1.5537, Train: 68.82%, Valid: 66.60% Test: 51.03%\n",
            "Epoch: 24, Loss: 1.4963, Train: 70.16%, Valid: 68.13% Test: 51.90%\n",
            "Epoch: 25, Loss: 1.4434, Train: 71.83%, Valid: 69.78% Test: 52.86%\n",
            "Epoch: 26, Loss: 1.3870, Train: 73.67%, Valid: 71.12% Test: 53.81%\n",
            "Epoch: 27, Loss: 1.3473, Train: 75.29%, Valid: 72.39% Test: 54.92%\n",
            "Epoch: 28, Loss: 1.2973, Train: 76.67%, Valid: 73.73% Test: 55.94%\n",
            "Epoch: 29, Loss: 1.2440, Train: 77.95%, Valid: 75.06% Test: 56.86%\n",
            "Epoch: 30, Loss: 1.2012, Train: 79.17%, Valid: 75.95% Test: 57.77%\n",
            "Epoch: 31, Loss: 1.1551, Train: 80.01%, Valid: 76.78% Test: 58.52%\n",
            "Epoch: 32, Loss: 1.1199, Train: 80.73%, Valid: 77.48% Test: 59.12%\n",
            "Epoch: 33, Loss: 1.0826, Train: 81.28%, Valid: 77.74% Test: 59.63%\n",
            "Epoch: 34, Loss: 1.0535, Train: 81.77%, Valid: 78.31% Test: 60.02%\n",
            "Epoch: 35, Loss: 1.0126, Train: 82.30%, Valid: 78.82% Test: 60.34%\n",
            "Epoch: 36, Loss: 0.9844, Train: 82.76%, Valid: 79.26% Test: 60.72%\n",
            "Epoch: 37, Loss: 0.9456, Train: 83.36%, Valid: 80.09% Test: 61.12%\n",
            "Epoch: 38, Loss: 0.9196, Train: 84.04%, Valid: 80.66% Test: 61.68%\n",
            "Epoch: 39, Loss: 0.8950, Train: 84.86%, Valid: 81.17% Test: 62.29%\n",
            "Epoch: 40, Loss: 0.8696, Train: 85.61%, Valid: 82.06% Test: 62.91%\n",
            "Epoch: 41, Loss: 0.8416, Train: 86.23%, Valid: 82.32% Test: 63.49%\n",
            "Epoch: 42, Loss: 0.8172, Train: 86.76%, Valid: 82.70% Test: 63.95%\n",
            "Epoch: 43, Loss: 0.7911, Train: 87.21%, Valid: 83.08% Test: 64.33%\n",
            "Epoch: 44, Loss: 0.7712, Train: 87.75%, Valid: 83.78% Test: 64.74%\n",
            "Epoch: 45, Loss: 0.7525, Train: 88.14%, Valid: 84.22% Test: 65.08%\n",
            "Epoch: 46, Loss: 0.7304, Train: 88.48%, Valid: 84.54% Test: 65.37%\n",
            "Epoch: 47, Loss: 0.7094, Train: 88.76%, Valid: 84.80% Test: 65.68%\n",
            "Epoch: 48, Loss: 0.6981, Train: 89.09%, Valid: 85.11% Test: 65.89%\n",
            "Epoch: 49, Loss: 0.6748, Train: 89.37%, Valid: 85.31% Test: 66.14%\n",
            "Epoch: 50, Loss: 0.6592, Train: 89.53%, Valid: 85.37% Test: 66.37%\n",
            "Epoch: 51, Loss: 0.6429, Train: 89.77%, Valid: 85.43% Test: 66.54%\n",
            "Epoch: 52, Loss: 0.6279, Train: 90.02%, Valid: 85.56% Test: 66.70%\n",
            "Epoch: 53, Loss: 0.6125, Train: 90.18%, Valid: 85.56% Test: 66.88%\n",
            "Epoch: 54, Loss: 0.5991, Train: 90.37%, Valid: 85.88% Test: 67.06%\n",
            "Epoch: 55, Loss: 0.5772, Train: 90.54%, Valid: 86.20% Test: 67.27%\n",
            "Epoch: 56, Loss: 0.5720, Train: 90.73%, Valid: 86.51% Test: 67.46%\n",
            "Epoch: 57, Loss: 0.5645, Train: 90.87%, Valid: 86.58% Test: 67.65%\n",
            "Epoch: 58, Loss: 0.5479, Train: 90.95%, Valid: 86.83% Test: 67.93%\n",
            "Epoch: 59, Loss: 0.5357, Train: 91.13%, Valid: 87.02% Test: 68.20%\n",
            "Epoch: 60, Loss: 0.5203, Train: 91.29%, Valid: 87.02% Test: 68.51%\n",
            "Epoch: 61, Loss: 0.5188, Train: 91.39%, Valid: 87.09% Test: 68.79%\n",
            "Epoch: 62, Loss: 0.5076, Train: 91.44%, Valid: 87.21% Test: 69.06%\n",
            "Epoch: 63, Loss: 0.4937, Train: 91.54%, Valid: 87.34% Test: 69.31%\n",
            "Epoch: 64, Loss: 0.4953, Train: 91.63%, Valid: 87.28% Test: 69.55%\n",
            "Epoch: 65, Loss: 0.4815, Train: 91.72%, Valid: 87.21% Test: 69.74%\n",
            "Epoch: 66, Loss: 0.4677, Train: 91.79%, Valid: 87.21% Test: 69.93%\n",
            "Epoch: 67, Loss: 0.4697, Train: 91.83%, Valid: 87.28% Test: 70.10%\n",
            "Epoch: 68, Loss: 0.4615, Train: 91.90%, Valid: 87.34% Test: 70.25%\n",
            "Epoch: 69, Loss: 0.4542, Train: 92.00%, Valid: 87.34% Test: 70.36%\n",
            "Epoch: 70, Loss: 0.4490, Train: 92.03%, Valid: 87.47% Test: 70.43%\n",
            "Epoch: 71, Loss: 0.4443, Train: 92.09%, Valid: 87.53% Test: 70.52%\n",
            "Epoch: 72, Loss: 0.4386, Train: 92.14%, Valid: 87.66% Test: 70.61%\n",
            "Epoch: 73, Loss: 0.4256, Train: 92.18%, Valid: 87.60% Test: 70.71%\n",
            "Epoch: 74, Loss: 0.4236, Train: 92.25%, Valid: 87.53% Test: 70.82%\n",
            "Epoch: 75, Loss: 0.4161, Train: 92.32%, Valid: 87.34% Test: 70.95%\n",
            "Epoch: 76, Loss: 0.4130, Train: 92.34%, Valid: 87.34% Test: 71.07%\n",
            "Epoch: 77, Loss: 0.4120, Train: 92.41%, Valid: 87.47% Test: 71.21%\n",
            "Epoch: 78, Loss: 0.4059, Train: 92.46%, Valid: 87.47% Test: 71.34%\n",
            "Epoch: 79, Loss: 0.4006, Train: 92.51%, Valid: 87.60% Test: 71.51%\n",
            "Epoch: 80, Loss: 0.3961, Train: 92.58%, Valid: 87.53% Test: 71.63%\n",
            "Epoch: 81, Loss: 0.3962, Train: 92.64%, Valid: 87.53% Test: 71.74%\n",
            "Epoch: 82, Loss: 0.3866, Train: 92.73%, Valid: 87.53% Test: 71.88%\n",
            "Epoch: 83, Loss: 0.3805, Train: 92.82%, Valid: 87.53% Test: 71.99%\n",
            "Epoch: 84, Loss: 0.3775, Train: 92.89%, Valid: 87.60% Test: 72.11%\n",
            "Epoch: 85, Loss: 0.3716, Train: 92.96%, Valid: 87.60% Test: 72.22%\n",
            "Epoch: 86, Loss: 0.3740, Train: 93.04%, Valid: 87.53% Test: 72.32%\n",
            "Epoch: 87, Loss: 0.3652, Train: 93.14%, Valid: 87.60% Test: 72.39%\n",
            "Epoch: 88, Loss: 0.3604, Train: 93.17%, Valid: 87.72% Test: 72.49%\n",
            "Epoch: 89, Loss: 0.3623, Train: 93.20%, Valid: 87.72% Test: 72.58%\n",
            "Epoch: 90, Loss: 0.3576, Train: 93.26%, Valid: 87.79% Test: 72.65%\n",
            "Epoch: 91, Loss: 0.3553, Train: 93.30%, Valid: 87.98% Test: 72.74%\n",
            "Epoch: 92, Loss: 0.3512, Train: 93.38%, Valid: 87.91% Test: 72.80%\n",
            "Epoch: 93, Loss: 0.3499, Train: 93.43%, Valid: 87.91% Test: 72.89%\n",
            "Epoch: 94, Loss: 0.3493, Train: 93.47%, Valid: 88.04% Test: 73.01%\n",
            "Epoch: 95, Loss: 0.3441, Train: 93.51%, Valid: 88.10% Test: 73.07%\n",
            "Epoch: 96, Loss: 0.3411, Train: 93.53%, Valid: 88.17% Test: 73.12%\n",
            "Epoch: 97, Loss: 0.3462, Train: 93.56%, Valid: 88.23% Test: 73.17%\n",
            "Epoch: 98, Loss: 0.3358, Train: 93.57%, Valid: 88.23% Test: 73.22%\n",
            "Epoch: 99, Loss: 0.3299, Train: 93.62%, Valid: 88.30% Test: 73.23%\n",
            "Epoch: 100, Loss: 0.3335, Train: 93.64%, Valid: 88.30% Test: 73.28%\n",
            "Epoch: 101, Loss: 0.3289, Train: 93.68%, Valid: 88.30% Test: 73.32%\n",
            "Epoch: 102, Loss: 0.3305, Train: 93.72%, Valid: 88.30% Test: 73.32%\n",
            "Epoch: 103, Loss: 0.3261, Train: 93.71%, Valid: 88.30% Test: 73.38%\n",
            "Epoch: 104, Loss: 0.3231, Train: 93.72%, Valid: 88.36% Test: 73.41%\n",
            "Epoch: 105, Loss: 0.3177, Train: 93.74%, Valid: 88.36% Test: 73.47%\n",
            "Epoch: 106, Loss: 0.3189, Train: 93.77%, Valid: 88.49% Test: 73.50%\n",
            "Epoch: 107, Loss: 0.3146, Train: 93.80%, Valid: 88.55% Test: 73.58%\n",
            "Epoch: 108, Loss: 0.3124, Train: 93.81%, Valid: 88.61% Test: 73.63%\n",
            "Epoch: 109, Loss: 0.3128, Train: 93.82%, Valid: 88.61% Test: 73.68%\n",
            "Epoch: 110, Loss: 0.3120, Train: 93.85%, Valid: 88.55% Test: 73.73%\n",
            "Epoch: 111, Loss: 0.3117, Train: 93.88%, Valid: 88.55% Test: 73.81%\n",
            "Epoch: 112, Loss: 0.3078, Train: 93.89%, Valid: 88.55% Test: 73.86%\n",
            "Epoch: 113, Loss: 0.3046, Train: 93.91%, Valid: 88.55% Test: 73.93%\n",
            "Epoch: 114, Loss: 0.3012, Train: 93.92%, Valid: 88.49% Test: 73.99%\n",
            "Epoch: 115, Loss: 0.3023, Train: 93.96%, Valid: 88.55% Test: 74.05%\n",
            "Epoch: 116, Loss: 0.3045, Train: 93.99%, Valid: 88.61% Test: 74.09%\n",
            "Epoch: 117, Loss: 0.2980, Train: 94.02%, Valid: 88.61% Test: 74.13%\n",
            "Epoch: 118, Loss: 0.2951, Train: 94.00%, Valid: 88.61% Test: 74.19%\n",
            "Epoch: 119, Loss: 0.2959, Train: 94.04%, Valid: 88.61% Test: 74.24%\n",
            "Epoch: 120, Loss: 0.2927, Train: 94.05%, Valid: 88.61% Test: 74.28%\n",
            "Epoch: 121, Loss: 0.2951, Train: 94.05%, Valid: 88.55% Test: 74.31%\n",
            "Epoch: 122, Loss: 0.2912, Train: 94.08%, Valid: 88.55% Test: 74.30%\n",
            "Epoch: 123, Loss: 0.2943, Train: 94.08%, Valid: 88.55% Test: 74.35%\n",
            "Epoch: 124, Loss: 0.2907, Train: 94.11%, Valid: 88.55% Test: 74.39%\n",
            "Epoch: 125, Loss: 0.2906, Train: 94.13%, Valid: 88.55% Test: 74.41%\n",
            "Epoch: 126, Loss: 0.2872, Train: 94.15%, Valid: 88.55% Test: 74.45%\n",
            "Epoch: 127, Loss: 0.2842, Train: 94.19%, Valid: 88.55% Test: 74.48%\n",
            "Epoch: 128, Loss: 0.2845, Train: 94.21%, Valid: 88.68% Test: 74.52%\n",
            "Epoch: 129, Loss: 0.2844, Train: 94.23%, Valid: 88.68% Test: 74.54%\n",
            "Epoch: 130, Loss: 0.2816, Train: 94.25%, Valid: 88.80% Test: 74.58%\n",
            "Epoch: 131, Loss: 0.2846, Train: 94.26%, Valid: 88.80% Test: 74.61%\n",
            "Epoch: 132, Loss: 0.2788, Train: 94.28%, Valid: 88.80% Test: 74.61%\n",
            "Epoch: 133, Loss: 0.2823, Train: 94.30%, Valid: 88.87% Test: 74.64%\n",
            "Epoch: 134, Loss: 0.2745, Train: 94.31%, Valid: 88.80% Test: 74.66%\n",
            "Epoch: 135, Loss: 0.2813, Train: 94.34%, Valid: 88.87% Test: 74.71%\n",
            "Epoch: 136, Loss: 0.2741, Train: 94.36%, Valid: 88.74% Test: 74.72%\n",
            "Epoch: 137, Loss: 0.2769, Train: 94.38%, Valid: 88.87% Test: 74.72%\n",
            "Epoch: 138, Loss: 0.2741, Train: 94.38%, Valid: 88.80% Test: 74.71%\n",
            "Epoch: 139, Loss: 0.2738, Train: 94.40%, Valid: 88.80% Test: 74.71%\n",
            "Epoch: 140, Loss: 0.2737, Train: 94.41%, Valid: 88.87% Test: 74.72%\n",
            "Epoch: 141, Loss: 0.2703, Train: 94.45%, Valid: 88.80% Test: 74.75%\n",
            "Epoch: 142, Loss: 0.2726, Train: 94.45%, Valid: 88.87% Test: 74.77%\n",
            "Epoch: 143, Loss: 0.2709, Train: 94.49%, Valid: 88.87% Test: 74.81%\n",
            "Epoch: 144, Loss: 0.2706, Train: 94.50%, Valid: 88.87% Test: 74.88%\n",
            "Epoch: 145, Loss: 0.2702, Train: 94.53%, Valid: 88.80% Test: 74.91%\n",
            "Epoch: 146, Loss: 0.2730, Train: 94.56%, Valid: 88.68% Test: 74.96%\n",
            "Epoch: 147, Loss: 0.2677, Train: 94.56%, Valid: 88.74% Test: 74.98%\n",
            "Epoch: 148, Loss: 0.2668, Train: 94.58%, Valid: 88.80% Test: 75.01%\n",
            "Epoch: 149, Loss: 0.2675, Train: 94.59%, Valid: 88.87% Test: 75.05%\n",
            "Epoch: 150, Loss: 0.2640, Train: 94.58%, Valid: 88.87% Test: 75.05%\n",
            "Epoch: 151, Loss: 0.2636, Train: 94.63%, Valid: 88.87% Test: 75.01%\n",
            "Epoch: 152, Loss: 0.2628, Train: 94.60%, Valid: 88.93% Test: 75.00%\n",
            "Epoch: 153, Loss: 0.2624, Train: 94.59%, Valid: 88.87% Test: 75.00%\n",
            "Epoch: 154, Loss: 0.2687, Train: 94.64%, Valid: 88.87% Test: 74.97%\n",
            "Epoch: 155, Loss: 0.2598, Train: 94.64%, Valid: 88.87% Test: 74.95%\n",
            "Epoch: 156, Loss: 0.2566, Train: 94.66%, Valid: 88.80% Test: 74.98%\n",
            "Epoch: 157, Loss: 0.2577, Train: 94.65%, Valid: 88.80% Test: 75.01%\n",
            "Epoch: 158, Loss: 0.2591, Train: 94.66%, Valid: 88.80% Test: 75.05%\n",
            "Epoch: 159, Loss: 0.2596, Train: 94.67%, Valid: 88.80% Test: 75.12%\n",
            "Epoch: 160, Loss: 0.2564, Train: 94.70%, Valid: 88.80% Test: 75.18%\n",
            "Epoch: 161, Loss: 0.2543, Train: 94.72%, Valid: 88.80% Test: 75.26%\n",
            "Epoch: 162, Loss: 0.2503, Train: 94.74%, Valid: 88.87% Test: 75.35%\n",
            "Epoch: 163, Loss: 0.2503, Train: 94.74%, Valid: 88.80% Test: 75.40%\n",
            "Epoch: 164, Loss: 0.2511, Train: 94.77%, Valid: 88.80% Test: 75.42%\n",
            "Epoch: 165, Loss: 0.2522, Train: 94.79%, Valid: 88.80% Test: 75.44%\n",
            "Epoch: 166, Loss: 0.2499, Train: 94.81%, Valid: 88.80% Test: 75.47%\n",
            "Epoch: 167, Loss: 0.2518, Train: 94.83%, Valid: 88.80% Test: 75.47%\n",
            "Epoch: 168, Loss: 0.2480, Train: 94.83%, Valid: 88.80% Test: 75.48%\n",
            "Epoch: 169, Loss: 0.2485, Train: 94.83%, Valid: 88.93% Test: 75.46%\n",
            "Epoch: 170, Loss: 0.2456, Train: 94.83%, Valid: 88.80% Test: 75.44%\n",
            "Epoch: 171, Loss: 0.2453, Train: 94.83%, Valid: 88.80% Test: 75.42%\n",
            "Epoch: 172, Loss: 0.2497, Train: 94.84%, Valid: 88.80% Test: 75.42%\n",
            "Epoch: 173, Loss: 0.2472, Train: 94.85%, Valid: 88.93% Test: 75.43%\n",
            "Epoch: 174, Loss: 0.2457, Train: 94.86%, Valid: 88.93% Test: 75.45%\n",
            "Epoch: 175, Loss: 0.2442, Train: 94.85%, Valid: 88.99% Test: 75.46%\n",
            "Epoch: 176, Loss: 0.2461, Train: 94.85%, Valid: 88.93% Test: 75.49%\n",
            "Epoch: 177, Loss: 0.2425, Train: 94.90%, Valid: 88.99% Test: 75.54%\n",
            "Epoch: 178, Loss: 0.2433, Train: 94.91%, Valid: 89.06% Test: 75.56%\n",
            "Epoch: 179, Loss: 0.2433, Train: 94.91%, Valid: 88.99% Test: 75.55%\n",
            "Epoch: 180, Loss: 0.2407, Train: 94.92%, Valid: 89.06% Test: 75.56%\n",
            "Epoch: 181, Loss: 0.2379, Train: 94.93%, Valid: 88.99% Test: 75.60%\n",
            "Epoch: 182, Loss: 0.2418, Train: 94.91%, Valid: 89.06% Test: 75.63%\n",
            "Epoch: 183, Loss: 0.2436, Train: 94.90%, Valid: 88.99% Test: 75.63%\n",
            "Epoch: 184, Loss: 0.2398, Train: 94.91%, Valid: 88.99% Test: 75.64%\n",
            "Epoch: 185, Loss: 0.2374, Train: 94.92%, Valid: 88.99% Test: 75.65%\n",
            "Epoch: 186, Loss: 0.2390, Train: 94.91%, Valid: 89.06% Test: 75.69%\n",
            "Epoch: 187, Loss: 0.2378, Train: 94.93%, Valid: 89.06% Test: 75.70%\n",
            "Epoch: 188, Loss: 0.2375, Train: 94.93%, Valid: 89.12% Test: 75.71%\n",
            "Epoch: 189, Loss: 0.2407, Train: 94.93%, Valid: 89.12% Test: 75.74%\n",
            "Epoch: 190, Loss: 0.2362, Train: 94.93%, Valid: 89.06% Test: 75.76%\n",
            "Epoch: 191, Loss: 0.2322, Train: 94.94%, Valid: 89.06% Test: 75.77%\n",
            "Epoch: 192, Loss: 0.2361, Train: 94.94%, Valid: 89.06% Test: 75.79%\n",
            "Epoch: 193, Loss: 0.2367, Train: 94.96%, Valid: 88.99% Test: 75.79%\n",
            "Epoch: 194, Loss: 0.2317, Train: 94.98%, Valid: 88.99% Test: 75.82%\n",
            "Epoch: 195, Loss: 0.2320, Train: 95.00%, Valid: 88.99% Test: 75.82%\n",
            "Epoch: 196, Loss: 0.2320, Train: 95.02%, Valid: 89.06% Test: 75.83%\n",
            "Epoch: 197, Loss: 0.2310, Train: 95.02%, Valid: 89.06% Test: 75.83%\n",
            "Epoch: 198, Loss: 0.2303, Train: 95.04%, Valid: 89.06% Test: 75.83%\n",
            "Epoch: 199, Loss: 0.2303, Train: 95.04%, Valid: 89.06% Test: 75.84%\n",
            "Epoch: 200, Loss: 0.2269, Train: 95.03%, Valid: 89.06% Test: 75.88%\n",
            "Epoch: 201, Loss: 0.2303, Train: 95.04%, Valid: 89.06% Test: 75.93%\n",
            "Epoch: 202, Loss: 0.2289, Train: 95.05%, Valid: 89.06% Test: 75.93%\n",
            "Epoch: 203, Loss: 0.2274, Train: 95.06%, Valid: 89.06% Test: 75.95%\n",
            "Epoch: 204, Loss: 0.2278, Train: 95.07%, Valid: 89.06% Test: 75.97%\n",
            "Epoch: 205, Loss: 0.2285, Train: 95.06%, Valid: 89.12% Test: 75.99%\n",
            "Epoch: 206, Loss: 0.2254, Train: 95.04%, Valid: 89.12% Test: 76.01%\n",
            "Epoch: 207, Loss: 0.2253, Train: 95.04%, Valid: 89.12% Test: 76.00%\n",
            "Epoch: 208, Loss: 0.2268, Train: 95.06%, Valid: 89.12% Test: 75.99%\n",
            "Epoch: 209, Loss: 0.2286, Train: 95.07%, Valid: 89.19% Test: 76.00%\n",
            "Epoch: 210, Loss: 0.2254, Train: 95.10%, Valid: 89.25% Test: 76.02%\n",
            "Epoch: 211, Loss: 0.2249, Train: 95.10%, Valid: 89.25% Test: 76.03%\n",
            "Epoch: 212, Loss: 0.2233, Train: 95.10%, Valid: 89.19% Test: 76.05%\n",
            "Epoch: 213, Loss: 0.2221, Train: 95.10%, Valid: 89.25% Test: 76.07%\n",
            "Epoch: 214, Loss: 0.2223, Train: 95.08%, Valid: 89.25% Test: 76.07%\n",
            "Epoch: 215, Loss: 0.2234, Train: 95.08%, Valid: 89.25% Test: 76.10%\n",
            "Epoch: 216, Loss: 0.2203, Train: 95.10%, Valid: 89.19% Test: 76.12%\n",
            "Epoch: 217, Loss: 0.2211, Train: 95.13%, Valid: 89.19% Test: 76.12%\n",
            "Epoch: 218, Loss: 0.2224, Train: 95.13%, Valid: 89.12% Test: 76.14%\n",
            "Epoch: 219, Loss: 0.2181, Train: 95.11%, Valid: 89.25% Test: 76.17%\n",
            "Epoch: 220, Loss: 0.2188, Train: 95.11%, Valid: 89.25% Test: 76.18%\n",
            "Epoch: 221, Loss: 0.2195, Train: 95.09%, Valid: 89.25% Test: 76.22%\n",
            "Epoch: 222, Loss: 0.2198, Train: 95.10%, Valid: 89.25% Test: 76.26%\n",
            "Epoch: 223, Loss: 0.2242, Train: 95.10%, Valid: 89.25% Test: 76.30%\n",
            "Epoch: 224, Loss: 0.2211, Train: 95.11%, Valid: 89.25% Test: 76.32%\n",
            "Epoch: 225, Loss: 0.2154, Train: 95.13%, Valid: 89.38% Test: 76.34%\n",
            "Epoch: 226, Loss: 0.2174, Train: 95.15%, Valid: 89.38% Test: 76.34%\n",
            "Epoch: 227, Loss: 0.2146, Train: 95.19%, Valid: 89.38% Test: 76.33%\n",
            "Epoch: 228, Loss: 0.2155, Train: 95.20%, Valid: 89.25% Test: 76.33%\n",
            "Epoch: 229, Loss: 0.2169, Train: 95.20%, Valid: 89.31% Test: 76.33%\n",
            "Epoch: 230, Loss: 0.2156, Train: 95.21%, Valid: 89.25% Test: 76.32%\n",
            "Epoch: 231, Loss: 0.2162, Train: 95.24%, Valid: 89.31% Test: 76.33%\n",
            "Epoch: 232, Loss: 0.2153, Train: 95.23%, Valid: 89.31% Test: 76.32%\n",
            "Epoch: 233, Loss: 0.2136, Train: 95.23%, Valid: 89.31% Test: 76.31%\n",
            "Epoch: 234, Loss: 0.2143, Train: 95.25%, Valid: 89.38% Test: 76.30%\n",
            "Epoch: 235, Loss: 0.2164, Train: 95.27%, Valid: 89.25% Test: 76.33%\n",
            "Epoch: 236, Loss: 0.2152, Train: 95.30%, Valid: 89.25% Test: 76.36%\n",
            "Epoch: 237, Loss: 0.2141, Train: 95.32%, Valid: 89.25% Test: 76.35%\n",
            "Epoch: 238, Loss: 0.2118, Train: 95.32%, Valid: 89.31% Test: 76.40%\n",
            "Epoch: 239, Loss: 0.2123, Train: 95.32%, Valid: 89.31% Test: 76.44%\n",
            "Epoch: 240, Loss: 0.2104, Train: 95.32%, Valid: 89.31% Test: 76.46%\n",
            "Epoch: 241, Loss: 0.2109, Train: 95.34%, Valid: 89.31% Test: 76.51%\n",
            "Epoch: 242, Loss: 0.2114, Train: 95.32%, Valid: 89.44% Test: 76.53%\n",
            "Epoch: 243, Loss: 0.2096, Train: 95.30%, Valid: 89.38% Test: 76.55%\n",
            "Epoch: 244, Loss: 0.2110, Train: 95.32%, Valid: 89.38% Test: 76.57%\n",
            "Epoch: 245, Loss: 0.2094, Train: 95.32%, Valid: 89.44% Test: 76.57%\n",
            "Epoch: 246, Loss: 0.2071, Train: 95.32%, Valid: 89.44% Test: 76.58%\n",
            "Epoch: 247, Loss: 0.2070, Train: 95.30%, Valid: 89.44% Test: 76.60%\n",
            "Epoch: 248, Loss: 0.2078, Train: 95.29%, Valid: 89.50% Test: 76.60%\n",
            "Epoch: 249, Loss: 0.2074, Train: 95.31%, Valid: 89.50% Test: 76.59%\n",
            "Epoch: 250, Loss: 0.2049, Train: 95.32%, Valid: 89.44% Test: 76.57%\n",
            "Epoch: 251, Loss: 0.2057, Train: 95.35%, Valid: 89.50% Test: 76.57%\n",
            "Epoch: 252, Loss: 0.2085, Train: 95.37%, Valid: 89.63% Test: 76.57%\n",
            "Epoch: 253, Loss: 0.2077, Train: 95.39%, Valid: 89.63% Test: 76.55%\n",
            "Epoch: 254, Loss: 0.2059, Train: 95.42%, Valid: 89.57% Test: 76.55%\n",
            "Epoch: 255, Loss: 0.2042, Train: 95.42%, Valid: 89.57% Test: 76.57%\n",
            "Epoch: 256, Loss: 0.2063, Train: 95.43%, Valid: 89.57% Test: 76.61%\n",
            "Epoch: 257, Loss: 0.2036, Train: 95.43%, Valid: 89.63% Test: 76.64%\n",
            "Epoch: 258, Loss: 0.2063, Train: 95.44%, Valid: 89.57% Test: 76.61%\n",
            "Epoch: 259, Loss: 0.2046, Train: 95.44%, Valid: 89.57% Test: 76.59%\n",
            "Epoch: 260, Loss: 0.2056, Train: 95.45%, Valid: 89.50% Test: 76.56%\n",
            "Epoch: 261, Loss: 0.2013, Train: 95.46%, Valid: 89.57% Test: 76.60%\n",
            "Epoch: 262, Loss: 0.2024, Train: 95.44%, Valid: 89.50% Test: 76.62%\n",
            "Epoch: 263, Loss: 0.2031, Train: 95.45%, Valid: 89.57% Test: 76.61%\n",
            "Epoch: 264, Loss: 0.1972, Train: 95.46%, Valid: 89.57% Test: 76.63%\n",
            "Epoch: 265, Loss: 0.2017, Train: 95.44%, Valid: 89.57% Test: 76.67%\n",
            "Epoch: 266, Loss: 0.2025, Train: 95.45%, Valid: 89.50% Test: 76.64%\n",
            "Epoch: 267, Loss: 0.2029, Train: 95.47%, Valid: 89.50% Test: 76.64%\n",
            "Epoch: 268, Loss: 0.1978, Train: 95.49%, Valid: 89.50% Test: 76.65%\n",
            "Epoch: 269, Loss: 0.1965, Train: 95.50%, Valid: 89.50% Test: 76.64%\n",
            "Epoch: 270, Loss: 0.1997, Train: 95.55%, Valid: 89.50% Test: 76.64%\n",
            "Epoch: 271, Loss: 0.1994, Train: 95.55%, Valid: 89.57% Test: 76.65%\n",
            "Epoch: 272, Loss: 0.1981, Train: 95.55%, Valid: 89.50% Test: 76.69%\n",
            "Epoch: 273, Loss: 0.1972, Train: 95.57%, Valid: 89.50% Test: 76.74%\n",
            "Epoch: 274, Loss: 0.1964, Train: 95.57%, Valid: 89.50% Test: 76.77%\n",
            "Epoch: 275, Loss: 0.1953, Train: 95.58%, Valid: 89.50% Test: 76.82%\n",
            "Epoch: 276, Loss: 0.1968, Train: 95.60%, Valid: 89.50% Test: 76.84%\n",
            "Epoch: 277, Loss: 0.1961, Train: 95.62%, Valid: 89.50% Test: 76.85%\n",
            "Epoch: 278, Loss: 0.1986, Train: 95.62%, Valid: 89.44% Test: 76.85%\n",
            "Epoch: 279, Loss: 0.1944, Train: 95.62%, Valid: 89.50% Test: 76.82%\n",
            "Epoch: 280, Loss: 0.1993, Train: 95.62%, Valid: 89.63% Test: 76.77%\n",
            "Epoch: 281, Loss: 0.1962, Train: 95.61%, Valid: 89.63% Test: 76.76%\n",
            "Epoch: 282, Loss: 0.1927, Train: 95.61%, Valid: 89.57% Test: 76.75%\n",
            "Epoch: 283, Loss: 0.1945, Train: 95.62%, Valid: 89.63% Test: 76.80%\n",
            "Epoch: 284, Loss: 0.1940, Train: 95.60%, Valid: 89.63% Test: 76.84%\n",
            "Epoch: 285, Loss: 0.1945, Train: 95.60%, Valid: 89.69% Test: 76.87%\n",
            "Epoch: 286, Loss: 0.1927, Train: 95.58%, Valid: 89.76% Test: 76.91%\n",
            "Epoch: 287, Loss: 0.1970, Train: 95.61%, Valid: 89.76% Test: 76.91%\n",
            "Epoch: 288, Loss: 0.1938, Train: 95.61%, Valid: 89.82% Test: 76.88%\n",
            "Epoch: 289, Loss: 0.1944, Train: 95.63%, Valid: 89.82% Test: 76.85%\n",
            "Epoch: 290, Loss: 0.1934, Train: 95.65%, Valid: 89.82% Test: 76.85%\n",
            "Epoch: 291, Loss: 0.1897, Train: 95.66%, Valid: 89.82% Test: 76.81%\n",
            "Epoch: 292, Loss: 0.1913, Train: 95.66%, Valid: 89.76% Test: 76.80%\n",
            "Epoch: 293, Loss: 0.1894, Train: 95.68%, Valid: 89.69% Test: 76.79%\n",
            "Epoch: 294, Loss: 0.1916, Train: 95.69%, Valid: 89.63% Test: 76.77%\n",
            "Epoch: 295, Loss: 0.1949, Train: 95.69%, Valid: 89.69% Test: 76.78%\n",
            "Epoch: 296, Loss: 0.1888, Train: 95.68%, Valid: 89.63% Test: 76.80%\n",
            "Epoch: 297, Loss: 0.1934, Train: 95.68%, Valid: 89.63% Test: 76.83%\n",
            "Epoch: 298, Loss: 0.1884, Train: 95.71%, Valid: 89.63% Test: 76.89%\n",
            "Epoch: 299, Loss: 0.1889, Train: 95.72%, Valid: 89.69% Test: 76.91%\n",
            "Epoch: 300, Loss: 0.1905, Train: 95.76%, Valid: 89.69% Test: 76.93%\n",
            "Epoch: 301, Loss: 0.1919, Train: 95.76%, Valid: 89.76% Test: 76.93%\n",
            "Epoch: 302, Loss: 0.1912, Train: 95.75%, Valid: 89.82% Test: 76.90%\n",
            "Epoch: 303, Loss: 0.1886, Train: 95.73%, Valid: 89.82% Test: 76.86%\n",
            "Epoch: 304, Loss: 0.1885, Train: 95.74%, Valid: 89.82% Test: 76.82%\n",
            "Epoch: 305, Loss: 0.1876, Train: 95.73%, Valid: 89.82% Test: 76.79%\n",
            "Epoch: 306, Loss: 0.1877, Train: 95.74%, Valid: 89.82% Test: 76.76%\n",
            "Epoch: 307, Loss: 0.1880, Train: 95.73%, Valid: 89.89% Test: 76.76%\n",
            "Epoch: 308, Loss: 0.1847, Train: 95.74%, Valid: 89.89% Test: 76.80%\n",
            "Epoch: 309, Loss: 0.1867, Train: 95.74%, Valid: 89.89% Test: 76.83%\n",
            "Epoch: 310, Loss: 0.1879, Train: 95.75%, Valid: 89.89% Test: 76.85%\n",
            "Epoch: 311, Loss: 0.1873, Train: 95.76%, Valid: 89.82% Test: 76.88%\n",
            "Epoch: 312, Loss: 0.1836, Train: 95.78%, Valid: 89.89% Test: 76.88%\n",
            "Epoch: 313, Loss: 0.1851, Train: 95.80%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 314, Loss: 0.1821, Train: 95.79%, Valid: 89.89% Test: 76.86%\n",
            "Epoch: 315, Loss: 0.1855, Train: 95.82%, Valid: 89.76% Test: 76.82%\n",
            "Epoch: 316, Loss: 0.1877, Train: 95.83%, Valid: 89.69% Test: 76.84%\n",
            "Epoch: 317, Loss: 0.1825, Train: 95.85%, Valid: 89.82% Test: 76.86%\n",
            "Epoch: 318, Loss: 0.1845, Train: 95.85%, Valid: 89.76% Test: 76.84%\n",
            "Epoch: 319, Loss: 0.1833, Train: 95.84%, Valid: 89.76% Test: 76.83%\n",
            "Epoch: 320, Loss: 0.1810, Train: 95.84%, Valid: 89.69% Test: 76.83%\n",
            "Epoch: 321, Loss: 0.1828, Train: 95.84%, Valid: 89.69% Test: 76.81%\n",
            "Epoch: 322, Loss: 0.1804, Train: 95.84%, Valid: 89.76% Test: 76.80%\n",
            "Epoch: 323, Loss: 0.1826, Train: 95.85%, Valid: 89.95% Test: 76.79%\n",
            "Epoch: 324, Loss: 0.1830, Train: 95.83%, Valid: 89.95% Test: 76.86%\n",
            "Epoch: 325, Loss: 0.1792, Train: 95.82%, Valid: 90.01% Test: 76.88%\n",
            "Epoch: 326, Loss: 0.1809, Train: 95.83%, Valid: 90.01% Test: 76.94%\n",
            "Epoch: 327, Loss: 0.1812, Train: 95.84%, Valid: 89.95% Test: 76.99%\n",
            "Epoch: 328, Loss: 0.1793, Train: 95.87%, Valid: 89.89% Test: 77.00%\n",
            "Epoch: 329, Loss: 0.1820, Train: 95.87%, Valid: 89.82% Test: 77.02%\n",
            "Epoch: 330, Loss: 0.1811, Train: 95.87%, Valid: 89.82% Test: 77.01%\n",
            "Epoch: 331, Loss: 0.1802, Train: 95.89%, Valid: 89.82% Test: 77.00%\n",
            "Epoch: 332, Loss: 0.1821, Train: 95.89%, Valid: 89.76% Test: 76.97%\n",
            "Epoch: 333, Loss: 0.1767, Train: 95.89%, Valid: 89.82% Test: 76.94%\n",
            "Epoch: 334, Loss: 0.1793, Train: 95.89%, Valid: 89.82% Test: 76.86%\n",
            "Epoch: 335, Loss: 0.1771, Train: 95.87%, Valid: 89.82% Test: 76.79%\n",
            "Epoch: 336, Loss: 0.1787, Train: 95.87%, Valid: 89.89% Test: 76.75%\n",
            "Epoch: 337, Loss: 0.1771, Train: 95.87%, Valid: 89.82% Test: 76.72%\n",
            "Epoch: 338, Loss: 0.1789, Train: 95.87%, Valid: 89.82% Test: 76.71%\n",
            "Epoch: 339, Loss: 0.1787, Train: 95.87%, Valid: 89.95% Test: 76.76%\n",
            "Epoch: 340, Loss: 0.1770, Train: 95.87%, Valid: 89.95% Test: 76.80%\n",
            "Epoch: 341, Loss: 0.1764, Train: 95.89%, Valid: 89.95% Test: 76.87%\n",
            "Epoch: 342, Loss: 0.1753, Train: 95.89%, Valid: 89.95% Test: 76.93%\n",
            "Epoch: 343, Loss: 0.1761, Train: 95.93%, Valid: 90.01% Test: 76.96%\n",
            "Epoch: 344, Loss: 0.1746, Train: 95.93%, Valid: 89.89% Test: 77.00%\n",
            "Epoch: 345, Loss: 0.1781, Train: 95.95%, Valid: 89.82% Test: 77.01%\n",
            "Epoch: 346, Loss: 0.1759, Train: 95.96%, Valid: 89.82% Test: 77.01%\n",
            "Epoch: 347, Loss: 0.1745, Train: 95.95%, Valid: 89.82% Test: 76.96%\n",
            "Epoch: 348, Loss: 0.1767, Train: 95.92%, Valid: 89.89% Test: 76.91%\n",
            "Epoch: 349, Loss: 0.1761, Train: 95.91%, Valid: 89.95% Test: 76.84%\n",
            "Epoch: 350, Loss: 0.1739, Train: 95.91%, Valid: 89.82% Test: 76.79%\n",
            "Epoch: 351, Loss: 0.1703, Train: 95.87%, Valid: 89.76% Test: 76.76%\n",
            "Epoch: 352, Loss: 0.1732, Train: 95.86%, Valid: 89.76% Test: 76.75%\n",
            "Epoch: 353, Loss: 0.1742, Train: 95.86%, Valid: 89.82% Test: 76.81%\n",
            "Epoch: 354, Loss: 0.1735, Train: 95.88%, Valid: 89.89% Test: 76.87%\n",
            "Epoch: 355, Loss: 0.1738, Train: 95.91%, Valid: 89.89% Test: 76.99%\n",
            "Epoch: 356, Loss: 0.1734, Train: 95.91%, Valid: 89.82% Test: 77.04%\n",
            "Epoch: 357, Loss: 0.1707, Train: 95.93%, Valid: 89.76% Test: 77.06%\n",
            "Epoch: 358, Loss: 0.1704, Train: 95.94%, Valid: 89.76% Test: 77.07%\n",
            "Epoch: 359, Loss: 0.1745, Train: 95.95%, Valid: 89.76% Test: 77.02%\n",
            "Epoch: 360, Loss: 0.1720, Train: 95.92%, Valid: 89.76% Test: 77.00%\n",
            "Epoch: 361, Loss: 0.1742, Train: 95.93%, Valid: 89.76% Test: 76.97%\n",
            "Epoch: 362, Loss: 0.1737, Train: 95.91%, Valid: 89.76% Test: 76.92%\n",
            "Epoch: 363, Loss: 0.1733, Train: 95.90%, Valid: 89.89% Test: 76.85%\n",
            "Epoch: 364, Loss: 0.1714, Train: 95.89%, Valid: 89.82% Test: 76.82%\n",
            "Epoch: 365, Loss: 0.1665, Train: 95.93%, Valid: 89.82% Test: 76.78%\n",
            "Epoch: 366, Loss: 0.1677, Train: 95.95%, Valid: 89.76% Test: 76.74%\n",
            "Epoch: 367, Loss: 0.1695, Train: 95.94%, Valid: 89.82% Test: 76.71%\n",
            "Epoch: 368, Loss: 0.1703, Train: 95.96%, Valid: 89.82% Test: 76.72%\n",
            "Epoch: 369, Loss: 0.1709, Train: 95.99%, Valid: 89.89% Test: 76.78%\n",
            "Epoch: 370, Loss: 0.1688, Train: 96.05%, Valid: 89.89% Test: 76.83%\n",
            "Epoch: 371, Loss: 0.1696, Train: 96.02%, Valid: 89.95% Test: 76.88%\n",
            "Epoch: 372, Loss: 0.1681, Train: 96.01%, Valid: 89.95% Test: 76.96%\n",
            "Epoch: 373, Loss: 0.1673, Train: 95.98%, Valid: 89.95% Test: 76.97%\n",
            "Epoch: 374, Loss: 0.1700, Train: 96.01%, Valid: 89.95% Test: 77.01%\n",
            "Epoch: 375, Loss: 0.1677, Train: 96.01%, Valid: 89.95% Test: 77.02%\n",
            "Epoch: 376, Loss: 0.1685, Train: 95.98%, Valid: 89.95% Test: 77.05%\n",
            "Epoch: 377, Loss: 0.1703, Train: 95.97%, Valid: 89.95% Test: 77.04%\n",
            "Epoch: 378, Loss: 0.1684, Train: 95.96%, Valid: 89.89% Test: 76.96%\n",
            "Epoch: 379, Loss: 0.1667, Train: 95.98%, Valid: 89.69% Test: 76.89%\n",
            "Epoch: 380, Loss: 0.1683, Train: 95.98%, Valid: 89.69% Test: 76.86%\n",
            "Epoch: 381, Loss: 0.1639, Train: 95.98%, Valid: 89.69% Test: 76.79%\n",
            "Epoch: 382, Loss: 0.1663, Train: 96.01%, Valid: 89.69% Test: 76.77%\n",
            "Epoch: 383, Loss: 0.1679, Train: 96.01%, Valid: 89.69% Test: 76.75%\n",
            "Epoch: 384, Loss: 0.1657, Train: 96.02%, Valid: 89.76% Test: 76.75%\n",
            "Epoch: 385, Loss: 0.1657, Train: 96.04%, Valid: 89.76% Test: 76.75%\n",
            "Epoch: 386, Loss: 0.1662, Train: 96.04%, Valid: 89.76% Test: 76.79%\n",
            "Epoch: 387, Loss: 0.1639, Train: 96.04%, Valid: 89.76% Test: 76.77%\n",
            "Epoch: 388, Loss: 0.1649, Train: 96.06%, Valid: 89.69% Test: 76.79%\n",
            "Epoch: 389, Loss: 0.1646, Train: 96.05%, Valid: 89.69% Test: 76.79%\n",
            "Epoch: 390, Loss: 0.1653, Train: 96.07%, Valid: 89.69% Test: 76.81%\n",
            "Epoch: 391, Loss: 0.1673, Train: 96.10%, Valid: 89.76% Test: 76.82%\n",
            "Epoch: 392, Loss: 0.1640, Train: 96.09%, Valid: 89.76% Test: 76.89%\n",
            "Epoch: 393, Loss: 0.1648, Train: 96.10%, Valid: 89.82% Test: 76.93%\n",
            "Epoch: 394, Loss: 0.1625, Train: 96.10%, Valid: 89.76% Test: 76.98%\n",
            "Epoch: 395, Loss: 0.1620, Train: 96.10%, Valid: 89.82% Test: 77.02%\n",
            "Epoch: 396, Loss: 0.1646, Train: 96.10%, Valid: 89.82% Test: 77.03%\n",
            "Epoch: 397, Loss: 0.1653, Train: 96.06%, Valid: 89.82% Test: 76.98%\n",
            "Epoch: 398, Loss: 0.1625, Train: 96.06%, Valid: 89.76% Test: 76.96%\n",
            "Epoch: 399, Loss: 0.1622, Train: 96.06%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 400, Loss: 0.1671, Train: 96.05%, Valid: 90.01% Test: 76.84%\n",
            "Epoch: 401, Loss: 0.1650, Train: 96.08%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 402, Loss: 0.1604, Train: 96.08%, Valid: 89.89% Test: 76.78%\n",
            "Epoch: 403, Loss: 0.1624, Train: 96.10%, Valid: 89.82% Test: 76.74%\n",
            "Epoch: 404, Loss: 0.1589, Train: 96.12%, Valid: 89.82% Test: 76.75%\n",
            "Epoch: 405, Loss: 0.1636, Train: 96.11%, Valid: 89.76% Test: 76.76%\n",
            "Epoch: 406, Loss: 0.1585, Train: 96.13%, Valid: 89.76% Test: 76.81%\n",
            "Epoch: 407, Loss: 0.1613, Train: 96.14%, Valid: 89.76% Test: 76.84%\n",
            "Epoch: 408, Loss: 0.1616, Train: 96.13%, Valid: 89.95% Test: 76.89%\n",
            "Epoch: 409, Loss: 0.1609, Train: 96.14%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 410, Loss: 0.1594, Train: 96.14%, Valid: 89.82% Test: 76.86%\n",
            "Epoch: 411, Loss: 0.1591, Train: 96.13%, Valid: 89.82% Test: 76.82%\n",
            "Epoch: 412, Loss: 0.1600, Train: 96.14%, Valid: 89.69% Test: 76.81%\n",
            "Epoch: 413, Loss: 0.1605, Train: 96.14%, Valid: 89.63% Test: 76.77%\n",
            "Epoch: 414, Loss: 0.1579, Train: 96.13%, Valid: 89.69% Test: 76.74%\n",
            "Epoch: 415, Loss: 0.1602, Train: 96.12%, Valid: 89.76% Test: 76.75%\n",
            "Epoch: 416, Loss: 0.1570, Train: 96.16%, Valid: 89.69% Test: 76.75%\n",
            "Epoch: 417, Loss: 0.1606, Train: 96.16%, Valid: 89.76% Test: 76.73%\n",
            "Epoch: 418, Loss: 0.1601, Train: 96.17%, Valid: 89.76% Test: 76.73%\n",
            "Epoch: 419, Loss: 0.1599, Train: 96.19%, Valid: 89.82% Test: 76.73%\n",
            "Epoch: 420, Loss: 0.1580, Train: 96.19%, Valid: 89.82% Test: 76.78%\n",
            "Epoch: 421, Loss: 0.1592, Train: 96.19%, Valid: 89.82% Test: 76.82%\n",
            "Epoch: 422, Loss: 0.1572, Train: 96.21%, Valid: 89.89% Test: 76.83%\n",
            "Epoch: 423, Loss: 0.1585, Train: 96.20%, Valid: 89.89% Test: 76.84%\n",
            "Epoch: 424, Loss: 0.1552, Train: 96.19%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 425, Loss: 0.1607, Train: 96.20%, Valid: 89.82% Test: 76.89%\n",
            "Epoch: 426, Loss: 0.1579, Train: 96.24%, Valid: 89.76% Test: 76.88%\n",
            "Epoch: 427, Loss: 0.1581, Train: 96.24%, Valid: 89.69% Test: 76.87%\n",
            "Epoch: 428, Loss: 0.1576, Train: 96.25%, Valid: 89.76% Test: 76.83%\n",
            "Epoch: 429, Loss: 0.1550, Train: 96.26%, Valid: 89.76% Test: 76.73%\n",
            "Epoch: 430, Loss: 0.1555, Train: 96.24%, Valid: 89.76% Test: 76.67%\n",
            "Epoch: 431, Loss: 0.1526, Train: 96.25%, Valid: 89.82% Test: 76.69%\n",
            "Epoch: 432, Loss: 0.1580, Train: 96.27%, Valid: 89.82% Test: 76.71%\n",
            "Epoch: 433, Loss: 0.1532, Train: 96.28%, Valid: 89.89% Test: 76.72%\n",
            "Epoch: 434, Loss: 0.1576, Train: 96.30%, Valid: 89.89% Test: 76.76%\n",
            "Epoch: 435, Loss: 0.1523, Train: 96.27%, Valid: 89.89% Test: 76.77%\n",
            "Epoch: 436, Loss: 0.1534, Train: 96.27%, Valid: 89.89% Test: 76.78%\n",
            "Epoch: 437, Loss: 0.1525, Train: 96.27%, Valid: 89.95% Test: 76.82%\n",
            "Epoch: 438, Loss: 0.1545, Train: 96.29%, Valid: 89.89% Test: 76.87%\n",
            "Epoch: 439, Loss: 0.1504, Train: 96.28%, Valid: 89.82% Test: 76.89%\n",
            "Epoch: 440, Loss: 0.1541, Train: 96.23%, Valid: 89.82% Test: 76.89%\n",
            "Epoch: 441, Loss: 0.1517, Train: 96.25%, Valid: 89.82% Test: 76.89%\n",
            "Epoch: 442, Loss: 0.1553, Train: 96.27%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 443, Loss: 0.1512, Train: 96.28%, Valid: 89.89% Test: 76.89%\n",
            "Epoch: 444, Loss: 0.1524, Train: 96.31%, Valid: 89.95% Test: 76.87%\n",
            "Epoch: 445, Loss: 0.1529, Train: 96.33%, Valid: 89.95% Test: 76.86%\n",
            "Epoch: 446, Loss: 0.1518, Train: 96.31%, Valid: 89.95% Test: 76.83%\n",
            "Epoch: 447, Loss: 0.1518, Train: 96.29%, Valid: 89.95% Test: 76.83%\n",
            "Epoch: 448, Loss: 0.1524, Train: 96.29%, Valid: 89.95% Test: 76.82%\n",
            "Epoch: 449, Loss: 0.1519, Train: 96.31%, Valid: 89.95% Test: 76.79%\n",
            "Epoch: 450, Loss: 0.1547, Train: 96.31%, Valid: 89.89% Test: 76.77%\n",
            "Epoch: 451, Loss: 0.1522, Train: 96.30%, Valid: 89.89% Test: 76.73%\n",
            "Epoch: 452, Loss: 0.1524, Train: 96.33%, Valid: 89.89% Test: 76.71%\n",
            "Epoch: 453, Loss: 0.1486, Train: 96.35%, Valid: 89.89% Test: 76.70%\n",
            "Epoch: 454, Loss: 0.1526, Train: 96.35%, Valid: 89.89% Test: 76.72%\n",
            "Epoch: 455, Loss: 0.1521, Train: 96.38%, Valid: 89.82% Test: 76.77%\n",
            "Epoch: 456, Loss: 0.1503, Train: 96.39%, Valid: 89.82% Test: 76.80%\n",
            "Epoch: 457, Loss: 0.1511, Train: 96.38%, Valid: 89.82% Test: 76.83%\n",
            "Epoch: 458, Loss: 0.1505, Train: 96.36%, Valid: 89.82% Test: 76.87%\n",
            "Epoch: 459, Loss: 0.1489, Train: 96.33%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 460, Loss: 0.1480, Train: 96.33%, Valid: 89.89% Test: 76.91%\n",
            "Epoch: 461, Loss: 0.1520, Train: 96.34%, Valid: 89.95% Test: 76.92%\n",
            "Epoch: 462, Loss: 0.1492, Train: 96.33%, Valid: 89.89% Test: 76.91%\n",
            "Epoch: 463, Loss: 0.1483, Train: 96.34%, Valid: 89.89% Test: 76.87%\n",
            "Epoch: 464, Loss: 0.1475, Train: 96.33%, Valid: 89.89% Test: 76.84%\n",
            "Epoch: 465, Loss: 0.1487, Train: 96.34%, Valid: 89.82% Test: 76.82%\n",
            "Epoch: 466, Loss: 0.1463, Train: 96.36%, Valid: 89.82% Test: 76.79%\n",
            "Epoch: 467, Loss: 0.1497, Train: 96.38%, Valid: 89.89% Test: 76.76%\n",
            "Epoch: 468, Loss: 0.1447, Train: 96.38%, Valid: 89.89% Test: 76.75%\n",
            "Epoch: 469, Loss: 0.1473, Train: 96.39%, Valid: 89.89% Test: 76.75%\n",
            "Epoch: 470, Loss: 0.1485, Train: 96.41%, Valid: 89.95% Test: 76.80%\n",
            "Epoch: 471, Loss: 0.1493, Train: 96.43%, Valid: 89.82% Test: 76.82%\n",
            "Epoch: 472, Loss: 0.1462, Train: 96.42%, Valid: 89.82% Test: 76.84%\n",
            "Epoch: 473, Loss: 0.1455, Train: 96.42%, Valid: 89.89% Test: 76.86%\n",
            "Epoch: 474, Loss: 0.1472, Train: 96.42%, Valid: 89.82% Test: 76.89%\n",
            "Epoch: 475, Loss: 0.1465, Train: 96.42%, Valid: 89.82% Test: 76.88%\n",
            "Epoch: 476, Loss: 0.1447, Train: 96.44%, Valid: 89.89% Test: 76.87%\n",
            "Epoch: 477, Loss: 0.1468, Train: 96.44%, Valid: 89.89% Test: 76.83%\n",
            "Epoch: 478, Loss: 0.1451, Train: 96.42%, Valid: 89.76% Test: 76.83%\n",
            "Epoch: 479, Loss: 0.1464, Train: 96.46%, Valid: 89.82% Test: 76.84%\n",
            "Epoch: 480, Loss: 0.1446, Train: 96.48%, Valid: 89.82% Test: 76.83%\n",
            "Epoch: 481, Loss: 0.1444, Train: 96.47%, Valid: 89.89% Test: 76.82%\n",
            "Epoch: 482, Loss: 0.1477, Train: 96.48%, Valid: 89.95% Test: 76.84%\n",
            "Epoch: 483, Loss: 0.1446, Train: 96.45%, Valid: 89.95% Test: 76.83%\n",
            "Epoch: 484, Loss: 0.1433, Train: 96.44%, Valid: 89.95% Test: 76.82%\n",
            "Epoch: 485, Loss: 0.1455, Train: 96.46%, Valid: 90.01% Test: 76.82%\n",
            "Epoch: 486, Loss: 0.1440, Train: 96.46%, Valid: 90.01% Test: 76.87%\n",
            "Epoch: 487, Loss: 0.1444, Train: 96.48%, Valid: 90.01% Test: 76.87%\n",
            "Epoch: 488, Loss: 0.1445, Train: 96.48%, Valid: 89.95% Test: 76.88%\n",
            "Epoch: 489, Loss: 0.1457, Train: 96.48%, Valid: 89.95% Test: 76.91%\n",
            "Epoch: 490, Loss: 0.1421, Train: 96.49%, Valid: 89.95% Test: 76.87%\n",
            "Epoch: 491, Loss: 0.1467, Train: 96.53%, Valid: 89.89% Test: 76.86%\n",
            "Epoch: 492, Loss: 0.1423, Train: 96.55%, Valid: 89.95% Test: 76.84%\n",
            "Epoch: 493, Loss: 0.1421, Train: 96.56%, Valid: 90.01% Test: 76.83%\n",
            "Epoch: 494, Loss: 0.1426, Train: 96.57%, Valid: 90.08% Test: 76.84%\n",
            "Epoch: 495, Loss: 0.1426, Train: 96.53%, Valid: 90.08% Test: 76.85%\n",
            "Epoch: 496, Loss: 0.1410, Train: 96.54%, Valid: 90.08% Test: 76.87%\n",
            "Epoch: 497, Loss: 0.1434, Train: 96.56%, Valid: 90.08% Test: 76.92%\n",
            "Epoch: 498, Loss: 0.1413, Train: 96.55%, Valid: 90.01% Test: 76.94%\n",
            "Epoch: 499, Loss: 0.1447, Train: 96.56%, Valid: 90.01% Test: 76.91%\n",
            "Epoch: 500, Loss: 0.1403, Train: 96.57%, Valid: 89.95% Test: 76.87%\n",
            "Epoch: 501, Loss: 0.1391, Train: 96.57%, Valid: 89.95% Test: 76.84%\n",
            "Epoch: 502, Loss: 0.1434, Train: 96.58%, Valid: 89.95% Test: 76.82%\n",
            "Epoch: 503, Loss: 0.1413, Train: 96.58%, Valid: 89.95% Test: 76.80%\n",
            "Epoch: 504, Loss: 0.1419, Train: 96.58%, Valid: 89.89% Test: 76.79%\n",
            "Epoch: 505, Loss: 0.1417, Train: 96.59%, Valid: 89.89% Test: 76.81%\n",
            "Epoch: 506, Loss: 0.1439, Train: 96.61%, Valid: 90.01% Test: 76.79%\n",
            "Epoch: 507, Loss: 0.1398, Train: 96.59%, Valid: 90.01% Test: 76.82%\n",
            "Epoch: 508, Loss: 0.1392, Train: 96.58%, Valid: 90.01% Test: 76.84%\n",
            "Epoch: 509, Loss: 0.1415, Train: 96.59%, Valid: 90.01% Test: 76.88%\n",
            "Epoch: 510, Loss: 0.1418, Train: 96.59%, Valid: 90.01% Test: 76.87%\n",
            "Epoch: 511, Loss: 0.1384, Train: 96.59%, Valid: 90.01% Test: 76.88%\n",
            "Epoch: 512, Loss: 0.1405, Train: 96.59%, Valid: 89.95% Test: 76.89%\n",
            "Epoch: 513, Loss: 0.1358, Train: 96.61%, Valid: 89.95% Test: 76.91%\n",
            "Epoch: 514, Loss: 0.1414, Train: 96.61%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 515, Loss: 0.1357, Train: 96.62%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 516, Loss: 0.1356, Train: 96.63%, Valid: 89.95% Test: 76.85%\n",
            "Epoch: 517, Loss: 0.1370, Train: 96.65%, Valid: 89.89% Test: 76.83%\n",
            "Epoch: 518, Loss: 0.1378, Train: 96.65%, Valid: 89.95% Test: 76.78%\n",
            "Epoch: 519, Loss: 0.1404, Train: 96.64%, Valid: 90.01% Test: 76.77%\n",
            "Epoch: 520, Loss: 0.1392, Train: 96.64%, Valid: 89.95% Test: 76.73%\n",
            "Epoch: 521, Loss: 0.1377, Train: 96.63%, Valid: 90.01% Test: 76.75%\n",
            "Epoch: 522, Loss: 0.1388, Train: 96.63%, Valid: 90.01% Test: 76.75%\n",
            "Epoch: 523, Loss: 0.1397, Train: 96.63%, Valid: 90.01% Test: 76.82%\n",
            "Epoch: 524, Loss: 0.1373, Train: 96.62%, Valid: 90.01% Test: 76.86%\n",
            "Epoch: 525, Loss: 0.1366, Train: 96.62%, Valid: 90.08% Test: 76.86%\n",
            "Epoch: 526, Loss: 0.1364, Train: 96.62%, Valid: 90.01% Test: 76.85%\n",
            "Epoch: 527, Loss: 0.1387, Train: 96.61%, Valid: 90.01% Test: 76.83%\n",
            "Epoch: 528, Loss: 0.1356, Train: 96.62%, Valid: 90.01% Test: 76.82%\n",
            "Epoch: 529, Loss: 0.1369, Train: 96.65%, Valid: 89.95% Test: 76.79%\n",
            "Epoch: 530, Loss: 0.1337, Train: 96.67%, Valid: 89.95% Test: 76.75%\n",
            "Epoch: 531, Loss: 0.1380, Train: 96.70%, Valid: 89.95% Test: 76.76%\n",
            "Epoch: 532, Loss: 0.1387, Train: 96.72%, Valid: 89.95% Test: 76.72%\n",
            "Epoch: 533, Loss: 0.1335, Train: 96.76%, Valid: 89.95% Test: 76.74%\n",
            "Epoch: 534, Loss: 0.1343, Train: 96.74%, Valid: 90.01% Test: 76.75%\n",
            "Epoch: 535, Loss: 0.1350, Train: 96.74%, Valid: 90.01% Test: 76.77%\n",
            "Epoch: 536, Loss: 0.1362, Train: 96.74%, Valid: 89.95% Test: 76.83%\n",
            "Epoch: 537, Loss: 0.1350, Train: 96.76%, Valid: 90.01% Test: 76.82%\n",
            "Epoch: 538, Loss: 0.1393, Train: 96.74%, Valid: 89.95% Test: 76.82%\n",
            "Epoch: 539, Loss: 0.1356, Train: 96.72%, Valid: 90.01% Test: 76.78%\n",
            "Epoch: 540, Loss: 0.1361, Train: 96.71%, Valid: 90.01% Test: 76.75%\n",
            "Epoch: 541, Loss: 0.1343, Train: 96.71%, Valid: 90.01% Test: 76.78%\n",
            "Epoch: 542, Loss: 0.1350, Train: 96.68%, Valid: 89.95% Test: 76.78%\n",
            "Epoch: 543, Loss: 0.1374, Train: 96.69%, Valid: 89.95% Test: 76.78%\n",
            "Epoch: 544, Loss: 0.1329, Train: 96.70%, Valid: 89.95% Test: 76.80%\n",
            "Epoch: 545, Loss: 0.1329, Train: 96.72%, Valid: 89.89% Test: 76.80%\n",
            "Epoch: 546, Loss: 0.1357, Train: 96.72%, Valid: 89.95% Test: 76.83%\n",
            "Epoch: 547, Loss: 0.1350, Train: 96.70%, Valid: 90.08% Test: 76.88%\n",
            "Epoch: 548, Loss: 0.1343, Train: 96.69%, Valid: 90.14% Test: 76.87%\n",
            "Epoch: 549, Loss: 0.1337, Train: 96.69%, Valid: 90.14% Test: 76.83%\n",
            "Epoch: 550, Loss: 0.1344, Train: 96.70%, Valid: 90.14% Test: 76.79%\n",
            "Epoch: 551, Loss: 0.1343, Train: 96.72%, Valid: 90.14% Test: 76.77%\n",
            "Epoch: 552, Loss: 0.1350, Train: 96.74%, Valid: 90.08% Test: 76.75%\n",
            "Epoch: 553, Loss: 0.1328, Train: 96.72%, Valid: 90.08% Test: 76.73%\n",
            "Epoch: 554, Loss: 0.1315, Train: 96.73%, Valid: 90.08% Test: 76.74%\n",
            "Epoch: 555, Loss: 0.1333, Train: 96.75%, Valid: 90.08% Test: 76.75%\n",
            "Epoch: 556, Loss: 0.1335, Train: 96.76%, Valid: 90.08% Test: 76.75%\n",
            "Epoch: 557, Loss: 0.1325, Train: 96.74%, Valid: 90.08% Test: 76.77%\n",
            "Epoch: 558, Loss: 0.1296, Train: 96.78%, Valid: 90.08% Test: 76.80%\n",
            "Epoch: 559, Loss: 0.1305, Train: 96.79%, Valid: 90.14% Test: 76.86%\n",
            "Epoch: 560, Loss: 0.1302, Train: 96.76%, Valid: 90.14% Test: 76.91%\n",
            "Epoch: 561, Loss: 0.1298, Train: 96.76%, Valid: 90.14% Test: 76.90%\n",
            "Epoch: 562, Loss: 0.1346, Train: 96.78%, Valid: 90.08% Test: 76.85%\n",
            "Epoch: 563, Loss: 0.1310, Train: 96.77%, Valid: 90.01% Test: 76.86%\n",
            "Epoch: 564, Loss: 0.1287, Train: 96.76%, Valid: 90.01% Test: 76.84%\n",
            "Epoch: 565, Loss: 0.1299, Train: 96.80%, Valid: 90.01% Test: 76.83%\n",
            "Epoch: 566, Loss: 0.1296, Train: 96.80%, Valid: 90.01% Test: 76.85%\n",
            "Epoch: 567, Loss: 0.1312, Train: 96.78%, Valid: 90.08% Test: 76.83%\n",
            "Epoch: 568, Loss: 0.1311, Train: 96.82%, Valid: 90.08% Test: 76.83%\n",
            "Epoch: 569, Loss: 0.1289, Train: 96.85%, Valid: 90.08% Test: 76.82%\n",
            "Epoch: 570, Loss: 0.1313, Train: 96.84%, Valid: 90.14% Test: 76.83%\n",
            "Epoch: 571, Loss: 0.1307, Train: 96.84%, Valid: 90.14% Test: 76.87%\n",
            "Epoch: 572, Loss: 0.1293, Train: 96.81%, Valid: 90.08% Test: 76.89%\n",
            "Epoch: 573, Loss: 0.1291, Train: 96.80%, Valid: 90.08% Test: 76.87%\n",
            "Epoch: 574, Loss: 0.1283, Train: 96.78%, Valid: 90.08% Test: 76.87%\n",
            "Epoch: 575, Loss: 0.1318, Train: 96.79%, Valid: 90.01% Test: 76.88%\n",
            "Epoch: 576, Loss: 0.1299, Train: 96.81%, Valid: 89.95% Test: 76.88%\n",
            "Epoch: 577, Loss: 0.1291, Train: 96.83%, Valid: 89.89% Test: 76.89%\n",
            "Epoch: 578, Loss: 0.1314, Train: 96.86%, Valid: 89.82% Test: 76.89%\n",
            "Epoch: 579, Loss: 0.1289, Train: 96.88%, Valid: 89.89% Test: 76.89%\n",
            "Epoch: 580, Loss: 0.1276, Train: 96.91%, Valid: 89.89% Test: 76.91%\n",
            "Epoch: 581, Loss: 0.1298, Train: 96.89%, Valid: 90.01% Test: 76.89%\n",
            "Epoch: 582, Loss: 0.1277, Train: 96.91%, Valid: 90.01% Test: 76.87%\n",
            "Epoch: 583, Loss: 0.1280, Train: 96.89%, Valid: 90.01% Test: 76.84%\n",
            "Epoch: 584, Loss: 0.1289, Train: 96.88%, Valid: 90.01% Test: 76.83%\n",
            "Epoch: 585, Loss: 0.1270, Train: 96.87%, Valid: 90.01% Test: 76.82%\n",
            "Epoch: 586, Loss: 0.1266, Train: 96.89%, Valid: 90.01% Test: 76.81%\n",
            "Epoch: 587, Loss: 0.1291, Train: 96.89%, Valid: 89.95% Test: 76.81%\n",
            "Epoch: 588, Loss: 0.1265, Train: 96.85%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 589, Loss: 0.1257, Train: 96.85%, Valid: 90.01% Test: 76.81%\n",
            "Epoch: 590, Loss: 0.1317, Train: 96.89%, Valid: 90.01% Test: 76.79%\n",
            "Epoch: 591, Loss: 0.1278, Train: 96.93%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 592, Loss: 0.1252, Train: 96.93%, Valid: 90.01% Test: 76.78%\n",
            "Epoch: 593, Loss: 0.1254, Train: 96.96%, Valid: 89.95% Test: 76.79%\n",
            "Epoch: 594, Loss: 0.1261, Train: 96.94%, Valid: 90.14% Test: 76.77%\n",
            "Epoch: 595, Loss: 0.1265, Train: 96.95%, Valid: 90.14% Test: 76.76%\n",
            "Epoch: 596, Loss: 0.1265, Train: 96.93%, Valid: 90.20% Test: 76.76%\n",
            "Epoch: 597, Loss: 0.1252, Train: 96.93%, Valid: 90.14% Test: 76.80%\n",
            "Epoch: 598, Loss: 0.1280, Train: 96.95%, Valid: 90.08% Test: 76.80%\n",
            "Epoch: 599, Loss: 0.1263, Train: 96.92%, Valid: 90.14% Test: 76.83%\n",
            "Epoch: 600, Loss: 0.1253, Train: 96.90%, Valid: 90.14% Test: 76.83%\n",
            "Epoch: 601, Loss: 0.1233, Train: 96.88%, Valid: 90.20% Test: 76.82%\n",
            "Epoch: 602, Loss: 0.1267, Train: 96.90%, Valid: 90.20% Test: 76.80%\n",
            "Epoch: 603, Loss: 0.1228, Train: 96.93%, Valid: 90.20% Test: 76.78%\n",
            "Epoch: 604, Loss: 0.1230, Train: 96.93%, Valid: 90.20% Test: 76.78%\n",
            "Epoch: 605, Loss: 0.1250, Train: 96.93%, Valid: 90.14% Test: 76.72%\n",
            "Epoch: 606, Loss: 0.1246, Train: 96.94%, Valid: 90.20% Test: 76.74%\n",
            "Epoch: 607, Loss: 0.1253, Train: 96.95%, Valid: 90.20% Test: 76.76%\n",
            "Epoch: 608, Loss: 0.1221, Train: 96.95%, Valid: 90.08% Test: 76.78%\n",
            "Epoch: 609, Loss: 0.1255, Train: 96.98%, Valid: 90.20% Test: 76.79%\n",
            "Epoch: 610, Loss: 0.1230, Train: 96.99%, Valid: 90.14% Test: 76.82%\n",
            "Epoch: 611, Loss: 0.1228, Train: 97.00%, Valid: 90.08% Test: 76.83%\n",
            "Epoch: 612, Loss: 0.1241, Train: 96.97%, Valid: 90.08% Test: 76.86%\n",
            "Epoch: 613, Loss: 0.1240, Train: 96.97%, Valid: 90.01% Test: 76.88%\n",
            "Epoch: 614, Loss: 0.1211, Train: 96.99%, Valid: 90.08% Test: 76.84%\n",
            "Epoch: 615, Loss: 0.1222, Train: 96.99%, Valid: 90.08% Test: 76.85%\n",
            "Epoch: 616, Loss: 0.1235, Train: 96.97%, Valid: 90.08% Test: 76.79%\n",
            "Epoch: 617, Loss: 0.1198, Train: 96.93%, Valid: 90.08% Test: 76.78%\n",
            "Epoch: 618, Loss: 0.1228, Train: 96.94%, Valid: 90.08% Test: 76.76%\n",
            "Epoch: 619, Loss: 0.1197, Train: 96.94%, Valid: 90.01% Test: 76.77%\n",
            "Epoch: 620, Loss: 0.1218, Train: 96.96%, Valid: 90.01% Test: 76.79%\n",
            "Epoch: 621, Loss: 0.1235, Train: 97.00%, Valid: 90.08% Test: 76.80%\n",
            "Epoch: 622, Loss: 0.1189, Train: 96.97%, Valid: 90.08% Test: 76.84%\n",
            "Epoch: 623, Loss: 0.1233, Train: 97.02%, Valid: 90.14% Test: 76.86%\n",
            "Epoch: 624, Loss: 0.1218, Train: 97.02%, Valid: 90.14% Test: 76.83%\n",
            "Epoch: 625, Loss: 0.1220, Train: 97.03%, Valid: 90.14% Test: 76.79%\n",
            "Epoch: 626, Loss: 0.1200, Train: 97.08%, Valid: 90.20% Test: 76.82%\n",
            "Epoch: 627, Loss: 0.1199, Train: 97.10%, Valid: 90.14% Test: 76.82%\n",
            "Epoch: 628, Loss: 0.1209, Train: 97.10%, Valid: 90.14% Test: 76.76%\n",
            "Epoch: 629, Loss: 0.1206, Train: 97.07%, Valid: 90.08% Test: 76.70%\n",
            "Epoch: 630, Loss: 0.1206, Train: 97.03%, Valid: 90.08% Test: 76.68%\n",
            "Epoch: 631, Loss: 0.1210, Train: 97.03%, Valid: 90.08% Test: 76.69%\n",
            "Epoch: 632, Loss: 0.1199, Train: 97.02%, Valid: 90.14% Test: 76.71%\n",
            "Epoch: 633, Loss: 0.1219, Train: 97.04%, Valid: 90.14% Test: 76.70%\n",
            "Epoch: 634, Loss: 0.1218, Train: 97.03%, Valid: 90.20% Test: 76.69%\n",
            "Epoch: 635, Loss: 0.1222, Train: 97.05%, Valid: 90.20% Test: 76.70%\n",
            "Epoch: 636, Loss: 0.1216, Train: 97.08%, Valid: 90.14% Test: 76.70%\n",
            "Epoch: 637, Loss: 0.1188, Train: 97.12%, Valid: 90.01% Test: 76.75%\n",
            "Epoch: 638, Loss: 0.1218, Train: 97.12%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 639, Loss: 0.1184, Train: 97.12%, Valid: 90.01% Test: 76.86%\n",
            "Epoch: 640, Loss: 0.1193, Train: 97.11%, Valid: 90.01% Test: 76.93%\n",
            "Epoch: 641, Loss: 0.1198, Train: 97.08%, Valid: 89.95% Test: 76.93%\n",
            "Epoch: 642, Loss: 0.1207, Train: 97.10%, Valid: 90.01% Test: 76.94%\n",
            "Epoch: 643, Loss: 0.1202, Train: 97.11%, Valid: 89.95% Test: 76.94%\n",
            "Epoch: 644, Loss: 0.1169, Train: 97.10%, Valid: 89.95% Test: 76.95%\n",
            "Epoch: 645, Loss: 0.1179, Train: 97.12%, Valid: 89.95% Test: 76.95%\n",
            "Epoch: 646, Loss: 0.1169, Train: 97.12%, Valid: 89.95% Test: 76.88%\n",
            "Epoch: 647, Loss: 0.1184, Train: 97.14%, Valid: 89.89% Test: 76.84%\n",
            "Epoch: 648, Loss: 0.1169, Train: 97.14%, Valid: 89.95% Test: 76.79%\n",
            "Epoch: 649, Loss: 0.1203, Train: 97.12%, Valid: 90.01% Test: 76.70%\n",
            "Epoch: 650, Loss: 0.1201, Train: 97.10%, Valid: 90.01% Test: 76.65%\n",
            "Epoch: 651, Loss: 0.1183, Train: 97.12%, Valid: 90.08% Test: 76.63%\n",
            "Epoch: 652, Loss: 0.1192, Train: 97.13%, Valid: 90.08% Test: 76.65%\n",
            "Epoch: 653, Loss: 0.1176, Train: 97.10%, Valid: 90.08% Test: 76.67%\n",
            "Epoch: 654, Loss: 0.1174, Train: 97.14%, Valid: 90.08% Test: 76.68%\n",
            "Epoch: 655, Loss: 0.1138, Train: 97.10%, Valid: 90.08% Test: 76.76%\n",
            "Epoch: 656, Loss: 0.1175, Train: 97.10%, Valid: 90.08% Test: 76.79%\n",
            "Epoch: 657, Loss: 0.1142, Train: 97.13%, Valid: 90.08% Test: 76.84%\n",
            "Epoch: 658, Loss: 0.1190, Train: 97.14%, Valid: 90.08% Test: 76.87%\n",
            "Epoch: 659, Loss: 0.1215, Train: 97.24%, Valid: 90.08% Test: 76.89%\n",
            "Epoch: 660, Loss: 0.1188, Train: 97.23%, Valid: 90.08% Test: 76.89%\n",
            "Epoch: 661, Loss: 0.1149, Train: 97.23%, Valid: 90.08% Test: 76.87%\n",
            "Epoch: 662, Loss: 0.1162, Train: 97.25%, Valid: 90.08% Test: 76.88%\n",
            "Epoch: 663, Loss: 0.1176, Train: 97.27%, Valid: 90.14% Test: 76.86%\n",
            "Epoch: 664, Loss: 0.1171, Train: 97.24%, Valid: 90.01% Test: 76.86%\n",
            "Epoch: 665, Loss: 0.1156, Train: 97.25%, Valid: 90.01% Test: 76.86%\n",
            "Epoch: 666, Loss: 0.1134, Train: 97.25%, Valid: 89.89% Test: 76.83%\n",
            "Epoch: 667, Loss: 0.1163, Train: 97.25%, Valid: 89.89% Test: 76.82%\n",
            "Epoch: 668, Loss: 0.1141, Train: 97.24%, Valid: 89.82% Test: 76.78%\n",
            "Epoch: 669, Loss: 0.1142, Train: 97.22%, Valid: 89.89% Test: 76.76%\n",
            "Epoch: 670, Loss: 0.1138, Train: 97.23%, Valid: 89.89% Test: 76.77%\n",
            "Epoch: 671, Loss: 0.1150, Train: 97.24%, Valid: 89.89% Test: 76.79%\n",
            "Epoch: 672, Loss: 0.1168, Train: 97.25%, Valid: 89.95% Test: 76.81%\n",
            "Epoch: 673, Loss: 0.1171, Train: 97.26%, Valid: 89.95% Test: 76.87%\n",
            "Epoch: 674, Loss: 0.1174, Train: 97.27%, Valid: 89.95% Test: 76.86%\n",
            "Epoch: 675, Loss: 0.1135, Train: 97.26%, Valid: 89.95% Test: 76.84%\n",
            "Epoch: 676, Loss: 0.1162, Train: 97.23%, Valid: 90.01% Test: 76.83%\n",
            "Epoch: 677, Loss: 0.1153, Train: 97.21%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 678, Loss: 0.1121, Train: 97.23%, Valid: 89.95% Test: 76.82%\n",
            "Epoch: 679, Loss: 0.1151, Train: 97.24%, Valid: 89.89% Test: 76.83%\n",
            "Epoch: 680, Loss: 0.1135, Train: 97.25%, Valid: 89.95% Test: 76.80%\n",
            "Epoch: 681, Loss: 0.1125, Train: 97.27%, Valid: 89.89% Test: 76.84%\n",
            "Epoch: 682, Loss: 0.1188, Train: 97.31%, Valid: 89.89% Test: 76.86%\n",
            "Epoch: 683, Loss: 0.1111, Train: 97.31%, Valid: 89.95% Test: 76.91%\n",
            "Epoch: 684, Loss: 0.1136, Train: 97.32%, Valid: 89.89% Test: 76.92%\n",
            "Epoch: 685, Loss: 0.1115, Train: 97.31%, Valid: 90.01% Test: 76.86%\n",
            "Epoch: 686, Loss: 0.1130, Train: 97.33%, Valid: 90.01% Test: 76.83%\n",
            "Epoch: 687, Loss: 0.1125, Train: 97.36%, Valid: 90.08% Test: 76.81%\n",
            "Epoch: 688, Loss: 0.1137, Train: 97.35%, Valid: 90.01% Test: 76.74%\n",
            "Epoch: 689, Loss: 0.1111, Train: 97.29%, Valid: 90.08% Test: 76.66%\n",
            "Epoch: 690, Loss: 0.1111, Train: 97.29%, Valid: 89.95% Test: 76.67%\n",
            "Epoch: 691, Loss: 0.1149, Train: 97.29%, Valid: 89.95% Test: 76.71%\n",
            "Epoch: 692, Loss: 0.1134, Train: 97.31%, Valid: 89.95% Test: 76.73%\n",
            "Epoch: 693, Loss: 0.1119, Train: 97.35%, Valid: 89.95% Test: 76.77%\n",
            "Epoch: 694, Loss: 0.1110, Train: 97.35%, Valid: 90.01% Test: 76.74%\n",
            "Epoch: 695, Loss: 0.1150, Train: 97.38%, Valid: 90.08% Test: 76.78%\n",
            "Epoch: 696, Loss: 0.1118, Train: 97.38%, Valid: 89.95% Test: 76.79%\n",
            "Epoch: 697, Loss: 0.1113, Train: 97.42%, Valid: 89.95% Test: 76.81%\n",
            "Epoch: 698, Loss: 0.1111, Train: 97.40%, Valid: 89.95% Test: 76.75%\n",
            "Epoch: 699, Loss: 0.1131, Train: 97.38%, Valid: 89.95% Test: 76.74%\n",
            "Epoch: 700, Loss: 0.1111, Train: 97.39%, Valid: 89.95% Test: 76.70%\n",
            "Epoch: 701, Loss: 0.1150, Train: 97.40%, Valid: 89.95% Test: 76.73%\n",
            "Epoch: 702, Loss: 0.1091, Train: 97.40%, Valid: 89.95% Test: 76.74%\n",
            "Epoch: 703, Loss: 0.1114, Train: 97.38%, Valid: 90.08% Test: 76.80%\n",
            "Epoch: 704, Loss: 0.1101, Train: 97.38%, Valid: 90.08% Test: 76.80%\n",
            "Epoch: 705, Loss: 0.1078, Train: 97.38%, Valid: 89.95% Test: 76.79%\n",
            "Epoch: 706, Loss: 0.1120, Train: 97.37%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 707, Loss: 0.1091, Train: 97.39%, Valid: 89.95% Test: 76.80%\n",
            "Epoch: 708, Loss: 0.1123, Train: 97.40%, Valid: 90.01% Test: 76.78%\n",
            "Epoch: 709, Loss: 0.1074, Train: 97.41%, Valid: 90.08% Test: 76.76%\n",
            "Epoch: 710, Loss: 0.1096, Train: 97.42%, Valid: 90.01% Test: 76.71%\n",
            "Epoch: 711, Loss: 0.1105, Train: 97.42%, Valid: 90.08% Test: 76.66%\n",
            "Epoch: 712, Loss: 0.1086, Train: 97.40%, Valid: 90.08% Test: 76.62%\n",
            "Epoch: 713, Loss: 0.1096, Train: 97.39%, Valid: 90.08% Test: 76.61%\n",
            "Epoch: 714, Loss: 0.1120, Train: 97.42%, Valid: 90.08% Test: 76.64%\n",
            "Epoch: 715, Loss: 0.1135, Train: 97.42%, Valid: 90.08% Test: 76.70%\n",
            "Epoch: 716, Loss: 0.1087, Train: 97.42%, Valid: 90.01% Test: 76.76%\n",
            "Epoch: 717, Loss: 0.1106, Train: 97.40%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 718, Loss: 0.1099, Train: 97.43%, Valid: 89.95% Test: 76.83%\n",
            "Epoch: 719, Loss: 0.1071, Train: 97.44%, Valid: 89.95% Test: 76.84%\n",
            "Epoch: 720, Loss: 0.1094, Train: 97.46%, Valid: 90.01% Test: 76.82%\n",
            "Epoch: 721, Loss: 0.1067, Train: 97.43%, Valid: 89.95% Test: 76.77%\n",
            "Epoch: 722, Loss: 0.1071, Train: 97.43%, Valid: 89.95% Test: 76.73%\n",
            "Epoch: 723, Loss: 0.1104, Train: 97.44%, Valid: 89.95% Test: 76.71%\n",
            "Epoch: 724, Loss: 0.1104, Train: 97.42%, Valid: 89.95% Test: 76.68%\n",
            "Epoch: 725, Loss: 0.1080, Train: 97.42%, Valid: 89.82% Test: 76.70%\n",
            "Epoch: 726, Loss: 0.1056, Train: 97.41%, Valid: 89.89% Test: 76.72%\n",
            "Epoch: 727, Loss: 0.1074, Train: 97.43%, Valid: 89.89% Test: 76.72%\n",
            "Epoch: 728, Loss: 0.1068, Train: 97.44%, Valid: 89.89% Test: 76.73%\n",
            "Epoch: 729, Loss: 0.1061, Train: 97.45%, Valid: 89.89% Test: 76.70%\n",
            "Epoch: 730, Loss: 0.1083, Train: 97.48%, Valid: 89.89% Test: 76.71%\n",
            "Epoch: 731, Loss: 0.1081, Train: 97.50%, Valid: 89.95% Test: 76.74%\n",
            "Epoch: 732, Loss: 0.1067, Train: 97.48%, Valid: 90.01% Test: 76.77%\n",
            "Epoch: 733, Loss: 0.1049, Train: 97.48%, Valid: 90.01% Test: 76.83%\n",
            "Epoch: 734, Loss: 0.1079, Train: 97.49%, Valid: 89.89% Test: 76.88%\n",
            "Epoch: 735, Loss: 0.1060, Train: 97.50%, Valid: 89.89% Test: 76.92%\n",
            "Epoch: 736, Loss: 0.1066, Train: 97.44%, Valid: 89.95% Test: 76.89%\n",
            "Epoch: 737, Loss: 0.1055, Train: 97.44%, Valid: 90.01% Test: 76.91%\n",
            "Epoch: 738, Loss: 0.1050, Train: 97.46%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 739, Loss: 0.1052, Train: 97.46%, Valid: 90.14% Test: 76.74%\n",
            "Epoch: 740, Loss: 0.1059, Train: 97.47%, Valid: 90.01% Test: 76.71%\n",
            "Epoch: 741, Loss: 0.1041, Train: 97.52%, Valid: 89.95% Test: 76.69%\n",
            "Epoch: 742, Loss: 0.1057, Train: 97.54%, Valid: 89.89% Test: 76.72%\n",
            "Epoch: 743, Loss: 0.1043, Train: 97.55%, Valid: 89.82% Test: 76.78%\n",
            "Epoch: 744, Loss: 0.1075, Train: 97.57%, Valid: 89.76% Test: 76.81%\n",
            "Epoch: 745, Loss: 0.1051, Train: 97.58%, Valid: 89.82% Test: 76.92%\n",
            "Epoch: 746, Loss: 0.1086, Train: 97.58%, Valid: 89.69% Test: 76.94%\n",
            "Epoch: 747, Loss: 0.1055, Train: 97.57%, Valid: 89.76% Test: 76.90%\n",
            "Epoch: 748, Loss: 0.1078, Train: 97.53%, Valid: 89.89% Test: 76.91%\n",
            "Epoch: 749, Loss: 0.1055, Train: 97.53%, Valid: 89.89% Test: 76.90%\n",
            "Epoch: 750, Loss: 0.1053, Train: 97.51%, Valid: 90.01% Test: 76.92%\n",
            "Epoch: 751, Loss: 0.1068, Train: 97.53%, Valid: 90.08% Test: 76.92%\n",
            "Epoch: 752, Loss: 0.1043, Train: 97.54%, Valid: 90.01% Test: 76.88%\n",
            "Epoch: 753, Loss: 0.1043, Train: 97.54%, Valid: 90.01% Test: 76.87%\n",
            "Epoch: 754, Loss: 0.1037, Train: 97.55%, Valid: 90.08% Test: 76.80%\n",
            "Epoch: 755, Loss: 0.1051, Train: 97.55%, Valid: 90.01% Test: 76.77%\n",
            "Epoch: 756, Loss: 0.1028, Train: 97.52%, Valid: 89.95% Test: 76.77%\n",
            "Epoch: 757, Loss: 0.1036, Train: 97.49%, Valid: 89.95% Test: 76.75%\n",
            "Epoch: 758, Loss: 0.1032, Train: 97.50%, Valid: 89.95% Test: 76.73%\n",
            "Epoch: 759, Loss: 0.1020, Train: 97.50%, Valid: 89.89% Test: 76.72%\n",
            "Epoch: 760, Loss: 0.1006, Train: 97.52%, Valid: 89.89% Test: 76.71%\n",
            "Epoch: 761, Loss: 0.1066, Train: 97.53%, Valid: 89.76% Test: 76.72%\n",
            "Epoch: 762, Loss: 0.1048, Train: 97.53%, Valid: 89.89% Test: 76.73%\n",
            "Epoch: 763, Loss: 0.0995, Train: 97.55%, Valid: 89.82% Test: 76.71%\n",
            "Epoch: 764, Loss: 0.1029, Train: 97.59%, Valid: 89.82% Test: 76.71%\n",
            "Epoch: 765, Loss: 0.1025, Train: 97.58%, Valid: 89.95% Test: 76.70%\n",
            "Epoch: 766, Loss: 0.1037, Train: 97.60%, Valid: 89.89% Test: 76.75%\n",
            "Epoch: 767, Loss: 0.1049, Train: 97.58%, Valid: 90.01% Test: 76.76%\n",
            "Epoch: 768, Loss: 0.1011, Train: 97.56%, Valid: 90.08% Test: 76.74%\n",
            "Epoch: 769, Loss: 0.1038, Train: 97.56%, Valid: 90.08% Test: 76.70%\n",
            "Epoch: 770, Loss: 0.1020, Train: 97.55%, Valid: 90.08% Test: 76.70%\n",
            "Epoch: 771, Loss: 0.1047, Train: 97.56%, Valid: 90.08% Test: 76.66%\n",
            "Epoch: 772, Loss: 0.1026, Train: 97.58%, Valid: 90.08% Test: 76.66%\n",
            "Epoch: 773, Loss: 0.1032, Train: 97.57%, Valid: 90.01% Test: 76.68%\n",
            "Epoch: 774, Loss: 0.1011, Train: 97.58%, Valid: 89.95% Test: 76.67%\n",
            "Epoch: 775, Loss: 0.1008, Train: 97.58%, Valid: 89.89% Test: 76.70%\n",
            "Epoch: 776, Loss: 0.0984, Train: 97.62%, Valid: 89.89% Test: 76.74%\n",
            "Epoch: 777, Loss: 0.1044, Train: 97.63%, Valid: 89.76% Test: 76.76%\n",
            "Epoch: 778, Loss: 0.1040, Train: 97.66%, Valid: 89.63% Test: 76.73%\n",
            "Epoch: 779, Loss: 0.1000, Train: 97.65%, Valid: 89.63% Test: 76.76%\n",
            "Epoch: 780, Loss: 0.0998, Train: 97.64%, Valid: 89.69% Test: 76.76%\n",
            "Epoch: 781, Loss: 0.1024, Train: 97.63%, Valid: 89.69% Test: 76.76%\n",
            "Epoch: 782, Loss: 0.0987, Train: 97.59%, Valid: 89.63% Test: 76.75%\n",
            "Epoch: 783, Loss: 0.1012, Train: 97.57%, Valid: 89.76% Test: 76.71%\n",
            "Epoch: 784, Loss: 0.1051, Train: 97.56%, Valid: 89.82% Test: 76.68%\n",
            "Epoch: 785, Loss: 0.1026, Train: 97.58%, Valid: 89.69% Test: 76.66%\n",
            "Epoch: 786, Loss: 0.0999, Train: 97.59%, Valid: 89.82% Test: 76.66%\n",
            "Epoch: 787, Loss: 0.0991, Train: 97.63%, Valid: 89.82% Test: 76.69%\n",
            "Epoch: 788, Loss: 0.1014, Train: 97.66%, Valid: 89.76% Test: 76.74%\n",
            "Epoch: 789, Loss: 0.1020, Train: 97.67%, Valid: 89.69% Test: 76.77%\n",
            "Epoch: 790, Loss: 0.1003, Train: 97.70%, Valid: 89.63% Test: 76.82%\n",
            "Epoch: 791, Loss: 0.0986, Train: 97.70%, Valid: 89.69% Test: 76.89%\n",
            "Epoch: 792, Loss: 0.0997, Train: 97.70%, Valid: 89.63% Test: 76.95%\n",
            "Epoch: 793, Loss: 0.1032, Train: 97.70%, Valid: 89.63% Test: 76.95%\n",
            "Epoch: 794, Loss: 0.0996, Train: 97.68%, Valid: 89.63% Test: 76.92%\n",
            "Epoch: 795, Loss: 0.0982, Train: 97.70%, Valid: 89.69% Test: 76.95%\n",
            "Epoch: 796, Loss: 0.1019, Train: 97.69%, Valid: 89.69% Test: 76.95%\n",
            "Epoch: 797, Loss: 0.1024, Train: 97.67%, Valid: 89.76% Test: 76.95%\n",
            "Epoch: 798, Loss: 0.1012, Train: 97.67%, Valid: 89.69% Test: 76.93%\n",
            "Epoch: 799, Loss: 0.1002, Train: 97.72%, Valid: 89.69% Test: 76.88%\n",
            "Epoch: 800, Loss: 0.1016, Train: 97.72%, Valid: 89.69% Test: 76.81%\n",
            "Epoch: 801, Loss: 0.0952, Train: 97.73%, Valid: 89.82% Test: 76.75%\n",
            "Epoch: 802, Loss: 0.0994, Train: 97.72%, Valid: 89.89% Test: 76.70%\n",
            "Epoch: 803, Loss: 0.0986, Train: 97.69%, Valid: 89.95% Test: 76.64%\n",
            "Epoch: 804, Loss: 0.0990, Train: 97.69%, Valid: 89.95% Test: 76.61%\n",
            "Epoch: 805, Loss: 0.1003, Train: 97.74%, Valid: 89.82% Test: 76.60%\n",
            "Epoch: 806, Loss: 0.0965, Train: 97.76%, Valid: 89.69% Test: 76.57%\n",
            "Epoch: 807, Loss: 0.0974, Train: 97.74%, Valid: 89.82% Test: 76.59%\n",
            "Epoch: 808, Loss: 0.1001, Train: 97.74%, Valid: 89.82% Test: 76.61%\n",
            "Epoch: 809, Loss: 0.0969, Train: 97.74%, Valid: 89.82% Test: 76.64%\n",
            "Epoch: 810, Loss: 0.1001, Train: 97.72%, Valid: 89.82% Test: 76.66%\n",
            "Epoch: 811, Loss: 0.0956, Train: 97.70%, Valid: 89.82% Test: 76.69%\n",
            "Epoch: 812, Loss: 0.0992, Train: 97.70%, Valid: 89.76% Test: 76.75%\n",
            "Epoch: 813, Loss: 0.0978, Train: 97.68%, Valid: 89.76% Test: 76.79%\n",
            "Epoch: 814, Loss: 0.0986, Train: 97.72%, Valid: 89.76% Test: 76.79%\n",
            "Epoch: 815, Loss: 0.0961, Train: 97.73%, Valid: 89.76% Test: 76.78%\n",
            "Epoch: 816, Loss: 0.0969, Train: 97.73%, Valid: 89.76% Test: 76.76%\n",
            "Epoch: 817, Loss: 0.0967, Train: 97.74%, Valid: 89.76% Test: 76.78%\n",
            "Epoch: 818, Loss: 0.0982, Train: 97.74%, Valid: 89.89% Test: 76.76%\n",
            "Epoch: 819, Loss: 0.0965, Train: 97.73%, Valid: 90.08% Test: 76.75%\n",
            "Epoch: 820, Loss: 0.0952, Train: 97.71%, Valid: 89.95% Test: 76.70%\n",
            "Epoch: 821, Loss: 0.0955, Train: 97.70%, Valid: 89.89% Test: 76.66%\n",
            "Epoch: 822, Loss: 0.0981, Train: 97.74%, Valid: 89.82% Test: 76.62%\n",
            "Epoch: 823, Loss: 0.0985, Train: 97.74%, Valid: 89.89% Test: 76.61%\n",
            "Epoch: 824, Loss: 0.0949, Train: 97.76%, Valid: 89.82% Test: 76.65%\n",
            "Epoch: 825, Loss: 0.0956, Train: 97.80%, Valid: 89.82% Test: 76.71%\n",
            "Epoch: 826, Loss: 0.0963, Train: 97.83%, Valid: 89.76% Test: 76.75%\n",
            "Epoch: 827, Loss: 0.0990, Train: 97.81%, Valid: 89.76% Test: 76.77%\n",
            "Epoch: 828, Loss: 0.0955, Train: 97.80%, Valid: 89.82% Test: 76.80%\n",
            "Epoch: 829, Loss: 0.0995, Train: 97.81%, Valid: 89.76% Test: 76.87%\n",
            "Epoch: 830, Loss: 0.0952, Train: 97.81%, Valid: 89.82% Test: 76.92%\n",
            "Epoch: 831, Loss: 0.0995, Train: 97.79%, Valid: 89.82% Test: 76.95%\n",
            "Epoch: 832, Loss: 0.0981, Train: 97.78%, Valid: 89.95% Test: 76.93%\n",
            "Epoch: 833, Loss: 0.0984, Train: 97.75%, Valid: 89.89% Test: 76.92%\n",
            "Epoch: 834, Loss: 0.0952, Train: 97.74%, Valid: 89.89% Test: 76.84%\n",
            "Epoch: 835, Loss: 0.0983, Train: 97.75%, Valid: 89.89% Test: 76.82%\n",
            "Epoch: 836, Loss: 0.0976, Train: 97.76%, Valid: 89.89% Test: 76.74%\n",
            "Epoch: 837, Loss: 0.0955, Train: 97.78%, Valid: 89.89% Test: 76.73%\n",
            "Epoch: 838, Loss: 0.0932, Train: 97.81%, Valid: 89.82% Test: 76.72%\n",
            "Epoch: 839, Loss: 0.0957, Train: 97.82%, Valid: 89.82% Test: 76.68%\n",
            "Epoch: 840, Loss: 0.0953, Train: 97.82%, Valid: 89.82% Test: 76.62%\n",
            "Epoch: 841, Loss: 0.0940, Train: 97.84%, Valid: 89.82% Test: 76.61%\n",
            "Epoch: 842, Loss: 0.0954, Train: 97.83%, Valid: 89.76% Test: 76.60%\n",
            "Epoch: 843, Loss: 0.0962, Train: 97.82%, Valid: 89.76% Test: 76.56%\n",
            "Epoch: 844, Loss: 0.0965, Train: 97.80%, Valid: 89.69% Test: 76.55%\n",
            "Epoch: 845, Loss: 0.0928, Train: 97.80%, Valid: 89.69% Test: 76.58%\n",
            "Epoch: 846, Loss: 0.0958, Train: 97.79%, Valid: 89.82% Test: 76.61%\n",
            "Epoch: 847, Loss: 0.0951, Train: 97.82%, Valid: 89.89% Test: 76.65%\n",
            "Epoch: 848, Loss: 0.0912, Train: 97.89%, Valid: 89.82% Test: 76.65%\n",
            "Epoch: 849, Loss: 0.0964, Train: 97.90%, Valid: 89.82% Test: 76.68%\n",
            "Epoch: 850, Loss: 0.0942, Train: 97.89%, Valid: 89.82% Test: 76.69%\n",
            "Epoch: 851, Loss: 0.0944, Train: 97.84%, Valid: 89.82% Test: 76.74%\n",
            "Epoch: 852, Loss: 0.0955, Train: 97.83%, Valid: 89.82% Test: 76.75%\n",
            "Epoch: 853, Loss: 0.0942, Train: 97.84%, Valid: 89.82% Test: 76.76%\n",
            "Epoch: 854, Loss: 0.0933, Train: 97.83%, Valid: 89.82% Test: 76.75%\n",
            "Epoch: 855, Loss: 0.0925, Train: 97.84%, Valid: 89.82% Test: 76.78%\n",
            "Epoch: 856, Loss: 0.0928, Train: 97.84%, Valid: 89.69% Test: 76.76%\n",
            "Epoch: 857, Loss: 0.0915, Train: 97.82%, Valid: 89.89% Test: 76.77%\n",
            "Epoch: 858, Loss: 0.0941, Train: 97.82%, Valid: 89.95% Test: 76.78%\n",
            "Epoch: 859, Loss: 0.0938, Train: 97.86%, Valid: 89.82% Test: 76.79%\n",
            "Epoch: 860, Loss: 0.0930, Train: 97.87%, Valid: 89.82% Test: 76.82%\n",
            "Epoch: 861, Loss: 0.0923, Train: 97.86%, Valid: 89.82% Test: 76.80%\n",
            "Epoch: 862, Loss: 0.0918, Train: 97.89%, Valid: 89.89% Test: 76.79%\n",
            "Epoch: 863, Loss: 0.0944, Train: 97.89%, Valid: 89.89% Test: 76.76%\n",
            "Epoch: 864, Loss: 0.0936, Train: 97.89%, Valid: 90.01% Test: 76.73%\n",
            "Epoch: 865, Loss: 0.0969, Train: 97.86%, Valid: 90.08% Test: 76.73%\n",
            "Epoch: 866, Loss: 0.0909, Train: 97.87%, Valid: 90.01% Test: 76.75%\n",
            "Epoch: 867, Loss: 0.0955, Train: 97.84%, Valid: 90.01% Test: 76.75%\n",
            "Epoch: 868, Loss: 0.0896, Train: 97.84%, Valid: 90.01% Test: 76.79%\n",
            "Epoch: 869, Loss: 0.0946, Train: 97.85%, Valid: 89.82% Test: 76.84%\n",
            "Epoch: 870, Loss: 0.0934, Train: 97.87%, Valid: 89.89% Test: 76.86%\n",
            "Epoch: 871, Loss: 0.0918, Train: 97.91%, Valid: 89.69% Test: 76.82%\n",
            "Epoch: 872, Loss: 0.0935, Train: 97.91%, Valid: 89.69% Test: 76.80%\n",
            "Epoch: 873, Loss: 0.0901, Train: 97.89%, Valid: 89.63% Test: 76.80%\n",
            "Epoch: 874, Loss: 0.0916, Train: 97.85%, Valid: 89.69% Test: 76.77%\n",
            "Epoch: 875, Loss: 0.0911, Train: 97.89%, Valid: 89.76% Test: 76.70%\n",
            "Epoch: 876, Loss: 0.0919, Train: 97.91%, Valid: 89.76% Test: 76.69%\n",
            "Epoch: 877, Loss: 0.0899, Train: 97.93%, Valid: 89.69% Test: 76.70%\n",
            "Epoch: 878, Loss: 0.0918, Train: 97.95%, Valid: 89.76% Test: 76.69%\n",
            "Epoch: 879, Loss: 0.0912, Train: 97.93%, Valid: 89.89% Test: 76.71%\n",
            "Epoch: 880, Loss: 0.0918, Train: 97.89%, Valid: 89.95% Test: 76.73%\n",
            "Epoch: 881, Loss: 0.0889, Train: 97.88%, Valid: 90.01% Test: 76.77%\n",
            "Epoch: 882, Loss: 0.0879, Train: 97.89%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 883, Loss: 0.0926, Train: 97.91%, Valid: 90.01% Test: 76.85%\n",
            "Epoch: 884, Loss: 0.0943, Train: 97.91%, Valid: 89.95% Test: 76.86%\n",
            "Epoch: 885, Loss: 0.0912, Train: 97.91%, Valid: 89.89% Test: 76.84%\n",
            "Epoch: 886, Loss: 0.0926, Train: 97.89%, Valid: 89.82% Test: 76.82%\n",
            "Epoch: 887, Loss: 0.0886, Train: 97.91%, Valid: 89.82% Test: 76.79%\n",
            "Epoch: 888, Loss: 0.0924, Train: 97.91%, Valid: 89.76% Test: 76.74%\n",
            "Epoch: 889, Loss: 0.0895, Train: 97.93%, Valid: 89.76% Test: 76.71%\n",
            "Epoch: 890, Loss: 0.0889, Train: 97.95%, Valid: 89.95% Test: 76.66%\n",
            "Epoch: 891, Loss: 0.0884, Train: 97.93%, Valid: 90.01% Test: 76.66%\n",
            "Epoch: 892, Loss: 0.0859, Train: 97.94%, Valid: 89.95% Test: 76.67%\n",
            "Epoch: 893, Loss: 0.0901, Train: 97.94%, Valid: 89.76% Test: 76.68%\n",
            "Epoch: 894, Loss: 0.0875, Train: 97.95%, Valid: 89.76% Test: 76.71%\n",
            "Epoch: 895, Loss: 0.0874, Train: 97.93%, Valid: 89.69% Test: 76.72%\n",
            "Epoch: 896, Loss: 0.0885, Train: 97.96%, Valid: 89.82% Test: 76.72%\n",
            "Epoch: 897, Loss: 0.0912, Train: 97.95%, Valid: 89.89% Test: 76.72%\n",
            "Epoch: 898, Loss: 0.0870, Train: 97.94%, Valid: 89.89% Test: 76.74%\n",
            "Epoch: 899, Loss: 0.0901, Train: 97.96%, Valid: 89.95% Test: 76.77%\n",
            "Epoch: 900, Loss: 0.0878, Train: 97.96%, Valid: 89.95% Test: 76.79%\n",
            "Epoch: 901, Loss: 0.0904, Train: 97.99%, Valid: 90.01% Test: 76.82%\n",
            "Epoch: 902, Loss: 0.0913, Train: 97.99%, Valid: 90.01% Test: 76.84%\n",
            "Epoch: 903, Loss: 0.0868, Train: 97.97%, Valid: 89.95% Test: 76.85%\n",
            "Epoch: 904, Loss: 0.0882, Train: 97.99%, Valid: 89.95% Test: 76.89%\n",
            "Epoch: 905, Loss: 0.0905, Train: 98.00%, Valid: 89.95% Test: 76.91%\n",
            "Epoch: 906, Loss: 0.0886, Train: 97.99%, Valid: 90.14% Test: 76.91%\n",
            "Epoch: 907, Loss: 0.0881, Train: 97.99%, Valid: 89.95% Test: 76.83%\n",
            "Epoch: 908, Loss: 0.0863, Train: 97.99%, Valid: 90.01% Test: 76.80%\n",
            "Epoch: 909, Loss: 0.0929, Train: 98.03%, Valid: 90.01% Test: 76.73%\n",
            "Epoch: 910, Loss: 0.0881, Train: 98.01%, Valid: 90.01% Test: 76.68%\n",
            "Epoch: 911, Loss: 0.0887, Train: 98.04%, Valid: 89.82% Test: 76.70%\n",
            "Epoch: 912, Loss: 0.0897, Train: 98.04%, Valid: 89.82% Test: 76.69%\n",
            "Epoch: 913, Loss: 0.0859, Train: 98.01%, Valid: 89.76% Test: 76.63%\n",
            "Epoch: 914, Loss: 0.0856, Train: 97.98%, Valid: 89.76% Test: 76.62%\n",
            "Epoch: 915, Loss: 0.0884, Train: 97.98%, Valid: 89.82% Test: 76.62%\n",
            "Epoch: 916, Loss: 0.0873, Train: 97.94%, Valid: 89.95% Test: 76.65%\n",
            "Epoch: 917, Loss: 0.0850, Train: 97.99%, Valid: 89.89% Test: 76.65%\n",
            "Epoch: 918, Loss: 0.0843, Train: 98.04%, Valid: 89.89% Test: 76.67%\n",
            "Epoch: 919, Loss: 0.0880, Train: 98.08%, Valid: 89.89% Test: 76.68%\n",
            "Epoch: 920, Loss: 0.0870, Train: 98.08%, Valid: 90.08% Test: 76.68%\n",
            "Epoch: 921, Loss: 0.0877, Train: 98.10%, Valid: 90.01% Test: 76.70%\n",
            "Epoch: 922, Loss: 0.0858, Train: 98.11%, Valid: 89.89% Test: 76.68%\n",
            "Epoch: 923, Loss: 0.0930, Train: 98.10%, Valid: 89.82% Test: 76.65%\n",
            "Epoch: 924, Loss: 0.0866, Train: 98.08%, Valid: 89.82% Test: 76.64%\n",
            "Epoch: 925, Loss: 0.0851, Train: 98.08%, Valid: 89.82% Test: 76.66%\n",
            "Epoch: 926, Loss: 0.0872, Train: 98.10%, Valid: 89.82% Test: 76.71%\n",
            "Epoch: 927, Loss: 0.0847, Train: 98.09%, Valid: 89.76% Test: 76.73%\n",
            "Epoch: 928, Loss: 0.0851, Train: 98.06%, Valid: 89.82% Test: 76.71%\n",
            "Epoch: 929, Loss: 0.0841, Train: 98.05%, Valid: 89.89% Test: 76.73%\n",
            "Epoch: 930, Loss: 0.0880, Train: 98.07%, Valid: 89.89% Test: 76.68%\n",
            "Epoch: 931, Loss: 0.0852, Train: 98.08%, Valid: 89.95% Test: 76.59%\n",
            "Epoch: 932, Loss: 0.0877, Train: 98.09%, Valid: 89.89% Test: 76.55%\n",
            "Epoch: 933, Loss: 0.0881, Train: 98.11%, Valid: 89.69% Test: 76.55%\n",
            "Epoch: 934, Loss: 0.0862, Train: 98.09%, Valid: 89.69% Test: 76.61%\n",
            "Epoch: 935, Loss: 0.0855, Train: 98.11%, Valid: 89.76% Test: 76.66%\n",
            "Epoch: 936, Loss: 0.0857, Train: 98.11%, Valid: 89.89% Test: 76.72%\n",
            "Epoch: 937, Loss: 0.0827, Train: 98.12%, Valid: 89.95% Test: 76.83%\n",
            "Epoch: 938, Loss: 0.0869, Train: 98.14%, Valid: 90.01% Test: 76.87%\n",
            "Epoch: 939, Loss: 0.0863, Train: 98.13%, Valid: 89.95% Test: 76.90%\n",
            "Epoch: 940, Loss: 0.0830, Train: 98.12%, Valid: 90.01% Test: 76.97%\n",
            "Epoch: 941, Loss: 0.0854, Train: 98.10%, Valid: 89.95% Test: 76.91%\n",
            "Epoch: 942, Loss: 0.0876, Train: 98.10%, Valid: 90.01% Test: 76.85%\n",
            "Epoch: 943, Loss: 0.0837, Train: 98.10%, Valid: 89.89% Test: 76.77%\n",
            "Epoch: 944, Loss: 0.0840, Train: 98.10%, Valid: 89.95% Test: 76.68%\n",
            "Epoch: 945, Loss: 0.0847, Train: 98.07%, Valid: 89.95% Test: 76.63%\n",
            "Epoch: 946, Loss: 0.0896, Train: 98.09%, Valid: 89.89% Test: 76.63%\n",
            "Epoch: 947, Loss: 0.0858, Train: 98.11%, Valid: 89.82% Test: 76.63%\n",
            "Epoch: 948, Loss: 0.0869, Train: 98.14%, Valid: 89.82% Test: 76.64%\n",
            "Epoch: 949, Loss: 0.0861, Train: 98.14%, Valid: 89.82% Test: 76.65%\n",
            "Epoch: 950, Loss: 0.0866, Train: 98.18%, Valid: 89.76% Test: 76.62%\n",
            "Epoch: 951, Loss: 0.0839, Train: 98.19%, Valid: 89.82% Test: 76.63%\n",
            "Epoch: 952, Loss: 0.0853, Train: 98.18%, Valid: 89.76% Test: 76.61%\n",
            "Epoch: 953, Loss: 0.0837, Train: 98.19%, Valid: 89.82% Test: 76.60%\n",
            "Epoch: 954, Loss: 0.0861, Train: 98.16%, Valid: 89.82% Test: 76.63%\n",
            "Epoch: 955, Loss: 0.0827, Train: 98.14%, Valid: 89.89% Test: 76.62%\n",
            "Epoch: 956, Loss: 0.0834, Train: 98.13%, Valid: 89.76% Test: 76.64%\n",
            "Epoch: 957, Loss: 0.0858, Train: 98.10%, Valid: 89.76% Test: 76.66%\n",
            "Epoch: 958, Loss: 0.0832, Train: 98.08%, Valid: 89.76% Test: 76.67%\n",
            "Epoch: 959, Loss: 0.0862, Train: 98.12%, Valid: 89.69% Test: 76.69%\n",
            "Epoch: 960, Loss: 0.0837, Train: 98.18%, Valid: 89.76% Test: 76.74%\n",
            "Epoch: 961, Loss: 0.0842, Train: 98.17%, Valid: 89.76% Test: 76.74%\n",
            "Epoch: 962, Loss: 0.0826, Train: 98.15%, Valid: 89.76% Test: 76.72%\n",
            "Epoch: 963, Loss: 0.0820, Train: 98.13%, Valid: 89.89% Test: 76.66%\n",
            "Epoch: 964, Loss: 0.0807, Train: 98.12%, Valid: 89.82% Test: 76.61%\n",
            "Epoch: 965, Loss: 0.0855, Train: 98.12%, Valid: 89.89% Test: 76.60%\n",
            "Epoch: 966, Loss: 0.0813, Train: 98.14%, Valid: 89.95% Test: 76.59%\n",
            "Epoch: 967, Loss: 0.0807, Train: 98.18%, Valid: 89.82% Test: 76.58%\n",
            "Epoch: 968, Loss: 0.0836, Train: 98.17%, Valid: 89.82% Test: 76.63%\n",
            "Epoch: 969, Loss: 0.0822, Train: 98.18%, Valid: 89.82% Test: 76.65%\n",
            "Epoch: 970, Loss: 0.0823, Train: 98.20%, Valid: 89.76% Test: 76.68%\n",
            "Epoch: 971, Loss: 0.0815, Train: 98.18%, Valid: 89.76% Test: 76.70%\n",
            "Epoch: 972, Loss: 0.0801, Train: 98.18%, Valid: 89.76% Test: 76.73%\n",
            "Epoch: 973, Loss: 0.0843, Train: 98.21%, Valid: 89.82% Test: 76.68%\n",
            "Epoch: 974, Loss: 0.0857, Train: 98.21%, Valid: 89.95% Test: 76.67%\n",
            "Epoch: 975, Loss: 0.0840, Train: 98.23%, Valid: 89.95% Test: 76.71%\n",
            "Epoch: 976, Loss: 0.0832, Train: 98.23%, Valid: 89.95% Test: 76.75%\n",
            "Epoch: 977, Loss: 0.0831, Train: 98.21%, Valid: 89.95% Test: 76.77%\n",
            "Epoch: 978, Loss: 0.0826, Train: 98.19%, Valid: 89.89% Test: 76.76%\n",
            "Epoch: 979, Loss: 0.0833, Train: 98.18%, Valid: 89.82% Test: 76.79%\n",
            "Epoch: 980, Loss: 0.0808, Train: 98.14%, Valid: 89.82% Test: 76.77%\n",
            "Epoch: 981, Loss: 0.0841, Train: 98.16%, Valid: 90.01% Test: 76.72%\n",
            "Epoch: 982, Loss: 0.0848, Train: 98.16%, Valid: 90.01% Test: 76.69%\n",
            "Epoch: 983, Loss: 0.0802, Train: 98.18%, Valid: 89.89% Test: 76.64%\n",
            "Epoch: 984, Loss: 0.0831, Train: 98.18%, Valid: 89.82% Test: 76.55%\n",
            "Epoch: 985, Loss: 0.0789, Train: 98.19%, Valid: 89.76% Test: 76.52%\n",
            "Epoch: 986, Loss: 0.0825, Train: 98.21%, Valid: 89.76% Test: 76.53%\n",
            "Epoch: 987, Loss: 0.0833, Train: 98.23%, Valid: 89.69% Test: 76.59%\n",
            "Epoch: 988, Loss: 0.0832, Train: 98.27%, Valid: 89.57% Test: 76.66%\n",
            "Epoch: 989, Loss: 0.0833, Train: 98.26%, Valid: 89.63% Test: 76.66%\n",
            "Epoch: 990, Loss: 0.0804, Train: 98.30%, Valid: 89.57% Test: 76.71%\n",
            "Epoch: 991, Loss: 0.0841, Train: 98.32%, Valid: 89.50% Test: 76.69%\n",
            "Epoch: 992, Loss: 0.0790, Train: 98.31%, Valid: 89.63% Test: 76.72%\n",
            "Epoch: 993, Loss: 0.0814, Train: 98.32%, Valid: 89.76% Test: 76.70%\n",
            "Epoch: 994, Loss: 0.0802, Train: 98.27%, Valid: 89.89% Test: 76.69%\n",
            "Epoch: 995, Loss: 0.0794, Train: 98.29%, Valid: 89.89% Test: 76.63%\n",
            "Epoch: 996, Loss: 0.0816, Train: 98.28%, Valid: 89.95% Test: 76.63%\n",
            "Epoch: 997, Loss: 0.0819, Train: 98.27%, Valid: 89.95% Test: 76.63%\n",
            "Epoch: 998, Loss: 0.0796, Train: 98.27%, Valid: 89.95% Test: 76.68%\n",
            "Epoch: 999, Loss: 0.0820, Train: 98.27%, Valid: 89.95% Test: 76.71%\n",
            "Best Test accuracy is 0.7675983573983309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add KL Divergence Regularization\n",
        "\n",
        "KLLoss extends the basic loss computation (like cross-entropy) by adding a regularization term\n",
        "    based on KL divergence. This is useful in scenarios where one wishes to penalize the divergence\n",
        "    between the model's output distribution and a target distribution, which in this case is provided\n",
        "    by 'lm_logits'. The lambda (lmbda) parameter controls the weight of this regularization term.\n",
        "\n",
        "\n",
        "The MPNET logits are available at https://drive.google.com/file/d/18gitCCIT5f_hS1p-CcDQB1a5djWVSgV-/view?usp=drive_link, please create a copy of this file in your Google Drive account and update the filepath in the code accordingly\n"
      ],
      "metadata": {
        "id": "sN79xLSueMbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_logits='/content/drive/Shareddrives/CS224W Project/products_embeddings_logits/mpnet_logits_products.pkl'\n",
        "lm_logits=pickle.load(open(filepath_logits, \"rb\"))"
      ],
      "metadata": {
        "id": "jlN3AA6IeiyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KLLoss(Loss):\n",
        "    \"\"\"\n",
        "    A class extending Loss to incorporate Kullback-Leibler (KL) divergence as a regularization term.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    lm_logits : torch.Tensor\n",
        "        The logits from a language model or a pre-defined target distribution.\n",
        "    lmbda : float\n",
        "        The weight (lambda) of the KL divergence regularization term in the overall loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lm_logits, lmbda):\n",
        "        \"\"\"\n",
        "        The constructor for KLLoss class.\n",
        "\n",
        "        Initializes the KLLoss instance with provided language model logits and lambda value.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        lm_logits : torch.Tensor\n",
        "            The logits from a language model or a pre-defined target distribution.\n",
        "        lmbda : float\n",
        "            The weight (lambda) of the KL divergence regularization term in the overall loss.\n",
        "        \"\"\"\n",
        "        self.lmbda = lmbda\n",
        "        self.lm_logits = lm_logits\n",
        "        super(KLLoss, self).__init__()\n",
        "\n",
        "    def get_loss(self, out, labels, train_idx):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        out : torch.Tensor\n",
        "            The output predictions from the neural network model, typically the logits.\n",
        "        labels : torch.Tensor\n",
        "            The true labels for the training data.\n",
        "        train_idx : torch.Tensor or list\n",
        "            The indices of the training data samples.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        torch.Tensor\n",
        "            The computed loss, combining cross-entropy and KL divergence.\n",
        "        \"\"\"\n",
        "        loss = F.cross_entropy(out, labels[train_idx])\n",
        "        reg_penalty = torch.nn.KLDivLoss(log_target=True)\n",
        "        reg = reg_penalty(F.log_softmax(out, dim=1), F.log_softmax(torch.tensor(self.lm_logits[train_idx]).to(device), dim=1))\n",
        "        loss += reg * self.lmbda\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "yyJFavYJeZb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lmbda=1\n",
        "load_data=LoadData()\n",
        "kl_loss_obj=KLLoss(lm_logits,lmbda)\n",
        "kl_best_acc = train_loop(load_data, kl_loss_obj, hyperparams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYdJ2QhafNQD",
        "outputId": "afdc8016-67ef-4647-cdc8-942e19e5a315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00, Loss: 3.9299, Train: 15.34%, Valid: 14.25% Test: 9.66%\n",
            "Epoch: 01, Loss: 3.7758, Train: 27.05%, Valid: 24.05% Test: 16.93%\n",
            "Epoch: 02, Loss: 3.6415, Train: 27.55%, Valid: 24.62% Test: 17.45%\n",
            "Epoch: 03, Loss: 3.5012, Train: 27.41%, Valid: 24.43% Test: 17.41%\n",
            "Epoch: 04, Loss: 3.3658, Train: 27.33%, Valid: 24.43% Test: 17.38%\n",
            "Epoch: 05, Loss: 3.2378, Train: 27.33%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 06, Loss: 3.1191, Train: 27.31%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 07, Loss: 3.0035, Train: 27.31%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 08, Loss: 2.9094, Train: 27.31%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 09, Loss: 2.8163, Train: 27.32%, Valid: 24.36% Test: 17.37%\n",
            "Epoch: 10, Loss: 2.7386, Train: 27.37%, Valid: 24.43% Test: 17.38%\n",
            "Epoch: 11, Loss: 2.6790, Train: 27.73%, Valid: 24.81% Test: 17.52%\n",
            "Epoch: 12, Loss: 2.6059, Train: 28.92%, Valid: 25.76% Test: 18.02%\n",
            "Epoch: 13, Loss: 2.5443, Train: 31.17%, Valid: 27.67% Test: 18.95%\n",
            "Epoch: 14, Loss: 2.4885, Train: 33.55%, Valid: 29.96% Test: 20.16%\n",
            "Epoch: 15, Loss: 2.4431, Train: 36.07%, Valid: 33.21% Test: 22.17%\n",
            "Epoch: 16, Loss: 2.3795, Train: 38.90%, Valid: 35.43% Test: 24.42%\n",
            "Epoch: 17, Loss: 2.3360, Train: 41.43%, Valid: 39.19% Test: 26.54%\n",
            "Epoch: 18, Loss: 2.2970, Train: 43.89%, Valid: 43.00% Test: 28.86%\n",
            "Epoch: 19, Loss: 2.2539, Train: 46.17%, Valid: 44.59% Test: 30.72%\n",
            "Epoch: 20, Loss: 2.2165, Train: 48.28%, Valid: 46.06% Test: 32.22%\n",
            "Epoch: 21, Loss: 2.1551, Train: 50.02%, Valid: 47.39% Test: 33.45%\n",
            "Epoch: 22, Loss: 2.1184, Train: 51.52%, Valid: 48.09% Test: 34.47%\n",
            "Epoch: 23, Loss: 2.0583, Train: 52.71%, Valid: 48.98% Test: 35.37%\n",
            "Epoch: 24, Loss: 2.0220, Train: 53.81%, Valid: 50.06% Test: 36.24%\n",
            "Epoch: 25, Loss: 1.9643, Train: 54.78%, Valid: 51.08% Test: 37.17%\n",
            "Epoch: 26, Loss: 1.9209, Train: 55.93%, Valid: 52.80% Test: 38.24%\n",
            "Epoch: 27, Loss: 1.8858, Train: 57.25%, Valid: 54.20% Test: 39.37%\n",
            "Epoch: 28, Loss: 1.8369, Train: 58.79%, Valid: 56.04% Test: 40.81%\n",
            "Epoch: 29, Loss: 1.7894, Train: 60.56%, Valid: 57.57% Test: 42.33%\n",
            "Epoch: 30, Loss: 1.7485, Train: 62.33%, Valid: 58.91% Test: 43.58%\n",
            "Epoch: 31, Loss: 1.6997, Train: 63.88%, Valid: 60.62% Test: 45.04%\n",
            "Epoch: 32, Loss: 1.6717, Train: 65.32%, Valid: 63.10% Test: 46.37%\n",
            "Epoch: 33, Loss: 1.6305, Train: 66.55%, Valid: 64.76% Test: 47.66%\n",
            "Epoch: 34, Loss: 1.5956, Train: 67.62%, Valid: 66.41% Test: 48.81%\n",
            "Epoch: 35, Loss: 1.5611, Train: 68.51%, Valid: 67.75% Test: 49.76%\n",
            "Epoch: 36, Loss: 1.5280, Train: 69.21%, Valid: 69.15% Test: 50.53%\n",
            "Epoch: 37, Loss: 1.5003, Train: 69.88%, Valid: 69.72% Test: 51.26%\n",
            "Epoch: 38, Loss: 1.4765, Train: 70.64%, Valid: 70.29% Test: 51.87%\n",
            "Epoch: 39, Loss: 1.4414, Train: 71.12%, Valid: 70.42% Test: 52.40%\n",
            "Epoch: 40, Loss: 1.4055, Train: 71.60%, Valid: 71.06% Test: 52.75%\n",
            "Epoch: 41, Loss: 1.3761, Train: 72.09%, Valid: 71.31% Test: 53.29%\n",
            "Epoch: 42, Loss: 1.3769, Train: 72.59%, Valid: 71.82% Test: 53.73%\n",
            "Epoch: 43, Loss: 1.3357, Train: 73.05%, Valid: 72.84% Test: 54.20%\n",
            "Epoch: 44, Loss: 1.3271, Train: 73.54%, Valid: 73.09% Test: 54.60%\n",
            "Epoch: 45, Loss: 1.2962, Train: 74.12%, Valid: 73.79% Test: 55.00%\n",
            "Epoch: 46, Loss: 1.2851, Train: 74.52%, Valid: 73.98% Test: 55.47%\n",
            "Epoch: 47, Loss: 1.2758, Train: 74.87%, Valid: 74.55% Test: 55.95%\n",
            "Epoch: 48, Loss: 1.2494, Train: 75.22%, Valid: 75.25% Test: 56.33%\n",
            "Epoch: 49, Loss: 1.2395, Train: 75.51%, Valid: 75.38% Test: 56.73%\n",
            "Epoch: 50, Loss: 1.2222, Train: 75.74%, Valid: 75.51% Test: 57.05%\n",
            "Epoch: 51, Loss: 1.2010, Train: 76.07%, Valid: 75.95% Test: 57.24%\n",
            "Epoch: 52, Loss: 1.1891, Train: 76.28%, Valid: 76.34% Test: 57.40%\n",
            "Epoch: 53, Loss: 1.1842, Train: 76.47%, Valid: 76.53% Test: 57.59%\n",
            "Epoch: 54, Loss: 1.1626, Train: 76.68%, Valid: 76.84% Test: 57.83%\n",
            "Epoch: 55, Loss: 1.1560, Train: 76.96%, Valid: 76.97% Test: 58.05%\n",
            "Epoch: 56, Loss: 1.1485, Train: 77.15%, Valid: 76.91% Test: 58.28%\n",
            "Epoch: 57, Loss: 1.1338, Train: 77.43%, Valid: 77.04% Test: 58.50%\n",
            "Epoch: 58, Loss: 1.1189, Train: 77.62%, Valid: 77.16% Test: 58.78%\n",
            "Epoch: 59, Loss: 1.1212, Train: 77.78%, Valid: 77.35% Test: 58.99%\n",
            "Epoch: 60, Loss: 1.1081, Train: 77.94%, Valid: 77.42% Test: 59.23%\n",
            "Epoch: 61, Loss: 1.0961, Train: 77.94%, Valid: 77.48% Test: 59.44%\n",
            "Epoch: 62, Loss: 1.0833, Train: 78.03%, Valid: 77.54% Test: 59.65%\n",
            "Epoch: 63, Loss: 1.0877, Train: 78.20%, Valid: 77.67% Test: 59.84%\n",
            "Epoch: 64, Loss: 1.0704, Train: 78.39%, Valid: 77.99% Test: 60.02%\n",
            "Epoch: 65, Loss: 1.0618, Train: 78.51%, Valid: 78.12% Test: 60.18%\n",
            "Epoch: 66, Loss: 1.0535, Train: 78.59%, Valid: 78.05% Test: 60.38%\n",
            "Epoch: 67, Loss: 1.0579, Train: 78.74%, Valid: 78.12% Test: 60.56%\n",
            "Epoch: 68, Loss: 1.0372, Train: 78.85%, Valid: 78.12% Test: 60.75%\n",
            "Epoch: 69, Loss: 1.0342, Train: 79.00%, Valid: 78.37% Test: 60.95%\n",
            "Epoch: 70, Loss: 1.0189, Train: 79.07%, Valid: 78.50% Test: 61.15%\n",
            "Epoch: 71, Loss: 1.0146, Train: 79.22%, Valid: 78.69% Test: 61.34%\n",
            "Epoch: 72, Loss: 1.0002, Train: 79.36%, Valid: 78.88% Test: 61.56%\n",
            "Epoch: 73, Loss: 0.9993, Train: 79.45%, Valid: 79.13% Test: 61.75%\n",
            "Epoch: 74, Loss: 1.0002, Train: 79.53%, Valid: 79.26% Test: 61.89%\n",
            "Epoch: 75, Loss: 0.9963, Train: 79.60%, Valid: 79.33% Test: 62.03%\n",
            "Epoch: 76, Loss: 0.9834, Train: 79.72%, Valid: 79.39% Test: 62.17%\n",
            "Epoch: 77, Loss: 0.9873, Train: 79.88%, Valid: 79.52% Test: 62.29%\n",
            "Epoch: 78, Loss: 0.9680, Train: 79.94%, Valid: 79.39% Test: 62.42%\n",
            "Epoch: 79, Loss: 0.9707, Train: 80.00%, Valid: 79.52% Test: 62.52%\n",
            "Epoch: 80, Loss: 0.9722, Train: 80.02%, Valid: 79.52% Test: 62.63%\n",
            "Epoch: 81, Loss: 0.9701, Train: 80.10%, Valid: 79.71% Test: 62.74%\n",
            "Epoch: 82, Loss: 0.9585, Train: 80.21%, Valid: 79.77% Test: 62.85%\n",
            "Epoch: 83, Loss: 0.9632, Train: 80.27%, Valid: 80.03% Test: 62.97%\n",
            "Epoch: 84, Loss: 0.9546, Train: 80.35%, Valid: 80.09% Test: 63.12%\n",
            "Epoch: 85, Loss: 0.9409, Train: 80.42%, Valid: 80.09% Test: 63.24%\n",
            "Epoch: 86, Loss: 0.9403, Train: 80.51%, Valid: 80.15% Test: 63.33%\n",
            "Epoch: 87, Loss: 0.9340, Train: 80.59%, Valid: 80.22% Test: 63.43%\n",
            "Epoch: 88, Loss: 0.9326, Train: 80.68%, Valid: 80.41% Test: 63.56%\n",
            "Epoch: 89, Loss: 0.9333, Train: 80.77%, Valid: 80.66% Test: 63.66%\n",
            "Epoch: 90, Loss: 0.9296, Train: 80.85%, Valid: 80.79% Test: 63.80%\n",
            "Epoch: 91, Loss: 0.9149, Train: 80.95%, Valid: 80.79% Test: 63.88%\n",
            "Epoch: 92, Loss: 0.9128, Train: 80.98%, Valid: 80.98% Test: 63.97%\n",
            "Epoch: 93, Loss: 0.9162, Train: 81.03%, Valid: 81.17% Test: 64.03%\n",
            "Epoch: 94, Loss: 0.9027, Train: 81.07%, Valid: 81.23% Test: 64.06%\n",
            "Epoch: 95, Loss: 0.9006, Train: 81.11%, Valid: 81.17% Test: 64.15%\n",
            "Epoch: 96, Loss: 0.8985, Train: 81.21%, Valid: 81.11% Test: 64.19%\n",
            "Epoch: 97, Loss: 0.8905, Train: 81.26%, Valid: 81.11% Test: 64.28%\n",
            "Epoch: 98, Loss: 0.8949, Train: 81.32%, Valid: 81.11% Test: 64.36%\n",
            "Epoch: 99, Loss: 0.8910, Train: 81.36%, Valid: 81.23% Test: 64.41%\n",
            "Epoch: 100, Loss: 0.8854, Train: 81.47%, Valid: 81.23% Test: 64.53%\n",
            "Epoch: 101, Loss: 0.8906, Train: 81.55%, Valid: 81.30% Test: 64.66%\n",
            "Epoch: 102, Loss: 0.8744, Train: 81.63%, Valid: 81.30% Test: 64.80%\n",
            "Epoch: 103, Loss: 0.8750, Train: 81.68%, Valid: 81.55% Test: 64.89%\n",
            "Epoch: 104, Loss: 0.8749, Train: 81.70%, Valid: 81.55% Test: 64.95%\n",
            "Epoch: 105, Loss: 0.8707, Train: 81.77%, Valid: 81.68% Test: 64.98%\n",
            "Epoch: 106, Loss: 0.8697, Train: 81.80%, Valid: 81.81% Test: 65.04%\n",
            "Epoch: 107, Loss: 0.8644, Train: 81.83%, Valid: 81.81% Test: 65.07%\n",
            "Epoch: 108, Loss: 0.8712, Train: 81.88%, Valid: 81.81% Test: 65.11%\n",
            "Epoch: 109, Loss: 0.8537, Train: 81.93%, Valid: 81.81% Test: 65.19%\n",
            "Epoch: 110, Loss: 0.8599, Train: 81.99%, Valid: 81.81% Test: 65.25%\n",
            "Epoch: 111, Loss: 0.8605, Train: 82.02%, Valid: 81.74% Test: 65.26%\n",
            "Epoch: 112, Loss: 0.8457, Train: 82.10%, Valid: 81.74% Test: 65.34%\n",
            "Epoch: 113, Loss: 0.8472, Train: 82.18%, Valid: 81.74% Test: 65.37%\n",
            "Epoch: 114, Loss: 0.8540, Train: 82.23%, Valid: 81.81% Test: 65.43%\n",
            "Epoch: 115, Loss: 0.8527, Train: 82.30%, Valid: 81.93% Test: 65.56%\n",
            "Epoch: 116, Loss: 0.8436, Train: 82.32%, Valid: 81.93% Test: 65.68%\n",
            "Epoch: 117, Loss: 0.8375, Train: 82.35%, Valid: 81.93% Test: 65.82%\n",
            "Epoch: 118, Loss: 0.8400, Train: 82.36%, Valid: 82.06% Test: 65.90%\n",
            "Epoch: 119, Loss: 0.8313, Train: 82.36%, Valid: 82.06% Test: 65.97%\n",
            "Epoch: 120, Loss: 0.8367, Train: 82.40%, Valid: 82.06% Test: 66.03%\n",
            "Epoch: 121, Loss: 0.8281, Train: 82.48%, Valid: 82.06% Test: 66.08%\n",
            "Epoch: 122, Loss: 0.8315, Train: 82.57%, Valid: 82.12% Test: 66.17%\n",
            "Epoch: 123, Loss: 0.8241, Train: 82.59%, Valid: 82.06% Test: 66.22%\n",
            "Epoch: 124, Loss: 0.8219, Train: 82.62%, Valid: 82.00% Test: 66.26%\n",
            "Epoch: 125, Loss: 0.8217, Train: 82.64%, Valid: 81.87% Test: 66.27%\n",
            "Epoch: 126, Loss: 0.8179, Train: 82.68%, Valid: 82.00% Test: 66.30%\n",
            "Epoch: 127, Loss: 0.8238, Train: 82.81%, Valid: 82.00% Test: 66.33%\n",
            "Epoch: 128, Loss: 0.8155, Train: 82.83%, Valid: 82.06% Test: 66.34%\n",
            "Epoch: 129, Loss: 0.8134, Train: 82.87%, Valid: 82.12% Test: 66.39%\n",
            "Epoch: 130, Loss: 0.8086, Train: 82.89%, Valid: 82.06% Test: 66.47%\n",
            "Epoch: 131, Loss: 0.8087, Train: 82.92%, Valid: 82.19% Test: 66.53%\n",
            "Epoch: 132, Loss: 0.8046, Train: 82.95%, Valid: 82.25% Test: 66.57%\n",
            "Epoch: 133, Loss: 0.8093, Train: 83.07%, Valid: 82.32% Test: 66.67%\n",
            "Epoch: 134, Loss: 0.8037, Train: 83.09%, Valid: 82.38% Test: 66.77%\n",
            "Epoch: 135, Loss: 0.8053, Train: 83.08%, Valid: 82.51% Test: 66.86%\n",
            "Epoch: 136, Loss: 0.8006, Train: 83.12%, Valid: 82.44% Test: 66.97%\n",
            "Epoch: 137, Loss: 0.7940, Train: 83.15%, Valid: 82.44% Test: 67.03%\n",
            "Epoch: 138, Loss: 0.8015, Train: 83.13%, Valid: 82.38% Test: 67.09%\n",
            "Epoch: 139, Loss: 0.7818, Train: 83.15%, Valid: 82.51% Test: 67.15%\n",
            "Epoch: 140, Loss: 0.7903, Train: 83.17%, Valid: 82.44% Test: 67.22%\n",
            "Epoch: 141, Loss: 0.7852, Train: 83.17%, Valid: 82.32% Test: 67.21%\n",
            "Epoch: 142, Loss: 0.7907, Train: 83.25%, Valid: 82.32% Test: 67.20%\n",
            "Epoch: 143, Loss: 0.7842, Train: 83.27%, Valid: 82.32% Test: 67.22%\n",
            "Epoch: 144, Loss: 0.7803, Train: 83.31%, Valid: 82.38% Test: 67.24%\n",
            "Epoch: 145, Loss: 0.7808, Train: 83.44%, Valid: 82.57% Test: 67.24%\n",
            "Epoch: 146, Loss: 0.7838, Train: 83.46%, Valid: 82.51% Test: 67.24%\n",
            "Epoch: 147, Loss: 0.7861, Train: 83.49%, Valid: 82.82% Test: 67.24%\n",
            "Epoch: 148, Loss: 0.7729, Train: 83.51%, Valid: 82.82% Test: 67.22%\n",
            "Epoch: 149, Loss: 0.7754, Train: 83.51%, Valid: 82.76% Test: 67.24%\n",
            "Epoch: 150, Loss: 0.7700, Train: 83.54%, Valid: 82.89% Test: 67.26%\n",
            "Epoch: 151, Loss: 0.7660, Train: 83.53%, Valid: 82.89% Test: 67.31%\n",
            "Epoch: 152, Loss: 0.7643, Train: 83.55%, Valid: 82.76% Test: 67.37%\n",
            "Epoch: 153, Loss: 0.7708, Train: 83.57%, Valid: 82.76% Test: 67.43%\n",
            "Epoch: 154, Loss: 0.7670, Train: 83.59%, Valid: 82.76% Test: 67.44%\n",
            "Epoch: 155, Loss: 0.7618, Train: 83.62%, Valid: 82.76% Test: 67.49%\n",
            "Epoch: 156, Loss: 0.7633, Train: 83.70%, Valid: 82.63% Test: 67.52%\n",
            "Epoch: 157, Loss: 0.7633, Train: 83.77%, Valid: 82.76% Test: 67.60%\n",
            "Epoch: 158, Loss: 0.7599, Train: 83.78%, Valid: 82.76% Test: 67.66%\n",
            "Epoch: 159, Loss: 0.7555, Train: 83.81%, Valid: 82.89% Test: 67.68%\n",
            "Epoch: 160, Loss: 0.7484, Train: 83.85%, Valid: 83.08% Test: 67.74%\n",
            "Epoch: 161, Loss: 0.7610, Train: 83.85%, Valid: 83.21% Test: 67.82%\n",
            "Epoch: 162, Loss: 0.7525, Train: 83.86%, Valid: 83.21% Test: 67.87%\n",
            "Epoch: 163, Loss: 0.7598, Train: 83.93%, Valid: 83.27% Test: 67.92%\n",
            "Epoch: 164, Loss: 0.7537, Train: 84.00%, Valid: 83.27% Test: 67.96%\n",
            "Epoch: 165, Loss: 0.7492, Train: 84.08%, Valid: 83.14% Test: 67.94%\n",
            "Epoch: 166, Loss: 0.7413, Train: 84.06%, Valid: 83.08% Test: 67.93%\n",
            "Epoch: 167, Loss: 0.7464, Train: 84.13%, Valid: 83.14% Test: 67.92%\n",
            "Epoch: 168, Loss: 0.7528, Train: 84.18%, Valid: 83.08% Test: 67.94%\n",
            "Epoch: 169, Loss: 0.7353, Train: 84.25%, Valid: 83.14% Test: 67.98%\n",
            "Epoch: 170, Loss: 0.7390, Train: 84.27%, Valid: 83.14% Test: 68.02%\n",
            "Epoch: 171, Loss: 0.7444, Train: 84.25%, Valid: 83.14% Test: 68.05%\n",
            "Epoch: 172, Loss: 0.7395, Train: 84.24%, Valid: 83.33% Test: 68.07%\n",
            "Epoch: 173, Loss: 0.7348, Train: 84.26%, Valid: 83.46% Test: 68.10%\n",
            "Epoch: 174, Loss: 0.7346, Train: 84.29%, Valid: 83.52% Test: 68.10%\n",
            "Epoch: 175, Loss: 0.7333, Train: 84.29%, Valid: 83.52% Test: 68.13%\n",
            "Epoch: 176, Loss: 0.7373, Train: 84.33%, Valid: 83.65% Test: 68.14%\n",
            "Epoch: 177, Loss: 0.7376, Train: 84.35%, Valid: 83.72% Test: 68.14%\n",
            "Epoch: 178, Loss: 0.7223, Train: 84.37%, Valid: 83.65% Test: 68.11%\n",
            "Epoch: 179, Loss: 0.7289, Train: 84.46%, Valid: 83.65% Test: 68.13%\n",
            "Epoch: 180, Loss: 0.7239, Train: 84.46%, Valid: 83.59% Test: 68.13%\n",
            "Epoch: 181, Loss: 0.7298, Train: 84.52%, Valid: 83.52% Test: 68.14%\n",
            "Epoch: 182, Loss: 0.7278, Train: 84.53%, Valid: 83.46% Test: 68.15%\n",
            "Epoch: 183, Loss: 0.7214, Train: 84.58%, Valid: 83.40% Test: 68.16%\n",
            "Epoch: 184, Loss: 0.7219, Train: 84.59%, Valid: 83.40% Test: 68.15%\n",
            "Epoch: 185, Loss: 0.7129, Train: 84.61%, Valid: 83.46% Test: 68.20%\n",
            "Epoch: 186, Loss: 0.7154, Train: 84.65%, Valid: 83.59% Test: 68.23%\n",
            "Epoch: 187, Loss: 0.7124, Train: 84.71%, Valid: 83.65% Test: 68.24%\n",
            "Epoch: 188, Loss: 0.7111, Train: 84.75%, Valid: 83.65% Test: 68.27%\n",
            "Epoch: 189, Loss: 0.7084, Train: 84.76%, Valid: 83.72% Test: 68.33%\n",
            "Epoch: 190, Loss: 0.7199, Train: 84.78%, Valid: 83.65% Test: 68.38%\n",
            "Epoch: 191, Loss: 0.7203, Train: 84.80%, Valid: 83.59% Test: 68.44%\n",
            "Epoch: 192, Loss: 0.7104, Train: 84.81%, Valid: 83.52% Test: 68.43%\n",
            "Epoch: 193, Loss: 0.7115, Train: 84.85%, Valid: 83.52% Test: 68.45%\n",
            "Epoch: 194, Loss: 0.7095, Train: 84.82%, Valid: 83.72% Test: 68.48%\n",
            "Epoch: 195, Loss: 0.7096, Train: 84.87%, Valid: 83.72% Test: 68.50%\n",
            "Epoch: 196, Loss: 0.7070, Train: 84.89%, Valid: 83.72% Test: 68.53%\n",
            "Epoch: 197, Loss: 0.7044, Train: 84.94%, Valid: 83.59% Test: 68.53%\n",
            "Epoch: 198, Loss: 0.7103, Train: 84.97%, Valid: 83.59% Test: 68.51%\n",
            "Epoch: 199, Loss: 0.6983, Train: 84.99%, Valid: 83.52% Test: 68.51%\n",
            "Epoch: 200, Loss: 0.6962, Train: 85.04%, Valid: 83.46% Test: 68.54%\n",
            "Epoch: 201, Loss: 0.7033, Train: 85.10%, Valid: 83.52% Test: 68.59%\n",
            "Epoch: 202, Loss: 0.6955, Train: 85.14%, Valid: 83.65% Test: 68.56%\n",
            "Epoch: 203, Loss: 0.6902, Train: 85.16%, Valid: 83.65% Test: 68.58%\n",
            "Epoch: 204, Loss: 0.6986, Train: 85.12%, Valid: 83.78% Test: 68.59%\n",
            "Epoch: 205, Loss: 0.6944, Train: 85.15%, Valid: 83.97% Test: 68.56%\n",
            "Epoch: 206, Loss: 0.6862, Train: 85.21%, Valid: 83.97% Test: 68.57%\n",
            "Epoch: 207, Loss: 0.6964, Train: 85.21%, Valid: 84.16% Test: 68.58%\n",
            "Epoch: 208, Loss: 0.6933, Train: 85.21%, Valid: 84.10% Test: 68.62%\n",
            "Epoch: 209, Loss: 0.6889, Train: 85.21%, Valid: 83.97% Test: 68.64%\n",
            "Epoch: 210, Loss: 0.6916, Train: 85.26%, Valid: 83.84% Test: 68.64%\n",
            "Epoch: 211, Loss: 0.6911, Train: 85.25%, Valid: 83.84% Test: 68.68%\n",
            "Epoch: 212, Loss: 0.6811, Train: 85.28%, Valid: 83.97% Test: 68.70%\n",
            "Epoch: 213, Loss: 0.6852, Train: 85.29%, Valid: 83.97% Test: 68.68%\n",
            "Epoch: 214, Loss: 0.6800, Train: 85.32%, Valid: 84.10% Test: 68.70%\n",
            "Epoch: 215, Loss: 0.6868, Train: 85.35%, Valid: 84.10% Test: 68.70%\n",
            "Epoch: 216, Loss: 0.6711, Train: 85.38%, Valid: 84.10% Test: 68.76%\n",
            "Epoch: 217, Loss: 0.6860, Train: 85.42%, Valid: 84.03% Test: 68.78%\n",
            "Epoch: 218, Loss: 0.6796, Train: 85.47%, Valid: 83.91% Test: 68.80%\n",
            "Epoch: 219, Loss: 0.6753, Train: 85.50%, Valid: 83.84% Test: 68.81%\n",
            "Epoch: 220, Loss: 0.6816, Train: 85.50%, Valid: 83.84% Test: 68.81%\n",
            "Epoch: 221, Loss: 0.6844, Train: 85.57%, Valid: 83.91% Test: 68.83%\n",
            "Epoch: 222, Loss: 0.6741, Train: 85.60%, Valid: 83.97% Test: 68.82%\n",
            "Epoch: 223, Loss: 0.6708, Train: 85.64%, Valid: 84.03% Test: 68.83%\n",
            "Epoch: 224, Loss: 0.6737, Train: 85.61%, Valid: 84.03% Test: 68.80%\n",
            "Epoch: 225, Loss: 0.6739, Train: 85.63%, Valid: 83.97% Test: 68.78%\n",
            "Epoch: 226, Loss: 0.6620, Train: 85.63%, Valid: 84.16% Test: 68.77%\n",
            "Epoch: 227, Loss: 0.6816, Train: 85.65%, Valid: 84.16% Test: 68.77%\n",
            "Epoch: 228, Loss: 0.6629, Train: 85.67%, Valid: 84.22% Test: 68.79%\n",
            "Epoch: 229, Loss: 0.6641, Train: 85.68%, Valid: 84.16% Test: 68.84%\n",
            "Epoch: 230, Loss: 0.6721, Train: 85.69%, Valid: 84.10% Test: 68.87%\n",
            "Epoch: 231, Loss: 0.6631, Train: 85.69%, Valid: 84.16% Test: 68.90%\n",
            "Epoch: 232, Loss: 0.6637, Train: 85.78%, Valid: 84.22% Test: 68.92%\n",
            "Epoch: 233, Loss: 0.6641, Train: 85.75%, Valid: 84.29% Test: 68.94%\n",
            "Epoch: 234, Loss: 0.6662, Train: 85.77%, Valid: 84.29% Test: 68.95%\n",
            "Epoch: 235, Loss: 0.6600, Train: 85.83%, Valid: 84.22% Test: 68.97%\n",
            "Epoch: 236, Loss: 0.6698, Train: 85.87%, Valid: 84.29% Test: 68.95%\n",
            "Epoch: 237, Loss: 0.6588, Train: 85.92%, Valid: 84.29% Test: 68.98%\n",
            "Epoch: 238, Loss: 0.6563, Train: 85.97%, Valid: 84.22% Test: 68.96%\n",
            "Epoch: 239, Loss: 0.6582, Train: 85.95%, Valid: 84.16% Test: 68.95%\n",
            "Epoch: 240, Loss: 0.6546, Train: 85.97%, Valid: 84.22% Test: 68.94%\n",
            "Epoch: 241, Loss: 0.6577, Train: 85.97%, Valid: 84.29% Test: 68.95%\n",
            "Epoch: 242, Loss: 0.6551, Train: 86.05%, Valid: 84.22% Test: 68.97%\n",
            "Epoch: 243, Loss: 0.6516, Train: 86.08%, Valid: 84.22% Test: 68.98%\n",
            "Epoch: 244, Loss: 0.6571, Train: 86.14%, Valid: 84.22% Test: 69.02%\n",
            "Epoch: 245, Loss: 0.6613, Train: 86.18%, Valid: 84.16% Test: 69.07%\n",
            "Epoch: 246, Loss: 0.6525, Train: 86.20%, Valid: 84.16% Test: 69.09%\n",
            "Epoch: 247, Loss: 0.6509, Train: 86.23%, Valid: 84.29% Test: 69.11%\n",
            "Epoch: 248, Loss: 0.6507, Train: 86.24%, Valid: 84.22% Test: 69.11%\n",
            "Epoch: 249, Loss: 0.6513, Train: 86.21%, Valid: 84.22% Test: 69.14%\n",
            "Epoch: 250, Loss: 0.6512, Train: 86.20%, Valid: 84.29% Test: 69.15%\n",
            "Epoch: 251, Loss: 0.6493, Train: 86.27%, Valid: 84.35% Test: 69.14%\n",
            "Epoch: 252, Loss: 0.6471, Train: 86.33%, Valid: 84.41% Test: 69.15%\n",
            "Epoch: 253, Loss: 0.6492, Train: 86.28%, Valid: 84.41% Test: 69.18%\n",
            "Epoch: 254, Loss: 0.6447, Train: 86.32%, Valid: 84.41% Test: 69.21%\n",
            "Epoch: 255, Loss: 0.6482, Train: 86.32%, Valid: 84.41% Test: 69.23%\n",
            "Epoch: 256, Loss: 0.6411, Train: 86.35%, Valid: 84.35% Test: 69.21%\n",
            "Epoch: 257, Loss: 0.6390, Train: 86.35%, Valid: 84.22% Test: 69.17%\n",
            "Epoch: 258, Loss: 0.6366, Train: 86.33%, Valid: 84.48% Test: 69.13%\n",
            "Epoch: 259, Loss: 0.6391, Train: 86.37%, Valid: 84.54% Test: 69.12%\n",
            "Epoch: 260, Loss: 0.6336, Train: 86.43%, Valid: 84.48% Test: 69.15%\n",
            "Epoch: 261, Loss: 0.6342, Train: 86.44%, Valid: 84.48% Test: 69.17%\n",
            "Epoch: 262, Loss: 0.6368, Train: 86.44%, Valid: 84.41% Test: 69.14%\n",
            "Epoch: 263, Loss: 0.6417, Train: 86.42%, Valid: 84.48% Test: 69.15%\n",
            "Epoch: 264, Loss: 0.6333, Train: 86.47%, Valid: 84.54% Test: 69.18%\n",
            "Epoch: 265, Loss: 0.6372, Train: 86.48%, Valid: 84.48% Test: 69.22%\n",
            "Epoch: 266, Loss: 0.6290, Train: 86.50%, Valid: 84.41% Test: 69.29%\n",
            "Epoch: 267, Loss: 0.6335, Train: 86.51%, Valid: 84.48% Test: 69.33%\n",
            "Epoch: 268, Loss: 0.6349, Train: 86.56%, Valid: 84.48% Test: 69.36%\n",
            "Epoch: 269, Loss: 0.6274, Train: 86.60%, Valid: 84.48% Test: 69.41%\n",
            "Epoch: 270, Loss: 0.6331, Train: 86.59%, Valid: 84.61% Test: 69.42%\n",
            "Epoch: 271, Loss: 0.6183, Train: 86.61%, Valid: 84.67% Test: 69.44%\n",
            "Epoch: 272, Loss: 0.6235, Train: 86.59%, Valid: 84.67% Test: 69.44%\n",
            "Epoch: 273, Loss: 0.6224, Train: 86.61%, Valid: 84.67% Test: 69.45%\n",
            "Epoch: 274, Loss: 0.6360, Train: 86.69%, Valid: 84.61% Test: 69.42%\n",
            "Epoch: 275, Loss: 0.6217, Train: 86.71%, Valid: 84.54% Test: 69.41%\n",
            "Epoch: 276, Loss: 0.6202, Train: 86.71%, Valid: 84.61% Test: 69.38%\n",
            "Epoch: 277, Loss: 0.6179, Train: 86.71%, Valid: 84.86% Test: 69.37%\n",
            "Epoch: 278, Loss: 0.6253, Train: 86.69%, Valid: 84.80% Test: 69.37%\n",
            "Epoch: 279, Loss: 0.6221, Train: 86.72%, Valid: 84.99% Test: 69.34%\n",
            "Epoch: 280, Loss: 0.6230, Train: 86.69%, Valid: 84.86% Test: 69.37%\n",
            "Epoch: 281, Loss: 0.6228, Train: 86.71%, Valid: 84.86% Test: 69.40%\n",
            "Epoch: 282, Loss: 0.6150, Train: 86.79%, Valid: 84.86% Test: 69.44%\n",
            "Epoch: 283, Loss: 0.6159, Train: 86.82%, Valid: 84.92% Test: 69.48%\n",
            "Epoch: 284, Loss: 0.6180, Train: 86.87%, Valid: 84.86% Test: 69.50%\n",
            "Epoch: 285, Loss: 0.6148, Train: 86.88%, Valid: 84.92% Test: 69.51%\n",
            "Epoch: 286, Loss: 0.6228, Train: 86.86%, Valid: 84.99% Test: 69.53%\n",
            "Epoch: 287, Loss: 0.6111, Train: 86.89%, Valid: 84.92% Test: 69.55%\n",
            "Epoch: 288, Loss: 0.6196, Train: 86.92%, Valid: 84.86% Test: 69.60%\n",
            "Epoch: 289, Loss: 0.6195, Train: 86.97%, Valid: 84.86% Test: 69.61%\n",
            "Epoch: 290, Loss: 0.6087, Train: 86.98%, Valid: 84.99% Test: 69.56%\n",
            "Epoch: 291, Loss: 0.6124, Train: 87.00%, Valid: 84.92% Test: 69.54%\n",
            "Epoch: 292, Loss: 0.6093, Train: 87.01%, Valid: 84.92% Test: 69.49%\n",
            "Epoch: 293, Loss: 0.6083, Train: 87.01%, Valid: 84.92% Test: 69.46%\n",
            "Epoch: 294, Loss: 0.6009, Train: 87.03%, Valid: 84.80% Test: 69.41%\n",
            "Epoch: 295, Loss: 0.6154, Train: 87.04%, Valid: 84.73% Test: 69.39%\n",
            "Epoch: 296, Loss: 0.6036, Train: 87.03%, Valid: 84.73% Test: 69.41%\n",
            "Epoch: 297, Loss: 0.6089, Train: 87.07%, Valid: 84.73% Test: 69.43%\n",
            "Epoch: 298, Loss: 0.6096, Train: 87.12%, Valid: 84.73% Test: 69.47%\n",
            "Epoch: 299, Loss: 0.6008, Train: 87.16%, Valid: 84.73% Test: 69.49%\n",
            "Epoch: 300, Loss: 0.6046, Train: 87.16%, Valid: 84.67% Test: 69.52%\n",
            "Epoch: 301, Loss: 0.6058, Train: 87.18%, Valid: 84.67% Test: 69.55%\n",
            "Epoch: 302, Loss: 0.6026, Train: 87.22%, Valid: 84.80% Test: 69.55%\n",
            "Epoch: 303, Loss: 0.5937, Train: 87.26%, Valid: 84.99% Test: 69.57%\n",
            "Epoch: 304, Loss: 0.5988, Train: 87.26%, Valid: 84.99% Test: 69.60%\n",
            "Epoch: 305, Loss: 0.5971, Train: 87.28%, Valid: 84.92% Test: 69.59%\n",
            "Epoch: 306, Loss: 0.5975, Train: 87.29%, Valid: 84.86% Test: 69.59%\n",
            "Epoch: 307, Loss: 0.5986, Train: 87.32%, Valid: 84.86% Test: 69.63%\n",
            "Epoch: 308, Loss: 0.5982, Train: 87.31%, Valid: 84.80% Test: 69.64%\n",
            "Epoch: 309, Loss: 0.6002, Train: 87.35%, Valid: 84.86% Test: 69.63%\n",
            "Epoch: 310, Loss: 0.5896, Train: 87.37%, Valid: 84.86% Test: 69.61%\n",
            "Epoch: 311, Loss: 0.6019, Train: 87.37%, Valid: 84.86% Test: 69.62%\n",
            "Epoch: 312, Loss: 0.5979, Train: 87.41%, Valid: 84.86% Test: 69.61%\n",
            "Epoch: 313, Loss: 0.5990, Train: 87.42%, Valid: 84.92% Test: 69.63%\n",
            "Epoch: 314, Loss: 0.5957, Train: 87.48%, Valid: 84.92% Test: 69.61%\n",
            "Epoch: 315, Loss: 0.5932, Train: 87.52%, Valid: 84.80% Test: 69.58%\n",
            "Epoch: 316, Loss: 0.5925, Train: 87.57%, Valid: 84.73% Test: 69.58%\n",
            "Epoch: 317, Loss: 0.5917, Train: 87.56%, Valid: 84.86% Test: 69.60%\n",
            "Epoch: 318, Loss: 0.5817, Train: 87.56%, Valid: 84.86% Test: 69.66%\n",
            "Epoch: 319, Loss: 0.5965, Train: 87.58%, Valid: 84.86% Test: 69.70%\n",
            "Epoch: 320, Loss: 0.5876, Train: 87.63%, Valid: 84.80% Test: 69.72%\n",
            "Epoch: 321, Loss: 0.5821, Train: 87.64%, Valid: 84.73% Test: 69.74%\n",
            "Epoch: 322, Loss: 0.5876, Train: 87.66%, Valid: 84.73% Test: 69.75%\n",
            "Epoch: 323, Loss: 0.5915, Train: 87.70%, Valid: 84.86% Test: 69.79%\n",
            "Epoch: 324, Loss: 0.5878, Train: 87.70%, Valid: 84.80% Test: 69.76%\n",
            "Epoch: 325, Loss: 0.5894, Train: 87.71%, Valid: 84.80% Test: 69.77%\n",
            "Epoch: 326, Loss: 0.5869, Train: 87.74%, Valid: 84.86% Test: 69.79%\n",
            "Epoch: 327, Loss: 0.5900, Train: 87.78%, Valid: 84.80% Test: 69.77%\n",
            "Epoch: 328, Loss: 0.5854, Train: 87.78%, Valid: 84.92% Test: 69.78%\n",
            "Epoch: 329, Loss: 0.5834, Train: 87.77%, Valid: 84.80% Test: 69.75%\n",
            "Epoch: 330, Loss: 0.5835, Train: 87.78%, Valid: 84.80% Test: 69.76%\n",
            "Epoch: 331, Loss: 0.5836, Train: 87.76%, Valid: 84.80% Test: 69.81%\n",
            "Epoch: 332, Loss: 0.5838, Train: 87.80%, Valid: 84.80% Test: 69.81%\n",
            "Epoch: 333, Loss: 0.5868, Train: 87.80%, Valid: 84.86% Test: 69.86%\n",
            "Epoch: 334, Loss: 0.5799, Train: 87.80%, Valid: 84.99% Test: 69.90%\n",
            "Epoch: 335, Loss: 0.5762, Train: 87.82%, Valid: 84.86% Test: 69.93%\n",
            "Epoch: 336, Loss: 0.5718, Train: 87.84%, Valid: 84.92% Test: 69.93%\n",
            "Epoch: 337, Loss: 0.5728, Train: 87.90%, Valid: 84.86% Test: 69.92%\n",
            "Epoch: 338, Loss: 0.5780, Train: 87.95%, Valid: 84.86% Test: 69.94%\n",
            "Epoch: 339, Loss: 0.5740, Train: 87.97%, Valid: 84.86% Test: 69.90%\n",
            "Epoch: 340, Loss: 0.5804, Train: 87.96%, Valid: 84.86% Test: 69.88%\n",
            "Epoch: 341, Loss: 0.5833, Train: 87.97%, Valid: 84.86% Test: 69.85%\n",
            "Epoch: 342, Loss: 0.5752, Train: 87.99%, Valid: 84.80% Test: 69.83%\n",
            "Epoch: 343, Loss: 0.5782, Train: 87.99%, Valid: 84.73% Test: 69.80%\n",
            "Epoch: 344, Loss: 0.5692, Train: 87.99%, Valid: 84.86% Test: 69.79%\n",
            "Epoch: 345, Loss: 0.5781, Train: 88.05%, Valid: 84.86% Test: 69.81%\n",
            "Epoch: 346, Loss: 0.5755, Train: 88.07%, Valid: 84.92% Test: 69.84%\n",
            "Epoch: 347, Loss: 0.5807, Train: 88.07%, Valid: 85.05% Test: 69.82%\n",
            "Epoch: 348, Loss: 0.5679, Train: 88.08%, Valid: 85.05% Test: 69.82%\n",
            "Epoch: 349, Loss: 0.5680, Train: 88.06%, Valid: 84.99% Test: 69.83%\n",
            "Epoch: 350, Loss: 0.5667, Train: 88.10%, Valid: 84.99% Test: 69.86%\n",
            "Epoch: 351, Loss: 0.5623, Train: 88.09%, Valid: 84.92% Test: 69.92%\n",
            "Epoch: 352, Loss: 0.5735, Train: 88.09%, Valid: 84.92% Test: 69.97%\n",
            "Epoch: 353, Loss: 0.5700, Train: 88.12%, Valid: 84.86% Test: 70.03%\n",
            "Epoch: 354, Loss: 0.5652, Train: 88.17%, Valid: 84.86% Test: 70.06%\n",
            "Epoch: 355, Loss: 0.5731, Train: 88.16%, Valid: 84.92% Test: 70.04%\n",
            "Epoch: 356, Loss: 0.5651, Train: 88.18%, Valid: 84.92% Test: 70.05%\n",
            "Epoch: 357, Loss: 0.5665, Train: 88.21%, Valid: 84.92% Test: 70.04%\n",
            "Epoch: 358, Loss: 0.5590, Train: 88.20%, Valid: 84.92% Test: 70.06%\n",
            "Epoch: 359, Loss: 0.5591, Train: 88.22%, Valid: 85.05% Test: 70.06%\n",
            "Epoch: 360, Loss: 0.5624, Train: 88.24%, Valid: 85.05% Test: 70.09%\n",
            "Epoch: 361, Loss: 0.5540, Train: 88.21%, Valid: 85.05% Test: 70.05%\n",
            "Epoch: 362, Loss: 0.5535, Train: 88.22%, Valid: 85.11% Test: 70.08%\n",
            "Epoch: 363, Loss: 0.5666, Train: 88.22%, Valid: 85.18% Test: 70.12%\n",
            "Epoch: 364, Loss: 0.5593, Train: 88.29%, Valid: 85.05% Test: 70.14%\n",
            "Epoch: 365, Loss: 0.5643, Train: 88.22%, Valid: 85.11% Test: 70.15%\n",
            "Epoch: 366, Loss: 0.5601, Train: 88.21%, Valid: 84.99% Test: 70.13%\n",
            "Epoch: 367, Loss: 0.5566, Train: 88.25%, Valid: 84.86% Test: 70.16%\n",
            "Epoch: 368, Loss: 0.5599, Train: 88.24%, Valid: 84.86% Test: 70.12%\n",
            "Epoch: 369, Loss: 0.5573, Train: 88.23%, Valid: 84.80% Test: 70.11%\n",
            "Epoch: 370, Loss: 0.5557, Train: 88.26%, Valid: 84.92% Test: 70.13%\n",
            "Epoch: 371, Loss: 0.5580, Train: 88.32%, Valid: 84.99% Test: 70.14%\n",
            "Epoch: 372, Loss: 0.5494, Train: 88.39%, Valid: 85.05% Test: 70.15%\n",
            "Epoch: 373, Loss: 0.5574, Train: 88.41%, Valid: 84.99% Test: 70.19%\n",
            "Epoch: 374, Loss: 0.5652, Train: 88.48%, Valid: 84.99% Test: 70.23%\n",
            "Epoch: 375, Loss: 0.5592, Train: 88.49%, Valid: 84.92% Test: 70.27%\n",
            "Epoch: 376, Loss: 0.5514, Train: 88.51%, Valid: 84.92% Test: 70.33%\n",
            "Epoch: 377, Loss: 0.5507, Train: 88.54%, Valid: 84.92% Test: 70.36%\n",
            "Epoch: 378, Loss: 0.5505, Train: 88.56%, Valid: 85.05% Test: 70.34%\n",
            "Epoch: 379, Loss: 0.5518, Train: 88.57%, Valid: 85.18% Test: 70.33%\n",
            "Epoch: 380, Loss: 0.5514, Train: 88.56%, Valid: 85.05% Test: 70.30%\n",
            "Epoch: 381, Loss: 0.5541, Train: 88.56%, Valid: 85.11% Test: 70.29%\n",
            "Epoch: 382, Loss: 0.5427, Train: 88.60%, Valid: 84.99% Test: 70.23%\n",
            "Epoch: 383, Loss: 0.5429, Train: 88.60%, Valid: 84.99% Test: 70.23%\n",
            "Epoch: 384, Loss: 0.5534, Train: 88.59%, Valid: 84.86% Test: 70.26%\n",
            "Epoch: 385, Loss: 0.5427, Train: 88.60%, Valid: 84.86% Test: 70.27%\n",
            "Epoch: 386, Loss: 0.5523, Train: 88.59%, Valid: 84.86% Test: 70.28%\n",
            "Epoch: 387, Loss: 0.5531, Train: 88.57%, Valid: 84.86% Test: 70.33%\n",
            "Epoch: 388, Loss: 0.5472, Train: 88.57%, Valid: 84.86% Test: 70.37%\n",
            "Epoch: 389, Loss: 0.5487, Train: 88.54%, Valid: 84.80% Test: 70.41%\n",
            "Epoch: 390, Loss: 0.5470, Train: 88.58%, Valid: 85.05% Test: 70.40%\n",
            "Epoch: 391, Loss: 0.5448, Train: 88.63%, Valid: 85.11% Test: 70.44%\n",
            "Epoch: 392, Loss: 0.5510, Train: 88.57%, Valid: 84.99% Test: 70.48%\n",
            "Epoch: 393, Loss: 0.5405, Train: 88.58%, Valid: 84.86% Test: 70.48%\n",
            "Epoch: 394, Loss: 0.5400, Train: 88.60%, Valid: 84.99% Test: 70.48%\n",
            "Epoch: 395, Loss: 0.5334, Train: 88.69%, Valid: 84.86% Test: 70.54%\n",
            "Epoch: 396, Loss: 0.5434, Train: 88.67%, Valid: 84.86% Test: 70.52%\n",
            "Epoch: 397, Loss: 0.5391, Train: 88.69%, Valid: 84.92% Test: 70.50%\n",
            "Epoch: 398, Loss: 0.5497, Train: 88.72%, Valid: 84.99% Test: 70.51%\n",
            "Epoch: 399, Loss: 0.5384, Train: 88.84%, Valid: 85.05% Test: 70.49%\n",
            "Epoch: 400, Loss: 0.5373, Train: 88.84%, Valid: 84.99% Test: 70.48%\n",
            "Epoch: 401, Loss: 0.5416, Train: 88.84%, Valid: 84.92% Test: 70.48%\n",
            "Epoch: 402, Loss: 0.5347, Train: 88.82%, Valid: 84.99% Test: 70.49%\n",
            "Epoch: 403, Loss: 0.5355, Train: 88.82%, Valid: 84.99% Test: 70.47%\n",
            "Epoch: 404, Loss: 0.5411, Train: 88.86%, Valid: 84.92% Test: 70.48%\n",
            "Epoch: 405, Loss: 0.5383, Train: 88.86%, Valid: 84.92% Test: 70.47%\n",
            "Epoch: 406, Loss: 0.5416, Train: 88.88%, Valid: 84.92% Test: 70.51%\n",
            "Epoch: 407, Loss: 0.5311, Train: 88.82%, Valid: 84.92% Test: 70.52%\n",
            "Epoch: 408, Loss: 0.5354, Train: 88.90%, Valid: 84.99% Test: 70.55%\n",
            "Epoch: 409, Loss: 0.5312, Train: 88.90%, Valid: 85.05% Test: 70.58%\n",
            "Epoch: 410, Loss: 0.5341, Train: 88.93%, Valid: 85.05% Test: 70.60%\n",
            "Epoch: 411, Loss: 0.5333, Train: 88.94%, Valid: 85.18% Test: 70.63%\n",
            "Epoch: 412, Loss: 0.5362, Train: 88.94%, Valid: 85.11% Test: 70.62%\n",
            "Epoch: 413, Loss: 0.5325, Train: 88.95%, Valid: 84.99% Test: 70.62%\n",
            "Epoch: 414, Loss: 0.5392, Train: 88.94%, Valid: 85.05% Test: 70.62%\n",
            "Epoch: 415, Loss: 0.5279, Train: 88.93%, Valid: 85.05% Test: 70.62%\n",
            "Epoch: 416, Loss: 0.5347, Train: 88.92%, Valid: 84.92% Test: 70.62%\n",
            "Epoch: 417, Loss: 0.5239, Train: 88.96%, Valid: 84.92% Test: 70.58%\n",
            "Epoch: 418, Loss: 0.5304, Train: 88.99%, Valid: 85.05% Test: 70.53%\n",
            "Epoch: 419, Loss: 0.5281, Train: 88.98%, Valid: 84.99% Test: 70.53%\n",
            "Epoch: 420, Loss: 0.5248, Train: 88.99%, Valid: 85.11% Test: 70.51%\n",
            "Epoch: 421, Loss: 0.5276, Train: 89.03%, Valid: 85.11% Test: 70.47%\n",
            "Epoch: 422, Loss: 0.5218, Train: 89.05%, Valid: 85.05% Test: 70.44%\n",
            "Epoch: 423, Loss: 0.5250, Train: 89.03%, Valid: 85.18% Test: 70.44%\n",
            "Epoch: 424, Loss: 0.5323, Train: 89.02%, Valid: 85.11% Test: 70.42%\n",
            "Epoch: 425, Loss: 0.5335, Train: 89.03%, Valid: 85.05% Test: 70.45%\n",
            "Epoch: 426, Loss: 0.5217, Train: 89.07%, Valid: 85.05% Test: 70.48%\n",
            "Epoch: 427, Loss: 0.5254, Train: 89.11%, Valid: 85.05% Test: 70.53%\n",
            "Epoch: 428, Loss: 0.5303, Train: 89.14%, Valid: 84.92% Test: 70.59%\n",
            "Epoch: 429, Loss: 0.5184, Train: 89.15%, Valid: 84.99% Test: 70.64%\n",
            "Epoch: 430, Loss: 0.5279, Train: 89.22%, Valid: 84.99% Test: 70.71%\n",
            "Epoch: 431, Loss: 0.5166, Train: 89.22%, Valid: 85.05% Test: 70.71%\n",
            "Epoch: 432, Loss: 0.5227, Train: 89.24%, Valid: 85.05% Test: 70.72%\n",
            "Epoch: 433, Loss: 0.5175, Train: 89.26%, Valid: 85.05% Test: 70.72%\n",
            "Epoch: 434, Loss: 0.5222, Train: 89.26%, Valid: 84.99% Test: 70.73%\n",
            "Epoch: 435, Loss: 0.5191, Train: 89.24%, Valid: 85.05% Test: 70.71%\n",
            "Epoch: 436, Loss: 0.5262, Train: 89.22%, Valid: 85.05% Test: 70.67%\n",
            "Epoch: 437, Loss: 0.5196, Train: 89.19%, Valid: 84.99% Test: 70.66%\n",
            "Epoch: 438, Loss: 0.5199, Train: 89.22%, Valid: 84.99% Test: 70.61%\n",
            "Epoch: 439, Loss: 0.5143, Train: 89.22%, Valid: 84.99% Test: 70.58%\n",
            "Epoch: 440, Loss: 0.5143, Train: 89.24%, Valid: 84.99% Test: 70.57%\n",
            "Epoch: 441, Loss: 0.5138, Train: 89.28%, Valid: 84.99% Test: 70.59%\n",
            "Epoch: 442, Loss: 0.5211, Train: 89.26%, Valid: 84.99% Test: 70.57%\n",
            "Epoch: 443, Loss: 0.5142, Train: 89.29%, Valid: 85.05% Test: 70.52%\n",
            "Epoch: 444, Loss: 0.5105, Train: 89.29%, Valid: 85.11% Test: 70.53%\n",
            "Epoch: 445, Loss: 0.5113, Train: 89.30%, Valid: 84.92% Test: 70.55%\n",
            "Epoch: 446, Loss: 0.5108, Train: 89.36%, Valid: 84.99% Test: 70.55%\n",
            "Epoch: 447, Loss: 0.5180, Train: 89.38%, Valid: 85.05% Test: 70.54%\n",
            "Epoch: 448, Loss: 0.5092, Train: 89.43%, Valid: 84.99% Test: 70.59%\n",
            "Epoch: 449, Loss: 0.5147, Train: 89.45%, Valid: 84.99% Test: 70.62%\n",
            "Epoch: 450, Loss: 0.5105, Train: 89.45%, Valid: 84.99% Test: 70.70%\n",
            "Epoch: 451, Loss: 0.4980, Train: 89.47%, Valid: 85.11% Test: 70.76%\n",
            "Epoch: 452, Loss: 0.5155, Train: 89.48%, Valid: 85.24% Test: 70.80%\n",
            "Epoch: 453, Loss: 0.5173, Train: 89.55%, Valid: 85.24% Test: 70.80%\n",
            "Epoch: 454, Loss: 0.5124, Train: 89.56%, Valid: 85.18% Test: 70.82%\n",
            "Epoch: 455, Loss: 0.5125, Train: 89.58%, Valid: 85.24% Test: 70.79%\n",
            "Epoch: 456, Loss: 0.5079, Train: 89.59%, Valid: 85.31% Test: 70.80%\n",
            "Epoch: 457, Loss: 0.5068, Train: 89.60%, Valid: 85.18% Test: 70.74%\n",
            "Epoch: 458, Loss: 0.5105, Train: 89.61%, Valid: 85.11% Test: 70.71%\n",
            "Epoch: 459, Loss: 0.5096, Train: 89.60%, Valid: 84.99% Test: 70.60%\n",
            "Epoch: 460, Loss: 0.5094, Train: 89.62%, Valid: 85.05% Test: 70.62%\n",
            "Epoch: 461, Loss: 0.5114, Train: 89.60%, Valid: 85.24% Test: 70.61%\n",
            "Epoch: 462, Loss: 0.5063, Train: 89.63%, Valid: 85.18% Test: 70.61%\n",
            "Epoch: 463, Loss: 0.5056, Train: 89.60%, Valid: 85.31% Test: 70.61%\n",
            "Epoch: 464, Loss: 0.5110, Train: 89.61%, Valid: 85.18% Test: 70.59%\n",
            "Epoch: 465, Loss: 0.5022, Train: 89.60%, Valid: 85.24% Test: 70.59%\n",
            "Epoch: 466, Loss: 0.5139, Train: 89.61%, Valid: 85.37% Test: 70.58%\n",
            "Epoch: 467, Loss: 0.5090, Train: 89.65%, Valid: 85.37% Test: 70.61%\n",
            "Epoch: 468, Loss: 0.5066, Train: 89.65%, Valid: 85.11% Test: 70.63%\n",
            "Epoch: 469, Loss: 0.5049, Train: 89.69%, Valid: 85.31% Test: 70.67%\n",
            "Epoch: 470, Loss: 0.5033, Train: 89.66%, Valid: 85.05% Test: 70.73%\n",
            "Epoch: 471, Loss: 0.5033, Train: 89.64%, Valid: 84.99% Test: 70.81%\n",
            "Epoch: 472, Loss: 0.5021, Train: 89.63%, Valid: 84.92% Test: 70.83%\n",
            "Epoch: 473, Loss: 0.5044, Train: 89.63%, Valid: 85.11% Test: 70.86%\n",
            "Epoch: 474, Loss: 0.4956, Train: 89.65%, Valid: 85.18% Test: 70.89%\n",
            "Epoch: 475, Loss: 0.5030, Train: 89.67%, Valid: 85.24% Test: 70.90%\n",
            "Epoch: 476, Loss: 0.5024, Train: 89.72%, Valid: 85.37% Test: 70.90%\n",
            "Epoch: 477, Loss: 0.5049, Train: 89.72%, Valid: 85.43% Test: 70.87%\n",
            "Epoch: 478, Loss: 0.4962, Train: 89.76%, Valid: 85.31% Test: 70.79%\n",
            "Epoch: 479, Loss: 0.5003, Train: 89.79%, Valid: 85.18% Test: 70.71%\n",
            "Epoch: 480, Loss: 0.5028, Train: 89.83%, Valid: 85.24% Test: 70.69%\n",
            "Epoch: 481, Loss: 0.4947, Train: 89.81%, Valid: 85.24% Test: 70.62%\n",
            "Epoch: 482, Loss: 0.4997, Train: 89.82%, Valid: 85.31% Test: 70.61%\n",
            "Epoch: 483, Loss: 0.5007, Train: 89.84%, Valid: 85.11% Test: 70.60%\n",
            "Epoch: 484, Loss: 0.4920, Train: 89.86%, Valid: 85.18% Test: 70.61%\n",
            "Epoch: 485, Loss: 0.4970, Train: 89.90%, Valid: 85.18% Test: 70.67%\n",
            "Epoch: 486, Loss: 0.4984, Train: 89.95%, Valid: 85.31% Test: 70.72%\n",
            "Epoch: 487, Loss: 0.4935, Train: 89.96%, Valid: 85.43% Test: 70.77%\n",
            "Epoch: 488, Loss: 0.4852, Train: 89.96%, Valid: 85.43% Test: 70.83%\n",
            "Epoch: 489, Loss: 0.5001, Train: 89.96%, Valid: 85.31% Test: 70.89%\n",
            "Epoch: 490, Loss: 0.4938, Train: 89.95%, Valid: 85.24% Test: 70.89%\n",
            "Epoch: 491, Loss: 0.4881, Train: 89.96%, Valid: 85.31% Test: 70.89%\n",
            "Epoch: 492, Loss: 0.5013, Train: 90.03%, Valid: 85.31% Test: 70.91%\n",
            "Epoch: 493, Loss: 0.4945, Train: 90.07%, Valid: 85.24% Test: 70.89%\n",
            "Epoch: 494, Loss: 0.4910, Train: 90.04%, Valid: 85.37% Test: 70.93%\n",
            "Epoch: 495, Loss: 0.4932, Train: 90.06%, Valid: 85.31% Test: 70.92%\n",
            "Epoch: 496, Loss: 0.4905, Train: 90.05%, Valid: 85.31% Test: 70.88%\n",
            "Epoch: 497, Loss: 0.4901, Train: 90.05%, Valid: 85.24% Test: 70.88%\n",
            "Epoch: 498, Loss: 0.4900, Train: 90.12%, Valid: 85.24% Test: 70.88%\n",
            "Epoch: 499, Loss: 0.4957, Train: 90.16%, Valid: 85.18% Test: 70.86%\n",
            "Epoch: 500, Loss: 0.4926, Train: 90.17%, Valid: 85.18% Test: 70.87%\n",
            "Epoch: 501, Loss: 0.4847, Train: 90.17%, Valid: 85.18% Test: 70.85%\n",
            "Epoch: 502, Loss: 0.4859, Train: 90.14%, Valid: 85.31% Test: 70.87%\n",
            "Epoch: 503, Loss: 0.4873, Train: 90.11%, Valid: 85.37% Test: 70.88%\n",
            "Epoch: 504, Loss: 0.4854, Train: 90.09%, Valid: 85.37% Test: 70.89%\n",
            "Epoch: 505, Loss: 0.4838, Train: 90.11%, Valid: 85.43% Test: 70.90%\n",
            "Epoch: 506, Loss: 0.4816, Train: 90.13%, Valid: 85.43% Test: 70.88%\n",
            "Epoch: 507, Loss: 0.4899, Train: 90.14%, Valid: 85.43% Test: 70.85%\n",
            "Epoch: 508, Loss: 0.4813, Train: 90.14%, Valid: 85.50% Test: 70.82%\n",
            "Epoch: 509, Loss: 0.4808, Train: 90.18%, Valid: 85.69% Test: 70.79%\n",
            "Epoch: 510, Loss: 0.4804, Train: 90.18%, Valid: 85.69% Test: 70.76%\n",
            "Epoch: 511, Loss: 0.4895, Train: 90.18%, Valid: 85.56% Test: 70.73%\n",
            "Epoch: 512, Loss: 0.4841, Train: 90.21%, Valid: 85.56% Test: 70.71%\n",
            "Epoch: 513, Loss: 0.4746, Train: 90.21%, Valid: 85.62% Test: 70.71%\n",
            "Epoch: 514, Loss: 0.4910, Train: 90.27%, Valid: 85.56% Test: 70.70%\n",
            "Epoch: 515, Loss: 0.4829, Train: 90.30%, Valid: 85.56% Test: 70.74%\n",
            "Epoch: 516, Loss: 0.4809, Train: 90.32%, Valid: 85.62% Test: 70.78%\n",
            "Epoch: 517, Loss: 0.4855, Train: 90.37%, Valid: 85.50% Test: 70.84%\n",
            "Epoch: 518, Loss: 0.4769, Train: 90.32%, Valid: 85.37% Test: 70.92%\n",
            "Epoch: 519, Loss: 0.4790, Train: 90.29%, Valid: 85.37% Test: 70.90%\n",
            "Epoch: 520, Loss: 0.4828, Train: 90.30%, Valid: 85.43% Test: 70.92%\n",
            "Epoch: 521, Loss: 0.4801, Train: 90.30%, Valid: 85.43% Test: 70.93%\n",
            "Epoch: 522, Loss: 0.4781, Train: 90.34%, Valid: 85.37% Test: 70.96%\n",
            "Epoch: 523, Loss: 0.4783, Train: 90.34%, Valid: 85.37% Test: 70.97%\n",
            "Epoch: 524, Loss: 0.4797, Train: 90.35%, Valid: 85.43% Test: 70.95%\n",
            "Epoch: 525, Loss: 0.4766, Train: 90.37%, Valid: 85.50% Test: 70.95%\n",
            "Epoch: 526, Loss: 0.4819, Train: 90.35%, Valid: 85.50% Test: 70.93%\n",
            "Epoch: 527, Loss: 0.4777, Train: 90.41%, Valid: 85.50% Test: 70.89%\n",
            "Epoch: 528, Loss: 0.4762, Train: 90.46%, Valid: 85.43% Test: 70.80%\n",
            "Epoch: 529, Loss: 0.4693, Train: 90.48%, Valid: 85.50% Test: 70.72%\n",
            "Epoch: 530, Loss: 0.4744, Train: 90.45%, Valid: 85.43% Test: 70.68%\n",
            "Epoch: 531, Loss: 0.4829, Train: 90.48%, Valid: 85.37% Test: 70.67%\n",
            "Epoch: 532, Loss: 0.4799, Train: 90.45%, Valid: 85.31% Test: 70.71%\n",
            "Epoch: 533, Loss: 0.4792, Train: 90.45%, Valid: 85.24% Test: 70.73%\n",
            "Epoch: 534, Loss: 0.4811, Train: 90.46%, Valid: 85.24% Test: 70.75%\n",
            "Epoch: 535, Loss: 0.4827, Train: 90.46%, Valid: 85.24% Test: 70.80%\n",
            "Epoch: 536, Loss: 0.4746, Train: 90.46%, Valid: 85.24% Test: 70.83%\n",
            "Epoch: 537, Loss: 0.4771, Train: 90.43%, Valid: 85.24% Test: 70.84%\n",
            "Epoch: 538, Loss: 0.4792, Train: 90.42%, Valid: 85.18% Test: 70.82%\n",
            "Epoch: 539, Loss: 0.4761, Train: 90.45%, Valid: 85.18% Test: 70.81%\n",
            "Epoch: 540, Loss: 0.4779, Train: 90.48%, Valid: 85.18% Test: 70.81%\n",
            "Epoch: 541, Loss: 0.4738, Train: 90.48%, Valid: 85.31% Test: 70.81%\n",
            "Epoch: 542, Loss: 0.4716, Train: 90.47%, Valid: 85.37% Test: 70.77%\n",
            "Epoch: 543, Loss: 0.4714, Train: 90.54%, Valid: 85.37% Test: 70.80%\n",
            "Epoch: 544, Loss: 0.4740, Train: 90.52%, Valid: 85.31% Test: 70.78%\n",
            "Epoch: 545, Loss: 0.4644, Train: 90.51%, Valid: 85.31% Test: 70.76%\n",
            "Epoch: 546, Loss: 0.4652, Train: 90.53%, Valid: 85.31% Test: 70.77%\n",
            "Epoch: 547, Loss: 0.4748, Train: 90.55%, Valid: 85.31% Test: 70.79%\n",
            "Epoch: 548, Loss: 0.4724, Train: 90.56%, Valid: 85.31% Test: 70.77%\n",
            "Epoch: 549, Loss: 0.4723, Train: 90.61%, Valid: 85.37% Test: 70.73%\n",
            "Epoch: 550, Loss: 0.4694, Train: 90.66%, Valid: 85.37% Test: 70.69%\n",
            "Epoch: 551, Loss: 0.4644, Train: 90.69%, Valid: 85.31% Test: 70.69%\n",
            "Epoch: 552, Loss: 0.4771, Train: 90.70%, Valid: 85.37% Test: 70.71%\n",
            "Epoch: 553, Loss: 0.4644, Train: 90.73%, Valid: 85.37% Test: 70.76%\n",
            "Epoch: 554, Loss: 0.4647, Train: 90.74%, Valid: 85.37% Test: 70.79%\n",
            "Epoch: 555, Loss: 0.4659, Train: 90.71%, Valid: 85.37% Test: 70.85%\n",
            "Epoch: 556, Loss: 0.4677, Train: 90.75%, Valid: 85.50% Test: 70.92%\n",
            "Epoch: 557, Loss: 0.4661, Train: 90.79%, Valid: 85.50% Test: 70.98%\n",
            "Epoch: 558, Loss: 0.4633, Train: 90.75%, Valid: 85.62% Test: 71.05%\n",
            "Epoch: 559, Loss: 0.4657, Train: 90.77%, Valid: 85.62% Test: 71.10%\n",
            "Epoch: 560, Loss: 0.4664, Train: 90.76%, Valid: 85.56% Test: 71.07%\n",
            "Epoch: 561, Loss: 0.4710, Train: 90.74%, Valid: 85.50% Test: 71.05%\n",
            "Epoch: 562, Loss: 0.4626, Train: 90.76%, Valid: 85.43% Test: 71.04%\n",
            "Epoch: 563, Loss: 0.4613, Train: 90.76%, Valid: 85.43% Test: 70.99%\n",
            "Epoch: 564, Loss: 0.4594, Train: 90.76%, Valid: 85.43% Test: 70.96%\n",
            "Epoch: 565, Loss: 0.4658, Train: 90.75%, Valid: 85.50% Test: 70.93%\n",
            "Epoch: 566, Loss: 0.4643, Train: 90.76%, Valid: 85.50% Test: 70.88%\n",
            "Epoch: 567, Loss: 0.4662, Train: 90.75%, Valid: 85.50% Test: 70.88%\n",
            "Epoch: 568, Loss: 0.4654, Train: 90.78%, Valid: 85.43% Test: 70.84%\n",
            "Epoch: 569, Loss: 0.4568, Train: 90.77%, Valid: 85.50% Test: 70.85%\n",
            "Epoch: 570, Loss: 0.4598, Train: 90.76%, Valid: 85.31% Test: 70.86%\n",
            "Epoch: 571, Loss: 0.4590, Train: 90.79%, Valid: 85.24% Test: 70.90%\n",
            "Epoch: 572, Loss: 0.4553, Train: 90.81%, Valid: 85.24% Test: 70.98%\n",
            "Epoch: 573, Loss: 0.4571, Train: 90.80%, Valid: 85.37% Test: 70.97%\n",
            "Epoch: 574, Loss: 0.4551, Train: 90.80%, Valid: 85.50% Test: 70.99%\n",
            "Epoch: 575, Loss: 0.4607, Train: 90.83%, Valid: 85.50% Test: 70.99%\n",
            "Epoch: 576, Loss: 0.4576, Train: 90.85%, Valid: 85.62% Test: 71.03%\n",
            "Epoch: 577, Loss: 0.4628, Train: 90.89%, Valid: 85.56% Test: 71.04%\n",
            "Epoch: 578, Loss: 0.4526, Train: 90.88%, Valid: 85.50% Test: 71.02%\n",
            "Epoch: 579, Loss: 0.4535, Train: 90.90%, Valid: 85.56% Test: 71.00%\n",
            "Epoch: 580, Loss: 0.4636, Train: 90.88%, Valid: 85.62% Test: 70.99%\n",
            "Epoch: 581, Loss: 0.4532, Train: 90.88%, Valid: 85.50% Test: 70.98%\n",
            "Epoch: 582, Loss: 0.4629, Train: 90.90%, Valid: 85.50% Test: 70.91%\n",
            "Epoch: 583, Loss: 0.4521, Train: 90.90%, Valid: 85.43% Test: 70.88%\n",
            "Epoch: 584, Loss: 0.4559, Train: 90.90%, Valid: 85.43% Test: 70.86%\n",
            "Epoch: 585, Loss: 0.4564, Train: 90.90%, Valid: 85.43% Test: 70.84%\n",
            "Epoch: 586, Loss: 0.4551, Train: 90.96%, Valid: 85.37% Test: 70.84%\n",
            "Epoch: 587, Loss: 0.4517, Train: 90.97%, Valid: 85.24% Test: 70.83%\n",
            "Epoch: 588, Loss: 0.4525, Train: 90.97%, Valid: 85.24% Test: 70.80%\n",
            "Epoch: 589, Loss: 0.4628, Train: 91.02%, Valid: 85.24% Test: 70.78%\n",
            "Epoch: 590, Loss: 0.4608, Train: 91.02%, Valid: 85.24% Test: 70.80%\n",
            "Epoch: 591, Loss: 0.4609, Train: 91.05%, Valid: 85.31% Test: 70.81%\n",
            "Epoch: 592, Loss: 0.4527, Train: 91.10%, Valid: 85.43% Test: 70.85%\n",
            "Epoch: 593, Loss: 0.4514, Train: 91.13%, Valid: 85.37% Test: 70.88%\n",
            "Epoch: 594, Loss: 0.4623, Train: 91.12%, Valid: 85.37% Test: 70.87%\n",
            "Epoch: 595, Loss: 0.4576, Train: 91.09%, Valid: 85.43% Test: 70.87%\n",
            "Epoch: 596, Loss: 0.4454, Train: 91.11%, Valid: 85.50% Test: 70.86%\n",
            "Epoch: 597, Loss: 0.4522, Train: 91.10%, Valid: 85.43% Test: 70.83%\n",
            "Epoch: 598, Loss: 0.4478, Train: 91.13%, Valid: 85.56% Test: 70.87%\n",
            "Epoch: 599, Loss: 0.4496, Train: 91.11%, Valid: 85.56% Test: 70.93%\n",
            "Epoch: 600, Loss: 0.4498, Train: 91.14%, Valid: 85.50% Test: 70.96%\n",
            "Epoch: 601, Loss: 0.4474, Train: 91.13%, Valid: 85.50% Test: 70.97%\n",
            "Epoch: 602, Loss: 0.4411, Train: 91.14%, Valid: 85.50% Test: 71.02%\n",
            "Epoch: 603, Loss: 0.4581, Train: 91.11%, Valid: 85.43% Test: 71.05%\n",
            "Epoch: 604, Loss: 0.4486, Train: 91.09%, Valid: 85.50% Test: 71.06%\n",
            "Epoch: 605, Loss: 0.4523, Train: 91.08%, Valid: 85.50% Test: 71.08%\n",
            "Epoch: 606, Loss: 0.4527, Train: 91.09%, Valid: 85.50% Test: 71.05%\n",
            "Epoch: 607, Loss: 0.4533, Train: 91.12%, Valid: 85.50% Test: 71.06%\n",
            "Epoch: 608, Loss: 0.4492, Train: 91.11%, Valid: 85.56% Test: 71.08%\n",
            "Epoch: 609, Loss: 0.4524, Train: 91.15%, Valid: 85.56% Test: 71.09%\n",
            "Epoch: 610, Loss: 0.4408, Train: 91.20%, Valid: 85.56% Test: 71.09%\n",
            "Epoch: 611, Loss: 0.4469, Train: 91.21%, Valid: 85.50% Test: 71.11%\n",
            "Epoch: 612, Loss: 0.4440, Train: 91.22%, Valid: 85.43% Test: 71.11%\n",
            "Epoch: 613, Loss: 0.4492, Train: 91.20%, Valid: 85.43% Test: 71.12%\n",
            "Epoch: 614, Loss: 0.4520, Train: 91.24%, Valid: 85.43% Test: 71.15%\n",
            "Epoch: 615, Loss: 0.4410, Train: 91.24%, Valid: 85.50% Test: 71.18%\n",
            "Epoch: 616, Loss: 0.4451, Train: 91.26%, Valid: 85.50% Test: 71.17%\n",
            "Epoch: 617, Loss: 0.4449, Train: 91.28%, Valid: 85.56% Test: 71.22%\n",
            "Epoch: 618, Loss: 0.4411, Train: 91.25%, Valid: 85.62% Test: 71.23%\n",
            "Epoch: 619, Loss: 0.4537, Train: 91.29%, Valid: 85.62% Test: 71.24%\n",
            "Epoch: 620, Loss: 0.4497, Train: 91.27%, Valid: 85.62% Test: 71.20%\n",
            "Epoch: 621, Loss: 0.4443, Train: 91.31%, Valid: 85.50% Test: 71.18%\n",
            "Epoch: 622, Loss: 0.4379, Train: 91.33%, Valid: 85.43% Test: 71.10%\n",
            "Epoch: 623, Loss: 0.4491, Train: 91.29%, Valid: 85.50% Test: 71.05%\n",
            "Epoch: 624, Loss: 0.4428, Train: 91.30%, Valid: 85.62% Test: 70.99%\n",
            "Epoch: 625, Loss: 0.4421, Train: 91.26%, Valid: 85.56% Test: 70.98%\n",
            "Epoch: 626, Loss: 0.4422, Train: 91.20%, Valid: 85.62% Test: 70.98%\n",
            "Epoch: 627, Loss: 0.4416, Train: 91.20%, Valid: 85.62% Test: 70.97%\n",
            "Epoch: 628, Loss: 0.4500, Train: 91.25%, Valid: 85.56% Test: 70.97%\n",
            "Epoch: 629, Loss: 0.4434, Train: 91.27%, Valid: 85.43% Test: 70.98%\n",
            "Epoch: 630, Loss: 0.4390, Train: 91.30%, Valid: 85.50% Test: 71.01%\n",
            "Epoch: 631, Loss: 0.4412, Train: 91.32%, Valid: 85.50% Test: 71.06%\n",
            "Epoch: 632, Loss: 0.4454, Train: 91.32%, Valid: 85.37% Test: 71.10%\n",
            "Epoch: 633, Loss: 0.4408, Train: 91.37%, Valid: 85.37% Test: 71.14%\n",
            "Epoch: 634, Loss: 0.4356, Train: 91.36%, Valid: 85.37% Test: 71.19%\n",
            "Epoch: 635, Loss: 0.4456, Train: 91.39%, Valid: 85.37% Test: 71.21%\n",
            "Epoch: 636, Loss: 0.4386, Train: 91.41%, Valid: 85.31% Test: 71.22%\n",
            "Epoch: 637, Loss: 0.4384, Train: 91.41%, Valid: 85.31% Test: 71.20%\n",
            "Epoch: 638, Loss: 0.4364, Train: 91.42%, Valid: 85.24% Test: 71.18%\n",
            "Epoch: 639, Loss: 0.4387, Train: 91.47%, Valid: 85.31% Test: 71.16%\n",
            "Epoch: 640, Loss: 0.4400, Train: 91.47%, Valid: 85.18% Test: 71.15%\n",
            "Epoch: 641, Loss: 0.4298, Train: 91.45%, Valid: 85.18% Test: 71.12%\n",
            "Epoch: 642, Loss: 0.4386, Train: 91.41%, Valid: 85.24% Test: 71.09%\n",
            "Epoch: 643, Loss: 0.4338, Train: 91.42%, Valid: 85.43% Test: 71.06%\n",
            "Epoch: 644, Loss: 0.4361, Train: 91.42%, Valid: 85.43% Test: 71.02%\n",
            "Epoch: 645, Loss: 0.4380, Train: 91.48%, Valid: 85.37% Test: 70.99%\n",
            "Epoch: 646, Loss: 0.4278, Train: 91.49%, Valid: 85.43% Test: 70.98%\n",
            "Epoch: 647, Loss: 0.4321, Train: 91.52%, Valid: 85.50% Test: 71.02%\n",
            "Epoch: 648, Loss: 0.4413, Train: 91.58%, Valid: 85.43% Test: 71.07%\n",
            "Epoch: 649, Loss: 0.4438, Train: 91.58%, Valid: 85.43% Test: 71.12%\n",
            "Epoch: 650, Loss: 0.4359, Train: 91.58%, Valid: 85.37% Test: 71.16%\n",
            "Epoch: 651, Loss: 0.4392, Train: 91.53%, Valid: 85.43% Test: 71.23%\n",
            "Epoch: 652, Loss: 0.4419, Train: 91.53%, Valid: 85.50% Test: 71.26%\n",
            "Epoch: 653, Loss: 0.4345, Train: 91.51%, Valid: 85.62% Test: 71.27%\n",
            "Epoch: 654, Loss: 0.4337, Train: 91.54%, Valid: 85.62% Test: 71.26%\n",
            "Epoch: 655, Loss: 0.4328, Train: 91.56%, Valid: 85.50% Test: 71.24%\n",
            "Epoch: 656, Loss: 0.4395, Train: 91.52%, Valid: 85.50% Test: 71.23%\n",
            "Epoch: 657, Loss: 0.4383, Train: 91.56%, Valid: 85.43% Test: 71.20%\n",
            "Epoch: 658, Loss: 0.4375, Train: 91.57%, Valid: 85.50% Test: 71.15%\n",
            "Epoch: 659, Loss: 0.4287, Train: 91.58%, Valid: 85.50% Test: 71.11%\n",
            "Epoch: 660, Loss: 0.4280, Train: 91.60%, Valid: 85.50% Test: 71.09%\n",
            "Epoch: 661, Loss: 0.4359, Train: 91.59%, Valid: 85.69% Test: 71.06%\n",
            "Epoch: 662, Loss: 0.4333, Train: 91.63%, Valid: 85.62% Test: 71.04%\n",
            "Epoch: 663, Loss: 0.4314, Train: 91.62%, Valid: 85.62% Test: 71.02%\n",
            "Epoch: 664, Loss: 0.4292, Train: 91.60%, Valid: 85.62% Test: 71.06%\n",
            "Epoch: 665, Loss: 0.4277, Train: 91.64%, Valid: 85.62% Test: 71.07%\n",
            "Epoch: 666, Loss: 0.4358, Train: 91.67%, Valid: 85.56% Test: 71.10%\n",
            "Epoch: 667, Loss: 0.4326, Train: 91.71%, Valid: 85.56% Test: 71.13%\n",
            "Epoch: 668, Loss: 0.4279, Train: 91.75%, Valid: 85.56% Test: 71.15%\n",
            "Epoch: 669, Loss: 0.4326, Train: 91.75%, Valid: 85.50% Test: 71.17%\n",
            "Epoch: 670, Loss: 0.4239, Train: 91.75%, Valid: 85.50% Test: 71.20%\n",
            "Epoch: 671, Loss: 0.4256, Train: 91.80%, Valid: 85.50% Test: 71.18%\n",
            "Epoch: 672, Loss: 0.4305, Train: 91.79%, Valid: 85.50% Test: 71.19%\n",
            "Epoch: 673, Loss: 0.4300, Train: 91.78%, Valid: 85.56% Test: 71.20%\n",
            "Epoch: 674, Loss: 0.4336, Train: 91.76%, Valid: 85.56% Test: 71.18%\n",
            "Epoch: 675, Loss: 0.4207, Train: 91.78%, Valid: 85.56% Test: 71.20%\n",
            "Epoch: 676, Loss: 0.4270, Train: 91.75%, Valid: 85.56% Test: 71.21%\n",
            "Epoch: 677, Loss: 0.4238, Train: 91.76%, Valid: 85.56% Test: 71.22%\n",
            "Epoch: 678, Loss: 0.4276, Train: 91.79%, Valid: 85.56% Test: 71.23%\n",
            "Epoch: 679, Loss: 0.4365, Train: 91.82%, Valid: 85.56% Test: 71.17%\n",
            "Epoch: 680, Loss: 0.4341, Train: 91.85%, Valid: 85.56% Test: 71.13%\n",
            "Epoch: 681, Loss: 0.4256, Train: 91.86%, Valid: 85.62% Test: 71.10%\n",
            "Epoch: 682, Loss: 0.4317, Train: 91.84%, Valid: 85.69% Test: 71.09%\n",
            "Epoch: 683, Loss: 0.4288, Train: 91.86%, Valid: 85.62% Test: 71.09%\n",
            "Epoch: 684, Loss: 0.4255, Train: 91.92%, Valid: 85.62% Test: 71.07%\n",
            "Epoch: 685, Loss: 0.4284, Train: 91.90%, Valid: 85.50% Test: 71.09%\n",
            "Epoch: 686, Loss: 0.4295, Train: 91.89%, Valid: 85.43% Test: 71.10%\n",
            "Epoch: 687, Loss: 0.4229, Train: 91.90%, Valid: 85.43% Test: 71.14%\n",
            "Epoch: 688, Loss: 0.4243, Train: 91.93%, Valid: 85.43% Test: 71.15%\n",
            "Epoch: 689, Loss: 0.4235, Train: 91.98%, Valid: 85.50% Test: 71.15%\n",
            "Epoch: 690, Loss: 0.4254, Train: 92.00%, Valid: 85.43% Test: 71.19%\n",
            "Epoch: 691, Loss: 0.4267, Train: 92.00%, Valid: 85.43% Test: 71.24%\n",
            "Epoch: 692, Loss: 0.4226, Train: 91.95%, Valid: 85.50% Test: 71.30%\n",
            "Epoch: 693, Loss: 0.4230, Train: 91.96%, Valid: 85.56% Test: 71.31%\n",
            "Epoch: 694, Loss: 0.4166, Train: 91.95%, Valid: 85.62% Test: 71.27%\n",
            "Epoch: 695, Loss: 0.4154, Train: 92.00%, Valid: 85.50% Test: 71.25%\n",
            "Epoch: 696, Loss: 0.4146, Train: 91.97%, Valid: 85.50% Test: 71.23%\n",
            "Epoch: 697, Loss: 0.4246, Train: 91.96%, Valid: 85.50% Test: 71.20%\n",
            "Epoch: 698, Loss: 0.4213, Train: 91.98%, Valid: 85.62% Test: 71.19%\n",
            "Epoch: 699, Loss: 0.4169, Train: 92.02%, Valid: 85.62% Test: 71.19%\n",
            "Epoch: 700, Loss: 0.4176, Train: 92.02%, Valid: 85.69% Test: 71.18%\n",
            "Epoch: 701, Loss: 0.4162, Train: 92.04%, Valid: 85.69% Test: 71.20%\n",
            "Epoch: 702, Loss: 0.4178, Train: 92.04%, Valid: 85.62% Test: 71.24%\n",
            "Epoch: 703, Loss: 0.4261, Train: 92.11%, Valid: 85.62% Test: 71.24%\n",
            "Epoch: 704, Loss: 0.4202, Train: 92.13%, Valid: 85.75% Test: 71.25%\n",
            "Epoch: 705, Loss: 0.4302, Train: 92.16%, Valid: 85.75% Test: 71.29%\n",
            "Epoch: 706, Loss: 0.4131, Train: 92.19%, Valid: 85.69% Test: 71.30%\n",
            "Epoch: 707, Loss: 0.4249, Train: 92.21%, Valid: 85.75% Test: 71.29%\n",
            "Epoch: 708, Loss: 0.4180, Train: 92.17%, Valid: 85.75% Test: 71.28%\n",
            "Epoch: 709, Loss: 0.4155, Train: 92.24%, Valid: 85.62% Test: 71.25%\n",
            "Epoch: 710, Loss: 0.4245, Train: 92.25%, Valid: 85.62% Test: 71.27%\n",
            "Epoch: 711, Loss: 0.4212, Train: 92.26%, Valid: 85.69% Test: 71.31%\n",
            "Epoch: 712, Loss: 0.4253, Train: 92.33%, Valid: 85.62% Test: 71.32%\n",
            "Epoch: 713, Loss: 0.4138, Train: 92.30%, Valid: 85.69% Test: 71.32%\n",
            "Epoch: 714, Loss: 0.4134, Train: 92.30%, Valid: 85.50% Test: 71.30%\n",
            "Epoch: 715, Loss: 0.4126, Train: 92.30%, Valid: 85.43% Test: 71.25%\n",
            "Epoch: 716, Loss: 0.4218, Train: 92.30%, Valid: 85.50% Test: 71.24%\n",
            "Epoch: 717, Loss: 0.4171, Train: 92.28%, Valid: 85.50% Test: 71.19%\n",
            "Epoch: 718, Loss: 0.4162, Train: 92.26%, Valid: 85.56% Test: 71.15%\n",
            "Epoch: 719, Loss: 0.4153, Train: 92.28%, Valid: 85.50% Test: 71.10%\n",
            "Epoch: 720, Loss: 0.4203, Train: 92.29%, Valid: 85.50% Test: 71.10%\n",
            "Epoch: 721, Loss: 0.4162, Train: 92.29%, Valid: 85.43% Test: 71.08%\n",
            "Epoch: 722, Loss: 0.4107, Train: 92.32%, Valid: 85.50% Test: 71.14%\n",
            "Epoch: 723, Loss: 0.4126, Train: 92.36%, Valid: 85.50% Test: 71.14%\n",
            "Epoch: 724, Loss: 0.4194, Train: 92.36%, Valid: 85.56% Test: 71.17%\n",
            "Epoch: 725, Loss: 0.4130, Train: 92.38%, Valid: 85.50% Test: 71.19%\n",
            "Epoch: 726, Loss: 0.4166, Train: 92.39%, Valid: 85.56% Test: 71.20%\n",
            "Epoch: 727, Loss: 0.4107, Train: 92.40%, Valid: 85.56% Test: 71.27%\n",
            "Epoch: 728, Loss: 0.4136, Train: 92.43%, Valid: 85.56% Test: 71.30%\n",
            "Epoch: 729, Loss: 0.4128, Train: 92.41%, Valid: 85.62% Test: 71.35%\n",
            "Epoch: 730, Loss: 0.4124, Train: 92.43%, Valid: 85.62% Test: 71.36%\n",
            "Epoch: 731, Loss: 0.4127, Train: 92.39%, Valid: 85.43% Test: 71.38%\n",
            "Epoch: 732, Loss: 0.4112, Train: 92.41%, Valid: 85.43% Test: 71.35%\n",
            "Epoch: 733, Loss: 0.4163, Train: 92.40%, Valid: 85.43% Test: 71.32%\n",
            "Epoch: 734, Loss: 0.4223, Train: 92.41%, Valid: 85.37% Test: 71.30%\n",
            "Epoch: 735, Loss: 0.4166, Train: 92.39%, Valid: 85.43% Test: 71.25%\n",
            "Epoch: 736, Loss: 0.4130, Train: 92.41%, Valid: 85.37% Test: 71.24%\n",
            "Epoch: 737, Loss: 0.4068, Train: 92.41%, Valid: 85.37% Test: 71.23%\n",
            "Epoch: 738, Loss: 0.4114, Train: 92.38%, Valid: 85.37% Test: 71.24%\n",
            "Epoch: 739, Loss: 0.4170, Train: 92.38%, Valid: 85.31% Test: 71.26%\n",
            "Epoch: 740, Loss: 0.4087, Train: 92.41%, Valid: 85.37% Test: 71.27%\n",
            "Epoch: 741, Loss: 0.4163, Train: 92.41%, Valid: 85.31% Test: 71.25%\n",
            "Epoch: 742, Loss: 0.4037, Train: 92.40%, Valid: 85.50% Test: 71.28%\n",
            "Epoch: 743, Loss: 0.4057, Train: 92.41%, Valid: 85.62% Test: 71.34%\n",
            "Epoch: 744, Loss: 0.4090, Train: 92.39%, Valid: 85.69% Test: 71.33%\n",
            "Epoch: 745, Loss: 0.4072, Train: 92.41%, Valid: 85.69% Test: 71.33%\n",
            "Epoch: 746, Loss: 0.4138, Train: 92.43%, Valid: 85.69% Test: 71.33%\n",
            "Epoch: 747, Loss: 0.4057, Train: 92.43%, Valid: 85.62% Test: 71.29%\n",
            "Epoch: 748, Loss: 0.4100, Train: 92.45%, Valid: 85.62% Test: 71.24%\n",
            "Epoch: 749, Loss: 0.4135, Train: 92.49%, Valid: 85.62% Test: 71.20%\n",
            "Epoch: 750, Loss: 0.4010, Train: 92.51%, Valid: 85.62% Test: 71.15%\n",
            "Epoch: 751, Loss: 0.4092, Train: 92.50%, Valid: 85.62% Test: 71.15%\n",
            "Epoch: 752, Loss: 0.4064, Train: 92.50%, Valid: 85.75% Test: 71.15%\n",
            "Epoch: 753, Loss: 0.4114, Train: 92.53%, Valid: 85.75% Test: 71.17%\n",
            "Epoch: 754, Loss: 0.4035, Train: 92.55%, Valid: 85.75% Test: 71.16%\n",
            "Epoch: 755, Loss: 0.4059, Train: 92.57%, Valid: 85.75% Test: 71.19%\n",
            "Epoch: 756, Loss: 0.4072, Train: 92.60%, Valid: 85.88% Test: 71.19%\n",
            "Epoch: 757, Loss: 0.4091, Train: 92.62%, Valid: 85.88% Test: 71.21%\n",
            "Epoch: 758, Loss: 0.4118, Train: 92.64%, Valid: 85.75% Test: 71.25%\n",
            "Epoch: 759, Loss: 0.4070, Train: 92.64%, Valid: 85.69% Test: 71.30%\n",
            "Epoch: 760, Loss: 0.4146, Train: 92.66%, Valid: 85.62% Test: 71.34%\n",
            "Epoch: 761, Loss: 0.4060, Train: 92.63%, Valid: 85.56% Test: 71.36%\n",
            "Epoch: 762, Loss: 0.4047, Train: 92.64%, Valid: 85.62% Test: 71.39%\n",
            "Epoch: 763, Loss: 0.3931, Train: 92.69%, Valid: 85.62% Test: 71.37%\n",
            "Epoch: 764, Loss: 0.4098, Train: 92.74%, Valid: 85.62% Test: 71.38%\n",
            "Epoch: 765, Loss: 0.4150, Train: 92.80%, Valid: 85.62% Test: 71.38%\n",
            "Epoch: 766, Loss: 0.4097, Train: 92.77%, Valid: 85.62% Test: 71.35%\n",
            "Epoch: 767, Loss: 0.4061, Train: 92.77%, Valid: 85.69% Test: 71.33%\n",
            "Epoch: 768, Loss: 0.4014, Train: 92.77%, Valid: 85.75% Test: 71.29%\n",
            "Epoch: 769, Loss: 0.4126, Train: 92.77%, Valid: 85.81% Test: 71.27%\n",
            "Epoch: 770, Loss: 0.4018, Train: 92.79%, Valid: 85.81% Test: 71.29%\n",
            "Epoch: 771, Loss: 0.4060, Train: 92.78%, Valid: 85.88% Test: 71.26%\n",
            "Epoch: 772, Loss: 0.3998, Train: 92.73%, Valid: 85.94% Test: 71.25%\n",
            "Epoch: 773, Loss: 0.4008, Train: 92.75%, Valid: 86.01% Test: 71.25%\n",
            "Epoch: 774, Loss: 0.4092, Train: 92.70%, Valid: 85.94% Test: 71.23%\n",
            "Epoch: 775, Loss: 0.3972, Train: 92.73%, Valid: 85.81% Test: 71.21%\n",
            "Epoch: 776, Loss: 0.3989, Train: 92.71%, Valid: 85.88% Test: 71.21%\n",
            "Epoch: 777, Loss: 0.3995, Train: 92.72%, Valid: 85.88% Test: 71.24%\n",
            "Epoch: 778, Loss: 0.3974, Train: 92.70%, Valid: 85.88% Test: 71.24%\n",
            "Epoch: 779, Loss: 0.4042, Train: 92.68%, Valid: 85.88% Test: 71.24%\n",
            "Epoch: 780, Loss: 0.4024, Train: 92.73%, Valid: 85.81% Test: 71.24%\n",
            "Epoch: 781, Loss: 0.4004, Train: 92.77%, Valid: 85.81% Test: 71.29%\n",
            "Epoch: 782, Loss: 0.3991, Train: 92.83%, Valid: 85.81% Test: 71.29%\n",
            "Epoch: 783, Loss: 0.4050, Train: 92.85%, Valid: 85.88% Test: 71.29%\n",
            "Epoch: 784, Loss: 0.4008, Train: 92.83%, Valid: 85.81% Test: 71.30%\n",
            "Epoch: 785, Loss: 0.4065, Train: 92.81%, Valid: 85.81% Test: 71.30%\n",
            "Epoch: 786, Loss: 0.3972, Train: 92.77%, Valid: 85.81% Test: 71.27%\n",
            "Epoch: 787, Loss: 0.4020, Train: 92.77%, Valid: 85.81% Test: 71.27%\n",
            "Epoch: 788, Loss: 0.3941, Train: 92.74%, Valid: 85.81% Test: 71.34%\n",
            "Epoch: 789, Loss: 0.3938, Train: 92.77%, Valid: 85.75% Test: 71.37%\n",
            "Epoch: 790, Loss: 0.3994, Train: 92.78%, Valid: 85.75% Test: 71.38%\n",
            "Epoch: 791, Loss: 0.4024, Train: 92.79%, Valid: 85.75% Test: 71.38%\n",
            "Epoch: 792, Loss: 0.4054, Train: 92.79%, Valid: 85.75% Test: 71.39%\n",
            "Epoch: 793, Loss: 0.3945, Train: 92.78%, Valid: 85.69% Test: 71.36%\n",
            "Epoch: 794, Loss: 0.3932, Train: 92.84%, Valid: 85.69% Test: 71.31%\n",
            "Epoch: 795, Loss: 0.4024, Train: 92.83%, Valid: 85.69% Test: 71.27%\n",
            "Epoch: 796, Loss: 0.3952, Train: 92.85%, Valid: 85.69% Test: 71.30%\n",
            "Epoch: 797, Loss: 0.3899, Train: 92.89%, Valid: 85.62% Test: 71.29%\n",
            "Epoch: 798, Loss: 0.4001, Train: 92.94%, Valid: 85.75% Test: 71.29%\n",
            "Epoch: 799, Loss: 0.3933, Train: 92.94%, Valid: 85.75% Test: 71.30%\n",
            "Epoch: 800, Loss: 0.3945, Train: 92.98%, Valid: 85.69% Test: 71.31%\n",
            "Epoch: 801, Loss: 0.3959, Train: 92.96%, Valid: 85.69% Test: 71.35%\n",
            "Epoch: 802, Loss: 0.4018, Train: 92.97%, Valid: 85.81% Test: 71.38%\n",
            "Epoch: 803, Loss: 0.3881, Train: 92.98%, Valid: 85.75% Test: 71.40%\n",
            "Epoch: 804, Loss: 0.3872, Train: 92.95%, Valid: 85.69% Test: 71.43%\n",
            "Epoch: 805, Loss: 0.4006, Train: 92.97%, Valid: 85.69% Test: 71.41%\n",
            "Epoch: 806, Loss: 0.4003, Train: 93.02%, Valid: 85.69% Test: 71.38%\n",
            "Epoch: 807, Loss: 0.3968, Train: 93.06%, Valid: 85.75% Test: 71.39%\n",
            "Epoch: 808, Loss: 0.3925, Train: 93.07%, Valid: 85.81% Test: 71.38%\n",
            "Epoch: 809, Loss: 0.3963, Train: 93.04%, Valid: 85.88% Test: 71.36%\n",
            "Epoch: 810, Loss: 0.3944, Train: 93.06%, Valid: 85.88% Test: 71.36%\n",
            "Epoch: 811, Loss: 0.3968, Train: 93.09%, Valid: 85.88% Test: 71.36%\n",
            "Epoch: 812, Loss: 0.3977, Train: 93.08%, Valid: 85.88% Test: 71.36%\n",
            "Epoch: 813, Loss: 0.3913, Train: 93.06%, Valid: 85.88% Test: 71.34%\n",
            "Epoch: 814, Loss: 0.3951, Train: 93.09%, Valid: 85.94% Test: 71.34%\n",
            "Epoch: 815, Loss: 0.3933, Train: 93.10%, Valid: 85.94% Test: 71.38%\n",
            "Epoch: 816, Loss: 0.3858, Train: 93.12%, Valid: 85.94% Test: 71.38%\n",
            "Epoch: 817, Loss: 0.3892, Train: 93.10%, Valid: 86.01% Test: 71.39%\n",
            "Epoch: 818, Loss: 0.3888, Train: 93.06%, Valid: 86.01% Test: 71.37%\n",
            "Epoch: 819, Loss: 0.3893, Train: 93.07%, Valid: 86.01% Test: 71.39%\n",
            "Epoch: 820, Loss: 0.3911, Train: 93.09%, Valid: 85.81% Test: 71.42%\n",
            "Epoch: 821, Loss: 0.3825, Train: 93.09%, Valid: 85.81% Test: 71.43%\n",
            "Epoch: 822, Loss: 0.3901, Train: 93.13%, Valid: 85.75% Test: 71.44%\n",
            "Epoch: 823, Loss: 0.3830, Train: 93.13%, Valid: 85.75% Test: 71.41%\n",
            "Epoch: 824, Loss: 0.3843, Train: 93.15%, Valid: 85.75% Test: 71.41%\n",
            "Epoch: 825, Loss: 0.3954, Train: 93.15%, Valid: 85.81% Test: 71.38%\n",
            "Epoch: 826, Loss: 0.3872, Train: 93.17%, Valid: 85.81% Test: 71.36%\n",
            "Epoch: 827, Loss: 0.3910, Train: 93.17%, Valid: 85.81% Test: 71.37%\n",
            "Epoch: 828, Loss: 0.3864, Train: 93.15%, Valid: 85.81% Test: 71.36%\n",
            "Epoch: 829, Loss: 0.3861, Train: 93.14%, Valid: 85.81% Test: 71.34%\n",
            "Epoch: 830, Loss: 0.3817, Train: 93.14%, Valid: 85.69% Test: 71.32%\n",
            "Epoch: 831, Loss: 0.3807, Train: 93.18%, Valid: 85.69% Test: 71.27%\n",
            "Epoch: 832, Loss: 0.3966, Train: 93.20%, Valid: 85.69% Test: 71.27%\n",
            "Epoch: 833, Loss: 0.3863, Train: 93.20%, Valid: 85.69% Test: 71.25%\n",
            "Epoch: 834, Loss: 0.3890, Train: 93.20%, Valid: 85.75% Test: 71.26%\n",
            "Epoch: 835, Loss: 0.3900, Train: 93.21%, Valid: 85.69% Test: 71.28%\n",
            "Epoch: 836, Loss: 0.3848, Train: 93.21%, Valid: 85.69% Test: 71.31%\n",
            "Epoch: 837, Loss: 0.3828, Train: 93.23%, Valid: 85.75% Test: 71.36%\n",
            "Epoch: 838, Loss: 0.3857, Train: 93.21%, Valid: 85.75% Test: 71.34%\n",
            "Epoch: 839, Loss: 0.3891, Train: 93.26%, Valid: 85.75% Test: 71.34%\n",
            "Epoch: 840, Loss: 0.3865, Train: 93.28%, Valid: 85.69% Test: 71.36%\n",
            "Epoch: 841, Loss: 0.3871, Train: 93.26%, Valid: 85.62% Test: 71.36%\n",
            "Epoch: 842, Loss: 0.3931, Train: 93.23%, Valid: 85.56% Test: 71.37%\n",
            "Epoch: 843, Loss: 0.3867, Train: 93.26%, Valid: 85.62% Test: 71.38%\n",
            "Epoch: 844, Loss: 0.3855, Train: 93.23%, Valid: 85.62% Test: 71.37%\n",
            "Epoch: 845, Loss: 0.3870, Train: 93.19%, Valid: 85.75% Test: 71.37%\n",
            "Epoch: 846, Loss: 0.3849, Train: 93.15%, Valid: 85.69% Test: 71.34%\n",
            "Epoch: 847, Loss: 0.3860, Train: 93.16%, Valid: 85.56% Test: 71.31%\n",
            "Epoch: 848, Loss: 0.3812, Train: 93.13%, Valid: 85.75% Test: 71.29%\n",
            "Epoch: 849, Loss: 0.3956, Train: 93.18%, Valid: 85.81% Test: 71.29%\n",
            "Epoch: 850, Loss: 0.3848, Train: 93.25%, Valid: 86.01% Test: 71.32%\n",
            "Epoch: 851, Loss: 0.3875, Train: 93.28%, Valid: 86.01% Test: 71.31%\n",
            "Epoch: 852, Loss: 0.3942, Train: 93.34%, Valid: 86.07% Test: 71.31%\n",
            "Epoch: 853, Loss: 0.3779, Train: 93.38%, Valid: 86.01% Test: 71.32%\n",
            "Epoch: 854, Loss: 0.3773, Train: 93.36%, Valid: 86.01% Test: 71.35%\n",
            "Epoch: 855, Loss: 0.3883, Train: 93.34%, Valid: 85.94% Test: 71.34%\n",
            "Epoch: 856, Loss: 0.3837, Train: 93.36%, Valid: 85.94% Test: 71.37%\n",
            "Epoch: 857, Loss: 0.3841, Train: 93.35%, Valid: 85.88% Test: 71.40%\n",
            "Epoch: 858, Loss: 0.3836, Train: 93.35%, Valid: 85.94% Test: 71.39%\n",
            "Epoch: 859, Loss: 0.3938, Train: 93.34%, Valid: 86.01% Test: 71.40%\n",
            "Epoch: 860, Loss: 0.3756, Train: 93.32%, Valid: 86.01% Test: 71.38%\n",
            "Epoch: 861, Loss: 0.3872, Train: 93.30%, Valid: 86.01% Test: 71.40%\n",
            "Epoch: 862, Loss: 0.3838, Train: 93.34%, Valid: 85.94% Test: 71.38%\n",
            "Epoch: 863, Loss: 0.3777, Train: 93.35%, Valid: 85.88% Test: 71.40%\n",
            "Epoch: 864, Loss: 0.3795, Train: 93.44%, Valid: 85.94% Test: 71.42%\n",
            "Epoch: 865, Loss: 0.3816, Train: 93.40%, Valid: 85.88% Test: 71.48%\n",
            "Epoch: 866, Loss: 0.3852, Train: 93.40%, Valid: 85.81% Test: 71.48%\n",
            "Epoch: 867, Loss: 0.3879, Train: 93.42%, Valid: 85.75% Test: 71.50%\n",
            "Epoch: 868, Loss: 0.3763, Train: 93.45%, Valid: 85.81% Test: 71.52%\n",
            "Epoch: 869, Loss: 0.3797, Train: 93.49%, Valid: 85.75% Test: 71.47%\n",
            "Epoch: 870, Loss: 0.3851, Train: 93.47%, Valid: 85.69% Test: 71.46%\n",
            "Epoch: 871, Loss: 0.3813, Train: 93.48%, Valid: 85.81% Test: 71.45%\n",
            "Epoch: 872, Loss: 0.3852, Train: 93.42%, Valid: 85.94% Test: 71.40%\n",
            "Epoch: 873, Loss: 0.3800, Train: 93.38%, Valid: 85.81% Test: 71.36%\n",
            "Epoch: 874, Loss: 0.3868, Train: 93.34%, Valid: 85.88% Test: 71.30%\n",
            "Epoch: 875, Loss: 0.3763, Train: 93.39%, Valid: 85.88% Test: 71.25%\n",
            "Epoch: 876, Loss: 0.3840, Train: 93.43%, Valid: 85.88% Test: 71.21%\n",
            "Epoch: 877, Loss: 0.3822, Train: 93.45%, Valid: 85.94% Test: 71.19%\n",
            "Epoch: 878, Loss: 0.3834, Train: 93.45%, Valid: 86.01% Test: 71.14%\n",
            "Epoch: 879, Loss: 0.3833, Train: 93.47%, Valid: 85.88% Test: 71.12%\n",
            "Epoch: 880, Loss: 0.3792, Train: 93.47%, Valid: 85.88% Test: 71.14%\n",
            "Epoch: 881, Loss: 0.3802, Train: 93.47%, Valid: 85.88% Test: 71.20%\n",
            "Epoch: 882, Loss: 0.3757, Train: 93.49%, Valid: 85.88% Test: 71.25%\n",
            "Epoch: 883, Loss: 0.3850, Train: 93.49%, Valid: 85.81% Test: 71.33%\n",
            "Epoch: 884, Loss: 0.3797, Train: 93.52%, Valid: 85.88% Test: 71.38%\n",
            "Epoch: 885, Loss: 0.3758, Train: 93.56%, Valid: 85.88% Test: 71.44%\n",
            "Epoch: 886, Loss: 0.3677, Train: 93.56%, Valid: 85.81% Test: 71.48%\n",
            "Epoch: 887, Loss: 0.3775, Train: 93.52%, Valid: 85.88% Test: 71.51%\n",
            "Epoch: 888, Loss: 0.3726, Train: 93.51%, Valid: 85.81% Test: 71.48%\n",
            "Epoch: 889, Loss: 0.3707, Train: 93.51%, Valid: 85.81% Test: 71.47%\n",
            "Epoch: 890, Loss: 0.3753, Train: 93.53%, Valid: 85.81% Test: 71.47%\n",
            "Epoch: 891, Loss: 0.3811, Train: 93.51%, Valid: 85.75% Test: 71.46%\n",
            "Epoch: 892, Loss: 0.3717, Train: 93.55%, Valid: 85.62% Test: 71.44%\n",
            "Epoch: 893, Loss: 0.3756, Train: 93.53%, Valid: 85.56% Test: 71.39%\n",
            "Epoch: 894, Loss: 0.3765, Train: 93.55%, Valid: 85.62% Test: 71.36%\n",
            "Epoch: 895, Loss: 0.3708, Train: 93.60%, Valid: 85.56% Test: 71.31%\n",
            "Epoch: 896, Loss: 0.3730, Train: 93.60%, Valid: 85.56% Test: 71.29%\n",
            "Epoch: 897, Loss: 0.3743, Train: 93.61%, Valid: 85.62% Test: 71.29%\n",
            "Epoch: 898, Loss: 0.3786, Train: 93.62%, Valid: 85.69% Test: 71.29%\n",
            "Epoch: 899, Loss: 0.3740, Train: 93.65%, Valid: 85.81% Test: 71.31%\n",
            "Epoch: 900, Loss: 0.3743, Train: 93.64%, Valid: 85.88% Test: 71.29%\n",
            "Epoch: 901, Loss: 0.3709, Train: 93.62%, Valid: 85.94% Test: 71.30%\n",
            "Epoch: 902, Loss: 0.3769, Train: 93.57%, Valid: 85.94% Test: 71.31%\n",
            "Epoch: 903, Loss: 0.3725, Train: 93.60%, Valid: 85.88% Test: 71.31%\n",
            "Epoch: 904, Loss: 0.3750, Train: 93.60%, Valid: 85.88% Test: 71.29%\n",
            "Epoch: 905, Loss: 0.3815, Train: 93.60%, Valid: 85.75% Test: 71.29%\n",
            "Epoch: 906, Loss: 0.3694, Train: 93.63%, Valid: 85.81% Test: 71.32%\n",
            "Epoch: 907, Loss: 0.3782, Train: 93.65%, Valid: 85.81% Test: 71.32%\n",
            "Epoch: 908, Loss: 0.3702, Train: 93.64%, Valid: 85.81% Test: 71.32%\n",
            "Epoch: 909, Loss: 0.3738, Train: 93.62%, Valid: 85.88% Test: 71.32%\n",
            "Epoch: 910, Loss: 0.3776, Train: 93.63%, Valid: 86.07% Test: 71.26%\n",
            "Epoch: 911, Loss: 0.3667, Train: 93.60%, Valid: 86.01% Test: 71.25%\n",
            "Epoch: 912, Loss: 0.3691, Train: 93.60%, Valid: 86.01% Test: 71.23%\n",
            "Epoch: 913, Loss: 0.3708, Train: 93.59%, Valid: 86.01% Test: 71.25%\n",
            "Epoch: 914, Loss: 0.3703, Train: 93.58%, Valid: 85.94% Test: 71.25%\n",
            "Epoch: 915, Loss: 0.3681, Train: 93.62%, Valid: 85.88% Test: 71.27%\n",
            "Epoch: 916, Loss: 0.3757, Train: 93.66%, Valid: 85.81% Test: 71.26%\n",
            "Epoch: 917, Loss: 0.3723, Train: 93.62%, Valid: 85.81% Test: 71.24%\n",
            "Epoch: 918, Loss: 0.3716, Train: 93.66%, Valid: 85.75% Test: 71.31%\n",
            "Epoch: 919, Loss: 0.3632, Train: 93.65%, Valid: 85.62% Test: 71.35%\n",
            "Epoch: 920, Loss: 0.3770, Train: 93.68%, Valid: 85.50% Test: 71.38%\n",
            "Epoch: 921, Loss: 0.3645, Train: 93.72%, Valid: 85.43% Test: 71.40%\n",
            "Epoch: 922, Loss: 0.3664, Train: 93.77%, Valid: 85.50% Test: 71.42%\n",
            "Epoch: 923, Loss: 0.3699, Train: 93.74%, Valid: 85.50% Test: 71.44%\n",
            "Epoch: 924, Loss: 0.3702, Train: 93.74%, Valid: 85.56% Test: 71.45%\n",
            "Epoch: 925, Loss: 0.3678, Train: 93.74%, Valid: 85.75% Test: 71.41%\n",
            "Epoch: 926, Loss: 0.3689, Train: 93.74%, Valid: 85.94% Test: 71.37%\n",
            "Epoch: 927, Loss: 0.3734, Train: 93.73%, Valid: 86.07% Test: 71.32%\n",
            "Epoch: 928, Loss: 0.3624, Train: 93.74%, Valid: 86.13% Test: 71.30%\n",
            "Epoch: 929, Loss: 0.3680, Train: 93.77%, Valid: 86.01% Test: 71.28%\n",
            "Epoch: 930, Loss: 0.3663, Train: 93.77%, Valid: 85.88% Test: 71.28%\n",
            "Epoch: 931, Loss: 0.3728, Train: 93.77%, Valid: 85.75% Test: 71.26%\n",
            "Epoch: 932, Loss: 0.3766, Train: 93.80%, Valid: 85.81% Test: 71.23%\n",
            "Epoch: 933, Loss: 0.3826, Train: 93.81%, Valid: 85.88% Test: 71.23%\n",
            "Epoch: 934, Loss: 0.3660, Train: 93.85%, Valid: 85.81% Test: 71.24%\n",
            "Epoch: 935, Loss: 0.3600, Train: 93.88%, Valid: 85.88% Test: 71.24%\n",
            "Epoch: 936, Loss: 0.3650, Train: 93.90%, Valid: 85.94% Test: 71.27%\n",
            "Epoch: 937, Loss: 0.3745, Train: 93.90%, Valid: 85.88% Test: 71.26%\n",
            "Epoch: 938, Loss: 0.3637, Train: 93.91%, Valid: 85.88% Test: 71.26%\n",
            "Epoch: 939, Loss: 0.3681, Train: 93.89%, Valid: 85.94% Test: 71.28%\n",
            "Epoch: 940, Loss: 0.3634, Train: 93.87%, Valid: 85.88% Test: 71.30%\n",
            "Epoch: 941, Loss: 0.3687, Train: 93.82%, Valid: 85.94% Test: 71.34%\n",
            "Epoch: 942, Loss: 0.3686, Train: 93.83%, Valid: 85.94% Test: 71.35%\n",
            "Epoch: 943, Loss: 0.3608, Train: 93.85%, Valid: 86.01% Test: 71.35%\n",
            "Epoch: 944, Loss: 0.3696, Train: 93.83%, Valid: 85.94% Test: 71.38%\n",
            "Epoch: 945, Loss: 0.3752, Train: 93.87%, Valid: 85.94% Test: 71.38%\n",
            "Epoch: 946, Loss: 0.3655, Train: 93.86%, Valid: 85.94% Test: 71.38%\n",
            "Epoch: 947, Loss: 0.3766, Train: 93.87%, Valid: 85.94% Test: 71.36%\n",
            "Epoch: 948, Loss: 0.3667, Train: 93.88%, Valid: 85.81% Test: 71.35%\n",
            "Epoch: 949, Loss: 0.3688, Train: 93.92%, Valid: 85.81% Test: 71.34%\n",
            "Epoch: 950, Loss: 0.3685, Train: 93.93%, Valid: 85.69% Test: 71.32%\n",
            "Epoch: 951, Loss: 0.3651, Train: 93.96%, Valid: 85.69% Test: 71.28%\n",
            "Epoch: 952, Loss: 0.3680, Train: 93.96%, Valid: 85.69% Test: 71.26%\n",
            "Epoch: 953, Loss: 0.3643, Train: 93.90%, Valid: 85.50% Test: 71.27%\n",
            "Epoch: 954, Loss: 0.3653, Train: 93.89%, Valid: 85.62% Test: 71.27%\n",
            "Epoch: 955, Loss: 0.3681, Train: 93.86%, Valid: 85.56% Test: 71.28%\n",
            "Epoch: 956, Loss: 0.3672, Train: 93.91%, Valid: 85.56% Test: 71.30%\n",
            "Epoch: 957, Loss: 0.3633, Train: 93.91%, Valid: 85.56% Test: 71.32%\n",
            "Epoch: 958, Loss: 0.3612, Train: 93.94%, Valid: 85.56% Test: 71.33%\n",
            "Epoch: 959, Loss: 0.3655, Train: 93.97%, Valid: 85.56% Test: 71.32%\n",
            "Epoch: 960, Loss: 0.3681, Train: 93.98%, Valid: 85.69% Test: 71.38%\n",
            "Epoch: 961, Loss: 0.3646, Train: 93.96%, Valid: 85.69% Test: 71.41%\n",
            "Epoch: 962, Loss: 0.3664, Train: 93.97%, Valid: 85.62% Test: 71.39%\n",
            "Epoch: 963, Loss: 0.3699, Train: 94.00%, Valid: 85.56% Test: 71.38%\n",
            "Epoch: 964, Loss: 0.3668, Train: 93.99%, Valid: 85.62% Test: 71.40%\n",
            "Epoch: 965, Loss: 0.3638, Train: 94.00%, Valid: 85.69% Test: 71.39%\n",
            "Epoch: 966, Loss: 0.3665, Train: 94.02%, Valid: 85.69% Test: 71.41%\n",
            "Epoch: 967, Loss: 0.3638, Train: 94.06%, Valid: 85.69% Test: 71.42%\n",
            "Epoch: 968, Loss: 0.3614, Train: 94.12%, Valid: 85.75% Test: 71.41%\n",
            "Epoch: 969, Loss: 0.3663, Train: 94.08%, Valid: 85.81% Test: 71.42%\n",
            "Epoch: 970, Loss: 0.3538, Train: 94.12%, Valid: 85.88% Test: 71.42%\n",
            "Epoch: 971, Loss: 0.3565, Train: 94.09%, Valid: 85.88% Test: 71.39%\n",
            "Epoch: 972, Loss: 0.3632, Train: 94.11%, Valid: 85.81% Test: 71.39%\n",
            "Epoch: 973, Loss: 0.3595, Train: 94.12%, Valid: 85.88% Test: 71.36%\n",
            "Epoch: 974, Loss: 0.3635, Train: 94.06%, Valid: 85.75% Test: 71.34%\n",
            "Epoch: 975, Loss: 0.3598, Train: 94.08%, Valid: 85.69% Test: 71.35%\n",
            "Epoch: 976, Loss: 0.3635, Train: 94.09%, Valid: 85.75% Test: 71.35%\n",
            "Epoch: 977, Loss: 0.3516, Train: 94.08%, Valid: 85.81% Test: 71.35%\n",
            "Epoch: 978, Loss: 0.3581, Train: 94.15%, Valid: 85.81% Test: 71.36%\n",
            "Epoch: 979, Loss: 0.3565, Train: 94.19%, Valid: 85.75% Test: 71.37%\n",
            "Epoch: 980, Loss: 0.3597, Train: 94.17%, Valid: 85.69% Test: 71.36%\n",
            "Epoch: 981, Loss: 0.3540, Train: 94.16%, Valid: 85.62% Test: 71.35%\n",
            "Epoch: 982, Loss: 0.3566, Train: 94.15%, Valid: 85.62% Test: 71.36%\n",
            "Epoch: 983, Loss: 0.3598, Train: 94.15%, Valid: 85.69% Test: 71.38%\n",
            "Epoch: 984, Loss: 0.3569, Train: 94.11%, Valid: 85.69% Test: 71.39%\n",
            "Epoch: 985, Loss: 0.3578, Train: 94.11%, Valid: 85.62% Test: 71.43%\n",
            "Epoch: 986, Loss: 0.3574, Train: 94.13%, Valid: 85.75% Test: 71.42%\n",
            "Epoch: 987, Loss: 0.3530, Train: 94.15%, Valid: 85.69% Test: 71.40%\n",
            "Epoch: 988, Loss: 0.3617, Train: 94.17%, Valid: 85.75% Test: 71.41%\n",
            "Epoch: 989, Loss: 0.3572, Train: 94.18%, Valid: 85.75% Test: 71.42%\n",
            "Epoch: 990, Loss: 0.3575, Train: 94.19%, Valid: 85.75% Test: 71.45%\n",
            "Epoch: 991, Loss: 0.3584, Train: 94.23%, Valid: 85.75% Test: 71.45%\n",
            "Epoch: 992, Loss: 0.3609, Train: 94.24%, Valid: 85.81% Test: 71.43%\n",
            "Epoch: 993, Loss: 0.3613, Train: 94.30%, Valid: 85.75% Test: 71.42%\n",
            "Epoch: 994, Loss: 0.3682, Train: 94.32%, Valid: 85.75% Test: 71.43%\n",
            "Epoch: 995, Loss: 0.3616, Train: 94.33%, Valid: 85.75% Test: 71.36%\n",
            "Epoch: 996, Loss: 0.3588, Train: 94.34%, Valid: 85.69% Test: 71.34%\n",
            "Epoch: 997, Loss: 0.3516, Train: 94.31%, Valid: 85.75% Test: 71.31%\n",
            "Epoch: 998, Loss: 0.3597, Train: 94.30%, Valid: 85.75% Test: 71.34%\n",
            "Epoch: 999, Loss: 0.3501, Train: 94.28%, Valid: 85.81% Test: 71.33%\n",
            "Best Test accuracy is 0.712995098688568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensembling\n",
        "\n",
        "We demonstrate an ensemble approach combining a base graph neural network model with scaled logits from a language model.\n",
        "\n"
      ],
      "metadata": {
        "id": "DvdH3QLEiSFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data,split_idx,_=LoadData().load_data()\n",
        "data.to(device)\n",
        "base_model.to(device)\n",
        "final_out = base_model(data.x, data.adj_t)\n",
        "lm_logits = torch.tensor(lm_logits).to(device)\n",
        "max_test_acc=0\n",
        "max_i=0\n",
        "for i in [1,5,10,15,20]:\n",
        "  final_out = final_out + i*lm_logits\n",
        "  y_pred = final_out.argmax(dim=-1, keepdim=True)\n",
        "  evaluator = Evaluator(name=DATASET)\n",
        "  test_acc = evaluator.eval({\n",
        "          'y_true': data.y[split_idx['test']],\n",
        "          'y_pred': y_pred[split_idx['test']],\n",
        "      })['acc']\n",
        "  if test_acc>max_test_acc:\n",
        "    max_test_acc=test_acc\n",
        "    max_i=i\n",
        "print(f'Max test acc: {max_test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5oWwEBMiVSZ",
        "outputId": "c0d24e42-f203-4338-92ea-1d735b01ead1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max test acc: 0.7417936150483507\n"
          ]
        }
      ]
    }
  ]
}