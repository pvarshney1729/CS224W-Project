{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYx-33HB_JDe",
    "outputId": "32f93f85-1c9f-4cf4-dc1d-4cdbed0e7cdc"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# torch_version = str(torch.__version__)\n",
    "# scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "# sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "# !pip install torch-scatter -f $scatter_src\n",
    "# !pip install torch-sparse -f $sparse_src\n",
    "# !pip install torch-geometric\n",
    "# !pip install ogb\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "import pickle\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ogbn-arxiv'\n",
    "DATA_ROOT = \"/nlp/scr/ananjan/graph_datasets/\"\n",
    "NUM_EPOCHS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tcZxxKDE_pX5"
   },
   "outputs": [],
   "source": [
    "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "dataset = PygNodePropPredDataset(name=DATASET,\n",
    "                                  transform=T.Compose([T.ToUndirected(), T.ToSparseTensor()]), root=DATA_ROOT)\n",
    "\n",
    "data = dataset[0]\n",
    "# data.adj_t = data.adj_t.to_symmetric()\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3Qbcoco7SGVi"
   },
   "outputs": [],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_arxiv.pkl\t\tminilm_arxiv.pkl\t roberta_arxiv.pkl\r\n",
      "bert_logits_arxiv.pkl\tminilm_logits_arxiv.pkl  roberta_logits_arxiv.pkl\r\n",
      "bert_trained_arxiv.pkl\tmpnet_arxiv.pkl\t\t roberta_trained_arxiv.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! ls /nlp/scr/ananjan/graph_embeddings/finetuned/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YPVFFGVRL_jt"
   },
   "outputs": [],
   "source": [
    "# # from google.colab import drive\n",
    "# # drive.mount(\"/content/drive/\")\n",
    "# import pickle\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# embs = pickle.load(open(\"/nlp/scr/ananjan/graph_embeddings/finetuned/roberta_arxiv.pkl\", \"rb\"))\n",
    "# # pca = PCA(n_components=128)\n",
    "# # embs = pca.fit_transform(embs)\n",
    "# # embs = torch.nn.functional.normalize(torch.tensor(embs).to(device), dim=-1)\n",
    "# embs = torch.tensor(embs).to(device)\n",
    "# data.x = embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "RE9184A0AGtk"
   },
   "outputs": [],
   "source": [
    "model = torch_geometric.nn.models.GAT(data.x.shape[1], 256, num_layers=3, out_channels=dataset.num_classes, dropout=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "q9jEb9CoAjyf"
   },
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "    loss = F.cross_entropy(out, data.y.squeeze(1)[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "Br0fdbBwBAHy",
    "outputId": "fb349ddd-2576-4062-f4e0-23e601c9821c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Loss: 3.7078, Train: 17.91%, Valid: 7.63% Test: 5.86%\n",
      "Epoch: 01, Loss: 3.3963, Train: 17.91%, Valid: 7.63% Test: 5.86%\n",
      "Epoch: 02, Loss: 3.3641, Train: 25.37%, Valid: 28.74% Test: 25.79%\n",
      "Epoch: 03, Loss: 3.1974, Train: 18.01%, Valid: 25.44% Test: 23.16%\n",
      "Epoch: 04, Loss: 3.1898, Train: 28.96%, Valid: 30.90% Test: 27.62%\n",
      "Epoch: 05, Loss: 3.1352, Train: 27.33%, Valid: 29.73% Test: 26.81%\n",
      "Epoch: 06, Loss: 3.0536, Train: 24.01%, Valid: 22.00% Test: 20.01%\n",
      "Epoch: 07, Loss: 2.9939, Train: 26.75%, Valid: 28.90% Test: 26.33%\n",
      "Epoch: 08, Loss: 2.9334, Train: 28.71%, Valid: 30.47% Test: 27.30%\n",
      "Epoch: 09, Loss: 2.8483, Train: 31.52%, Valid: 31.98% Test: 28.63%\n",
      "Epoch: 10, Loss: 2.7788, Train: 37.54%, Valid: 35.56% Test: 31.81%\n",
      "Epoch: 11, Loss: 2.7022, Train: 40.22%, Valid: 37.69% Test: 33.72%\n",
      "Epoch: 12, Loss: 2.6177, Train: 39.79%, Valid: 37.36% Test: 33.98%\n",
      "Epoch: 13, Loss: 2.5593, Train: 41.35%, Valid: 38.62% Test: 35.12%\n",
      "Epoch: 14, Loss: 2.4998, Train: 44.61%, Valid: 42.28% Test: 38.99%\n",
      "Epoch: 15, Loss: 2.4346, Train: 46.41%, Valid: 45.30% Test: 42.67%\n",
      "Epoch: 16, Loss: 2.3992, Train: 47.40%, Valid: 45.90% Test: 43.61%\n",
      "Epoch: 17, Loss: 2.3467, Train: 47.99%, Valid: 46.49% Test: 43.91%\n",
      "Epoch: 18, Loss: 2.3222, Train: 49.92%, Valid: 49.29% Test: 46.71%\n",
      "Epoch: 19, Loss: 2.2786, Train: 51.32%, Valid: 51.54% Test: 48.75%\n",
      "Epoch: 20, Loss: 2.2393, Train: 52.26%, Valid: 53.11% Test: 50.84%\n",
      "Epoch: 21, Loss: 2.2073, Train: 52.67%, Valid: 53.41% Test: 51.57%\n",
      "Epoch: 22, Loss: 2.1810, Train: 53.60%, Valid: 54.15% Test: 51.94%\n",
      "Epoch: 23, Loss: 2.1541, Train: 54.79%, Valid: 55.25% Test: 52.61%\n",
      "Epoch: 24, Loss: 2.1207, Train: 54.88%, Valid: 55.29% Test: 52.61%\n",
      "Epoch: 25, Loss: 2.0892, Train: 54.96%, Valid: 55.78% Test: 53.59%\n",
      "Epoch: 26, Loss: 2.0737, Train: 56.08%, Valid: 57.83% Test: 56.13%\n",
      "Epoch: 27, Loss: 2.0401, Train: 56.92%, Valid: 58.50% Test: 56.71%\n",
      "Epoch: 28, Loss: 2.0197, Train: 57.03%, Valid: 57.37% Test: 54.99%\n",
      "Epoch: 29, Loss: 1.9958, Train: 57.41%, Valid: 57.56% Test: 55.45%\n",
      "Epoch: 30, Loss: 1.9766, Train: 58.13%, Valid: 59.39% Test: 58.06%\n",
      "Epoch: 31, Loss: 1.9526, Train: 58.54%, Valid: 59.84% Test: 58.83%\n",
      "Epoch: 32, Loss: 1.9328, Train: 59.01%, Valid: 59.83% Test: 58.50%\n",
      "Epoch: 33, Loss: 1.9179, Train: 59.56%, Valid: 60.20% Test: 58.50%\n",
      "Epoch: 34, Loss: 1.8983, Train: 60.00%, Valid: 60.68% Test: 59.12%\n",
      "Epoch: 35, Loss: 1.8850, Train: 60.26%, Valid: 61.19% Test: 59.83%\n",
      "Epoch: 36, Loss: 1.8684, Train: 60.64%, Valid: 61.56% Test: 60.28%\n",
      "Epoch: 37, Loss: 1.8448, Train: 60.89%, Valid: 61.76% Test: 60.29%\n",
      "Epoch: 38, Loss: 1.8300, Train: 61.00%, Valid: 61.93% Test: 60.45%\n",
      "Epoch: 39, Loss: 1.8187, Train: 61.33%, Valid: 62.39% Test: 61.06%\n",
      "Epoch: 40, Loss: 1.8015, Train: 61.62%, Valid: 62.55% Test: 61.34%\n",
      "Epoch: 41, Loss: 1.7925, Train: 61.70%, Valid: 62.17% Test: 60.75%\n",
      "Epoch: 42, Loss: 1.7910, Train: 62.16%, Valid: 62.97% Test: 62.01%\n",
      "Epoch: 43, Loss: 1.7798, Train: 62.36%, Valid: 63.29% Test: 62.51%\n",
      "Epoch: 44, Loss: 1.7719, Train: 62.38%, Valid: 63.31% Test: 62.44%\n",
      "Epoch: 45, Loss: 1.7563, Train: 62.61%, Valid: 63.26% Test: 62.36%\n",
      "Epoch: 46, Loss: 1.7433, Train: 62.87%, Valid: 63.86% Test: 63.34%\n",
      "Epoch: 47, Loss: 1.7382, Train: 62.85%, Valid: 63.74% Test: 63.00%\n",
      "Epoch: 48, Loss: 1.7284, Train: 63.09%, Valid: 63.66% Test: 62.78%\n",
      "Epoch: 49, Loss: 1.7244, Train: 63.38%, Valid: 64.05% Test: 63.50%\n",
      "Epoch: 50, Loss: 1.7209, Train: 63.48%, Valid: 64.26% Test: 63.73%\n",
      "Epoch: 51, Loss: 1.7070, Train: 63.73%, Valid: 64.52% Test: 64.03%\n",
      "Epoch: 52, Loss: 1.6969, Train: 63.87%, Valid: 64.50% Test: 64.10%\n",
      "Epoch: 53, Loss: 1.6945, Train: 63.91%, Valid: 64.33% Test: 63.61%\n",
      "Epoch: 54, Loss: 1.6898, Train: 64.12%, Valid: 64.54% Test: 63.75%\n",
      "Epoch: 55, Loss: 1.6855, Train: 64.20%, Valid: 64.98% Test: 64.63%\n",
      "Epoch: 56, Loss: 1.6778, Train: 64.44%, Valid: 64.81% Test: 64.22%\n",
      "Epoch: 57, Loss: 1.6794, Train: 64.46%, Valid: 64.89% Test: 64.23%\n",
      "Epoch: 58, Loss: 1.6637, Train: 64.74%, Valid: 65.36% Test: 65.02%\n",
      "Epoch: 59, Loss: 1.6563, Train: 64.98%, Valid: 65.31% Test: 64.71%\n",
      "Epoch: 60, Loss: 1.6591, Train: 64.94%, Valid: 65.18% Test: 64.31%\n",
      "Epoch: 61, Loss: 1.6457, Train: 64.95%, Valid: 65.34% Test: 64.70%\n",
      "Epoch: 62, Loss: 1.6463, Train: 65.31%, Valid: 65.53% Test: 64.80%\n",
      "Epoch: 63, Loss: 1.6342, Train: 65.39%, Valid: 65.26% Test: 64.57%\n",
      "Epoch: 64, Loss: 1.6355, Train: 65.30%, Valid: 65.89% Test: 65.90%\n",
      "Epoch: 65, Loss: 1.6304, Train: 65.52%, Valid: 66.10% Test: 65.57%\n",
      "Epoch: 66, Loss: 1.6267, Train: 65.60%, Valid: 65.51% Test: 64.55%\n",
      "Epoch: 67, Loss: 1.6236, Train: 65.72%, Valid: 66.11% Test: 65.63%\n",
      "Epoch: 68, Loss: 1.6200, Train: 65.81%, Valid: 66.20% Test: 65.69%\n",
      "Epoch: 69, Loss: 1.6166, Train: 65.90%, Valid: 66.10% Test: 65.52%\n",
      "Epoch: 70, Loss: 1.6099, Train: 66.00%, Valid: 66.31% Test: 65.75%\n",
      "Epoch: 71, Loss: 1.6106, Train: 66.23%, Valid: 66.41% Test: 65.95%\n",
      "Epoch: 72, Loss: 1.6017, Train: 66.29%, Valid: 66.50% Test: 65.88%\n",
      "Epoch: 73, Loss: 1.5993, Train: 66.39%, Valid: 66.41% Test: 65.92%\n",
      "Epoch: 74, Loss: 1.5902, Train: 66.28%, Valid: 66.70% Test: 66.11%\n",
      "Epoch: 75, Loss: 1.5868, Train: 66.46%, Valid: 66.56% Test: 65.99%\n",
      "Epoch: 76, Loss: 1.5825, Train: 66.60%, Valid: 66.79% Test: 66.31%\n",
      "Epoch: 77, Loss: 1.5885, Train: 66.53%, Valid: 66.69% Test: 66.48%\n",
      "Epoch: 78, Loss: 1.5817, Train: 66.76%, Valid: 66.54% Test: 65.79%\n",
      "Epoch: 79, Loss: 1.5847, Train: 66.83%, Valid: 67.04% Test: 66.42%\n",
      "Epoch: 80, Loss: 1.5653, Train: 66.94%, Valid: 67.11% Test: 66.77%\n",
      "Epoch: 81, Loss: 1.5748, Train: 67.13%, Valid: 67.10% Test: 66.44%\n",
      "Epoch: 82, Loss: 1.5756, Train: 67.06%, Valid: 67.23% Test: 66.78%\n",
      "Epoch: 83, Loss: 1.5583, Train: 67.08%, Valid: 67.14% Test: 66.66%\n",
      "Epoch: 84, Loss: 1.5655, Train: 67.19%, Valid: 67.32% Test: 66.78%\n",
      "Epoch: 85, Loss: 1.5565, Train: 67.17%, Valid: 67.41% Test: 67.13%\n",
      "Epoch: 86, Loss: 1.5534, Train: 67.35%, Valid: 67.49% Test: 66.93%\n",
      "Epoch: 87, Loss: 1.5554, Train: 67.35%, Valid: 67.18% Test: 66.37%\n",
      "Epoch: 88, Loss: 1.5521, Train: 67.48%, Valid: 67.45% Test: 66.86%\n",
      "Epoch: 89, Loss: 1.5556, Train: 67.55%, Valid: 67.66% Test: 67.25%\n",
      "Epoch: 90, Loss: 1.5485, Train: 67.61%, Valid: 67.70% Test: 67.08%\n",
      "Epoch: 91, Loss: 1.5494, Train: 67.64%, Valid: 67.66% Test: 67.08%\n",
      "Epoch: 92, Loss: 1.5401, Train: 67.66%, Valid: 67.69% Test: 67.06%\n",
      "Epoch: 93, Loss: 1.5436, Train: 67.79%, Valid: 67.74% Test: 67.10%\n",
      "Epoch: 94, Loss: 1.5424, Train: 67.92%, Valid: 67.85% Test: 67.28%\n",
      "Epoch: 95, Loss: 1.5357, Train: 67.87%, Valid: 67.84% Test: 67.34%\n",
      "Epoch: 96, Loss: 1.5273, Train: 67.95%, Valid: 68.00% Test: 67.28%\n",
      "Epoch: 97, Loss: 1.5314, Train: 67.99%, Valid: 67.89% Test: 67.09%\n",
      "Epoch: 98, Loss: 1.5314, Train: 68.03%, Valid: 68.10% Test: 67.49%\n",
      "Epoch: 99, Loss: 1.5317, Train: 68.14%, Valid: 68.01% Test: 67.35%\n",
      "Epoch: 100, Loss: 1.5224, Train: 68.23%, Valid: 68.16% Test: 67.59%\n",
      "Epoch: 101, Loss: 1.5301, Train: 68.19%, Valid: 68.25% Test: 67.77%\n",
      "Epoch: 102, Loss: 1.5219, Train: 68.36%, Valid: 68.07% Test: 67.08%\n",
      "Epoch: 103, Loss: 1.5210, Train: 68.22%, Valid: 68.01% Test: 67.35%\n",
      "Epoch: 104, Loss: 1.5240, Train: 68.28%, Valid: 68.37% Test: 67.68%\n",
      "Epoch: 105, Loss: 1.5217, Train: 68.50%, Valid: 68.50% Test: 67.53%\n",
      "Epoch: 106, Loss: 1.5136, Train: 68.47%, Valid: 68.44% Test: 67.79%\n",
      "Epoch: 107, Loss: 1.5080, Train: 68.41%, Valid: 68.43% Test: 68.07%\n",
      "Epoch: 108, Loss: 1.5167, Train: 68.55%, Valid: 68.56% Test: 67.77%\n",
      "Epoch: 109, Loss: 1.5078, Train: 68.55%, Valid: 68.57% Test: 67.74%\n",
      "Epoch: 110, Loss: 1.5128, Train: 68.52%, Valid: 68.70% Test: 68.29%\n",
      "Epoch: 111, Loss: 1.5054, Train: 68.61%, Valid: 68.56% Test: 67.83%\n",
      "Epoch: 112, Loss: 1.4986, Train: 68.66%, Valid: 68.62% Test: 67.73%\n",
      "Epoch: 113, Loss: 1.5114, Train: 68.64%, Valid: 68.86% Test: 68.09%\n",
      "Epoch: 114, Loss: 1.5011, Train: 68.80%, Valid: 68.77% Test: 68.06%\n",
      "Epoch: 115, Loss: 1.5026, Train: 68.78%, Valid: 68.73% Test: 67.96%\n",
      "Epoch: 116, Loss: 1.4978, Train: 68.76%, Valid: 68.80% Test: 68.01%\n",
      "Epoch: 117, Loss: 1.4974, Train: 68.84%, Valid: 68.85% Test: 68.17%\n",
      "Epoch: 118, Loss: 1.4945, Train: 68.95%, Valid: 68.98% Test: 68.16%\n",
      "Epoch: 119, Loss: 1.4936, Train: 68.94%, Valid: 69.00% Test: 68.53%\n",
      "Epoch: 120, Loss: 1.4889, Train: 69.04%, Valid: 68.87% Test: 67.93%\n",
      "Epoch: 121, Loss: 1.4930, Train: 69.11%, Valid: 68.89% Test: 68.17%\n",
      "Epoch: 122, Loss: 1.4902, Train: 69.00%, Valid: 69.02% Test: 68.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123, Loss: 1.4909, Train: 69.12%, Valid: 68.87% Test: 68.18%\n",
      "Epoch: 124, Loss: 1.4886, Train: 69.08%, Valid: 69.07% Test: 68.22%\n",
      "Epoch: 125, Loss: 1.4866, Train: 69.09%, Valid: 69.07% Test: 68.38%\n",
      "Epoch: 126, Loss: 1.4874, Train: 69.18%, Valid: 69.33% Test: 68.72%\n",
      "Epoch: 127, Loss: 1.4847, Train: 69.34%, Valid: 69.19% Test: 68.31%\n",
      "Epoch: 128, Loss: 1.4847, Train: 69.29%, Valid: 69.01% Test: 68.35%\n",
      "Epoch: 129, Loss: 1.4810, Train: 69.31%, Valid: 69.21% Test: 68.66%\n",
      "Epoch: 130, Loss: 1.4866, Train: 69.35%, Valid: 69.31% Test: 68.43%\n",
      "Epoch: 131, Loss: 1.4796, Train: 69.35%, Valid: 69.33% Test: 68.57%\n",
      "Epoch: 132, Loss: 1.4748, Train: 69.36%, Valid: 69.15% Test: 68.20%\n",
      "Epoch: 133, Loss: 1.4814, Train: 69.40%, Valid: 69.34% Test: 68.51%\n",
      "Epoch: 134, Loss: 1.4779, Train: 69.48%, Valid: 69.50% Test: 68.86%\n",
      "Epoch: 135, Loss: 1.4768, Train: 69.52%, Valid: 69.38% Test: 68.74%\n",
      "Epoch: 136, Loss: 1.4706, Train: 69.47%, Valid: 69.38% Test: 68.48%\n",
      "Epoch: 137, Loss: 1.4705, Train: 69.49%, Valid: 69.34% Test: 68.59%\n",
      "Epoch: 138, Loss: 1.4680, Train: 69.51%, Valid: 69.33% Test: 68.65%\n",
      "Epoch: 139, Loss: 1.4652, Train: 69.47%, Valid: 69.54% Test: 68.98%\n",
      "Epoch: 140, Loss: 1.4687, Train: 69.64%, Valid: 69.01% Test: 68.17%\n",
      "Epoch: 141, Loss: 1.4710, Train: 69.65%, Valid: 69.44% Test: 68.74%\n",
      "Epoch: 142, Loss: 1.4605, Train: 69.55%, Valid: 69.54% Test: 68.92%\n",
      "Epoch: 143, Loss: 1.4686, Train: 69.75%, Valid: 69.29% Test: 68.32%\n",
      "Epoch: 144, Loss: 1.4635, Train: 69.69%, Valid: 69.50% Test: 68.84%\n",
      "Epoch: 145, Loss: 1.4637, Train: 69.64%, Valid: 69.58% Test: 68.86%\n",
      "Epoch: 146, Loss: 1.4624, Train: 69.75%, Valid: 69.54% Test: 68.49%\n",
      "Epoch: 147, Loss: 1.4610, Train: 69.84%, Valid: 69.43% Test: 68.58%\n",
      "Epoch: 148, Loss: 1.4589, Train: 69.75%, Valid: 69.70% Test: 68.95%\n",
      "Epoch: 149, Loss: 1.4568, Train: 69.81%, Valid: 69.50% Test: 68.50%\n",
      "Epoch: 150, Loss: 1.4468, Train: 69.95%, Valid: 69.52% Test: 68.72%\n",
      "Epoch: 151, Loss: 1.4607, Train: 69.91%, Valid: 69.84% Test: 69.06%\n",
      "Epoch: 152, Loss: 1.4539, Train: 69.92%, Valid: 69.69% Test: 68.62%\n",
      "Epoch: 153, Loss: 1.4535, Train: 69.96%, Valid: 69.62% Test: 68.77%\n",
      "Epoch: 154, Loss: 1.4562, Train: 69.90%, Valid: 69.87% Test: 69.36%\n",
      "Epoch: 155, Loss: 1.4518, Train: 70.00%, Valid: 69.56% Test: 68.81%\n",
      "Epoch: 156, Loss: 1.4514, Train: 70.02%, Valid: 69.74% Test: 68.98%\n",
      "Epoch: 157, Loss: 1.4513, Train: 70.07%, Valid: 69.87% Test: 69.07%\n",
      "Epoch: 158, Loss: 1.4519, Train: 70.09%, Valid: 69.77% Test: 68.76%\n",
      "Epoch: 159, Loss: 1.4488, Train: 70.07%, Valid: 69.85% Test: 69.07%\n",
      "Epoch: 160, Loss: 1.4530, Train: 70.14%, Valid: 69.68% Test: 68.85%\n",
      "Epoch: 161, Loss: 1.4456, Train: 70.10%, Valid: 69.57% Test: 68.63%\n",
      "Epoch: 162, Loss: 1.4490, Train: 70.10%, Valid: 69.94% Test: 69.30%\n",
      "Epoch: 163, Loss: 1.4510, Train: 70.16%, Valid: 69.81% Test: 69.15%\n",
      "Epoch: 164, Loss: 1.4428, Train: 70.14%, Valid: 69.74% Test: 68.93%\n",
      "Epoch: 165, Loss: 1.4473, Train: 70.18%, Valid: 69.93% Test: 69.27%\n",
      "Epoch: 166, Loss: 1.4486, Train: 70.26%, Valid: 69.87% Test: 69.01%\n",
      "Epoch: 167, Loss: 1.4397, Train: 70.21%, Valid: 70.02% Test: 69.22%\n",
      "Epoch: 168, Loss: 1.4369, Train: 70.26%, Valid: 69.82% Test: 68.99%\n",
      "Epoch: 169, Loss: 1.4414, Train: 70.25%, Valid: 69.95% Test: 69.09%\n",
      "Epoch: 170, Loss: 1.4314, Train: 70.33%, Valid: 69.73% Test: 68.81%\n",
      "Epoch: 171, Loss: 1.4398, Train: 70.35%, Valid: 70.07% Test: 69.48%\n",
      "Epoch: 172, Loss: 1.4423, Train: 70.32%, Valid: 70.06% Test: 69.29%\n",
      "Epoch: 173, Loss: 1.4351, Train: 70.31%, Valid: 69.93% Test: 69.08%\n",
      "Epoch: 174, Loss: 1.4314, Train: 70.24%, Valid: 70.07% Test: 69.55%\n",
      "Epoch: 175, Loss: 1.4314, Train: 70.23%, Valid: 69.68% Test: 68.80%\n",
      "Epoch: 176, Loss: 1.4347, Train: 70.25%, Valid: 70.07% Test: 69.33%\n",
      "Epoch: 177, Loss: 1.4378, Train: 70.40%, Valid: 69.96% Test: 69.25%\n",
      "Epoch: 178, Loss: 1.4287, Train: 70.50%, Valid: 69.98% Test: 69.25%\n",
      "Epoch: 179, Loss: 1.4352, Train: 70.40%, Valid: 70.26% Test: 69.54%\n",
      "Epoch: 180, Loss: 1.4259, Train: 70.44%, Valid: 69.99% Test: 69.05%\n",
      "Epoch: 181, Loss: 1.4324, Train: 70.49%, Valid: 70.10% Test: 69.32%\n",
      "Epoch: 182, Loss: 1.4350, Train: 70.53%, Valid: 70.16% Test: 69.46%\n",
      "Epoch: 183, Loss: 1.4321, Train: 70.43%, Valid: 70.17% Test: 69.51%\n",
      "Epoch: 184, Loss: 1.4307, Train: 70.47%, Valid: 70.08% Test: 69.16%\n",
      "Epoch: 185, Loss: 1.4266, Train: 70.56%, Valid: 70.16% Test: 69.24%\n",
      "Epoch: 186, Loss: 1.4310, Train: 70.48%, Valid: 70.04% Test: 69.41%\n",
      "Epoch: 187, Loss: 1.4278, Train: 70.53%, Valid: 70.00% Test: 69.10%\n",
      "Epoch: 188, Loss: 1.4257, Train: 70.61%, Valid: 70.15% Test: 69.31%\n",
      "Epoch: 189, Loss: 1.4262, Train: 70.62%, Valid: 70.15% Test: 69.38%\n",
      "Epoch: 190, Loss: 1.4300, Train: 70.54%, Valid: 70.28% Test: 69.72%\n",
      "Epoch: 191, Loss: 1.4241, Train: 70.59%, Valid: 69.85% Test: 68.91%\n",
      "Epoch: 192, Loss: 1.4190, Train: 70.63%, Valid: 70.10% Test: 69.40%\n",
      "Epoch: 193, Loss: 1.4204, Train: 70.52%, Valid: 70.37% Test: 69.76%\n",
      "Epoch: 194, Loss: 1.4243, Train: 70.66%, Valid: 70.10% Test: 68.92%\n",
      "Epoch: 195, Loss: 1.4142, Train: 70.65%, Valid: 70.19% Test: 69.50%\n",
      "Epoch: 196, Loss: 1.4235, Train: 70.70%, Valid: 70.24% Test: 69.48%\n",
      "Epoch: 197, Loss: 1.4174, Train: 70.73%, Valid: 70.33% Test: 69.48%\n",
      "Epoch: 198, Loss: 1.4238, Train: 70.75%, Valid: 70.28% Test: 69.51%\n",
      "Epoch: 199, Loss: 1.4179, Train: 70.79%, Valid: 70.21% Test: 69.28%\n",
      "Epoch: 200, Loss: 1.4217, Train: 70.73%, Valid: 70.46% Test: 69.74%\n",
      "Epoch: 201, Loss: 1.4126, Train: 70.74%, Valid: 70.35% Test: 69.71%\n",
      "Epoch: 202, Loss: 1.4175, Train: 70.69%, Valid: 70.41% Test: 69.53%\n",
      "Epoch: 203, Loss: 1.4094, Train: 70.70%, Valid: 70.41% Test: 69.50%\n",
      "Epoch: 204, Loss: 1.4110, Train: 70.82%, Valid: 70.34% Test: 69.39%\n",
      "Epoch: 205, Loss: 1.4153, Train: 70.78%, Valid: 70.42% Test: 69.81%\n",
      "Epoch: 206, Loss: 1.4102, Train: 70.85%, Valid: 70.30% Test: 69.26%\n",
      "Epoch: 207, Loss: 1.4163, Train: 70.86%, Valid: 70.39% Test: 69.60%\n",
      "Epoch: 208, Loss: 1.4080, Train: 70.83%, Valid: 70.49% Test: 69.82%\n",
      "Epoch: 209, Loss: 1.4123, Train: 70.88%, Valid: 70.25% Test: 68.95%\n",
      "Epoch: 210, Loss: 1.4082, Train: 70.77%, Valid: 70.43% Test: 69.69%\n",
      "Epoch: 211, Loss: 1.4091, Train: 70.82%, Valid: 70.35% Test: 69.65%\n",
      "Epoch: 212, Loss: 1.4119, Train: 70.83%, Valid: 70.23% Test: 69.17%\n",
      "Epoch: 213, Loss: 1.4105, Train: 70.81%, Valid: 70.45% Test: 69.73%\n",
      "Epoch: 214, Loss: 1.4098, Train: 70.87%, Valid: 70.07% Test: 69.11%\n",
      "Epoch: 215, Loss: 1.4142, Train: 70.85%, Valid: 70.53% Test: 69.77%\n",
      "Epoch: 216, Loss: 1.4056, Train: 71.00%, Valid: 70.49% Test: 69.57%\n",
      "Epoch: 217, Loss: 1.4065, Train: 70.92%, Valid: 70.36% Test: 69.93%\n",
      "Epoch: 218, Loss: 1.4086, Train: 70.95%, Valid: 70.41% Test: 69.74%\n",
      "Epoch: 219, Loss: 1.3992, Train: 70.95%, Valid: 70.36% Test: 69.29%\n",
      "Epoch: 220, Loss: 1.4082, Train: 70.97%, Valid: 70.51% Test: 69.70%\n",
      "Epoch: 221, Loss: 1.4026, Train: 70.90%, Valid: 70.24% Test: 69.48%\n",
      "Epoch: 222, Loss: 1.4057, Train: 70.91%, Valid: 70.48% Test: 69.58%\n",
      "Epoch: 223, Loss: 1.4056, Train: 71.00%, Valid: 70.23% Test: 69.53%\n",
      "Epoch: 224, Loss: 1.4024, Train: 70.91%, Valid: 70.59% Test: 70.21%\n",
      "Epoch: 225, Loss: 1.4114, Train: 70.99%, Valid: 70.06% Test: 68.61%\n",
      "Epoch: 226, Loss: 1.4074, Train: 71.08%, Valid: 70.68% Test: 69.79%\n",
      "Epoch: 227, Loss: 1.4058, Train: 71.06%, Valid: 70.64% Test: 69.88%\n",
      "Epoch: 228, Loss: 1.3994, Train: 71.07%, Valid: 70.19% Test: 68.97%\n",
      "Epoch: 229, Loss: 1.4002, Train: 70.97%, Valid: 70.61% Test: 69.95%\n",
      "Epoch: 230, Loss: 1.4073, Train: 71.04%, Valid: 70.25% Test: 69.43%\n",
      "Epoch: 231, Loss: 1.3998, Train: 71.15%, Valid: 70.52% Test: 69.77%\n",
      "Epoch: 232, Loss: 1.4062, Train: 71.08%, Valid: 70.73% Test: 69.94%\n",
      "Epoch: 233, Loss: 1.3959, Train: 71.19%, Valid: 70.50% Test: 69.55%\n",
      "Epoch: 234, Loss: 1.3994, Train: 71.09%, Valid: 70.32% Test: 69.22%\n",
      "Epoch: 235, Loss: 1.3951, Train: 70.99%, Valid: 70.70% Test: 70.09%\n",
      "Epoch: 236, Loss: 1.4000, Train: 71.18%, Valid: 70.44% Test: 69.55%\n",
      "Epoch: 237, Loss: 1.3984, Train: 71.11%, Valid: 70.64% Test: 69.90%\n",
      "Epoch: 238, Loss: 1.3966, Train: 71.14%, Valid: 70.60% Test: 69.85%\n",
      "Epoch: 239, Loss: 1.3915, Train: 71.15%, Valid: 70.31% Test: 69.44%\n",
      "Epoch: 240, Loss: 1.3957, Train: 71.10%, Valid: 70.64% Test: 70.08%\n",
      "Epoch: 241, Loss: 1.4011, Train: 71.21%, Valid: 70.61% Test: 69.81%\n",
      "Epoch: 242, Loss: 1.3938, Train: 71.22%, Valid: 70.42% Test: 69.53%\n",
      "Epoch: 243, Loss: 1.3938, Train: 71.16%, Valid: 70.69% Test: 69.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 244, Loss: 1.3928, Train: 71.29%, Valid: 70.62% Test: 69.70%\n",
      "Epoch: 245, Loss: 1.3975, Train: 71.24%, Valid: 70.67% Test: 69.94%\n",
      "Epoch: 246, Loss: 1.3888, Train: 71.22%, Valid: 70.67% Test: 70.18%\n",
      "Epoch: 247, Loss: 1.3944, Train: 71.29%, Valid: 70.21% Test: 69.27%\n",
      "Epoch: 248, Loss: 1.3936, Train: 71.25%, Valid: 70.82% Test: 70.15%\n",
      "Epoch: 249, Loss: 1.3875, Train: 71.29%, Valid: 70.62% Test: 69.79%\n",
      "Epoch: 250, Loss: 1.3875, Train: 71.26%, Valid: 70.44% Test: 69.42%\n",
      "Epoch: 251, Loss: 1.3890, Train: 71.21%, Valid: 70.71% Test: 70.18%\n",
      "Epoch: 252, Loss: 1.3873, Train: 71.35%, Valid: 70.52% Test: 69.72%\n",
      "Epoch: 253, Loss: 1.3973, Train: 71.33%, Valid: 70.67% Test: 69.75%\n",
      "Epoch: 254, Loss: 1.3904, Train: 71.27%, Valid: 70.68% Test: 70.02%\n",
      "Epoch: 255, Loss: 1.3847, Train: 71.31%, Valid: 70.36% Test: 69.35%\n",
      "Epoch: 256, Loss: 1.3912, Train: 71.36%, Valid: 70.78% Test: 69.99%\n",
      "Epoch: 257, Loss: 1.3814, Train: 71.31%, Valid: 70.84% Test: 70.08%\n",
      "Epoch: 258, Loss: 1.3884, Train: 71.39%, Valid: 70.23% Test: 69.31%\n",
      "Epoch: 259, Loss: 1.3874, Train: 71.24%, Valid: 70.77% Test: 70.04%\n",
      "Epoch: 260, Loss: 1.3879, Train: 71.35%, Valid: 70.77% Test: 70.05%\n",
      "Epoch: 261, Loss: 1.3820, Train: 71.40%, Valid: 70.47% Test: 69.56%\n",
      "Epoch: 262, Loss: 1.3852, Train: 71.28%, Valid: 70.73% Test: 70.03%\n",
      "Epoch: 263, Loss: 1.3861, Train: 71.40%, Valid: 70.86% Test: 69.98%\n",
      "Epoch: 264, Loss: 1.3826, Train: 71.37%, Valid: 70.68% Test: 69.71%\n",
      "Epoch: 265, Loss: 1.3770, Train: 71.31%, Valid: 70.81% Test: 70.01%\n",
      "Epoch: 266, Loss: 1.3810, Train: 71.41%, Valid: 70.78% Test: 70.03%\n",
      "Epoch: 267, Loss: 1.3741, Train: 71.45%, Valid: 70.88% Test: 70.24%\n",
      "Epoch: 268, Loss: 1.3881, Train: 71.36%, Valid: 70.89% Test: 70.06%\n",
      "Epoch: 269, Loss: 1.3808, Train: 71.45%, Valid: 70.64% Test: 69.64%\n",
      "Epoch: 270, Loss: 1.3827, Train: 71.49%, Valid: 70.85% Test: 70.08%\n",
      "Epoch: 271, Loss: 1.3756, Train: 71.46%, Valid: 70.94% Test: 70.18%\n",
      "Epoch: 272, Loss: 1.3759, Train: 71.43%, Valid: 70.66% Test: 69.67%\n",
      "Epoch: 273, Loss: 1.3819, Train: 71.42%, Valid: 70.74% Test: 70.09%\n",
      "Epoch: 274, Loss: 1.3797, Train: 71.46%, Valid: 70.86% Test: 70.15%\n",
      "Epoch: 275, Loss: 1.3791, Train: 71.52%, Valid: 70.77% Test: 69.97%\n",
      "Epoch: 276, Loss: 1.3760, Train: 71.50%, Valid: 70.77% Test: 70.13%\n",
      "Epoch: 277, Loss: 1.3791, Train: 71.55%, Valid: 70.84% Test: 70.01%\n",
      "Epoch: 278, Loss: 1.3794, Train: 71.60%, Valid: 70.71% Test: 69.70%\n",
      "Epoch: 279, Loss: 1.3748, Train: 71.54%, Valid: 70.70% Test: 70.00%\n",
      "Epoch: 280, Loss: 1.3779, Train: 71.48%, Valid: 70.91% Test: 70.23%\n",
      "Epoch: 281, Loss: 1.3772, Train: 71.42%, Valid: 70.60% Test: 69.49%\n",
      "Epoch: 282, Loss: 1.3816, Train: 71.47%, Valid: 70.60% Test: 69.87%\n",
      "Epoch: 283, Loss: 1.3736, Train: 71.44%, Valid: 70.88% Test: 70.35%\n",
      "Epoch: 284, Loss: 1.3783, Train: 71.57%, Valid: 70.50% Test: 69.28%\n",
      "Epoch: 285, Loss: 1.3794, Train: 71.58%, Valid: 70.74% Test: 69.86%\n",
      "Epoch: 286, Loss: 1.3709, Train: 71.46%, Valid: 70.91% Test: 70.43%\n",
      "Epoch: 287, Loss: 1.3771, Train: 71.57%, Valid: 70.55% Test: 69.38%\n",
      "Epoch: 288, Loss: 1.3765, Train: 71.58%, Valid: 70.88% Test: 70.22%\n",
      "Epoch: 289, Loss: 1.3705, Train: 71.58%, Valid: 70.77% Test: 70.39%\n",
      "Epoch: 290, Loss: 1.3728, Train: 71.60%, Valid: 70.39% Test: 69.21%\n",
      "Epoch: 291, Loss: 1.3779, Train: 71.42%, Valid: 70.74% Test: 70.21%\n",
      "Epoch: 292, Loss: 1.3716, Train: 71.70%, Valid: 70.95% Test: 69.93%\n",
      "Epoch: 293, Loss: 1.3781, Train: 71.67%, Valid: 70.79% Test: 69.77%\n",
      "Epoch: 294, Loss: 1.3776, Train: 71.44%, Valid: 70.81% Test: 70.21%\n",
      "Epoch: 295, Loss: 1.3744, Train: 71.58%, Valid: 70.50% Test: 69.34%\n",
      "Epoch: 296, Loss: 1.3701, Train: 71.60%, Valid: 70.66% Test: 69.94%\n",
      "Epoch: 297, Loss: 1.3744, Train: 71.41%, Valid: 70.84% Test: 70.29%\n",
      "Epoch: 298, Loss: 1.3734, Train: 71.66%, Valid: 70.43% Test: 69.22%\n",
      "Epoch: 299, Loss: 1.3756, Train: 71.70%, Valid: 70.88% Test: 69.94%\n",
      "Epoch: 300, Loss: 1.3683, Train: 71.48%, Valid: 70.94% Test: 70.49%\n",
      "Epoch: 301, Loss: 1.3680, Train: 71.69%, Valid: 70.53% Test: 69.20%\n",
      "Epoch: 302, Loss: 1.3712, Train: 71.75%, Valid: 70.85% Test: 69.82%\n",
      "Epoch: 303, Loss: 1.3738, Train: 71.41%, Valid: 70.83% Test: 70.25%\n",
      "Epoch: 304, Loss: 1.3651, Train: 71.79%, Valid: 70.69% Test: 69.51%\n",
      "Epoch: 305, Loss: 1.3627, Train: 71.73%, Valid: 70.80% Test: 69.72%\n",
      "Epoch: 306, Loss: 1.3658, Train: 71.55%, Valid: 70.87% Test: 70.18%\n",
      "Epoch: 307, Loss: 1.3683, Train: 71.71%, Valid: 70.96% Test: 69.93%\n",
      "Epoch: 308, Loss: 1.3720, Train: 71.70%, Valid: 70.78% Test: 69.97%\n",
      "Epoch: 309, Loss: 1.3724, Train: 71.56%, Valid: 70.81% Test: 70.07%\n",
      "Epoch: 310, Loss: 1.3710, Train: 71.70%, Valid: 70.80% Test: 69.82%\n",
      "Epoch: 311, Loss: 1.3636, Train: 71.72%, Valid: 70.83% Test: 69.95%\n",
      "Epoch: 312, Loss: 1.3667, Train: 71.63%, Valid: 70.91% Test: 70.23%\n",
      "Epoch: 313, Loss: 1.3620, Train: 71.79%, Valid: 70.94% Test: 69.67%\n",
      "Epoch: 314, Loss: 1.3690, Train: 71.75%, Valid: 70.97% Test: 69.95%\n",
      "Epoch: 315, Loss: 1.3680, Train: 71.60%, Valid: 70.94% Test: 70.39%\n",
      "Epoch: 316, Loss: 1.3641, Train: 71.83%, Valid: 70.78% Test: 69.68%\n",
      "Epoch: 317, Loss: 1.3616, Train: 71.77%, Valid: 70.99% Test: 70.18%\n",
      "Epoch: 318, Loss: 1.3660, Train: 71.72%, Valid: 71.00% Test: 70.36%\n",
      "Epoch: 319, Loss: 1.3697, Train: 71.87%, Valid: 70.88% Test: 69.81%\n",
      "Epoch: 320, Loss: 1.3621, Train: 71.80%, Valid: 70.92% Test: 70.13%\n",
      "Epoch: 321, Loss: 1.3659, Train: 71.77%, Valid: 71.03% Test: 70.19%\n",
      "Epoch: 322, Loss: 1.3641, Train: 71.86%, Valid: 71.06% Test: 70.26%\n",
      "Epoch: 323, Loss: 1.3579, Train: 71.84%, Valid: 71.05% Test: 70.21%\n",
      "Epoch: 324, Loss: 1.3625, Train: 71.84%, Valid: 70.98% Test: 69.95%\n",
      "Epoch: 325, Loss: 1.3558, Train: 71.85%, Valid: 71.03% Test: 69.97%\n",
      "Epoch: 326, Loss: 1.3644, Train: 71.83%, Valid: 71.21% Test: 70.60%\n",
      "Epoch: 327, Loss: 1.3613, Train: 71.83%, Valid: 71.12% Test: 70.38%\n",
      "Epoch: 328, Loss: 1.3590, Train: 71.80%, Valid: 70.83% Test: 69.72%\n",
      "Epoch: 329, Loss: 1.3577, Train: 71.85%, Valid: 71.09% Test: 70.37%\n",
      "Epoch: 330, Loss: 1.3608, Train: 71.93%, Valid: 71.11% Test: 70.32%\n",
      "Epoch: 331, Loss: 1.3556, Train: 71.89%, Valid: 71.13% Test: 70.24%\n",
      "Epoch: 332, Loss: 1.3556, Train: 71.84%, Valid: 71.00% Test: 70.26%\n",
      "Epoch: 333, Loss: 1.3570, Train: 71.88%, Valid: 70.93% Test: 69.76%\n",
      "Epoch: 334, Loss: 1.3628, Train: 71.96%, Valid: 71.06% Test: 70.18%\n",
      "Epoch: 335, Loss: 1.3607, Train: 71.92%, Valid: 71.18% Test: 70.51%\n",
      "Epoch: 336, Loss: 1.3542, Train: 71.97%, Valid: 70.96% Test: 69.89%\n",
      "Epoch: 337, Loss: 1.3560, Train: 71.95%, Valid: 71.04% Test: 70.14%\n",
      "Epoch: 338, Loss: 1.3618, Train: 71.95%, Valid: 71.16% Test: 70.39%\n",
      "Epoch: 339, Loss: 1.3517, Train: 71.98%, Valid: 71.08% Test: 70.24%\n",
      "Epoch: 340, Loss: 1.3609, Train: 71.95%, Valid: 71.20% Test: 70.40%\n",
      "Epoch: 341, Loss: 1.3562, Train: 71.99%, Valid: 71.16% Test: 70.42%\n",
      "Epoch: 342, Loss: 1.3574, Train: 71.93%, Valid: 71.12% Test: 70.31%\n",
      "Epoch: 343, Loss: 1.3540, Train: 71.98%, Valid: 71.11% Test: 70.20%\n",
      "Epoch: 344, Loss: 1.3495, Train: 71.93%, Valid: 71.10% Test: 70.29%\n",
      "Epoch: 345, Loss: 1.3546, Train: 71.97%, Valid: 71.06% Test: 70.29%\n",
      "Epoch: 346, Loss: 1.3498, Train: 71.98%, Valid: 71.18% Test: 70.43%\n",
      "Epoch: 347, Loss: 1.3583, Train: 71.94%, Valid: 71.13% Test: 70.44%\n",
      "Epoch: 348, Loss: 1.3562, Train: 71.96%, Valid: 70.75% Test: 69.54%\n",
      "Epoch: 349, Loss: 1.3518, Train: 71.92%, Valid: 71.11% Test: 70.41%\n",
      "Epoch: 350, Loss: 1.3495, Train: 71.99%, Valid: 71.18% Test: 70.48%\n",
      "Epoch: 351, Loss: 1.3577, Train: 72.08%, Valid: 70.74% Test: 69.77%\n",
      "Epoch: 352, Loss: 1.3522, Train: 71.95%, Valid: 71.06% Test: 70.51%\n",
      "Epoch: 353, Loss: 1.3506, Train: 72.00%, Valid: 71.11% Test: 70.55%\n",
      "Epoch: 354, Loss: 1.3526, Train: 72.12%, Valid: 70.78% Test: 69.63%\n",
      "Epoch: 355, Loss: 1.3492, Train: 71.97%, Valid: 71.05% Test: 70.35%\n",
      "Epoch: 356, Loss: 1.3556, Train: 71.98%, Valid: 71.09% Test: 70.34%\n",
      "Epoch: 357, Loss: 1.3493, Train: 72.06%, Valid: 71.10% Test: 70.11%\n",
      "Epoch: 358, Loss: 1.3568, Train: 72.00%, Valid: 71.23% Test: 70.54%\n",
      "Epoch: 359, Loss: 1.3436, Train: 72.09%, Valid: 71.13% Test: 70.05%\n",
      "Epoch: 360, Loss: 1.3540, Train: 72.08%, Valid: 71.22% Test: 70.28%\n",
      "Epoch: 361, Loss: 1.3469, Train: 72.04%, Valid: 71.26% Test: 70.41%\n",
      "Epoch: 362, Loss: 1.3484, Train: 72.04%, Valid: 71.09% Test: 70.26%\n",
      "Epoch: 363, Loss: 1.3475, Train: 72.06%, Valid: 71.09% Test: 70.32%\n",
      "Epoch: 364, Loss: 1.3501, Train: 72.06%, Valid: 71.14% Test: 70.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 365, Loss: 1.3539, Train: 72.03%, Valid: 71.33% Test: 70.57%\n",
      "Epoch: 366, Loss: 1.3476, Train: 72.13%, Valid: 70.81% Test: 69.71%\n",
      "Epoch: 367, Loss: 1.3443, Train: 72.05%, Valid: 71.20% Test: 70.45%\n",
      "Epoch: 368, Loss: 1.3503, Train: 72.09%, Valid: 71.22% Test: 70.51%\n",
      "Epoch: 369, Loss: 1.3519, Train: 72.12%, Valid: 71.10% Test: 70.30%\n",
      "Epoch: 370, Loss: 1.3481, Train: 72.01%, Valid: 71.20% Test: 70.35%\n",
      "Epoch: 371, Loss: 1.3474, Train: 72.13%, Valid: 71.16% Test: 70.26%\n",
      "Epoch: 372, Loss: 1.3456, Train: 72.14%, Valid: 71.21% Test: 70.31%\n",
      "Epoch: 373, Loss: 1.3512, Train: 72.19%, Valid: 71.33% Test: 70.54%\n",
      "Epoch: 374, Loss: 1.3465, Train: 72.13%, Valid: 71.25% Test: 70.35%\n",
      "Epoch: 375, Loss: 1.3444, Train: 72.13%, Valid: 71.19% Test: 70.25%\n",
      "Epoch: 376, Loss: 1.3456, Train: 72.04%, Valid: 71.42% Test: 70.64%\n",
      "Epoch: 377, Loss: 1.3470, Train: 72.05%, Valid: 71.21% Test: 70.30%\n",
      "Epoch: 378, Loss: 1.3451, Train: 72.13%, Valid: 71.16% Test: 70.09%\n",
      "Epoch: 379, Loss: 1.3456, Train: 72.17%, Valid: 71.28% Test: 70.42%\n",
      "Epoch: 380, Loss: 1.3488, Train: 72.20%, Valid: 71.25% Test: 70.36%\n",
      "Epoch: 381, Loss: 1.3515, Train: 72.14%, Valid: 71.32% Test: 70.62%\n",
      "Epoch: 382, Loss: 1.3459, Train: 72.19%, Valid: 71.28% Test: 70.33%\n",
      "Epoch: 383, Loss: 1.3506, Train: 72.16%, Valid: 71.20% Test: 70.22%\n",
      "Epoch: 384, Loss: 1.3409, Train: 72.09%, Valid: 71.35% Test: 70.62%\n",
      "Epoch: 385, Loss: 1.3471, Train: 72.14%, Valid: 71.21% Test: 70.18%\n",
      "Epoch: 386, Loss: 1.3432, Train: 72.13%, Valid: 71.28% Test: 70.35%\n",
      "Epoch: 387, Loss: 1.3408, Train: 72.15%, Valid: 71.31% Test: 70.40%\n",
      "Epoch: 388, Loss: 1.3462, Train: 72.20%, Valid: 71.34% Test: 70.17%\n",
      "Epoch: 389, Loss: 1.3368, Train: 72.16%, Valid: 71.32% Test: 70.53%\n",
      "Epoch: 390, Loss: 1.3439, Train: 72.08%, Valid: 71.17% Test: 70.51%\n",
      "Epoch: 391, Loss: 1.3400, Train: 72.19%, Valid: 71.26% Test: 70.14%\n",
      "Epoch: 392, Loss: 1.3430, Train: 72.26%, Valid: 71.32% Test: 70.19%\n",
      "Epoch: 393, Loss: 1.3428, Train: 72.15%, Valid: 71.21% Test: 70.26%\n",
      "Epoch: 394, Loss: 1.3399, Train: 72.21%, Valid: 71.24% Test: 70.47%\n",
      "Epoch: 395, Loss: 1.3423, Train: 72.29%, Valid: 71.22% Test: 70.09%\n",
      "Epoch: 396, Loss: 1.3446, Train: 72.23%, Valid: 71.31% Test: 70.55%\n",
      "Epoch: 397, Loss: 1.3372, Train: 72.14%, Valid: 71.20% Test: 70.64%\n",
      "Epoch: 398, Loss: 1.3431, Train: 72.29%, Valid: 70.97% Test: 69.66%\n",
      "Epoch: 399, Loss: 1.3386, Train: 72.23%, Valid: 71.32% Test: 70.29%\n",
      "Epoch: 400, Loss: 1.3394, Train: 72.21%, Valid: 71.36% Test: 70.65%\n",
      "Epoch: 401, Loss: 1.3376, Train: 72.32%, Valid: 71.06% Test: 69.92%\n",
      "Epoch: 402, Loss: 1.3389, Train: 72.26%, Valid: 71.26% Test: 70.51%\n",
      "Epoch: 403, Loss: 1.3381, Train: 72.33%, Valid: 71.41% Test: 70.55%\n",
      "Epoch: 404, Loss: 1.3443, Train: 72.34%, Valid: 71.47% Test: 70.38%\n",
      "Epoch: 405, Loss: 1.3387, Train: 72.25%, Valid: 71.28% Test: 70.43%\n",
      "Epoch: 406, Loss: 1.3416, Train: 72.30%, Valid: 71.32% Test: 70.38%\n",
      "Epoch: 407, Loss: 1.3419, Train: 72.40%, Valid: 71.42% Test: 70.28%\n",
      "Epoch: 408, Loss: 1.3410, Train: 72.29%, Valid: 71.36% Test: 70.44%\n",
      "Epoch: 409, Loss: 1.3406, Train: 72.35%, Valid: 71.34% Test: 70.49%\n",
      "Epoch: 410, Loss: 1.3401, Train: 72.42%, Valid: 71.34% Test: 70.15%\n",
      "Epoch: 411, Loss: 1.3289, Train: 72.33%, Valid: 71.46% Test: 70.65%\n",
      "Epoch: 412, Loss: 1.3377, Train: 72.36%, Valid: 71.47% Test: 70.68%\n",
      "Epoch: 413, Loss: 1.3401, Train: 72.42%, Valid: 71.15% Test: 69.89%\n",
      "Epoch: 414, Loss: 1.3325, Train: 72.35%, Valid: 71.35% Test: 70.55%\n",
      "Epoch: 415, Loss: 1.3371, Train: 72.37%, Valid: 71.47% Test: 70.60%\n",
      "Epoch: 416, Loss: 1.3352, Train: 72.39%, Valid: 71.42% Test: 70.37%\n",
      "Epoch: 417, Loss: 1.3317, Train: 72.33%, Valid: 71.30% Test: 70.54%\n",
      "Epoch: 418, Loss: 1.3332, Train: 72.37%, Valid: 71.34% Test: 70.25%\n",
      "Epoch: 419, Loss: 1.3342, Train: 72.35%, Valid: 71.47% Test: 70.32%\n",
      "Epoch: 420, Loss: 1.3346, Train: 72.29%, Valid: 71.43% Test: 70.60%\n",
      "Epoch: 421, Loss: 1.3405, Train: 72.41%, Valid: 71.17% Test: 70.10%\n",
      "Epoch: 422, Loss: 1.3437, Train: 72.47%, Valid: 71.28% Test: 70.13%\n",
      "Epoch: 423, Loss: 1.3403, Train: 72.38%, Valid: 71.58% Test: 70.78%\n",
      "Epoch: 424, Loss: 1.3322, Train: 72.39%, Valid: 71.47% Test: 70.69%\n",
      "Epoch: 425, Loss: 1.3341, Train: 72.41%, Valid: 71.04% Test: 69.75%\n",
      "Epoch: 426, Loss: 1.3327, Train: 72.33%, Valid: 71.42% Test: 70.59%\n",
      "Epoch: 427, Loss: 1.3370, Train: 72.37%, Valid: 71.40% Test: 70.46%\n",
      "Epoch: 428, Loss: 1.3350, Train: 72.40%, Valid: 71.39% Test: 70.45%\n",
      "Epoch: 429, Loss: 1.3328, Train: 72.38%, Valid: 71.37% Test: 70.31%\n",
      "Epoch: 430, Loss: 1.3335, Train: 72.46%, Valid: 71.45% Test: 70.37%\n",
      "Epoch: 431, Loss: 1.3333, Train: 72.37%, Valid: 71.52% Test: 70.73%\n",
      "Epoch: 432, Loss: 1.3347, Train: 72.43%, Valid: 71.41% Test: 70.48%\n",
      "Epoch: 433, Loss: 1.3262, Train: 72.46%, Valid: 71.47% Test: 70.45%\n",
      "Epoch: 434, Loss: 1.3303, Train: 72.45%, Valid: 71.55% Test: 70.70%\n",
      "Epoch: 435, Loss: 1.3272, Train: 72.40%, Valid: 71.46% Test: 70.58%\n",
      "Epoch: 436, Loss: 1.3301, Train: 72.45%, Valid: 71.27% Test: 70.03%\n",
      "Epoch: 437, Loss: 1.3343, Train: 72.53%, Valid: 71.51% Test: 70.34%\n",
      "Epoch: 438, Loss: 1.3330, Train: 72.40%, Valid: 71.55% Test: 71.03%\n",
      "Epoch: 439, Loss: 1.3310, Train: 72.57%, Valid: 71.40% Test: 70.18%\n",
      "Epoch: 440, Loss: 1.3363, Train: 72.51%, Valid: 71.50% Test: 70.51%\n",
      "Epoch: 441, Loss: 1.3259, Train: 72.46%, Valid: 71.54% Test: 70.57%\n",
      "Epoch: 442, Loss: 1.3375, Train: 72.53%, Valid: 71.49% Test: 70.30%\n",
      "Epoch: 443, Loss: 1.3345, Train: 72.46%, Valid: 71.61% Test: 70.73%\n",
      "Epoch: 444, Loss: 1.3313, Train: 72.43%, Valid: 71.35% Test: 70.48%\n",
      "Epoch: 445, Loss: 1.3314, Train: 72.46%, Valid: 71.22% Test: 69.98%\n",
      "Epoch: 446, Loss: 1.3360, Train: 72.45%, Valid: 71.52% Test: 70.72%\n",
      "Epoch: 447, Loss: 1.3338, Train: 72.53%, Valid: 71.53% Test: 70.59%\n",
      "Epoch: 448, Loss: 1.3335, Train: 72.54%, Valid: 71.45% Test: 70.20%\n",
      "Epoch: 449, Loss: 1.3340, Train: 72.47%, Valid: 71.51% Test: 70.48%\n",
      "Epoch: 450, Loss: 1.3302, Train: 72.54%, Valid: 71.52% Test: 70.35%\n",
      "Epoch: 451, Loss: 1.3280, Train: 72.51%, Valid: 71.45% Test: 70.48%\n",
      "Epoch: 452, Loss: 1.3309, Train: 72.57%, Valid: 71.51% Test: 70.57%\n",
      "Epoch: 453, Loss: 1.3345, Train: 72.59%, Valid: 71.57% Test: 70.50%\n",
      "Epoch: 454, Loss: 1.3305, Train: 72.55%, Valid: 71.54% Test: 70.71%\n",
      "Epoch: 455, Loss: 1.3294, Train: 72.61%, Valid: 71.26% Test: 70.10%\n",
      "Epoch: 456, Loss: 1.3264, Train: 72.56%, Valid: 71.54% Test: 70.60%\n",
      "Epoch: 457, Loss: 1.3321, Train: 72.53%, Valid: 71.53% Test: 70.67%\n",
      "Epoch: 458, Loss: 1.3279, Train: 72.56%, Valid: 71.37% Test: 70.01%\n",
      "Epoch: 459, Loss: 1.3299, Train: 72.50%, Valid: 71.51% Test: 70.59%\n",
      "Epoch: 460, Loss: 1.3277, Train: 72.45%, Valid: 71.61% Test: 70.85%\n",
      "Epoch: 461, Loss: 1.3301, Train: 72.58%, Valid: 71.39% Test: 70.08%\n",
      "Epoch: 462, Loss: 1.3306, Train: 72.53%, Valid: 71.58% Test: 70.69%\n",
      "Epoch: 463, Loss: 1.3303, Train: 72.58%, Valid: 71.52% Test: 70.40%\n",
      "Epoch: 464, Loss: 1.3293, Train: 72.57%, Valid: 71.51% Test: 70.60%\n",
      "Epoch: 465, Loss: 1.3316, Train: 72.51%, Valid: 71.64% Test: 70.78%\n",
      "Epoch: 466, Loss: 1.3243, Train: 72.59%, Valid: 71.50% Test: 70.25%\n",
      "Epoch: 467, Loss: 1.3263, Train: 72.62%, Valid: 71.42% Test: 70.43%\n",
      "Epoch: 468, Loss: 1.3242, Train: 72.57%, Valid: 71.64% Test: 70.81%\n",
      "Epoch: 469, Loss: 1.3294, Train: 72.66%, Valid: 71.58% Test: 70.63%\n",
      "Epoch: 470, Loss: 1.3264, Train: 72.70%, Valid: 71.53% Test: 70.55%\n",
      "Epoch: 471, Loss: 1.3259, Train: 72.66%, Valid: 71.63% Test: 70.71%\n",
      "Epoch: 472, Loss: 1.3278, Train: 72.69%, Valid: 71.59% Test: 70.37%\n",
      "Epoch: 473, Loss: 1.3225, Train: 72.67%, Valid: 71.50% Test: 70.56%\n",
      "Epoch: 474, Loss: 1.3196, Train: 72.64%, Valid: 71.53% Test: 70.70%\n",
      "Epoch: 475, Loss: 1.3248, Train: 72.65%, Valid: 71.62% Test: 70.44%\n",
      "Epoch: 476, Loss: 1.3242, Train: 72.68%, Valid: 71.77% Test: 70.75%\n",
      "Epoch: 477, Loss: 1.3227, Train: 72.64%, Valid: 71.44% Test: 70.57%\n",
      "Epoch: 478, Loss: 1.3283, Train: 72.64%, Valid: 71.40% Test: 70.31%\n",
      "Epoch: 479, Loss: 1.3232, Train: 72.64%, Valid: 71.63% Test: 70.61%\n",
      "Epoch: 480, Loss: 1.3134, Train: 72.64%, Valid: 71.49% Test: 70.70%\n",
      "Epoch: 481, Loss: 1.3231, Train: 72.66%, Valid: 71.38% Test: 70.22%\n",
      "Epoch: 482, Loss: 1.3215, Train: 72.67%, Valid: 71.65% Test: 70.85%\n",
      "Epoch: 483, Loss: 1.3242, Train: 72.66%, Valid: 71.54% Test: 70.56%\n",
      "Epoch: 484, Loss: 1.3239, Train: 72.67%, Valid: 71.30% Test: 70.11%\n",
      "Epoch: 485, Loss: 1.3242, Train: 72.63%, Valid: 71.52% Test: 70.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 486, Loss: 1.3199, Train: 72.71%, Valid: 71.54% Test: 70.60%\n",
      "Epoch: 487, Loss: 1.3213, Train: 72.64%, Valid: 71.59% Test: 70.94%\n",
      "Epoch: 488, Loss: 1.3201, Train: 72.67%, Valid: 71.38% Test: 70.11%\n",
      "Epoch: 489, Loss: 1.3242, Train: 72.64%, Valid: 71.50% Test: 70.63%\n",
      "Epoch: 490, Loss: 1.3172, Train: 72.70%, Valid: 71.64% Test: 70.72%\n",
      "Epoch: 491, Loss: 1.3197, Train: 72.77%, Valid: 71.55% Test: 70.65%\n",
      "Epoch: 492, Loss: 1.3297, Train: 72.76%, Valid: 71.46% Test: 70.42%\n",
      "Epoch: 493, Loss: 1.3239, Train: 72.72%, Valid: 71.69% Test: 70.89%\n",
      "Epoch: 494, Loss: 1.3233, Train: 72.77%, Valid: 71.59% Test: 70.54%\n",
      "Epoch: 495, Loss: 1.3220, Train: 72.72%, Valid: 71.35% Test: 70.39%\n",
      "Epoch: 496, Loss: 1.3221, Train: 72.71%, Valid: 71.62% Test: 70.55%\n",
      "Epoch: 497, Loss: 1.3217, Train: 72.72%, Valid: 71.72% Test: 70.70%\n",
      "Epoch: 498, Loss: 1.3213, Train: 72.73%, Valid: 71.62% Test: 70.47%\n",
      "Epoch: 499, Loss: 1.3147, Train: 72.69%, Valid: 71.47% Test: 70.65%\n",
      "Epoch: 500, Loss: 1.3189, Train: 72.71%, Valid: 71.55% Test: 70.53%\n",
      "Epoch: 501, Loss: 1.3155, Train: 72.76%, Valid: 71.46% Test: 70.29%\n",
      "Epoch: 502, Loss: 1.3183, Train: 72.74%, Valid: 71.60% Test: 70.83%\n",
      "Epoch: 503, Loss: 1.3196, Train: 72.73%, Valid: 71.59% Test: 70.45%\n",
      "Epoch: 504, Loss: 1.3215, Train: 72.75%, Valid: 71.66% Test: 70.51%\n",
      "Epoch: 505, Loss: 1.3242, Train: 72.66%, Valid: 71.50% Test: 70.82%\n",
      "Epoch: 506, Loss: 1.3185, Train: 72.79%, Valid: 71.39% Test: 70.18%\n",
      "Epoch: 507, Loss: 1.3220, Train: 72.76%, Valid: 71.69% Test: 70.82%\n",
      "Epoch: 508, Loss: 1.3257, Train: 72.80%, Valid: 71.71% Test: 70.68%\n",
      "Epoch: 509, Loss: 1.3188, Train: 72.82%, Valid: 71.58% Test: 70.50%\n",
      "Epoch: 510, Loss: 1.3180, Train: 72.67%, Valid: 71.64% Test: 70.89%\n",
      "Epoch: 511, Loss: 1.3211, Train: 72.82%, Valid: 71.39% Test: 70.36%\n",
      "Epoch: 512, Loss: 1.3233, Train: 72.70%, Valid: 71.69% Test: 70.87%\n",
      "Epoch: 513, Loss: 1.3188, Train: 72.69%, Valid: 71.58% Test: 70.74%\n",
      "Epoch: 514, Loss: 1.3137, Train: 72.76%, Valid: 71.20% Test: 69.60%\n",
      "Epoch: 515, Loss: 1.3133, Train: 72.72%, Valid: 71.57% Test: 70.78%\n",
      "Epoch: 516, Loss: 1.3146, Train: 72.71%, Valid: 71.71% Test: 71.03%\n",
      "Epoch: 517, Loss: 1.3183, Train: 72.83%, Valid: 71.31% Test: 70.00%\n",
      "Epoch: 518, Loss: 1.3145, Train: 72.67%, Valid: 71.54% Test: 70.65%\n",
      "Epoch: 519, Loss: 1.3223, Train: 72.77%, Valid: 71.50% Test: 70.51%\n",
      "Epoch: 520, Loss: 1.3146, Train: 72.82%, Valid: 71.65% Test: 70.44%\n",
      "Epoch: 521, Loss: 1.3168, Train: 72.65%, Valid: 71.43% Test: 70.66%\n",
      "Epoch: 522, Loss: 1.3146, Train: 72.83%, Valid: 71.37% Test: 70.15%\n",
      "Epoch: 523, Loss: 1.3198, Train: 72.82%, Valid: 71.78% Test: 71.03%\n",
      "Epoch: 524, Loss: 1.3161, Train: 72.84%, Valid: 71.64% Test: 70.95%\n",
      "Epoch: 525, Loss: 1.3142, Train: 72.83%, Valid: 71.23% Test: 69.87%\n",
      "Epoch: 526, Loss: 1.3163, Train: 72.74%, Valid: 71.52% Test: 70.70%\n",
      "Epoch: 527, Loss: 1.3161, Train: 72.88%, Valid: 71.61% Test: 70.70%\n",
      "Epoch: 528, Loss: 1.3124, Train: 72.87%, Valid: 71.56% Test: 70.38%\n",
      "Epoch: 529, Loss: 1.3182, Train: 72.78%, Valid: 71.62% Test: 70.92%\n",
      "Epoch: 530, Loss: 1.3172, Train: 72.87%, Valid: 71.32% Test: 70.11%\n",
      "Epoch: 531, Loss: 1.3166, Train: 72.96%, Valid: 71.57% Test: 70.52%\n",
      "Epoch: 532, Loss: 1.3155, Train: 72.87%, Valid: 71.72% Test: 70.87%\n",
      "Epoch: 533, Loss: 1.3153, Train: 72.88%, Valid: 71.50% Test: 70.32%\n",
      "Epoch: 534, Loss: 1.3184, Train: 72.87%, Valid: 71.64% Test: 70.72%\n",
      "Epoch: 535, Loss: 1.3166, Train: 72.94%, Valid: 71.72% Test: 70.80%\n",
      "Epoch: 536, Loss: 1.3144, Train: 72.91%, Valid: 71.55% Test: 70.47%\n",
      "Epoch: 537, Loss: 1.3087, Train: 72.93%, Valid: 71.63% Test: 70.59%\n",
      "Epoch: 538, Loss: 1.3184, Train: 72.90%, Valid: 71.77% Test: 70.75%\n",
      "Epoch: 539, Loss: 1.3168, Train: 72.94%, Valid: 71.86% Test: 70.90%\n",
      "Epoch: 540, Loss: 1.3169, Train: 72.89%, Valid: 71.59% Test: 70.60%\n",
      "Epoch: 541, Loss: 1.3136, Train: 72.92%, Valid: 71.52% Test: 70.37%\n",
      "Epoch: 542, Loss: 1.3107, Train: 72.94%, Valid: 71.72% Test: 70.72%\n",
      "Epoch: 543, Loss: 1.3152, Train: 72.92%, Valid: 71.80% Test: 70.80%\n",
      "Epoch: 544, Loss: 1.3088, Train: 72.91%, Valid: 71.49% Test: 70.52%\n",
      "Epoch: 545, Loss: 1.3133, Train: 72.94%, Valid: 71.56% Test: 70.50%\n",
      "Epoch: 546, Loss: 1.3184, Train: 72.91%, Valid: 71.87% Test: 70.87%\n",
      "Epoch: 547, Loss: 1.3066, Train: 72.78%, Valid: 71.63% Test: 70.85%\n",
      "Epoch: 548, Loss: 1.3133, Train: 72.96%, Valid: 71.40% Test: 70.00%\n",
      "Epoch: 549, Loss: 1.3149, Train: 72.98%, Valid: 71.78% Test: 70.94%\n",
      "Epoch: 550, Loss: 1.3120, Train: 72.98%, Valid: 71.80% Test: 71.06%\n",
      "Epoch: 551, Loss: 1.3175, Train: 72.98%, Valid: 71.49% Test: 70.31%\n",
      "Epoch: 552, Loss: 1.3126, Train: 72.89%, Valid: 71.61% Test: 71.04%\n",
      "Epoch: 553, Loss: 1.3170, Train: 72.95%, Valid: 71.84% Test: 70.68%\n",
      "Epoch: 554, Loss: 1.3178, Train: 72.93%, Valid: 71.83% Test: 70.71%\n",
      "Epoch: 555, Loss: 1.3073, Train: 72.88%, Valid: 71.75% Test: 70.78%\n",
      "Epoch: 556, Loss: 1.3122, Train: 73.02%, Valid: 71.47% Test: 69.88%\n",
      "Epoch: 557, Loss: 1.3087, Train: 72.90%, Valid: 71.81% Test: 71.05%\n",
      "Epoch: 558, Loss: 1.3170, Train: 72.95%, Valid: 71.72% Test: 70.90%\n",
      "Epoch: 559, Loss: 1.3185, Train: 73.02%, Valid: 71.43% Test: 69.92%\n",
      "Epoch: 560, Loss: 1.3105, Train: 72.83%, Valid: 71.58% Test: 70.88%\n",
      "Epoch: 561, Loss: 1.3151, Train: 73.02%, Valid: 71.38% Test: 70.02%\n",
      "Epoch: 562, Loss: 1.3148, Train: 73.00%, Valid: 71.46% Test: 70.23%\n",
      "Epoch: 563, Loss: 1.3088, Train: 72.71%, Valid: 71.41% Test: 70.90%\n",
      "Epoch: 564, Loss: 1.3163, Train: 73.02%, Valid: 71.49% Test: 70.17%\n",
      "Epoch: 565, Loss: 1.3093, Train: 72.99%, Valid: 71.61% Test: 70.44%\n",
      "Epoch: 566, Loss: 1.3079, Train: 72.87%, Valid: 71.60% Test: 70.90%\n",
      "Epoch: 567, Loss: 1.3150, Train: 73.13%, Valid: 71.45% Test: 70.16%\n",
      "Epoch: 568, Loss: 1.3161, Train: 72.99%, Valid: 71.71% Test: 70.97%\n",
      "Epoch: 569, Loss: 1.3095, Train: 72.88%, Valid: 71.69% Test: 70.81%\n",
      "Epoch: 570, Loss: 1.3158, Train: 73.07%, Valid: 71.48% Test: 70.08%\n",
      "Epoch: 571, Loss: 1.3142, Train: 73.01%, Valid: 71.61% Test: 71.06%\n",
      "Epoch: 572, Loss: 1.3173, Train: 72.98%, Valid: 71.62% Test: 70.71%\n",
      "Epoch: 573, Loss: 1.3101, Train: 73.01%, Valid: 71.42% Test: 70.15%\n",
      "Epoch: 574, Loss: 1.3077, Train: 73.08%, Valid: 71.75% Test: 70.99%\n",
      "Epoch: 575, Loss: 1.3084, Train: 73.07%, Valid: 71.75% Test: 70.86%\n",
      "Epoch: 576, Loss: 1.3099, Train: 73.14%, Valid: 71.71% Test: 70.57%\n",
      "Epoch: 577, Loss: 1.3025, Train: 73.09%, Valid: 71.67% Test: 70.63%\n",
      "Epoch: 578, Loss: 1.3085, Train: 73.06%, Valid: 71.76% Test: 70.85%\n",
      "Epoch: 579, Loss: 1.3015, Train: 73.10%, Valid: 71.79% Test: 70.73%\n",
      "Epoch: 580, Loss: 1.3121, Train: 73.03%, Valid: 71.88% Test: 70.77%\n",
      "Epoch: 581, Loss: 1.3135, Train: 73.02%, Valid: 71.89% Test: 70.87%\n",
      "Epoch: 582, Loss: 1.3061, Train: 73.08%, Valid: 71.80% Test: 70.63%\n",
      "Epoch: 583, Loss: 1.3031, Train: 73.02%, Valid: 71.88% Test: 70.93%\n",
      "Epoch: 584, Loss: 1.3071, Train: 73.00%, Valid: 71.76% Test: 70.66%\n",
      "Epoch: 585, Loss: 1.3011, Train: 73.07%, Valid: 71.79% Test: 70.48%\n",
      "Epoch: 586, Loss: 1.3024, Train: 73.01%, Valid: 71.81% Test: 71.20%\n",
      "Epoch: 587, Loss: 1.3074, Train: 73.12%, Valid: 71.85% Test: 70.87%\n",
      "Epoch: 588, Loss: 1.3016, Train: 73.09%, Valid: 71.68% Test: 70.59%\n",
      "Epoch: 589, Loss: 1.3075, Train: 73.13%, Valid: 71.80% Test: 70.75%\n",
      "Epoch: 590, Loss: 1.3036, Train: 73.15%, Valid: 71.91% Test: 70.96%\n",
      "Epoch: 591, Loss: 1.3087, Train: 73.11%, Valid: 71.87% Test: 70.84%\n",
      "Epoch: 592, Loss: 1.3060, Train: 73.08%, Valid: 71.71% Test: 70.74%\n",
      "Epoch: 593, Loss: 1.3074, Train: 73.14%, Valid: 71.80% Test: 70.85%\n",
      "Epoch: 594, Loss: 1.3009, Train: 73.12%, Valid: 71.69% Test: 70.77%\n",
      "Epoch: 595, Loss: 1.3069, Train: 73.06%, Valid: 71.72% Test: 70.78%\n",
      "Epoch: 596, Loss: 1.3088, Train: 73.10%, Valid: 71.88% Test: 70.88%\n",
      "Epoch: 597, Loss: 1.3097, Train: 73.18%, Valid: 71.63% Test: 70.67%\n",
      "Epoch: 598, Loss: 1.3051, Train: 73.11%, Valid: 71.85% Test: 71.05%\n",
      "Epoch: 599, Loss: 1.3116, Train: 73.09%, Valid: 71.77% Test: 70.61%\n",
      "Epoch: 600, Loss: 1.3058, Train: 73.17%, Valid: 71.76% Test: 70.50%\n",
      "Epoch: 601, Loss: 1.3102, Train: 73.15%, Valid: 71.79% Test: 70.87%\n",
      "Epoch: 602, Loss: 1.3018, Train: 73.17%, Valid: 71.89% Test: 70.89%\n",
      "Epoch: 603, Loss: 1.3018, Train: 73.07%, Valid: 71.94% Test: 70.88%\n",
      "Epoch: 604, Loss: 1.3048, Train: 73.02%, Valid: 71.51% Test: 70.19%\n",
      "Epoch: 605, Loss: 1.3012, Train: 73.03%, Valid: 71.67% Test: 70.84%\n",
      "Epoch: 606, Loss: 1.3039, Train: 73.08%, Valid: 71.89% Test: 71.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 607, Loss: 1.3012, Train: 73.18%, Valid: 71.55% Test: 70.14%\n",
      "Epoch: 608, Loss: 1.3086, Train: 73.13%, Valid: 71.90% Test: 71.03%\n",
      "Epoch: 609, Loss: 1.3022, Train: 73.12%, Valid: 71.88% Test: 71.03%\n",
      "Epoch: 610, Loss: 1.3049, Train: 73.20%, Valid: 71.42% Test: 69.66%\n",
      "Epoch: 611, Loss: 1.3069, Train: 73.00%, Valid: 71.82% Test: 70.91%\n",
      "Epoch: 612, Loss: 1.3030, Train: 73.14%, Valid: 71.83% Test: 70.80%\n",
      "Epoch: 613, Loss: 1.3050, Train: 73.19%, Valid: 71.50% Test: 70.22%\n",
      "Epoch: 614, Loss: 1.3058, Train: 73.09%, Valid: 71.80% Test: 70.95%\n",
      "Epoch: 615, Loss: 1.3053, Train: 73.26%, Valid: 71.79% Test: 70.75%\n",
      "Epoch: 616, Loss: 1.3027, Train: 73.27%, Valid: 71.72% Test: 70.62%\n",
      "Epoch: 617, Loss: 1.3012, Train: 73.06%, Valid: 71.70% Test: 71.01%\n",
      "Epoch: 618, Loss: 1.3055, Train: 73.24%, Valid: 71.67% Test: 70.28%\n",
      "Epoch: 619, Loss: 1.3039, Train: 73.22%, Valid: 71.79% Test: 70.74%\n",
      "Epoch: 620, Loss: 1.2988, Train: 73.05%, Valid: 71.75% Test: 71.01%\n",
      "Epoch: 621, Loss: 1.3052, Train: 73.21%, Valid: 71.55% Test: 70.17%\n",
      "Epoch: 622, Loss: 1.3042, Train: 73.16%, Valid: 71.74% Test: 70.49%\n",
      "Epoch: 623, Loss: 1.3045, Train: 73.09%, Valid: 71.87% Test: 71.09%\n",
      "Epoch: 624, Loss: 1.3010, Train: 73.20%, Valid: 71.70% Test: 70.47%\n",
      "Epoch: 625, Loss: 1.2978, Train: 73.16%, Valid: 71.71% Test: 70.38%\n",
      "Epoch: 626, Loss: 1.3076, Train: 73.15%, Valid: 71.94% Test: 71.10%\n",
      "Epoch: 627, Loss: 1.3064, Train: 73.23%, Valid: 71.82% Test: 70.78%\n",
      "Epoch: 628, Loss: 1.3011, Train: 73.26%, Valid: 71.56% Test: 70.58%\n",
      "Epoch: 629, Loss: 1.3003, Train: 73.25%, Valid: 71.90% Test: 70.95%\n",
      "Epoch: 630, Loss: 1.3029, Train: 73.31%, Valid: 71.87% Test: 70.75%\n",
      "Epoch: 631, Loss: 1.3026, Train: 73.23%, Valid: 71.86% Test: 70.79%\n",
      "Epoch: 632, Loss: 1.3017, Train: 73.24%, Valid: 71.89% Test: 70.77%\n",
      "Epoch: 633, Loss: 1.2952, Train: 73.23%, Valid: 71.81% Test: 70.67%\n",
      "Epoch: 634, Loss: 1.3086, Train: 73.21%, Valid: 71.93% Test: 70.86%\n",
      "Epoch: 635, Loss: 1.3010, Train: 73.29%, Valid: 71.76% Test: 70.76%\n",
      "Epoch: 636, Loss: 1.3071, Train: 73.29%, Valid: 71.92% Test: 70.79%\n",
      "Epoch: 637, Loss: 1.3031, Train: 73.25%, Valid: 71.91% Test: 71.04%\n",
      "Epoch: 638, Loss: 1.2972, Train: 73.32%, Valid: 71.72% Test: 70.59%\n",
      "Epoch: 639, Loss: 1.3040, Train: 73.28%, Valid: 71.98% Test: 71.02%\n",
      "Epoch: 640, Loss: 1.3047, Train: 73.26%, Valid: 71.99% Test: 71.09%\n",
      "Epoch: 641, Loss: 1.3010, Train: 73.31%, Valid: 71.89% Test: 70.65%\n",
      "Epoch: 642, Loss: 1.3035, Train: 73.24%, Valid: 72.00% Test: 71.11%\n",
      "Epoch: 643, Loss: 1.3037, Train: 73.25%, Valid: 71.74% Test: 70.58%\n",
      "Epoch: 644, Loss: 1.3049, Train: 73.23%, Valid: 71.83% Test: 70.68%\n",
      "Epoch: 645, Loss: 1.3006, Train: 73.20%, Valid: 71.86% Test: 71.01%\n",
      "Epoch: 646, Loss: 1.3021, Train: 73.28%, Valid: 71.79% Test: 70.59%\n",
      "Epoch: 647, Loss: 1.2998, Train: 73.26%, Valid: 71.96% Test: 70.96%\n",
      "Epoch: 648, Loss: 1.2985, Train: 73.27%, Valid: 71.88% Test: 71.10%\n",
      "Epoch: 649, Loss: 1.3025, Train: 73.29%, Valid: 71.72% Test: 70.38%\n",
      "Epoch: 650, Loss: 1.3044, Train: 73.21%, Valid: 72.02% Test: 70.94%\n",
      "Epoch: 651, Loss: 1.3069, Train: 73.29%, Valid: 71.99% Test: 71.14%\n",
      "Epoch: 652, Loss: 1.3022, Train: 73.31%, Valid: 71.81% Test: 70.70%\n",
      "Epoch: 653, Loss: 1.2988, Train: 73.31%, Valid: 71.80% Test: 70.66%\n",
      "Epoch: 654, Loss: 1.2986, Train: 73.26%, Valid: 72.03% Test: 70.94%\n",
      "Epoch: 655, Loss: 1.2970, Train: 73.40%, Valid: 71.91% Test: 70.52%\n",
      "Epoch: 656, Loss: 1.2978, Train: 73.31%, Valid: 71.88% Test: 70.88%\n",
      "Epoch: 657, Loss: 1.2988, Train: 73.32%, Valid: 71.76% Test: 70.64%\n",
      "Epoch: 658, Loss: 1.2949, Train: 73.37%, Valid: 71.91% Test: 70.78%\n",
      "Epoch: 659, Loss: 1.2995, Train: 73.33%, Valid: 72.01% Test: 70.98%\n",
      "Epoch: 660, Loss: 1.3005, Train: 73.35%, Valid: 71.70% Test: 70.60%\n",
      "Epoch: 661, Loss: 1.3006, Train: 73.34%, Valid: 71.72% Test: 70.68%\n",
      "Epoch: 662, Loss: 1.2988, Train: 73.30%, Valid: 72.03% Test: 71.03%\n",
      "Epoch: 663, Loss: 1.2969, Train: 73.36%, Valid: 71.90% Test: 71.09%\n",
      "Epoch: 664, Loss: 1.3036, Train: 73.39%, Valid: 71.72% Test: 70.43%\n",
      "Epoch: 665, Loss: 1.2950, Train: 73.30%, Valid: 71.93% Test: 70.96%\n",
      "Epoch: 666, Loss: 1.3003, Train: 73.37%, Valid: 71.93% Test: 70.90%\n",
      "Epoch: 667, Loss: 1.2950, Train: 73.38%, Valid: 71.83% Test: 70.87%\n",
      "Epoch: 668, Loss: 1.2923, Train: 73.34%, Valid: 71.98% Test: 71.05%\n",
      "Epoch: 669, Loss: 1.2965, Train: 73.35%, Valid: 72.00% Test: 70.95%\n",
      "Epoch: 670, Loss: 1.3006, Train: 73.36%, Valid: 71.97% Test: 70.86%\n",
      "Epoch: 671, Loss: 1.2995, Train: 73.39%, Valid: 71.86% Test: 70.69%\n",
      "Epoch: 672, Loss: 1.2976, Train: 73.39%, Valid: 71.88% Test: 70.70%\n",
      "Epoch: 673, Loss: 1.2972, Train: 73.35%, Valid: 72.06% Test: 71.03%\n",
      "Epoch: 674, Loss: 1.2947, Train: 73.45%, Valid: 71.92% Test: 70.77%\n",
      "Epoch: 675, Loss: 1.2938, Train: 73.38%, Valid: 71.94% Test: 70.98%\n",
      "Epoch: 676, Loss: 1.3016, Train: 73.35%, Valid: 71.98% Test: 70.96%\n",
      "Epoch: 677, Loss: 1.2923, Train: 73.32%, Valid: 71.98% Test: 70.90%\n",
      "Epoch: 678, Loss: 1.2944, Train: 73.41%, Valid: 71.95% Test: 70.89%\n",
      "Epoch: 679, Loss: 1.3057, Train: 73.42%, Valid: 72.06% Test: 70.93%\n",
      "Epoch: 680, Loss: 1.2954, Train: 73.31%, Valid: 71.90% Test: 71.00%\n",
      "Epoch: 681, Loss: 1.3030, Train: 73.44%, Valid: 71.64% Test: 70.11%\n",
      "Epoch: 682, Loss: 1.2974, Train: 73.32%, Valid: 71.76% Test: 70.93%\n",
      "Epoch: 683, Loss: 1.2912, Train: 73.32%, Valid: 71.74% Test: 70.60%\n",
      "Epoch: 684, Loss: 1.2940, Train: 73.48%, Valid: 71.80% Test: 70.51%\n",
      "Epoch: 685, Loss: 1.2959, Train: 73.29%, Valid: 71.85% Test: 71.06%\n",
      "Epoch: 686, Loss: 1.3008, Train: 73.38%, Valid: 71.83% Test: 70.49%\n",
      "Epoch: 687, Loss: 1.2911, Train: 73.38%, Valid: 71.81% Test: 70.63%\n",
      "Epoch: 688, Loss: 1.2975, Train: 73.37%, Valid: 72.00% Test: 70.96%\n",
      "Epoch: 689, Loss: 1.2991, Train: 73.40%, Valid: 71.88% Test: 70.90%\n",
      "Epoch: 690, Loss: 1.2948, Train: 73.35%, Valid: 71.86% Test: 70.93%\n",
      "Epoch: 691, Loss: 1.2931, Train: 73.37%, Valid: 71.84% Test: 70.75%\n",
      "Epoch: 692, Loss: 1.2930, Train: 73.42%, Valid: 71.83% Test: 70.69%\n",
      "Epoch: 693, Loss: 1.2992, Train: 73.37%, Valid: 72.02% Test: 71.12%\n",
      "Epoch: 694, Loss: 1.2984, Train: 73.41%, Valid: 72.02% Test: 70.80%\n",
      "Epoch: 695, Loss: 1.2940, Train: 73.51%, Valid: 71.67% Test: 70.20%\n",
      "Epoch: 696, Loss: 1.2972, Train: 73.49%, Valid: 72.06% Test: 70.95%\n",
      "Epoch: 697, Loss: 1.2951, Train: 73.43%, Valid: 72.02% Test: 70.98%\n",
      "Epoch: 698, Loss: 1.3009, Train: 73.48%, Valid: 71.94% Test: 70.66%\n",
      "Epoch: 699, Loss: 1.2981, Train: 73.49%, Valid: 72.03% Test: 71.09%\n",
      "Epoch: 700, Loss: 1.2959, Train: 73.42%, Valid: 72.08% Test: 71.15%\n",
      "Epoch: 701, Loss: 1.2905, Train: 73.46%, Valid: 71.69% Test: 70.44%\n",
      "Epoch: 702, Loss: 1.2949, Train: 73.44%, Valid: 71.91% Test: 70.93%\n",
      "Epoch: 703, Loss: 1.2963, Train: 73.46%, Valid: 72.03% Test: 71.30%\n",
      "Epoch: 704, Loss: 1.2883, Train: 73.52%, Valid: 71.97% Test: 70.65%\n",
      "Epoch: 705, Loss: 1.2951, Train: 73.38%, Valid: 71.70% Test: 70.27%\n",
      "Epoch: 706, Loss: 1.2985, Train: 73.46%, Valid: 71.95% Test: 71.00%\n",
      "Epoch: 707, Loss: 1.2876, Train: 73.49%, Valid: 71.86% Test: 70.80%\n",
      "Epoch: 708, Loss: 1.2952, Train: 73.44%, Valid: 71.66% Test: 70.27%\n",
      "Epoch: 709, Loss: 1.2947, Train: 73.46%, Valid: 72.07% Test: 71.00%\n",
      "Epoch: 710, Loss: 1.2932, Train: 73.49%, Valid: 71.71% Test: 70.68%\n",
      "Epoch: 711, Loss: 1.2921, Train: 73.27%, Valid: 71.66% Test: 70.59%\n",
      "Epoch: 712, Loss: 1.2980, Train: 73.38%, Valid: 71.94% Test: 70.75%\n",
      "Epoch: 713, Loss: 1.2919, Train: 73.53%, Valid: 71.87% Test: 70.72%\n",
      "Epoch: 714, Loss: 1.2868, Train: 73.39%, Valid: 71.99% Test: 71.02%\n",
      "Epoch: 715, Loss: 1.2972, Train: 73.47%, Valid: 72.00% Test: 71.08%\n",
      "Epoch: 716, Loss: 1.2942, Train: 73.46%, Valid: 71.81% Test: 70.50%\n",
      "Epoch: 717, Loss: 1.2986, Train: 73.35%, Valid: 71.61% Test: 70.62%\n",
      "Epoch: 718, Loss: 1.2977, Train: 73.49%, Valid: 71.88% Test: 71.11%\n",
      "Epoch: 719, Loss: 1.2888, Train: 73.47%, Valid: 71.86% Test: 70.72%\n",
      "Epoch: 720, Loss: 1.2964, Train: 73.56%, Valid: 72.00% Test: 70.94%\n",
      "Epoch: 721, Loss: 1.2928, Train: 73.43%, Valid: 72.05% Test: 71.06%\n",
      "Epoch: 722, Loss: 1.2920, Train: 73.41%, Valid: 71.63% Test: 70.46%\n",
      "Epoch: 723, Loss: 1.3020, Train: 73.44%, Valid: 71.87% Test: 70.44%\n",
      "Epoch: 724, Loss: 1.2964, Train: 73.32%, Valid: 72.04% Test: 70.92%\n",
      "Epoch: 725, Loss: 1.2953, Train: 73.44%, Valid: 71.99% Test: 70.84%\n",
      "Epoch: 726, Loss: 1.2985, Train: 73.54%, Valid: 71.88% Test: 70.52%\n",
      "Epoch: 727, Loss: 1.2865, Train: 73.41%, Valid: 71.91% Test: 71.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 728, Loss: 1.2915, Train: 73.52%, Valid: 71.82% Test: 70.69%\n",
      "Epoch: 729, Loss: 1.2896, Train: 73.53%, Valid: 71.79% Test: 70.45%\n",
      "Epoch: 730, Loss: 1.2875, Train: 73.44%, Valid: 71.90% Test: 71.07%\n",
      "Epoch: 731, Loss: 1.2862, Train: 73.50%, Valid: 72.15% Test: 70.99%\n",
      "Epoch: 732, Loss: 1.2891, Train: 73.50%, Valid: 71.81% Test: 70.54%\n",
      "Epoch: 733, Loss: 1.2894, Train: 73.46%, Valid: 71.83% Test: 70.72%\n",
      "Epoch: 734, Loss: 1.2906, Train: 73.48%, Valid: 71.86% Test: 70.82%\n",
      "Epoch: 735, Loss: 1.2882, Train: 73.46%, Valid: 71.96% Test: 70.66%\n",
      "Epoch: 736, Loss: 1.2954, Train: 73.54%, Valid: 72.04% Test: 70.93%\n",
      "Epoch: 737, Loss: 1.2905, Train: 73.48%, Valid: 71.97% Test: 71.04%\n",
      "Epoch: 738, Loss: 1.2859, Train: 73.50%, Valid: 71.93% Test: 70.84%\n",
      "Epoch: 739, Loss: 1.2940, Train: 73.48%, Valid: 71.94% Test: 70.79%\n",
      "Epoch: 740, Loss: 1.2919, Train: 73.42%, Valid: 71.99% Test: 71.16%\n",
      "Epoch: 741, Loss: 1.2883, Train: 73.51%, Valid: 72.01% Test: 70.94%\n",
      "Epoch: 742, Loss: 1.2915, Train: 73.50%, Valid: 71.99% Test: 71.08%\n",
      "Epoch: 743, Loss: 1.2891, Train: 73.49%, Valid: 71.93% Test: 70.84%\n",
      "Epoch: 744, Loss: 1.2912, Train: 73.58%, Valid: 72.02% Test: 70.87%\n",
      "Epoch: 745, Loss: 1.2957, Train: 73.60%, Valid: 71.94% Test: 70.79%\n",
      "Epoch: 746, Loss: 1.2930, Train: 73.56%, Valid: 71.98% Test: 71.05%\n",
      "Epoch: 747, Loss: 1.2929, Train: 73.62%, Valid: 72.10% Test: 71.09%\n",
      "Epoch: 748, Loss: 1.2946, Train: 73.65%, Valid: 72.01% Test: 70.81%\n",
      "Epoch: 749, Loss: 1.2907, Train: 73.52%, Valid: 72.02% Test: 70.91%\n",
      "Epoch: 750, Loss: 1.2891, Train: 73.49%, Valid: 72.06% Test: 70.92%\n",
      "Epoch: 751, Loss: 1.2882, Train: 73.49%, Valid: 72.02% Test: 70.95%\n",
      "Epoch: 752, Loss: 1.2955, Train: 73.58%, Valid: 72.05% Test: 71.14%\n",
      "Epoch: 753, Loss: 1.2904, Train: 73.63%, Valid: 72.04% Test: 70.99%\n",
      "Epoch: 754, Loss: 1.2808, Train: 73.55%, Valid: 72.00% Test: 70.83%\n",
      "Epoch: 755, Loss: 1.2968, Train: 73.62%, Valid: 71.88% Test: 70.61%\n",
      "Epoch: 756, Loss: 1.2910, Train: 73.53%, Valid: 71.98% Test: 71.27%\n",
      "Epoch: 757, Loss: 1.2921, Train: 73.54%, Valid: 71.98% Test: 71.05%\n",
      "Epoch: 758, Loss: 1.2885, Train: 73.64%, Valid: 71.77% Test: 70.39%\n",
      "Epoch: 759, Loss: 1.2937, Train: 73.52%, Valid: 72.03% Test: 71.06%\n",
      "Epoch: 760, Loss: 1.2925, Train: 73.70%, Valid: 72.02% Test: 70.82%\n",
      "Epoch: 761, Loss: 1.2869, Train: 73.63%, Valid: 71.83% Test: 70.31%\n",
      "Epoch: 762, Loss: 1.2895, Train: 73.56%, Valid: 72.04% Test: 71.22%\n",
      "Epoch: 763, Loss: 1.2914, Train: 73.69%, Valid: 72.04% Test: 70.88%\n",
      "Epoch: 764, Loss: 1.2849, Train: 73.60%, Valid: 71.83% Test: 70.60%\n",
      "Epoch: 765, Loss: 1.2837, Train: 73.54%, Valid: 72.00% Test: 70.97%\n",
      "Epoch: 766, Loss: 1.2909, Train: 73.59%, Valid: 72.16% Test: 71.02%\n",
      "Epoch: 767, Loss: 1.2860, Train: 73.59%, Valid: 72.08% Test: 71.12%\n",
      "Epoch: 768, Loss: 1.2904, Train: 73.60%, Valid: 72.10% Test: 70.91%\n",
      "Epoch: 769, Loss: 1.2886, Train: 73.58%, Valid: 72.07% Test: 70.91%\n",
      "Epoch: 770, Loss: 1.2925, Train: 73.56%, Valid: 72.00% Test: 70.97%\n",
      "Epoch: 771, Loss: 1.2904, Train: 73.63%, Valid: 72.04% Test: 71.12%\n",
      "Epoch: 772, Loss: 1.2913, Train: 73.68%, Valid: 72.13% Test: 71.01%\n",
      "Epoch: 773, Loss: 1.2912, Train: 73.59%, Valid: 72.06% Test: 70.98%\n",
      "Epoch: 774, Loss: 1.2987, Train: 73.60%, Valid: 72.05% Test: 71.07%\n",
      "Epoch: 775, Loss: 1.2898, Train: 73.57%, Valid: 71.91% Test: 70.78%\n",
      "Epoch: 776, Loss: 1.2838, Train: 73.65%, Valid: 71.84% Test: 70.55%\n",
      "Epoch: 777, Loss: 1.2868, Train: 73.54%, Valid: 72.03% Test: 71.20%\n",
      "Epoch: 778, Loss: 1.2961, Train: 73.64%, Valid: 71.97% Test: 71.00%\n",
      "Epoch: 779, Loss: 1.2879, Train: 73.54%, Valid: 71.95% Test: 70.94%\n",
      "Epoch: 780, Loss: 1.2901, Train: 73.59%, Valid: 71.97% Test: 70.76%\n",
      "Epoch: 781, Loss: 1.2814, Train: 73.52%, Valid: 71.87% Test: 70.75%\n",
      "Epoch: 782, Loss: 1.2914, Train: 73.62%, Valid: 71.85% Test: 70.74%\n",
      "Epoch: 783, Loss: 1.2903, Train: 73.67%, Valid: 72.02% Test: 70.95%\n",
      "Epoch: 784, Loss: 1.2850, Train: 73.62%, Valid: 72.07% Test: 71.13%\n",
      "Epoch: 785, Loss: 1.2888, Train: 73.71%, Valid: 72.04% Test: 70.90%\n",
      "Epoch: 786, Loss: 1.2892, Train: 73.69%, Valid: 71.79% Test: 70.49%\n",
      "Epoch: 787, Loss: 1.2875, Train: 73.67%, Valid: 71.94% Test: 70.81%\n",
      "Epoch: 788, Loss: 1.2880, Train: 73.55%, Valid: 71.96% Test: 71.27%\n",
      "Epoch: 789, Loss: 1.2859, Train: 73.68%, Valid: 71.87% Test: 70.52%\n",
      "Epoch: 790, Loss: 1.2826, Train: 73.65%, Valid: 72.01% Test: 71.15%\n",
      "Epoch: 791, Loss: 1.2865, Train: 73.67%, Valid: 71.86% Test: 70.46%\n",
      "Epoch: 792, Loss: 1.2856, Train: 73.66%, Valid: 71.83% Test: 70.53%\n",
      "Epoch: 793, Loss: 1.2901, Train: 73.60%, Valid: 72.17% Test: 71.27%\n",
      "Epoch: 794, Loss: 1.2892, Train: 73.63%, Valid: 72.09% Test: 71.12%\n",
      "Epoch: 795, Loss: 1.2880, Train: 73.65%, Valid: 71.97% Test: 70.69%\n",
      "Epoch: 796, Loss: 1.2870, Train: 73.61%, Valid: 72.13% Test: 71.12%\n",
      "Epoch: 797, Loss: 1.2949, Train: 73.63%, Valid: 71.90% Test: 71.08%\n",
      "Epoch: 798, Loss: 1.2846, Train: 73.67%, Valid: 72.12% Test: 71.13%\n",
      "Epoch: 799, Loss: 1.2785, Train: 73.78%, Valid: 71.98% Test: 70.60%\n",
      "Epoch: 800, Loss: 1.2833, Train: 73.74%, Valid: 72.11% Test: 71.03%\n",
      "Epoch: 801, Loss: 1.2893, Train: 73.66%, Valid: 71.81% Test: 70.97%\n",
      "Epoch: 802, Loss: 1.2837, Train: 73.69%, Valid: 71.96% Test: 70.71%\n",
      "Epoch: 803, Loss: 1.2863, Train: 73.71%, Valid: 72.08% Test: 70.84%\n",
      "Epoch: 804, Loss: 1.2901, Train: 73.65%, Valid: 72.20% Test: 71.08%\n",
      "Epoch: 805, Loss: 1.2884, Train: 73.74%, Valid: 72.11% Test: 70.81%\n",
      "Epoch: 806, Loss: 1.2805, Train: 73.74%, Valid: 72.03% Test: 70.88%\n",
      "Epoch: 807, Loss: 1.2862, Train: 73.69%, Valid: 72.13% Test: 71.08%\n",
      "Epoch: 808, Loss: 1.2866, Train: 73.72%, Valid: 71.94% Test: 70.79%\n",
      "Epoch: 809, Loss: 1.2808, Train: 73.70%, Valid: 72.09% Test: 71.18%\n",
      "Epoch: 810, Loss: 1.2821, Train: 73.68%, Valid: 71.91% Test: 70.86%\n",
      "Epoch: 811, Loss: 1.2869, Train: 73.72%, Valid: 71.97% Test: 70.86%\n",
      "Epoch: 812, Loss: 1.2826, Train: 73.71%, Valid: 72.06% Test: 71.09%\n",
      "Epoch: 813, Loss: 1.2864, Train: 73.80%, Valid: 72.01% Test: 70.64%\n",
      "Epoch: 814, Loss: 1.2905, Train: 73.77%, Valid: 72.22% Test: 71.05%\n",
      "Epoch: 815, Loss: 1.2862, Train: 73.72%, Valid: 72.17% Test: 71.25%\n",
      "Epoch: 816, Loss: 1.2873, Train: 73.77%, Valid: 72.06% Test: 70.89%\n",
      "Epoch: 817, Loss: 1.2828, Train: 73.71%, Valid: 72.13% Test: 70.88%\n",
      "Epoch: 818, Loss: 1.2827, Train: 73.67%, Valid: 72.13% Test: 71.19%\n",
      "Epoch: 819, Loss: 1.2822, Train: 73.73%, Valid: 71.96% Test: 70.87%\n",
      "Epoch: 820, Loss: 1.2883, Train: 73.69%, Valid: 72.06% Test: 71.08%\n",
      "Epoch: 821, Loss: 1.2794, Train: 73.70%, Valid: 71.98% Test: 70.83%\n",
      "Epoch: 822, Loss: 1.2753, Train: 73.80%, Valid: 72.17% Test: 71.03%\n",
      "Epoch: 823, Loss: 1.2877, Train: 73.76%, Valid: 72.19% Test: 71.27%\n",
      "Epoch: 824, Loss: 1.2886, Train: 73.84%, Valid: 71.98% Test: 70.62%\n",
      "Epoch: 825, Loss: 1.2795, Train: 73.67%, Valid: 71.96% Test: 71.02%\n",
      "Epoch: 826, Loss: 1.2878, Train: 73.71%, Valid: 72.11% Test: 70.97%\n",
      "Epoch: 827, Loss: 1.2884, Train: 73.70%, Valid: 72.05% Test: 70.77%\n",
      "Epoch: 828, Loss: 1.2825, Train: 73.67%, Valid: 72.09% Test: 70.78%\n",
      "Epoch: 829, Loss: 1.2802, Train: 73.69%, Valid: 72.06% Test: 70.69%\n",
      "Epoch: 830, Loss: 1.2854, Train: 73.75%, Valid: 72.19% Test: 70.92%\n",
      "Epoch: 831, Loss: 1.2798, Train: 73.73%, Valid: 72.13% Test: 71.19%\n",
      "Epoch: 832, Loss: 1.2895, Train: 73.78%, Valid: 71.97% Test: 70.89%\n",
      "Epoch: 833, Loss: 1.2849, Train: 73.80%, Valid: 72.14% Test: 71.04%\n",
      "Epoch: 834, Loss: 1.2780, Train: 73.73%, Valid: 72.26% Test: 71.15%\n",
      "Epoch: 835, Loss: 1.2864, Train: 73.71%, Valid: 71.96% Test: 70.56%\n",
      "Epoch: 836, Loss: 1.2796, Train: 73.70%, Valid: 72.02% Test: 70.98%\n",
      "Epoch: 837, Loss: 1.2897, Train: 73.74%, Valid: 72.14% Test: 71.09%\n",
      "Epoch: 838, Loss: 1.2818, Train: 73.79%, Valid: 72.10% Test: 70.87%\n",
      "Epoch: 839, Loss: 1.2854, Train: 73.69%, Valid: 72.08% Test: 71.14%\n",
      "Epoch: 840, Loss: 1.2825, Train: 73.79%, Valid: 71.98% Test: 70.62%\n",
      "Epoch: 841, Loss: 1.2798, Train: 73.81%, Valid: 72.05% Test: 70.96%\n",
      "Epoch: 842, Loss: 1.2835, Train: 73.69%, Valid: 72.14% Test: 71.32%\n",
      "Epoch: 843, Loss: 1.2795, Train: 73.87%, Valid: 71.89% Test: 70.37%\n",
      "Epoch: 844, Loss: 1.2862, Train: 73.77%, Valid: 71.99% Test: 70.65%\n",
      "Epoch: 845, Loss: 1.2826, Train: 73.71%, Valid: 72.16% Test: 71.30%\n",
      "Epoch: 846, Loss: 1.2845, Train: 73.91%, Valid: 71.91% Test: 70.48%\n",
      "Epoch: 847, Loss: 1.2807, Train: 73.79%, Valid: 72.03% Test: 70.88%\n",
      "Epoch: 848, Loss: 1.2840, Train: 73.72%, Valid: 72.13% Test: 71.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 849, Loss: 1.2827, Train: 73.90%, Valid: 71.95% Test: 70.32%\n",
      "Epoch: 850, Loss: 1.2901, Train: 73.80%, Valid: 72.11% Test: 71.30%\n",
      "Epoch: 851, Loss: 1.2799, Train: 73.81%, Valid: 72.13% Test: 71.12%\n",
      "Epoch: 852, Loss: 1.2795, Train: 73.91%, Valid: 72.07% Test: 70.55%\n",
      "Epoch: 853, Loss: 1.2875, Train: 73.80%, Valid: 72.14% Test: 71.27%\n",
      "Epoch: 854, Loss: 1.2881, Train: 73.74%, Valid: 72.13% Test: 71.14%\n",
      "Epoch: 855, Loss: 1.2834, Train: 73.83%, Valid: 71.93% Test: 70.45%\n",
      "Epoch: 856, Loss: 1.2885, Train: 73.78%, Valid: 72.10% Test: 70.85%\n",
      "Epoch: 857, Loss: 1.2792, Train: 73.78%, Valid: 72.12% Test: 71.08%\n",
      "Epoch: 858, Loss: 1.2807, Train: 73.82%, Valid: 72.01% Test: 70.72%\n",
      "Epoch: 859, Loss: 1.2828, Train: 73.80%, Valid: 72.12% Test: 71.04%\n",
      "Epoch: 860, Loss: 1.2797, Train: 73.79%, Valid: 72.18% Test: 71.26%\n",
      "Epoch: 861, Loss: 1.2855, Train: 73.89%, Valid: 72.00% Test: 70.56%\n",
      "Epoch: 862, Loss: 1.2850, Train: 73.83%, Valid: 72.17% Test: 71.25%\n",
      "Epoch: 863, Loss: 1.2885, Train: 73.75%, Valid: 72.19% Test: 71.16%\n",
      "Epoch: 864, Loss: 1.2818, Train: 73.81%, Valid: 72.07% Test: 70.76%\n",
      "Epoch: 865, Loss: 1.2841, Train: 73.77%, Valid: 72.16% Test: 71.09%\n",
      "Epoch: 866, Loss: 1.2757, Train: 73.79%, Valid: 72.10% Test: 71.07%\n",
      "Epoch: 867, Loss: 1.2727, Train: 73.87%, Valid: 71.99% Test: 70.51%\n",
      "Epoch: 868, Loss: 1.2845, Train: 73.85%, Valid: 71.98% Test: 71.00%\n",
      "Epoch: 869, Loss: 1.2810, Train: 73.74%, Valid: 72.00% Test: 71.13%\n",
      "Epoch: 870, Loss: 1.2808, Train: 73.89%, Valid: 72.01% Test: 70.47%\n",
      "Epoch: 871, Loss: 1.2791, Train: 73.83%, Valid: 72.31% Test: 71.27%\n",
      "Epoch: 872, Loss: 1.2811, Train: 73.83%, Valid: 72.11% Test: 71.16%\n",
      "Epoch: 873, Loss: 1.2804, Train: 73.84%, Valid: 71.89% Test: 70.81%\n",
      "Epoch: 874, Loss: 1.2785, Train: 73.86%, Valid: 72.15% Test: 71.15%\n",
      "Epoch: 875, Loss: 1.2792, Train: 73.77%, Valid: 72.25% Test: 71.23%\n",
      "Epoch: 876, Loss: 1.2808, Train: 73.79%, Valid: 72.13% Test: 71.24%\n",
      "Epoch: 877, Loss: 1.2794, Train: 73.80%, Valid: 71.92% Test: 70.43%\n",
      "Epoch: 878, Loss: 1.2786, Train: 73.78%, Valid: 72.14% Test: 71.06%\n",
      "Epoch: 879, Loss: 1.2780, Train: 73.89%, Valid: 72.27% Test: 71.08%\n",
      "Epoch: 880, Loss: 1.2775, Train: 73.92%, Valid: 72.05% Test: 70.63%\n",
      "Epoch: 881, Loss: 1.2787, Train: 73.73%, Valid: 72.08% Test: 71.16%\n",
      "Epoch: 882, Loss: 1.2866, Train: 73.82%, Valid: 71.94% Test: 70.58%\n",
      "Epoch: 883, Loss: 1.2832, Train: 73.87%, Valid: 72.19% Test: 70.91%\n",
      "Epoch: 884, Loss: 1.2756, Train: 73.75%, Valid: 72.23% Test: 71.26%\n",
      "Epoch: 885, Loss: 1.2841, Train: 73.87%, Valid: 71.87% Test: 70.12%\n",
      "Epoch: 886, Loss: 1.2836, Train: 73.71%, Valid: 72.17% Test: 71.13%\n",
      "Epoch: 887, Loss: 1.2814, Train: 73.75%, Valid: 72.13% Test: 71.20%\n",
      "Epoch: 888, Loss: 1.2743, Train: 73.89%, Valid: 71.80% Test: 70.13%\n",
      "Epoch: 889, Loss: 1.2854, Train: 73.82%, Valid: 72.20% Test: 71.10%\n",
      "Epoch: 890, Loss: 1.2801, Train: 73.79%, Valid: 72.11% Test: 71.30%\n",
      "Epoch: 891, Loss: 1.2759, Train: 73.85%, Valid: 71.63% Test: 70.07%\n",
      "Epoch: 892, Loss: 1.2729, Train: 73.90%, Valid: 72.26% Test: 71.17%\n",
      "Epoch: 893, Loss: 1.2725, Train: 73.77%, Valid: 72.25% Test: 71.19%\n",
      "Epoch: 894, Loss: 1.2784, Train: 73.90%, Valid: 71.81% Test: 70.05%\n",
      "Epoch: 895, Loss: 1.2819, Train: 73.78%, Valid: 72.09% Test: 71.06%\n",
      "Epoch: 896, Loss: 1.2736, Train: 73.80%, Valid: 72.16% Test: 71.17%\n",
      "Epoch: 897, Loss: 1.2739, Train: 73.89%, Valid: 72.04% Test: 70.70%\n",
      "Epoch: 898, Loss: 1.2784, Train: 73.84%, Valid: 72.08% Test: 71.16%\n",
      "Epoch: 899, Loss: 1.2772, Train: 73.83%, Valid: 72.19% Test: 71.25%\n",
      "Epoch: 900, Loss: 1.2750, Train: 73.88%, Valid: 71.86% Test: 70.53%\n",
      "Epoch: 901, Loss: 1.2754, Train: 73.84%, Valid: 72.02% Test: 71.18%\n",
      "Epoch: 902, Loss: 1.2763, Train: 73.89%, Valid: 72.16% Test: 71.19%\n",
      "Epoch: 903, Loss: 1.2772, Train: 73.87%, Valid: 72.08% Test: 70.74%\n",
      "Epoch: 904, Loss: 1.2783, Train: 73.73%, Valid: 72.08% Test: 71.33%\n",
      "Epoch: 905, Loss: 1.2751, Train: 73.83%, Valid: 72.03% Test: 70.89%\n",
      "Epoch: 906, Loss: 1.2795, Train: 73.92%, Valid: 72.00% Test: 70.67%\n",
      "Epoch: 907, Loss: 1.2810, Train: 73.87%, Valid: 72.21% Test: 71.19%\n",
      "Epoch: 908, Loss: 1.2807, Train: 73.94%, Valid: 72.23% Test: 71.12%\n",
      "Epoch: 909, Loss: 1.2776, Train: 73.99%, Valid: 71.98% Test: 70.60%\n",
      "Epoch: 910, Loss: 1.2775, Train: 73.90%, Valid: 72.25% Test: 71.31%\n",
      "Epoch: 911, Loss: 1.2799, Train: 73.95%, Valid: 72.26% Test: 71.03%\n",
      "Epoch: 912, Loss: 1.2792, Train: 73.92%, Valid: 72.16% Test: 70.82%\n",
      "Epoch: 913, Loss: 1.2756, Train: 73.89%, Valid: 72.21% Test: 70.92%\n",
      "Epoch: 914, Loss: 1.2817, Train: 73.92%, Valid: 72.23% Test: 71.02%\n",
      "Epoch: 915, Loss: 1.2797, Train: 73.92%, Valid: 72.28% Test: 71.36%\n",
      "Epoch: 916, Loss: 1.2708, Train: 73.95%, Valid: 72.27% Test: 71.25%\n",
      "Epoch: 917, Loss: 1.2723, Train: 73.97%, Valid: 72.09% Test: 71.02%\n",
      "Epoch: 918, Loss: 1.2735, Train: 73.93%, Valid: 72.18% Test: 71.23%\n",
      "Epoch: 919, Loss: 1.2737, Train: 73.94%, Valid: 72.11% Test: 70.99%\n",
      "Epoch: 920, Loss: 1.2741, Train: 73.92%, Valid: 72.07% Test: 70.85%\n",
      "Epoch: 921, Loss: 1.2704, Train: 73.93%, Valid: 72.15% Test: 71.02%\n",
      "Epoch: 922, Loss: 1.2819, Train: 73.96%, Valid: 72.15% Test: 71.09%\n",
      "Epoch: 923, Loss: 1.2812, Train: 73.97%, Valid: 72.29% Test: 71.20%\n",
      "Epoch: 924, Loss: 1.2821, Train: 73.93%, Valid: 72.02% Test: 70.84%\n",
      "Epoch: 925, Loss: 1.2818, Train: 73.96%, Valid: 72.19% Test: 71.18%\n",
      "Epoch: 926, Loss: 1.2814, Train: 73.90%, Valid: 72.14% Test: 71.32%\n",
      "Epoch: 927, Loss: 1.2793, Train: 74.01%, Valid: 72.00% Test: 70.72%\n",
      "Epoch: 928, Loss: 1.2738, Train: 73.94%, Valid: 72.14% Test: 71.11%\n",
      "Epoch: 929, Loss: 1.2746, Train: 73.90%, Valid: 72.13% Test: 71.14%\n",
      "Epoch: 930, Loss: 1.2735, Train: 73.94%, Valid: 72.05% Test: 70.91%\n",
      "Epoch: 931, Loss: 1.2725, Train: 73.95%, Valid: 72.25% Test: 71.09%\n",
      "Epoch: 932, Loss: 1.2787, Train: 73.94%, Valid: 72.12% Test: 70.90%\n",
      "Epoch: 933, Loss: 1.2773, Train: 74.01%, Valid: 72.11% Test: 70.92%\n",
      "Epoch: 934, Loss: 1.2720, Train: 73.99%, Valid: 72.21% Test: 71.22%\n",
      "Epoch: 935, Loss: 1.2726, Train: 73.98%, Valid: 72.08% Test: 71.07%\n",
      "Epoch: 936, Loss: 1.2792, Train: 73.99%, Valid: 72.18% Test: 71.04%\n",
      "Epoch: 937, Loss: 1.2730, Train: 73.97%, Valid: 72.20% Test: 71.31%\n",
      "Epoch: 938, Loss: 1.2776, Train: 74.05%, Valid: 72.09% Test: 70.78%\n",
      "Epoch: 939, Loss: 1.2757, Train: 74.03%, Valid: 72.27% Test: 71.17%\n",
      "Epoch: 940, Loss: 1.2742, Train: 73.98%, Valid: 72.22% Test: 71.40%\n",
      "Epoch: 941, Loss: 1.2701, Train: 73.99%, Valid: 72.19% Test: 70.98%\n",
      "Epoch: 942, Loss: 1.2771, Train: 74.04%, Valid: 72.14% Test: 70.82%\n",
      "Epoch: 943, Loss: 1.2780, Train: 73.86%, Valid: 72.21% Test: 71.27%\n",
      "Epoch: 944, Loss: 1.2693, Train: 74.01%, Valid: 72.26% Test: 71.02%\n",
      "Epoch: 945, Loss: 1.2750, Train: 74.00%, Valid: 71.98% Test: 70.44%\n",
      "Epoch: 946, Loss: 1.2778, Train: 73.86%, Valid: 72.17% Test: 71.20%\n",
      "Epoch: 947, Loss: 1.2831, Train: 73.93%, Valid: 72.11% Test: 71.06%\n",
      "Epoch: 948, Loss: 1.2745, Train: 74.02%, Valid: 72.17% Test: 70.81%\n",
      "Epoch: 949, Loss: 1.2799, Train: 74.01%, Valid: 72.32% Test: 71.28%\n",
      "Epoch: 950, Loss: 1.2748, Train: 74.03%, Valid: 72.21% Test: 71.18%\n",
      "Epoch: 951, Loss: 1.2725, Train: 74.02%, Valid: 72.14% Test: 70.92%\n",
      "Epoch: 952, Loss: 1.2733, Train: 74.05%, Valid: 72.11% Test: 70.86%\n",
      "Epoch: 953, Loss: 1.2734, Train: 73.97%, Valid: 72.33% Test: 71.13%\n",
      "Epoch: 954, Loss: 1.2686, Train: 73.93%, Valid: 72.25% Test: 71.12%\n",
      "Epoch: 955, Loss: 1.2751, Train: 73.98%, Valid: 72.22% Test: 70.85%\n",
      "Epoch: 956, Loss: 1.2750, Train: 74.04%, Valid: 72.14% Test: 70.86%\n",
      "Epoch: 957, Loss: 1.2753, Train: 73.96%, Valid: 72.19% Test: 71.34%\n",
      "Epoch: 958, Loss: 1.2721, Train: 74.01%, Valid: 72.20% Test: 70.86%\n",
      "Epoch: 959, Loss: 1.2743, Train: 74.00%, Valid: 72.22% Test: 71.01%\n",
      "Epoch: 960, Loss: 1.2700, Train: 73.96%, Valid: 72.24% Test: 71.20%\n",
      "Epoch: 961, Loss: 1.2750, Train: 73.97%, Valid: 72.14% Test: 70.94%\n",
      "Epoch: 962, Loss: 1.2771, Train: 73.98%, Valid: 72.16% Test: 70.92%\n",
      "Epoch: 963, Loss: 1.2794, Train: 74.04%, Valid: 72.19% Test: 70.99%\n",
      "Epoch: 964, Loss: 1.2781, Train: 74.01%, Valid: 72.28% Test: 71.14%\n",
      "Epoch: 965, Loss: 1.2686, Train: 73.95%, Valid: 72.11% Test: 71.18%\n",
      "Epoch: 966, Loss: 1.2792, Train: 74.09%, Valid: 72.08% Test: 70.74%\n",
      "Epoch: 967, Loss: 1.2776, Train: 74.11%, Valid: 71.93% Test: 70.80%\n",
      "Epoch: 968, Loss: 1.2794, Train: 73.99%, Valid: 72.12% Test: 71.22%\n",
      "Epoch: 969, Loss: 1.2670, Train: 74.02%, Valid: 72.09% Test: 70.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 970, Loss: 1.2791, Train: 73.98%, Valid: 72.05% Test: 70.87%\n",
      "Epoch: 971, Loss: 1.2761, Train: 73.91%, Valid: 72.18% Test: 71.17%\n",
      "Epoch: 972, Loss: 1.2780, Train: 73.91%, Valid: 72.08% Test: 70.57%\n",
      "Epoch: 973, Loss: 1.2806, Train: 73.99%, Valid: 72.24% Test: 70.86%\n",
      "Epoch: 974, Loss: 1.2749, Train: 73.91%, Valid: 72.38% Test: 71.48%\n",
      "Epoch: 975, Loss: 1.2778, Train: 74.07%, Valid: 72.25% Test: 70.94%\n",
      "Epoch: 976, Loss: 1.2777, Train: 73.91%, Valid: 72.15% Test: 70.89%\n",
      "Epoch: 977, Loss: 1.2785, Train: 74.02%, Valid: 72.19% Test: 70.86%\n",
      "Epoch: 978, Loss: 1.2700, Train: 74.03%, Valid: 72.19% Test: 71.10%\n",
      "Epoch: 979, Loss: 1.2741, Train: 74.01%, Valid: 72.33% Test: 71.19%\n",
      "Epoch: 980, Loss: 1.2691, Train: 74.02%, Valid: 71.98% Test: 70.78%\n",
      "Epoch: 981, Loss: 1.2768, Train: 74.07%, Valid: 72.17% Test: 71.11%\n",
      "Epoch: 982, Loss: 1.2761, Train: 74.06%, Valid: 72.35% Test: 71.21%\n",
      "Epoch: 983, Loss: 1.2856, Train: 74.05%, Valid: 72.02% Test: 70.44%\n",
      "Epoch: 984, Loss: 1.2791, Train: 73.99%, Valid: 72.15% Test: 70.91%\n",
      "Epoch: 985, Loss: 1.2777, Train: 73.89%, Valid: 72.32% Test: 71.46%\n",
      "Epoch: 986, Loss: 1.2758, Train: 74.03%, Valid: 72.17% Test: 70.73%\n",
      "Epoch: 987, Loss: 1.2694, Train: 73.96%, Valid: 72.18% Test: 71.09%\n",
      "Epoch: 988, Loss: 1.2752, Train: 74.07%, Valid: 72.24% Test: 71.00%\n",
      "Epoch: 989, Loss: 1.2773, Train: 74.05%, Valid: 72.05% Test: 70.97%\n",
      "Epoch: 990, Loss: 1.2766, Train: 74.09%, Valid: 72.26% Test: 71.22%\n",
      "Epoch: 991, Loss: 1.2680, Train: 74.14%, Valid: 72.18% Test: 71.05%\n",
      "Epoch: 992, Loss: 1.2729, Train: 74.04%, Valid: 72.15% Test: 70.97%\n",
      "Epoch: 993, Loss: 1.2716, Train: 74.04%, Valid: 72.19% Test: 71.26%\n",
      "Epoch: 994, Loss: 1.2670, Train: 74.07%, Valid: 72.18% Test: 70.81%\n",
      "Epoch: 995, Loss: 1.2706, Train: 74.06%, Valid: 72.25% Test: 71.09%\n",
      "Epoch: 996, Loss: 1.2701, Train: 74.00%, Valid: 72.33% Test: 71.45%\n",
      "Epoch: 997, Loss: 1.2742, Train: 74.11%, Valid: 72.11% Test: 70.61%\n",
      "Epoch: 998, Loss: 1.2722, Train: 74.04%, Valid: 72.25% Test: 71.26%\n",
      "Epoch: 999, Loss: 1.2685, Train: 74.05%, Valid: 72.30% Test: 71.28%\n",
      "Epoch: 1000, Loss: 1.2758, Train: 74.10%, Valid: 72.36% Test: 71.11%\n",
      "Epoch: 1001, Loss: 1.2768, Train: 74.04%, Valid: 72.22% Test: 71.02%\n",
      "Epoch: 1002, Loss: 1.2709, Train: 74.11%, Valid: 72.15% Test: 71.08%\n",
      "Epoch: 1003, Loss: 1.2642, Train: 74.13%, Valid: 72.25% Test: 71.03%\n",
      "Epoch: 1004, Loss: 1.2692, Train: 74.13%, Valid: 72.20% Test: 71.39%\n",
      "Epoch: 1005, Loss: 1.2742, Train: 74.14%, Valid: 72.19% Test: 71.06%\n",
      "Epoch: 1006, Loss: 1.2690, Train: 74.10%, Valid: 72.16% Test: 70.95%\n",
      "Epoch: 1007, Loss: 1.2735, Train: 74.02%, Valid: 72.28% Test: 71.41%\n",
      "Epoch: 1008, Loss: 1.2706, Train: 74.10%, Valid: 72.21% Test: 70.90%\n",
      "Epoch: 1009, Loss: 1.2683, Train: 74.09%, Valid: 72.18% Test: 71.06%\n",
      "Epoch: 1010, Loss: 1.2752, Train: 74.00%, Valid: 72.32% Test: 71.31%\n",
      "Epoch: 1011, Loss: 1.2689, Train: 74.11%, Valid: 72.04% Test: 70.43%\n",
      "Epoch: 1012, Loss: 1.2725, Train: 74.07%, Valid: 72.15% Test: 70.90%\n",
      "Epoch: 1013, Loss: 1.2684, Train: 74.03%, Valid: 72.23% Test: 71.14%\n",
      "Epoch: 1014, Loss: 1.2653, Train: 74.11%, Valid: 72.19% Test: 70.96%\n",
      "Epoch: 1015, Loss: 1.2711, Train: 74.17%, Valid: 72.27% Test: 70.95%\n",
      "Epoch: 1016, Loss: 1.2679, Train: 74.16%, Valid: 72.22% Test: 71.09%\n",
      "Epoch: 1017, Loss: 1.2734, Train: 74.19%, Valid: 72.27% Test: 71.12%\n",
      "Epoch: 1018, Loss: 1.2747, Train: 74.14%, Valid: 72.30% Test: 71.08%\n",
      "Epoch: 1019, Loss: 1.2708, Train: 74.06%, Valid: 71.92% Test: 70.68%\n",
      "Epoch: 1020, Loss: 1.2747, Train: 74.11%, Valid: 72.06% Test: 70.89%\n",
      "Epoch: 1021, Loss: 1.2733, Train: 73.97%, Valid: 72.29% Test: 71.54%\n",
      "Epoch: 1022, Loss: 1.2705, Train: 74.10%, Valid: 72.30% Test: 70.98%\n",
      "Epoch: 1023, Loss: 1.2751, Train: 74.14%, Valid: 72.10% Test: 70.61%\n",
      "Epoch: 1024, Loss: 1.2644, Train: 73.98%, Valid: 72.25% Test: 71.28%\n",
      "Epoch: 1025, Loss: 1.2722, Train: 74.17%, Valid: 72.21% Test: 70.80%\n",
      "Epoch: 1026, Loss: 1.2739, Train: 74.12%, Valid: 72.20% Test: 70.99%\n",
      "Epoch: 1027, Loss: 1.2712, Train: 74.08%, Valid: 72.22% Test: 71.16%\n",
      "Epoch: 1028, Loss: 1.2704, Train: 74.22%, Valid: 72.16% Test: 70.88%\n",
      "Epoch: 1029, Loss: 1.2734, Train: 74.17%, Valid: 72.09% Test: 70.80%\n",
      "Epoch: 1030, Loss: 1.2743, Train: 74.13%, Valid: 72.17% Test: 71.10%\n",
      "Epoch: 1031, Loss: 1.2645, Train: 74.18%, Valid: 72.25% Test: 71.10%\n",
      "Epoch: 1032, Loss: 1.2720, Train: 74.16%, Valid: 72.22% Test: 71.00%\n",
      "Epoch: 1033, Loss: 1.2690, Train: 74.11%, Valid: 72.19% Test: 71.01%\n",
      "Epoch: 1034, Loss: 1.2777, Train: 74.13%, Valid: 72.13% Test: 70.70%\n",
      "Epoch: 1035, Loss: 1.2718, Train: 74.12%, Valid: 72.22% Test: 71.10%\n",
      "Epoch: 1036, Loss: 1.2708, Train: 74.20%, Valid: 72.39% Test: 71.32%\n",
      "Epoch: 1037, Loss: 1.2727, Train: 74.15%, Valid: 72.36% Test: 71.35%\n",
      "Epoch: 1038, Loss: 1.2741, Train: 74.08%, Valid: 72.16% Test: 71.05%\n",
      "Epoch: 1039, Loss: 1.2682, Train: 74.20%, Valid: 72.19% Test: 70.90%\n",
      "Epoch: 1040, Loss: 1.2661, Train: 74.12%, Valid: 72.18% Test: 71.06%\n",
      "Epoch: 1041, Loss: 1.2647, Train: 74.16%, Valid: 72.23% Test: 70.81%\n",
      "Epoch: 1042, Loss: 1.2635, Train: 74.22%, Valid: 72.24% Test: 70.85%\n",
      "Epoch: 1043, Loss: 1.2688, Train: 74.04%, Valid: 72.22% Test: 71.37%\n",
      "Epoch: 1044, Loss: 1.2649, Train: 74.22%, Valid: 72.25% Test: 70.90%\n",
      "Epoch: 1045, Loss: 1.2715, Train: 74.20%, Valid: 72.18% Test: 70.68%\n",
      "Epoch: 1046, Loss: 1.2657, Train: 74.06%, Valid: 72.29% Test: 71.24%\n",
      "Epoch: 1047, Loss: 1.2659, Train: 74.21%, Valid: 72.40% Test: 71.22%\n",
      "Epoch: 1048, Loss: 1.2739, Train: 74.20%, Valid: 72.26% Test: 71.08%\n",
      "Epoch: 1049, Loss: 1.2692, Train: 74.12%, Valid: 72.26% Test: 71.15%\n",
      "Epoch: 1050, Loss: 1.2725, Train: 74.22%, Valid: 72.20% Test: 70.86%\n",
      "Epoch: 1051, Loss: 1.2704, Train: 74.19%, Valid: 72.23% Test: 71.08%\n",
      "Epoch: 1052, Loss: 1.2638, Train: 74.14%, Valid: 72.28% Test: 71.19%\n",
      "Epoch: 1053, Loss: 1.2693, Train: 74.16%, Valid: 72.21% Test: 70.99%\n",
      "Epoch: 1054, Loss: 1.2691, Train: 74.20%, Valid: 72.35% Test: 71.11%\n",
      "Epoch: 1055, Loss: 1.2681, Train: 74.20%, Valid: 72.42% Test: 71.25%\n",
      "Epoch: 1056, Loss: 1.2698, Train: 74.16%, Valid: 72.20% Test: 70.85%\n",
      "Epoch: 1057, Loss: 1.2672, Train: 74.12%, Valid: 72.01% Test: 70.87%\n",
      "Epoch: 1058, Loss: 1.2663, Train: 74.20%, Valid: 72.36% Test: 71.24%\n",
      "Epoch: 1059, Loss: 1.2726, Train: 74.22%, Valid: 72.40% Test: 70.98%\n",
      "Epoch: 1060, Loss: 1.2664, Train: 74.22%, Valid: 72.13% Test: 70.87%\n",
      "Epoch: 1061, Loss: 1.2715, Train: 74.20%, Valid: 72.31% Test: 71.09%\n",
      "Epoch: 1062, Loss: 1.2692, Train: 74.14%, Valid: 72.28% Test: 71.12%\n",
      "Epoch: 1063, Loss: 1.2675, Train: 74.25%, Valid: 72.03% Test: 70.61%\n",
      "Epoch: 1064, Loss: 1.2651, Train: 74.22%, Valid: 72.23% Test: 71.18%\n",
      "Epoch: 1065, Loss: 1.2668, Train: 74.22%, Valid: 72.29% Test: 71.27%\n",
      "Epoch: 1066, Loss: 1.2650, Train: 74.31%, Valid: 72.03% Test: 70.63%\n",
      "Epoch: 1067, Loss: 1.2722, Train: 74.12%, Valid: 72.28% Test: 71.32%\n",
      "Epoch: 1068, Loss: 1.2673, Train: 74.18%, Valid: 72.24% Test: 70.91%\n",
      "Epoch: 1069, Loss: 1.2678, Train: 74.17%, Valid: 72.10% Test: 70.71%\n",
      "Epoch: 1070, Loss: 1.2705, Train: 74.12%, Valid: 72.20% Test: 70.89%\n",
      "Epoch: 1071, Loss: 1.2589, Train: 74.19%, Valid: 72.33% Test: 71.28%\n",
      "Epoch: 1072, Loss: 1.2710, Train: 74.23%, Valid: 72.40% Test: 71.33%\n",
      "Epoch: 1073, Loss: 1.2685, Train: 74.20%, Valid: 72.22% Test: 70.96%\n",
      "Epoch: 1074, Loss: 1.2701, Train: 74.25%, Valid: 72.26% Test: 70.87%\n",
      "Epoch: 1075, Loss: 1.2689, Train: 74.29%, Valid: 72.30% Test: 71.07%\n",
      "Epoch: 1076, Loss: 1.2676, Train: 74.19%, Valid: 72.24% Test: 71.27%\n",
      "Epoch: 1077, Loss: 1.2726, Train: 74.30%, Valid: 72.18% Test: 70.93%\n",
      "Epoch: 1078, Loss: 1.2674, Train: 74.17%, Valid: 72.18% Test: 71.11%\n",
      "Epoch: 1079, Loss: 1.2628, Train: 74.17%, Valid: 72.15% Test: 71.01%\n",
      "Epoch: 1080, Loss: 1.2679, Train: 74.24%, Valid: 72.24% Test: 70.99%\n",
      "Epoch: 1081, Loss: 1.2660, Train: 74.16%, Valid: 72.37% Test: 71.34%\n",
      "Epoch: 1082, Loss: 1.2658, Train: 74.19%, Valid: 72.14% Test: 70.81%\n",
      "Epoch: 1083, Loss: 1.2713, Train: 74.28%, Valid: 72.05% Test: 70.59%\n",
      "Epoch: 1084, Loss: 1.2677, Train: 74.14%, Valid: 72.12% Test: 71.25%\n",
      "Epoch: 1085, Loss: 1.2670, Train: 74.24%, Valid: 72.18% Test: 70.72%\n",
      "Epoch: 1086, Loss: 1.2680, Train: 74.25%, Valid: 72.20% Test: 70.93%\n",
      "Epoch: 1087, Loss: 1.2680, Train: 74.16%, Valid: 72.19% Test: 71.25%\n",
      "Epoch: 1088, Loss: 1.2710, Train: 74.35%, Valid: 72.36% Test: 70.96%\n",
      "Epoch: 1089, Loss: 1.2658, Train: 74.24%, Valid: 72.30% Test: 71.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1090, Loss: 1.2651, Train: 74.19%, Valid: 72.18% Test: 70.92%\n",
      "Epoch: 1091, Loss: 1.2754, Train: 74.22%, Valid: 72.30% Test: 71.00%\n",
      "Epoch: 1092, Loss: 1.2668, Train: 74.16%, Valid: 72.39% Test: 71.28%\n",
      "Epoch: 1093, Loss: 1.2669, Train: 74.22%, Valid: 72.29% Test: 71.16%\n",
      "Epoch: 1094, Loss: 1.2693, Train: 74.30%, Valid: 72.31% Test: 71.14%\n",
      "Epoch: 1095, Loss: 1.2676, Train: 74.14%, Valid: 72.26% Test: 71.20%\n",
      "Epoch: 1096, Loss: 1.2686, Train: 74.18%, Valid: 72.10% Test: 70.64%\n",
      "Epoch: 1097, Loss: 1.2767, Train: 74.27%, Valid: 72.38% Test: 71.11%\n",
      "Epoch: 1098, Loss: 1.2672, Train: 74.14%, Valid: 72.29% Test: 71.36%\n",
      "Epoch: 1099, Loss: 1.2747, Train: 74.23%, Valid: 72.16% Test: 70.74%\n",
      "Epoch: 1100, Loss: 1.2643, Train: 74.26%, Valid: 72.20% Test: 70.73%\n",
      "Epoch: 1101, Loss: 1.2682, Train: 74.27%, Valid: 72.51% Test: 71.50%\n",
      "Epoch: 1102, Loss: 1.2689, Train: 74.27%, Valid: 72.50% Test: 71.09%\n",
      "Epoch: 1103, Loss: 1.2638, Train: 74.26%, Valid: 72.22% Test: 70.80%\n",
      "Epoch: 1104, Loss: 1.2655, Train: 74.24%, Valid: 72.34% Test: 71.39%\n",
      "Epoch: 1105, Loss: 1.2658, Train: 74.29%, Valid: 72.11% Test: 70.99%\n",
      "Epoch: 1106, Loss: 1.2716, Train: 74.18%, Valid: 72.29% Test: 71.22%\n",
      "Epoch: 1107, Loss: 1.2629, Train: 74.15%, Valid: 72.35% Test: 71.21%\n",
      "Epoch: 1108, Loss: 1.2716, Train: 74.31%, Valid: 72.18% Test: 70.80%\n",
      "Epoch: 1109, Loss: 1.2677, Train: 74.22%, Valid: 72.51% Test: 71.38%\n",
      "Epoch: 1110, Loss: 1.2687, Train: 74.21%, Valid: 72.42% Test: 71.41%\n",
      "Epoch: 1111, Loss: 1.2657, Train: 74.33%, Valid: 72.20% Test: 70.60%\n",
      "Epoch: 1112, Loss: 1.2585, Train: 74.29%, Valid: 72.40% Test: 71.17%\n",
      "Epoch: 1113, Loss: 1.2710, Train: 74.30%, Valid: 72.42% Test: 71.20%\n",
      "Epoch: 1114, Loss: 1.2726, Train: 74.28%, Valid: 72.35% Test: 71.06%\n",
      "Epoch: 1115, Loss: 1.2650, Train: 74.28%, Valid: 72.38% Test: 71.19%\n",
      "Epoch: 1116, Loss: 1.2687, Train: 74.32%, Valid: 72.30% Test: 71.07%\n",
      "Epoch: 1117, Loss: 1.2660, Train: 74.29%, Valid: 72.29% Test: 71.00%\n",
      "Epoch: 1118, Loss: 1.2654, Train: 74.26%, Valid: 72.30% Test: 71.14%\n",
      "Epoch: 1119, Loss: 1.2614, Train: 74.31%, Valid: 72.32% Test: 71.33%\n",
      "Epoch: 1120, Loss: 1.2701, Train: 74.30%, Valid: 72.42% Test: 71.36%\n",
      "Epoch: 1121, Loss: 1.2649, Train: 74.24%, Valid: 72.31% Test: 71.17%\n",
      "Epoch: 1122, Loss: 1.2675, Train: 74.33%, Valid: 72.27% Test: 70.94%\n",
      "Epoch: 1123, Loss: 1.2719, Train: 74.31%, Valid: 72.33% Test: 71.11%\n",
      "Epoch: 1124, Loss: 1.2673, Train: 74.26%, Valid: 72.33% Test: 71.27%\n",
      "Epoch: 1125, Loss: 1.2613, Train: 74.32%, Valid: 72.22% Test: 70.89%\n",
      "Epoch: 1126, Loss: 1.2625, Train: 74.28%, Valid: 72.28% Test: 71.28%\n",
      "Epoch: 1127, Loss: 1.2602, Train: 74.33%, Valid: 72.08% Test: 70.88%\n",
      "Epoch: 1128, Loss: 1.2611, Train: 74.33%, Valid: 72.20% Test: 70.87%\n",
      "Epoch: 1129, Loss: 1.2648, Train: 74.35%, Valid: 72.34% Test: 71.22%\n",
      "Epoch: 1130, Loss: 1.2606, Train: 74.38%, Valid: 72.45% Test: 71.08%\n",
      "Epoch: 1131, Loss: 1.2703, Train: 74.32%, Valid: 72.31% Test: 71.27%\n",
      "Epoch: 1132, Loss: 1.2610, Train: 74.34%, Valid: 72.43% Test: 71.18%\n",
      "Epoch: 1133, Loss: 1.2596, Train: 74.38%, Valid: 72.24% Test: 71.05%\n",
      "Epoch: 1134, Loss: 1.2643, Train: 74.34%, Valid: 72.29% Test: 71.17%\n",
      "Epoch: 1135, Loss: 1.2626, Train: 74.36%, Valid: 72.22% Test: 70.99%\n",
      "Epoch: 1136, Loss: 1.2615, Train: 74.35%, Valid: 72.38% Test: 71.20%\n",
      "Epoch: 1137, Loss: 1.2645, Train: 74.29%, Valid: 72.35% Test: 71.38%\n",
      "Epoch: 1138, Loss: 1.2633, Train: 74.37%, Valid: 72.25% Test: 71.02%\n",
      "Epoch: 1139, Loss: 1.2717, Train: 74.40%, Valid: 72.33% Test: 71.15%\n",
      "Epoch: 1140, Loss: 1.2671, Train: 74.32%, Valid: 72.42% Test: 71.23%\n",
      "Epoch: 1141, Loss: 1.2604, Train: 74.33%, Valid: 72.25% Test: 71.04%\n",
      "Epoch: 1142, Loss: 1.2616, Train: 74.35%, Valid: 72.35% Test: 71.16%\n",
      "Epoch: 1143, Loss: 1.2643, Train: 74.34%, Valid: 72.39% Test: 71.45%\n",
      "Epoch: 1144, Loss: 1.2573, Train: 74.44%, Valid: 72.46% Test: 71.24%\n",
      "Epoch: 1145, Loss: 1.2642, Train: 74.35%, Valid: 72.40% Test: 71.21%\n",
      "Epoch: 1146, Loss: 1.2611, Train: 74.29%, Valid: 72.18% Test: 71.13%\n",
      "Epoch: 1147, Loss: 1.2697, Train: 74.42%, Valid: 72.17% Test: 70.67%\n",
      "Epoch: 1148, Loss: 1.2633, Train: 74.32%, Valid: 72.42% Test: 71.35%\n",
      "Epoch: 1149, Loss: 1.2657, Train: 74.27%, Valid: 72.45% Test: 71.34%\n",
      "Epoch: 1150, Loss: 1.2665, Train: 74.39%, Valid: 71.97% Test: 70.24%\n",
      "Epoch: 1151, Loss: 1.2669, Train: 74.21%, Valid: 72.30% Test: 71.27%\n",
      "Epoch: 1152, Loss: 1.2711, Train: 74.33%, Valid: 72.36% Test: 71.02%\n",
      "Epoch: 1153, Loss: 1.2586, Train: 74.41%, Valid: 72.29% Test: 70.91%\n",
      "Epoch: 1154, Loss: 1.2606, Train: 74.22%, Valid: 72.28% Test: 71.55%\n",
      "Epoch: 1155, Loss: 1.2655, Train: 74.45%, Valid: 72.16% Test: 70.46%\n",
      "Epoch: 1156, Loss: 1.2670, Train: 74.33%, Valid: 72.43% Test: 71.25%\n",
      "Epoch: 1157, Loss: 1.2638, Train: 74.28%, Valid: 72.35% Test: 71.49%\n",
      "Epoch: 1158, Loss: 1.2623, Train: 74.44%, Valid: 72.09% Test: 70.39%\n",
      "Epoch: 1159, Loss: 1.2684, Train: 74.35%, Valid: 72.38% Test: 71.27%\n",
      "Epoch: 1160, Loss: 1.2634, Train: 74.33%, Valid: 72.40% Test: 71.38%\n",
      "Epoch: 1161, Loss: 1.2589, Train: 74.43%, Valid: 72.09% Test: 70.42%\n",
      "Epoch: 1162, Loss: 1.2644, Train: 74.34%, Valid: 72.40% Test: 71.34%\n",
      "Epoch: 1163, Loss: 1.2650, Train: 74.36%, Valid: 72.41% Test: 71.21%\n",
      "Epoch: 1164, Loss: 1.2597, Train: 74.39%, Valid: 72.39% Test: 70.92%\n",
      "Epoch: 1165, Loss: 1.2656, Train: 74.35%, Valid: 72.44% Test: 71.40%\n",
      "Epoch: 1166, Loss: 1.2682, Train: 74.38%, Valid: 72.34% Test: 71.16%\n",
      "Epoch: 1167, Loss: 1.2581, Train: 74.31%, Valid: 72.28% Test: 70.94%\n",
      "Epoch: 1168, Loss: 1.2623, Train: 74.33%, Valid: 72.21% Test: 70.99%\n",
      "Epoch: 1169, Loss: 1.2571, Train: 74.36%, Valid: 72.37% Test: 71.10%\n",
      "Epoch: 1170, Loss: 1.2635, Train: 74.40%, Valid: 72.46% Test: 71.37%\n",
      "Epoch: 1171, Loss: 1.2606, Train: 74.38%, Valid: 72.33% Test: 71.46%\n",
      "Epoch: 1172, Loss: 1.2601, Train: 74.46%, Valid: 72.19% Test: 70.71%\n",
      "Epoch: 1173, Loss: 1.2625, Train: 74.34%, Valid: 72.33% Test: 71.25%\n",
      "Epoch: 1174, Loss: 1.2686, Train: 74.36%, Valid: 72.37% Test: 71.08%\n",
      "Epoch: 1175, Loss: 1.2578, Train: 74.42%, Valid: 72.23% Test: 70.61%\n",
      "Epoch: 1176, Loss: 1.2664, Train: 74.26%, Valid: 72.32% Test: 71.29%\n",
      "Epoch: 1177, Loss: 1.2645, Train: 74.42%, Valid: 72.34% Test: 70.94%\n",
      "Epoch: 1178, Loss: 1.2621, Train: 74.42%, Valid: 72.29% Test: 70.86%\n",
      "Epoch: 1179, Loss: 1.2614, Train: 74.23%, Valid: 72.19% Test: 71.28%\n",
      "Epoch: 1180, Loss: 1.2591, Train: 74.41%, Valid: 72.09% Test: 70.64%\n",
      "Epoch: 1181, Loss: 1.2633, Train: 74.43%, Valid: 72.27% Test: 70.96%\n",
      "Epoch: 1182, Loss: 1.2632, Train: 74.28%, Valid: 72.27% Test: 71.38%\n",
      "Epoch: 1183, Loss: 1.2673, Train: 74.49%, Valid: 72.12% Test: 70.73%\n",
      "Epoch: 1184, Loss: 1.2612, Train: 74.44%, Valid: 72.42% Test: 71.10%\n",
      "Epoch: 1185, Loss: 1.2620, Train: 74.25%, Valid: 72.29% Test: 71.49%\n",
      "Epoch: 1186, Loss: 1.2616, Train: 74.42%, Valid: 72.29% Test: 71.00%\n",
      "Epoch: 1187, Loss: 1.2584, Train: 74.39%, Valid: 72.37% Test: 71.00%\n",
      "Epoch: 1188, Loss: 1.2626, Train: 74.27%, Valid: 72.37% Test: 71.37%\n",
      "Epoch: 1189, Loss: 1.2631, Train: 74.40%, Valid: 72.34% Test: 71.02%\n",
      "Epoch: 1190, Loss: 1.2651, Train: 74.43%, Valid: 72.40% Test: 71.12%\n",
      "Epoch: 1191, Loss: 1.2567, Train: 74.24%, Valid: 72.45% Test: 71.44%\n",
      "Epoch: 1192, Loss: 1.2569, Train: 74.47%, Valid: 72.12% Test: 70.67%\n",
      "Epoch: 1193, Loss: 1.2612, Train: 74.49%, Valid: 72.35% Test: 71.04%\n",
      "Epoch: 1194, Loss: 1.2604, Train: 74.34%, Valid: 72.45% Test: 71.59%\n",
      "Epoch: 1195, Loss: 1.2625, Train: 74.47%, Valid: 72.28% Test: 70.92%\n",
      "Epoch: 1196, Loss: 1.2651, Train: 74.48%, Valid: 72.29% Test: 70.84%\n",
      "Epoch: 1197, Loss: 1.2662, Train: 74.30%, Valid: 72.31% Test: 71.49%\n",
      "Epoch: 1198, Loss: 1.2585, Train: 74.48%, Valid: 72.24% Test: 70.83%\n",
      "Epoch: 1199, Loss: 1.2574, Train: 74.41%, Valid: 72.31% Test: 70.93%\n",
      "Epoch: 1200, Loss: 1.2599, Train: 74.33%, Valid: 72.42% Test: 71.39%\n",
      "Epoch: 1201, Loss: 1.2636, Train: 74.43%, Valid: 72.38% Test: 71.00%\n",
      "Epoch: 1202, Loss: 1.2572, Train: 74.43%, Valid: 72.45% Test: 71.17%\n",
      "Epoch: 1203, Loss: 1.2608, Train: 74.48%, Valid: 72.43% Test: 71.23%\n",
      "Epoch: 1204, Loss: 1.2645, Train: 74.48%, Valid: 72.36% Test: 71.19%\n",
      "Epoch: 1205, Loss: 1.2627, Train: 74.42%, Valid: 72.40% Test: 71.08%\n",
      "Epoch: 1206, Loss: 1.2529, Train: 74.44%, Valid: 72.43% Test: 71.30%\n",
      "Epoch: 1207, Loss: 1.2636, Train: 74.41%, Valid: 72.50% Test: 71.34%\n",
      "Epoch: 1208, Loss: 1.2565, Train: 74.40%, Valid: 72.43% Test: 71.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1209, Loss: 1.2606, Train: 74.49%, Valid: 72.34% Test: 71.03%\n",
      "Epoch: 1210, Loss: 1.2601, Train: 74.48%, Valid: 72.33% Test: 70.92%\n",
      "Epoch: 1211, Loss: 1.2586, Train: 74.46%, Valid: 72.43% Test: 71.23%\n",
      "Epoch: 1212, Loss: 1.2608, Train: 74.39%, Valid: 72.38% Test: 71.21%\n",
      "Epoch: 1213, Loss: 1.2629, Train: 74.45%, Valid: 72.27% Test: 70.72%\n",
      "Epoch: 1214, Loss: 1.2609, Train: 74.33%, Valid: 72.34% Test: 71.24%\n",
      "Epoch: 1215, Loss: 1.2627, Train: 74.40%, Valid: 72.42% Test: 71.24%\n",
      "Epoch: 1216, Loss: 1.2638, Train: 74.49%, Valid: 72.38% Test: 70.90%\n",
      "Epoch: 1217, Loss: 1.2658, Train: 74.35%, Valid: 72.48% Test: 71.39%\n",
      "Epoch: 1218, Loss: 1.2605, Train: 74.46%, Valid: 72.40% Test: 71.14%\n",
      "Epoch: 1219, Loss: 1.2567, Train: 74.57%, Valid: 72.22% Test: 70.81%\n",
      "Epoch: 1220, Loss: 1.2617, Train: 74.41%, Valid: 72.48% Test: 71.53%\n",
      "Epoch: 1221, Loss: 1.2611, Train: 74.45%, Valid: 72.45% Test: 71.21%\n",
      "Epoch: 1222, Loss: 1.2582, Train: 74.44%, Valid: 72.27% Test: 70.87%\n",
      "Epoch: 1223, Loss: 1.2547, Train: 74.45%, Valid: 72.29% Test: 71.21%\n",
      "Epoch: 1224, Loss: 1.2565, Train: 74.47%, Valid: 72.41% Test: 71.29%\n",
      "Epoch: 1225, Loss: 1.2597, Train: 74.47%, Valid: 72.35% Test: 71.09%\n",
      "Epoch: 1226, Loss: 1.2605, Train: 74.47%, Valid: 72.60% Test: 71.48%\n",
      "Epoch: 1227, Loss: 1.2634, Train: 74.48%, Valid: 72.46% Test: 71.35%\n",
      "Epoch: 1228, Loss: 1.2642, Train: 74.45%, Valid: 72.30% Test: 70.94%\n",
      "Epoch: 1229, Loss: 1.2540, Train: 74.35%, Valid: 72.34% Test: 71.27%\n",
      "Epoch: 1230, Loss: 1.2629, Train: 74.44%, Valid: 72.52% Test: 71.31%\n",
      "Epoch: 1231, Loss: 1.2622, Train: 74.44%, Valid: 72.46% Test: 71.32%\n",
      "Epoch: 1232, Loss: 1.2549, Train: 74.30%, Valid: 72.37% Test: 71.18%\n",
      "Epoch: 1233, Loss: 1.2607, Train: 74.48%, Valid: 72.09% Test: 70.49%\n",
      "Epoch: 1234, Loss: 1.2579, Train: 74.49%, Valid: 72.46% Test: 71.42%\n",
      "Epoch: 1235, Loss: 1.2673, Train: 74.49%, Valid: 72.38% Test: 71.46%\n",
      "Epoch: 1236, Loss: 1.2586, Train: 74.49%, Valid: 72.12% Test: 70.61%\n",
      "Epoch: 1237, Loss: 1.2616, Train: 74.50%, Valid: 72.47% Test: 71.42%\n",
      "Epoch: 1238, Loss: 1.2602, Train: 74.43%, Valid: 72.50% Test: 71.67%\n",
      "Epoch: 1239, Loss: 1.2600, Train: 74.48%, Valid: 72.28% Test: 70.68%\n",
      "Epoch: 1240, Loss: 1.2627, Train: 74.38%, Valid: 72.00% Test: 70.37%\n",
      "Epoch: 1241, Loss: 1.2638, Train: 74.41%, Valid: 72.46% Test: 71.45%\n",
      "Epoch: 1242, Loss: 1.2641, Train: 74.56%, Valid: 72.54% Test: 71.37%\n",
      "Epoch: 1243, Loss: 1.2598, Train: 74.47%, Valid: 72.43% Test: 71.39%\n",
      "Epoch: 1244, Loss: 1.2567, Train: 74.44%, Valid: 72.41% Test: 71.07%\n",
      "Epoch: 1245, Loss: 1.2610, Train: 74.52%, Valid: 72.20% Test: 70.72%\n",
      "Epoch: 1246, Loss: 1.2633, Train: 74.36%, Valid: 72.31% Test: 71.26%\n",
      "Epoch: 1247, Loss: 1.2570, Train: 74.43%, Valid: 72.28% Test: 70.93%\n",
      "Epoch: 1248, Loss: 1.2588, Train: 74.49%, Valid: 72.41% Test: 71.04%\n",
      "Epoch: 1249, Loss: 1.2644, Train: 74.34%, Valid: 72.34% Test: 71.41%\n",
      "Epoch: 1250, Loss: 1.2598, Train: 74.53%, Valid: 72.22% Test: 70.50%\n",
      "Epoch: 1251, Loss: 1.2583, Train: 74.44%, Valid: 72.55% Test: 71.36%\n",
      "Epoch: 1252, Loss: 1.2607, Train: 74.33%, Valid: 72.32% Test: 71.35%\n",
      "Epoch: 1253, Loss: 1.2532, Train: 74.51%, Valid: 72.01% Test: 70.22%\n",
      "Epoch: 1254, Loss: 1.2632, Train: 74.56%, Valid: 72.53% Test: 71.27%\n",
      "Epoch: 1255, Loss: 1.2601, Train: 74.41%, Valid: 72.47% Test: 71.59%\n",
      "Epoch: 1256, Loss: 1.2609, Train: 74.54%, Valid: 72.22% Test: 70.59%\n",
      "Epoch: 1257, Loss: 1.2579, Train: 74.51%, Valid: 72.26% Test: 70.78%\n",
      "Epoch: 1258, Loss: 1.2586, Train: 74.33%, Valid: 72.20% Test: 71.30%\n",
      "Epoch: 1259, Loss: 1.2577, Train: 74.50%, Valid: 72.16% Test: 70.84%\n",
      "Epoch: 1260, Loss: 1.2608, Train: 74.51%, Valid: 72.18% Test: 70.76%\n",
      "Epoch: 1261, Loss: 1.2608, Train: 74.30%, Valid: 71.98% Test: 71.06%\n",
      "Epoch: 1262, Loss: 1.2581, Train: 74.53%, Valid: 72.12% Test: 70.81%\n",
      "Epoch: 1263, Loss: 1.2559, Train: 74.52%, Valid: 72.42% Test: 71.16%\n",
      "Epoch: 1264, Loss: 1.2568, Train: 74.36%, Valid: 72.24% Test: 71.25%\n",
      "Epoch: 1265, Loss: 1.2607, Train: 74.51%, Valid: 72.15% Test: 70.72%\n",
      "Epoch: 1266, Loss: 1.2606, Train: 74.48%, Valid: 72.35% Test: 71.12%\n",
      "Epoch: 1267, Loss: 1.2601, Train: 74.35%, Valid: 72.20% Test: 71.20%\n",
      "Epoch: 1268, Loss: 1.2663, Train: 74.50%, Valid: 72.24% Test: 70.75%\n",
      "Epoch: 1269, Loss: 1.2635, Train: 74.43%, Valid: 72.56% Test: 71.47%\n",
      "Epoch: 1270, Loss: 1.2551, Train: 74.37%, Valid: 72.30% Test: 71.18%\n",
      "Epoch: 1271, Loss: 1.2584, Train: 74.49%, Valid: 72.28% Test: 70.66%\n",
      "Epoch: 1272, Loss: 1.2564, Train: 74.43%, Valid: 72.45% Test: 71.13%\n",
      "Epoch: 1273, Loss: 1.2581, Train: 74.33%, Valid: 72.35% Test: 71.39%\n",
      "Epoch: 1274, Loss: 1.2600, Train: 74.55%, Valid: 72.14% Test: 70.71%\n",
      "Epoch: 1275, Loss: 1.2514, Train: 74.41%, Valid: 72.29% Test: 70.99%\n",
      "Epoch: 1276, Loss: 1.2622, Train: 74.38%, Valid: 72.44% Test: 71.42%\n",
      "Epoch: 1277, Loss: 1.2593, Train: 74.54%, Valid: 72.27% Test: 70.82%\n",
      "Epoch: 1278, Loss: 1.2579, Train: 74.40%, Valid: 72.34% Test: 71.22%\n",
      "Epoch: 1279, Loss: 1.2555, Train: 74.48%, Valid: 72.46% Test: 71.39%\n",
      "Epoch: 1280, Loss: 1.2656, Train: 74.59%, Valid: 72.41% Test: 70.98%\n",
      "Epoch: 1281, Loss: 1.2592, Train: 74.57%, Valid: 72.32% Test: 71.22%\n",
      "Epoch: 1282, Loss: 1.2594, Train: 74.50%, Valid: 72.44% Test: 71.53%\n",
      "Epoch: 1283, Loss: 1.2535, Train: 74.58%, Valid: 72.52% Test: 71.08%\n",
      "Epoch: 1284, Loss: 1.2597, Train: 74.52%, Valid: 72.50% Test: 71.23%\n",
      "Epoch: 1285, Loss: 1.2607, Train: 74.53%, Valid: 72.50% Test: 71.21%\n",
      "Epoch: 1286, Loss: 1.2537, Train: 74.52%, Valid: 72.39% Test: 71.05%\n",
      "Epoch: 1287, Loss: 1.2548, Train: 74.45%, Valid: 72.38% Test: 71.18%\n",
      "Epoch: 1288, Loss: 1.2589, Train: 74.50%, Valid: 72.44% Test: 71.19%\n",
      "Epoch: 1289, Loss: 1.2633, Train: 74.56%, Valid: 72.28% Test: 71.08%\n",
      "Epoch: 1290, Loss: 1.2611, Train: 74.54%, Valid: 72.40% Test: 71.06%\n",
      "Epoch: 1291, Loss: 1.2640, Train: 74.54%, Valid: 72.52% Test: 71.26%\n",
      "Epoch: 1292, Loss: 1.2581, Train: 74.55%, Valid: 72.47% Test: 71.14%\n",
      "Epoch: 1293, Loss: 1.2578, Train: 74.47%, Valid: 72.44% Test: 71.33%\n",
      "Epoch: 1294, Loss: 1.2655, Train: 74.50%, Valid: 72.38% Test: 71.23%\n",
      "Epoch: 1295, Loss: 1.2568, Train: 74.57%, Valid: 72.40% Test: 71.15%\n",
      "Epoch: 1296, Loss: 1.2572, Train: 74.51%, Valid: 72.41% Test: 71.36%\n",
      "Epoch: 1297, Loss: 1.2568, Train: 74.54%, Valid: 72.53% Test: 71.53%\n",
      "Epoch: 1298, Loss: 1.2591, Train: 74.62%, Valid: 72.52% Test: 71.29%\n",
      "Epoch: 1299, Loss: 1.2541, Train: 74.59%, Valid: 72.41% Test: 71.17%\n",
      "Epoch: 1300, Loss: 1.2538, Train: 74.55%, Valid: 72.33% Test: 70.82%\n",
      "Epoch: 1301, Loss: 1.2581, Train: 74.51%, Valid: 72.41% Test: 71.09%\n",
      "Epoch: 1302, Loss: 1.2561, Train: 74.44%, Valid: 72.55% Test: 71.45%\n",
      "Epoch: 1303, Loss: 1.2576, Train: 74.54%, Valid: 72.37% Test: 71.02%\n",
      "Epoch: 1304, Loss: 1.2507, Train: 74.50%, Valid: 72.46% Test: 71.16%\n",
      "Epoch: 1305, Loss: 1.2581, Train: 74.46%, Valid: 72.36% Test: 71.21%\n",
      "Epoch: 1306, Loss: 1.2574, Train: 74.57%, Valid: 72.35% Test: 70.82%\n",
      "Epoch: 1307, Loss: 1.2517, Train: 74.56%, Valid: 72.46% Test: 71.26%\n",
      "Epoch: 1308, Loss: 1.2559, Train: 74.49%, Valid: 72.44% Test: 71.32%\n",
      "Epoch: 1309, Loss: 1.2559, Train: 74.59%, Valid: 72.43% Test: 71.12%\n",
      "Epoch: 1310, Loss: 1.2567, Train: 74.58%, Valid: 72.39% Test: 71.20%\n",
      "Epoch: 1311, Loss: 1.2531, Train: 74.63%, Valid: 72.47% Test: 71.19%\n",
      "Epoch: 1312, Loss: 1.2603, Train: 74.49%, Valid: 72.45% Test: 71.23%\n",
      "Epoch: 1313, Loss: 1.2568, Train: 74.45%, Valid: 72.34% Test: 71.29%\n",
      "Epoch: 1314, Loss: 1.2566, Train: 74.52%, Valid: 72.42% Test: 71.20%\n",
      "Epoch: 1315, Loss: 1.2571, Train: 74.51%, Valid: 72.55% Test: 71.33%\n",
      "Epoch: 1316, Loss: 1.2553, Train: 74.54%, Valid: 72.56% Test: 71.25%\n",
      "Epoch: 1317, Loss: 1.2571, Train: 74.54%, Valid: 72.37% Test: 71.34%\n",
      "Epoch: 1318, Loss: 1.2541, Train: 74.56%, Valid: 72.41% Test: 71.03%\n",
      "Epoch: 1319, Loss: 1.2563, Train: 74.50%, Valid: 72.46% Test: 71.17%\n",
      "Epoch: 1320, Loss: 1.2545, Train: 74.48%, Valid: 72.44% Test: 71.15%\n",
      "Epoch: 1321, Loss: 1.2540, Train: 74.58%, Valid: 72.48% Test: 71.15%\n",
      "Epoch: 1322, Loss: 1.2525, Train: 74.61%, Valid: 72.45% Test: 71.09%\n",
      "Epoch: 1323, Loss: 1.2552, Train: 74.45%, Valid: 72.47% Test: 71.46%\n",
      "Epoch: 1324, Loss: 1.2592, Train: 74.61%, Valid: 72.43% Test: 71.07%\n",
      "Epoch: 1325, Loss: 1.2572, Train: 74.60%, Valid: 72.39% Test: 71.06%\n",
      "Epoch: 1326, Loss: 1.2598, Train: 74.41%, Valid: 72.44% Test: 71.57%\n",
      "Epoch: 1327, Loss: 1.2597, Train: 74.50%, Valid: 72.43% Test: 71.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1328, Loss: 1.2581, Train: 74.56%, Valid: 72.36% Test: 70.89%\n",
      "Epoch: 1329, Loss: 1.2490, Train: 74.46%, Valid: 72.53% Test: 71.64%\n",
      "Epoch: 1330, Loss: 1.2569, Train: 74.53%, Valid: 72.50% Test: 71.28%\n",
      "Epoch: 1331, Loss: 1.2550, Train: 74.56%, Valid: 72.12% Test: 70.57%\n",
      "Epoch: 1332, Loss: 1.2582, Train: 74.46%, Valid: 72.31% Test: 71.30%\n",
      "Epoch: 1333, Loss: 1.2537, Train: 74.65%, Valid: 72.45% Test: 71.01%\n",
      "Epoch: 1334, Loss: 1.2550, Train: 74.56%, Valid: 72.46% Test: 71.21%\n",
      "Epoch: 1335, Loss: 1.2523, Train: 74.53%, Valid: 72.55% Test: 71.34%\n",
      "Epoch: 1336, Loss: 1.2605, Train: 74.66%, Valid: 72.46% Test: 71.10%\n",
      "Epoch: 1337, Loss: 1.2581, Train: 74.56%, Valid: 72.43% Test: 71.07%\n",
      "Epoch: 1338, Loss: 1.2557, Train: 74.45%, Valid: 72.54% Test: 71.38%\n",
      "Epoch: 1339, Loss: 1.2564, Train: 74.61%, Valid: 72.39% Test: 71.07%\n",
      "Epoch: 1340, Loss: 1.2571, Train: 74.57%, Valid: 72.39% Test: 71.00%\n",
      "Epoch: 1341, Loss: 1.2553, Train: 74.47%, Valid: 72.38% Test: 71.44%\n",
      "Epoch: 1342, Loss: 1.2506, Train: 74.63%, Valid: 72.46% Test: 71.22%\n",
      "Epoch: 1343, Loss: 1.2510, Train: 74.70%, Valid: 72.48% Test: 71.17%\n",
      "Epoch: 1344, Loss: 1.2516, Train: 74.51%, Valid: 72.41% Test: 71.45%\n",
      "Epoch: 1345, Loss: 1.2559, Train: 74.69%, Valid: 72.47% Test: 71.08%\n",
      "Epoch: 1346, Loss: 1.2513, Train: 74.63%, Valid: 72.45% Test: 71.26%\n",
      "Epoch: 1347, Loss: 1.2598, Train: 74.53%, Valid: 72.36% Test: 71.29%\n",
      "Epoch: 1348, Loss: 1.2541, Train: 74.56%, Valid: 72.22% Test: 70.56%\n",
      "Epoch: 1349, Loss: 1.2544, Train: 74.58%, Valid: 72.57% Test: 71.41%\n",
      "Epoch: 1350, Loss: 1.2586, Train: 74.48%, Valid: 72.58% Test: 71.70%\n",
      "Epoch: 1351, Loss: 1.2532, Train: 74.69%, Valid: 72.36% Test: 71.02%\n",
      "Epoch: 1352, Loss: 1.2552, Train: 74.67%, Valid: 72.43% Test: 71.07%\n",
      "Epoch: 1353, Loss: 1.2573, Train: 74.63%, Valid: 72.53% Test: 71.36%\n",
      "Epoch: 1354, Loss: 1.2588, Train: 74.61%, Valid: 72.48% Test: 71.18%\n",
      "Epoch: 1355, Loss: 1.2509, Train: 74.54%, Valid: 72.46% Test: 71.23%\n",
      "Epoch: 1356, Loss: 1.2577, Train: 74.51%, Valid: 72.29% Test: 71.03%\n",
      "Epoch: 1357, Loss: 1.2522, Train: 74.54%, Valid: 72.45% Test: 71.23%\n",
      "Epoch: 1358, Loss: 1.2587, Train: 74.65%, Valid: 72.57% Test: 71.45%\n",
      "Epoch: 1359, Loss: 1.2544, Train: 74.64%, Valid: 72.54% Test: 71.13%\n",
      "Epoch: 1360, Loss: 1.2569, Train: 74.56%, Valid: 72.45% Test: 71.17%\n",
      "Epoch: 1361, Loss: 1.2499, Train: 74.54%, Valid: 72.44% Test: 71.36%\n",
      "Epoch: 1362, Loss: 1.2604, Train: 74.65%, Valid: 72.39% Test: 71.21%\n",
      "Epoch: 1363, Loss: 1.2550, Train: 74.66%, Valid: 72.52% Test: 71.44%\n",
      "Epoch: 1364, Loss: 1.2567, Train: 74.61%, Valid: 72.51% Test: 71.42%\n",
      "Epoch: 1365, Loss: 1.2511, Train: 74.64%, Valid: 72.36% Test: 71.13%\n",
      "Epoch: 1366, Loss: 1.2571, Train: 74.61%, Valid: 72.38% Test: 71.11%\n",
      "Epoch: 1367, Loss: 1.2587, Train: 74.54%, Valid: 72.43% Test: 71.28%\n",
      "Epoch: 1368, Loss: 1.2554, Train: 74.62%, Valid: 72.35% Test: 71.05%\n",
      "Epoch: 1369, Loss: 1.2560, Train: 74.64%, Valid: 72.36% Test: 71.29%\n",
      "Epoch: 1370, Loss: 1.2518, Train: 74.64%, Valid: 72.61% Test: 71.49%\n",
      "Epoch: 1371, Loss: 1.2549, Train: 74.63%, Valid: 72.62% Test: 71.37%\n",
      "Epoch: 1372, Loss: 1.2594, Train: 74.60%, Valid: 72.55% Test: 71.23%\n",
      "Epoch: 1373, Loss: 1.2567, Train: 74.58%, Valid: 72.37% Test: 71.10%\n",
      "Epoch: 1374, Loss: 1.2540, Train: 74.56%, Valid: 72.46% Test: 71.25%\n",
      "Epoch: 1375, Loss: 1.2560, Train: 74.66%, Valid: 72.49% Test: 71.38%\n",
      "Epoch: 1376, Loss: 1.2542, Train: 74.69%, Valid: 72.48% Test: 71.09%\n",
      "Epoch: 1377, Loss: 1.2549, Train: 74.64%, Valid: 72.53% Test: 71.29%\n",
      "Epoch: 1378, Loss: 1.2531, Train: 74.68%, Valid: 72.45% Test: 71.35%\n",
      "Epoch: 1379, Loss: 1.2517, Train: 74.73%, Valid: 72.40% Test: 70.97%\n",
      "Epoch: 1380, Loss: 1.2528, Train: 74.61%, Valid: 72.48% Test: 71.18%\n",
      "Epoch: 1381, Loss: 1.2480, Train: 74.55%, Valid: 72.47% Test: 71.34%\n",
      "Epoch: 1382, Loss: 1.2522, Train: 74.63%, Valid: 72.20% Test: 70.71%\n",
      "Epoch: 1383, Loss: 1.2595, Train: 74.59%, Valid: 72.30% Test: 71.16%\n",
      "Epoch: 1384, Loss: 1.2523, Train: 74.63%, Valid: 72.42% Test: 71.41%\n",
      "Epoch: 1385, Loss: 1.2494, Train: 74.73%, Valid: 72.43% Test: 71.18%\n",
      "Epoch: 1386, Loss: 1.2570, Train: 74.68%, Valid: 72.42% Test: 71.22%\n",
      "Epoch: 1387, Loss: 1.2498, Train: 74.59%, Valid: 72.38% Test: 71.30%\n",
      "Epoch: 1388, Loss: 1.2511, Train: 74.73%, Valid: 72.35% Test: 71.03%\n",
      "Epoch: 1389, Loss: 1.2582, Train: 74.61%, Valid: 72.54% Test: 71.29%\n",
      "Epoch: 1390, Loss: 1.2540, Train: 74.54%, Valid: 72.45% Test: 71.31%\n",
      "Epoch: 1391, Loss: 1.2511, Train: 74.67%, Valid: 72.34% Test: 70.81%\n",
      "Epoch: 1392, Loss: 1.2565, Train: 74.67%, Valid: 72.51% Test: 71.40%\n",
      "Epoch: 1393, Loss: 1.2534, Train: 74.51%, Valid: 72.39% Test: 71.34%\n",
      "Epoch: 1394, Loss: 1.2523, Train: 74.66%, Valid: 72.20% Test: 70.68%\n",
      "Epoch: 1395, Loss: 1.2611, Train: 74.68%, Valid: 72.38% Test: 71.21%\n",
      "Epoch: 1396, Loss: 1.2574, Train: 74.62%, Valid: 72.41% Test: 71.59%\n",
      "Epoch: 1397, Loss: 1.2601, Train: 74.69%, Valid: 72.25% Test: 70.84%\n",
      "Epoch: 1398, Loss: 1.2532, Train: 74.66%, Valid: 72.39% Test: 71.15%\n",
      "Epoch: 1399, Loss: 1.2557, Train: 74.71%, Valid: 72.51% Test: 71.58%\n",
      "Epoch: 1400, Loss: 1.2569, Train: 74.71%, Valid: 72.56% Test: 71.38%\n",
      "Epoch: 1401, Loss: 1.2532, Train: 74.64%, Valid: 72.51% Test: 71.22%\n",
      "Epoch: 1402, Loss: 1.2512, Train: 74.67%, Valid: 72.36% Test: 70.97%\n",
      "Epoch: 1403, Loss: 1.2516, Train: 74.74%, Valid: 72.52% Test: 71.34%\n",
      "Epoch: 1404, Loss: 1.2548, Train: 74.76%, Valid: 72.57% Test: 71.53%\n",
      "Epoch: 1405, Loss: 1.2551, Train: 74.69%, Valid: 72.60% Test: 71.39%\n",
      "Epoch: 1406, Loss: 1.2452, Train: 74.70%, Valid: 72.47% Test: 71.18%\n",
      "Epoch: 1407, Loss: 1.2466, Train: 74.70%, Valid: 72.36% Test: 70.95%\n",
      "Epoch: 1408, Loss: 1.2539, Train: 74.66%, Valid: 72.52% Test: 71.45%\n",
      "Epoch: 1409, Loss: 1.2555, Train: 74.63%, Valid: 72.59% Test: 71.27%\n",
      "Epoch: 1410, Loss: 1.2599, Train: 74.67%, Valid: 72.38% Test: 71.02%\n",
      "Epoch: 1411, Loss: 1.2567, Train: 74.68%, Valid: 72.63% Test: 71.43%\n",
      "Epoch: 1412, Loss: 1.2545, Train: 74.77%, Valid: 72.38% Test: 70.99%\n",
      "Epoch: 1413, Loss: 1.2499, Train: 74.67%, Valid: 72.48% Test: 71.22%\n",
      "Epoch: 1414, Loss: 1.2548, Train: 74.64%, Valid: 72.43% Test: 71.15%\n",
      "Epoch: 1415, Loss: 1.2476, Train: 74.64%, Valid: 72.44% Test: 71.40%\n",
      "Epoch: 1416, Loss: 1.2516, Train: 74.74%, Valid: 72.37% Test: 71.11%\n",
      "Epoch: 1417, Loss: 1.2576, Train: 74.70%, Valid: 72.41% Test: 71.10%\n",
      "Epoch: 1418, Loss: 1.2521, Train: 74.63%, Valid: 72.53% Test: 71.58%\n",
      "Epoch: 1419, Loss: 1.2556, Train: 74.70%, Valid: 72.55% Test: 71.46%\n",
      "Epoch: 1420, Loss: 1.2556, Train: 74.78%, Valid: 72.41% Test: 71.01%\n",
      "Epoch: 1421, Loss: 1.2544, Train: 74.66%, Valid: 72.35% Test: 71.41%\n",
      "Epoch: 1422, Loss: 1.2521, Train: 74.72%, Valid: 72.26% Test: 70.88%\n",
      "Epoch: 1423, Loss: 1.2511, Train: 74.73%, Valid: 72.42% Test: 71.09%\n",
      "Epoch: 1424, Loss: 1.2555, Train: 74.65%, Valid: 72.51% Test: 71.53%\n",
      "Epoch: 1425, Loss: 1.2532, Train: 74.69%, Valid: 72.37% Test: 71.08%\n",
      "Epoch: 1426, Loss: 1.2541, Train: 74.63%, Valid: 72.48% Test: 71.38%\n",
      "Epoch: 1427, Loss: 1.2577, Train: 74.71%, Valid: 72.56% Test: 71.34%\n",
      "Epoch: 1428, Loss: 1.2517, Train: 74.70%, Valid: 72.53% Test: 71.19%\n",
      "Epoch: 1429, Loss: 1.2511, Train: 74.61%, Valid: 72.40% Test: 71.21%\n",
      "Epoch: 1430, Loss: 1.2512, Train: 74.72%, Valid: 72.43% Test: 71.14%\n",
      "Epoch: 1431, Loss: 1.2530, Train: 74.73%, Valid: 72.49% Test: 71.16%\n",
      "Epoch: 1432, Loss: 1.2499, Train: 74.63%, Valid: 72.56% Test: 71.29%\n",
      "Epoch: 1433, Loss: 1.2517, Train: 74.64%, Valid: 72.41% Test: 71.11%\n",
      "Epoch: 1434, Loss: 1.2498, Train: 74.71%, Valid: 72.40% Test: 71.09%\n",
      "Epoch: 1435, Loss: 1.2530, Train: 74.65%, Valid: 72.56% Test: 71.35%\n",
      "Epoch: 1436, Loss: 1.2587, Train: 74.67%, Valid: 72.46% Test: 71.31%\n",
      "Epoch: 1437, Loss: 1.2499, Train: 74.58%, Valid: 72.48% Test: 71.21%\n",
      "Epoch: 1438, Loss: 1.2545, Train: 74.74%, Valid: 72.32% Test: 70.99%\n",
      "Epoch: 1439, Loss: 1.2538, Train: 74.65%, Valid: 72.59% Test: 71.58%\n",
      "Epoch: 1440, Loss: 1.2550, Train: 74.65%, Valid: 72.54% Test: 71.36%\n",
      "Epoch: 1441, Loss: 1.2510, Train: 74.76%, Valid: 72.41% Test: 71.06%\n",
      "Epoch: 1442, Loss: 1.2503, Train: 74.76%, Valid: 72.44% Test: 71.21%\n",
      "Epoch: 1443, Loss: 1.2479, Train: 74.67%, Valid: 72.42% Test: 71.32%\n",
      "Epoch: 1444, Loss: 1.2603, Train: 74.72%, Valid: 72.33% Test: 70.92%\n",
      "Epoch: 1445, Loss: 1.2571, Train: 74.76%, Valid: 72.34% Test: 71.16%\n",
      "Epoch: 1446, Loss: 1.2511, Train: 74.73%, Valid: 72.66% Test: 71.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1447, Loss: 1.2602, Train: 74.66%, Valid: 72.57% Test: 71.39%\n",
      "Epoch: 1448, Loss: 1.2526, Train: 74.61%, Valid: 72.28% Test: 70.87%\n",
      "Epoch: 1449, Loss: 1.2539, Train: 74.66%, Valid: 72.34% Test: 71.00%\n",
      "Epoch: 1450, Loss: 1.2554, Train: 74.65%, Valid: 72.60% Test: 71.80%\n",
      "Epoch: 1451, Loss: 1.2514, Train: 74.72%, Valid: 72.60% Test: 71.28%\n",
      "Epoch: 1452, Loss: 1.2521, Train: 74.71%, Valid: 72.36% Test: 70.96%\n",
      "Epoch: 1453, Loss: 1.2513, Train: 74.68%, Valid: 72.50% Test: 71.31%\n",
      "Epoch: 1454, Loss: 1.2492, Train: 74.65%, Valid: 72.45% Test: 71.50%\n",
      "Epoch: 1455, Loss: 1.2495, Train: 74.77%, Valid: 72.43% Test: 71.07%\n",
      "Epoch: 1456, Loss: 1.2469, Train: 74.80%, Valid: 72.50% Test: 71.11%\n",
      "Epoch: 1457, Loss: 1.2540, Train: 74.75%, Valid: 72.62% Test: 71.60%\n",
      "Epoch: 1458, Loss: 1.2511, Train: 74.65%, Valid: 72.55% Test: 71.58%\n",
      "Epoch: 1459, Loss: 1.2511, Train: 74.79%, Valid: 72.28% Test: 70.65%\n",
      "Epoch: 1460, Loss: 1.2503, Train: 74.69%, Valid: 72.57% Test: 71.21%\n",
      "Epoch: 1461, Loss: 1.2512, Train: 74.64%, Valid: 72.53% Test: 71.59%\n",
      "Epoch: 1462, Loss: 1.2488, Train: 74.76%, Valid: 72.32% Test: 70.80%\n",
      "Epoch: 1463, Loss: 1.2547, Train: 74.63%, Valid: 72.38% Test: 71.18%\n",
      "Epoch: 1464, Loss: 1.2436, Train: 74.74%, Valid: 72.32% Test: 71.19%\n",
      "Epoch: 1465, Loss: 1.2487, Train: 74.74%, Valid: 72.26% Test: 70.91%\n",
      "Epoch: 1466, Loss: 1.2590, Train: 74.69%, Valid: 72.54% Test: 71.52%\n",
      "Epoch: 1467, Loss: 1.2514, Train: 74.66%, Valid: 72.45% Test: 71.29%\n",
      "Epoch: 1468, Loss: 1.2520, Train: 74.80%, Valid: 72.34% Test: 71.06%\n",
      "Epoch: 1469, Loss: 1.2535, Train: 74.77%, Valid: 72.47% Test: 71.25%\n",
      "Epoch: 1470, Loss: 1.2547, Train: 74.68%, Valid: 72.35% Test: 71.32%\n",
      "Epoch: 1471, Loss: 1.2466, Train: 74.72%, Valid: 72.45% Test: 71.18%\n",
      "Epoch: 1472, Loss: 1.2488, Train: 74.76%, Valid: 72.65% Test: 71.53%\n",
      "Epoch: 1473, Loss: 1.2598, Train: 74.71%, Valid: 72.54% Test: 71.70%\n",
      "Epoch: 1474, Loss: 1.2463, Train: 74.67%, Valid: 72.32% Test: 70.96%\n",
      "Epoch: 1475, Loss: 1.2527, Train: 74.73%, Valid: 72.37% Test: 70.87%\n",
      "Epoch: 1476, Loss: 1.2502, Train: 74.74%, Valid: 72.58% Test: 71.46%\n",
      "Epoch: 1477, Loss: 1.2452, Train: 74.71%, Valid: 72.60% Test: 71.68%\n",
      "Epoch: 1478, Loss: 1.2523, Train: 74.85%, Valid: 72.34% Test: 70.94%\n",
      "Epoch: 1479, Loss: 1.2517, Train: 74.79%, Valid: 72.35% Test: 71.08%\n",
      "Epoch: 1480, Loss: 1.2552, Train: 74.80%, Valid: 72.49% Test: 71.29%\n",
      "Epoch: 1481, Loss: 1.2522, Train: 74.80%, Valid: 72.60% Test: 71.31%\n",
      "Epoch: 1482, Loss: 1.2549, Train: 74.72%, Valid: 72.41% Test: 71.28%\n",
      "Epoch: 1483, Loss: 1.2507, Train: 74.84%, Valid: 72.36% Test: 71.06%\n",
      "Epoch: 1484, Loss: 1.2495, Train: 74.82%, Valid: 72.54% Test: 71.25%\n",
      "Epoch: 1485, Loss: 1.2518, Train: 74.60%, Valid: 72.52% Test: 71.49%\n",
      "Epoch: 1486, Loss: 1.2533, Train: 74.66%, Valid: 72.32% Test: 70.76%\n",
      "Epoch: 1487, Loss: 1.2511, Train: 74.78%, Valid: 72.43% Test: 71.12%\n",
      "Epoch: 1488, Loss: 1.2448, Train: 74.70%, Valid: 72.53% Test: 71.49%\n",
      "Epoch: 1489, Loss: 1.2563, Train: 74.76%, Valid: 72.40% Test: 70.70%\n",
      "Epoch: 1490, Loss: 1.2548, Train: 74.78%, Valid: 72.53% Test: 71.34%\n",
      "Epoch: 1491, Loss: 1.2484, Train: 74.61%, Valid: 72.50% Test: 71.48%\n",
      "Epoch: 1492, Loss: 1.2586, Train: 74.82%, Valid: 72.23% Test: 70.57%\n",
      "Epoch: 1493, Loss: 1.2558, Train: 74.75%, Valid: 72.49% Test: 71.39%\n",
      "Epoch: 1494, Loss: 1.2526, Train: 74.72%, Valid: 72.49% Test: 71.42%\n",
      "Epoch: 1495, Loss: 1.2476, Train: 74.87%, Valid: 72.24% Test: 70.58%\n",
      "Epoch: 1496, Loss: 1.2532, Train: 74.68%, Valid: 72.55% Test: 71.74%\n",
      "Epoch: 1497, Loss: 1.2516, Train: 74.67%, Valid: 72.34% Test: 71.45%\n",
      "Epoch: 1498, Loss: 1.2488, Train: 74.80%, Valid: 72.00% Test: 70.43%\n",
      "Epoch: 1499, Loss: 1.2554, Train: 74.69%, Valid: 72.51% Test: 71.64%\n",
      "Epoch: 1500, Loss: 1.2503, Train: 74.59%, Valid: 72.52% Test: 71.69%\n",
      "Epoch: 1501, Loss: 1.2495, Train: 74.75%, Valid: 72.20% Test: 70.16%\n",
      "Epoch: 1502, Loss: 1.2560, Train: 74.74%, Valid: 72.54% Test: 71.16%\n",
      "Epoch: 1503, Loss: 1.2486, Train: 74.60%, Valid: 72.49% Test: 71.74%\n",
      "Epoch: 1504, Loss: 1.2501, Train: 74.81%, Valid: 72.29% Test: 70.71%\n",
      "Epoch: 1505, Loss: 1.2529, Train: 74.78%, Valid: 72.35% Test: 70.87%\n",
      "Epoch: 1506, Loss: 1.2499, Train: 74.62%, Valid: 72.41% Test: 71.51%\n",
      "Epoch: 1507, Loss: 1.2513, Train: 74.86%, Valid: 72.41% Test: 71.06%\n",
      "Epoch: 1508, Loss: 1.2538, Train: 74.86%, Valid: 72.23% Test: 70.72%\n",
      "Epoch: 1509, Loss: 1.2491, Train: 74.67%, Valid: 72.34% Test: 71.59%\n",
      "Epoch: 1510, Loss: 1.2515, Train: 74.80%, Valid: 72.56% Test: 71.17%\n",
      "Epoch: 1511, Loss: 1.2528, Train: 74.69%, Valid: 72.45% Test: 71.00%\n",
      "Epoch: 1512, Loss: 1.2532, Train: 74.54%, Valid: 72.47% Test: 71.31%\n",
      "Epoch: 1513, Loss: 1.2526, Train: 74.71%, Valid: 72.32% Test: 70.94%\n",
      "Epoch: 1514, Loss: 1.2531, Train: 74.76%, Valid: 72.49% Test: 71.01%\n",
      "Epoch: 1515, Loss: 1.2530, Train: 74.71%, Valid: 72.58% Test: 71.63%\n",
      "Epoch: 1516, Loss: 1.2489, Train: 74.81%, Valid: 72.50% Test: 71.53%\n",
      "Epoch: 1517, Loss: 1.2479, Train: 74.88%, Valid: 72.56% Test: 71.40%\n",
      "Epoch: 1518, Loss: 1.2553, Train: 74.75%, Valid: 72.56% Test: 71.33%\n",
      "Epoch: 1519, Loss: 1.2517, Train: 74.79%, Valid: 72.34% Test: 71.26%\n",
      "Epoch: 1520, Loss: 1.2529, Train: 74.79%, Valid: 72.42% Test: 71.13%\n",
      "Epoch: 1521, Loss: 1.2531, Train: 74.82%, Valid: 72.52% Test: 71.31%\n",
      "Epoch: 1522, Loss: 1.2499, Train: 74.65%, Valid: 72.46% Test: 71.27%\n",
      "Epoch: 1523, Loss: 1.2481, Train: 74.81%, Valid: 72.40% Test: 71.10%\n",
      "Epoch: 1524, Loss: 1.2517, Train: 74.84%, Valid: 72.61% Test: 71.39%\n",
      "Epoch: 1525, Loss: 1.2535, Train: 74.68%, Valid: 72.61% Test: 71.51%\n",
      "Epoch: 1526, Loss: 1.2459, Train: 74.78%, Valid: 72.33% Test: 71.08%\n",
      "Epoch: 1527, Loss: 1.2504, Train: 74.77%, Valid: 72.38% Test: 71.10%\n",
      "Epoch: 1528, Loss: 1.2456, Train: 74.70%, Valid: 72.42% Test: 71.50%\n",
      "Epoch: 1529, Loss: 1.2538, Train: 74.81%, Valid: 72.54% Test: 71.17%\n",
      "Epoch: 1530, Loss: 1.2470, Train: 74.90%, Valid: 72.38% Test: 70.97%\n",
      "Epoch: 1531, Loss: 1.2448, Train: 74.68%, Valid: 72.48% Test: 71.65%\n",
      "Epoch: 1532, Loss: 1.2508, Train: 74.81%, Valid: 72.61% Test: 71.19%\n",
      "Epoch: 1533, Loss: 1.2543, Train: 74.76%, Valid: 72.47% Test: 71.10%\n",
      "Epoch: 1534, Loss: 1.2412, Train: 74.70%, Valid: 72.43% Test: 71.48%\n",
      "Epoch: 1535, Loss: 1.2462, Train: 74.82%, Valid: 72.51% Test: 71.16%\n",
      "Epoch: 1536, Loss: 1.2522, Train: 74.83%, Valid: 72.31% Test: 70.89%\n",
      "Epoch: 1537, Loss: 1.2488, Train: 74.77%, Valid: 72.60% Test: 71.34%\n",
      "Epoch: 1538, Loss: 1.2495, Train: 74.81%, Valid: 72.65% Test: 71.39%\n",
      "Epoch: 1539, Loss: 1.2518, Train: 74.79%, Valid: 72.49% Test: 71.31%\n",
      "Epoch: 1540, Loss: 1.2530, Train: 74.77%, Valid: 72.34% Test: 71.15%\n",
      "Epoch: 1541, Loss: 1.2498, Train: 74.74%, Valid: 72.30% Test: 71.10%\n",
      "Epoch: 1542, Loss: 1.2459, Train: 74.76%, Valid: 72.59% Test: 71.41%\n",
      "Epoch: 1543, Loss: 1.2498, Train: 74.75%, Valid: 72.63% Test: 71.47%\n",
      "Epoch: 1544, Loss: 1.2535, Train: 74.83%, Valid: 72.48% Test: 71.07%\n",
      "Epoch: 1545, Loss: 1.2499, Train: 74.82%, Valid: 72.33% Test: 71.06%\n",
      "Epoch: 1546, Loss: 1.2475, Train: 74.84%, Valid: 72.53% Test: 71.44%\n",
      "Epoch: 1547, Loss: 1.2454, Train: 74.73%, Valid: 72.54% Test: 71.57%\n",
      "Epoch: 1548, Loss: 1.2532, Train: 74.88%, Valid: 72.41% Test: 70.90%\n",
      "Epoch: 1549, Loss: 1.2481, Train: 74.80%, Valid: 72.50% Test: 71.24%\n",
      "Epoch: 1550, Loss: 1.2518, Train: 74.66%, Valid: 72.48% Test: 71.59%\n",
      "Epoch: 1551, Loss: 1.2473, Train: 74.84%, Valid: 72.59% Test: 71.17%\n",
      "Epoch: 1552, Loss: 1.2437, Train: 74.85%, Valid: 72.36% Test: 70.87%\n",
      "Epoch: 1553, Loss: 1.2456, Train: 74.79%, Valid: 72.46% Test: 71.43%\n",
      "Epoch: 1554, Loss: 1.2475, Train: 74.83%, Valid: 72.50% Test: 71.38%\n",
      "Epoch: 1555, Loss: 1.2495, Train: 74.96%, Valid: 72.32% Test: 71.00%\n",
      "Epoch: 1556, Loss: 1.2474, Train: 74.78%, Valid: 72.60% Test: 71.40%\n",
      "Epoch: 1557, Loss: 1.2477, Train: 74.92%, Valid: 72.54% Test: 71.29%\n",
      "Epoch: 1558, Loss: 1.2471, Train: 74.92%, Valid: 72.40% Test: 71.16%\n",
      "Epoch: 1559, Loss: 1.2531, Train: 74.76%, Valid: 72.59% Test: 71.61%\n",
      "Epoch: 1560, Loss: 1.2497, Train: 74.80%, Valid: 72.43% Test: 71.06%\n",
      "Epoch: 1561, Loss: 1.2589, Train: 74.79%, Valid: 72.34% Test: 70.88%\n",
      "Epoch: 1562, Loss: 1.2564, Train: 74.82%, Valid: 72.50% Test: 71.48%\n",
      "Epoch: 1563, Loss: 1.2471, Train: 74.85%, Valid: 72.63% Test: 71.62%\n",
      "Epoch: 1564, Loss: 1.2507, Train: 74.96%, Valid: 72.54% Test: 71.23%\n",
      "Epoch: 1565, Loss: 1.2500, Train: 74.91%, Valid: 72.53% Test: 71.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1566, Loss: 1.2511, Train: 74.74%, Valid: 72.37% Test: 71.19%\n",
      "Epoch: 1567, Loss: 1.2459, Train: 74.83%, Valid: 72.35% Test: 70.79%\n",
      "Epoch: 1568, Loss: 1.2464, Train: 74.77%, Valid: 72.51% Test: 71.34%\n",
      "Epoch: 1569, Loss: 1.2505, Train: 74.88%, Valid: 72.52% Test: 71.31%\n",
      "Epoch: 1570, Loss: 1.2456, Train: 74.87%, Valid: 72.53% Test: 71.47%\n",
      "Epoch: 1571, Loss: 1.2452, Train: 74.83%, Valid: 72.52% Test: 71.41%\n",
      "Epoch: 1572, Loss: 1.2445, Train: 74.89%, Valid: 72.43% Test: 71.14%\n",
      "Epoch: 1573, Loss: 1.2484, Train: 74.86%, Valid: 72.57% Test: 71.27%\n",
      "Epoch: 1574, Loss: 1.2465, Train: 74.83%, Valid: 72.56% Test: 71.29%\n",
      "Epoch: 1575, Loss: 1.2448, Train: 74.89%, Valid: 72.50% Test: 71.27%\n",
      "Epoch: 1576, Loss: 1.2412, Train: 74.99%, Valid: 72.43% Test: 71.06%\n",
      "Epoch: 1577, Loss: 1.2483, Train: 74.90%, Valid: 72.65% Test: 71.31%\n",
      "Epoch: 1578, Loss: 1.2491, Train: 74.84%, Valid: 72.50% Test: 71.27%\n",
      "Epoch: 1579, Loss: 1.2530, Train: 74.95%, Valid: 72.59% Test: 71.25%\n",
      "Epoch: 1580, Loss: 1.2471, Train: 74.99%, Valid: 72.65% Test: 71.46%\n",
      "Epoch: 1581, Loss: 1.2495, Train: 74.93%, Valid: 72.68% Test: 71.54%\n",
      "Epoch: 1582, Loss: 1.2438, Train: 74.89%, Valid: 72.44% Test: 71.13%\n",
      "Epoch: 1583, Loss: 1.2533, Train: 74.91%, Valid: 72.52% Test: 71.27%\n",
      "Epoch: 1584, Loss: 1.2447, Train: 74.83%, Valid: 72.55% Test: 71.50%\n",
      "Epoch: 1585, Loss: 1.2484, Train: 74.89%, Valid: 72.53% Test: 71.21%\n",
      "Epoch: 1586, Loss: 1.2476, Train: 74.89%, Valid: 72.44% Test: 71.08%\n",
      "Epoch: 1587, Loss: 1.2404, Train: 74.81%, Valid: 72.40% Test: 71.42%\n",
      "Epoch: 1588, Loss: 1.2493, Train: 74.81%, Valid: 72.32% Test: 71.12%\n",
      "Epoch: 1589, Loss: 1.2487, Train: 74.82%, Valid: 72.41% Test: 71.06%\n",
      "Epoch: 1590, Loss: 1.2441, Train: 74.84%, Valid: 72.56% Test: 71.46%\n",
      "Epoch: 1591, Loss: 1.2483, Train: 74.91%, Valid: 72.71% Test: 71.15%\n",
      "Epoch: 1592, Loss: 1.2562, Train: 74.84%, Valid: 72.61% Test: 71.30%\n",
      "Epoch: 1593, Loss: 1.2548, Train: 74.85%, Valid: 72.53% Test: 71.28%\n",
      "Epoch: 1594, Loss: 1.2519, Train: 74.92%, Valid: 72.46% Test: 70.98%\n",
      "Epoch: 1595, Loss: 1.2448, Train: 74.91%, Valid: 72.72% Test: 71.64%\n",
      "Epoch: 1596, Loss: 1.2470, Train: 74.87%, Valid: 72.53% Test: 71.56%\n",
      "Epoch: 1597, Loss: 1.2477, Train: 74.93%, Valid: 72.34% Test: 71.10%\n",
      "Epoch: 1598, Loss: 1.2455, Train: 74.83%, Valid: 72.47% Test: 71.47%\n",
      "Epoch: 1599, Loss: 1.2471, Train: 74.98%, Valid: 72.58% Test: 71.34%\n",
      "Epoch: 1600, Loss: 1.2494, Train: 74.99%, Valid: 72.51% Test: 71.14%\n",
      "Epoch: 1601, Loss: 1.2483, Train: 74.88%, Valid: 72.47% Test: 71.09%\n",
      "Epoch: 1602, Loss: 1.2456, Train: 74.85%, Valid: 72.53% Test: 71.28%\n",
      "Epoch: 1603, Loss: 1.2521, Train: 74.82%, Valid: 72.46% Test: 71.31%\n",
      "Epoch: 1604, Loss: 1.2454, Train: 74.87%, Valid: 72.44% Test: 70.90%\n",
      "Epoch: 1605, Loss: 1.2438, Train: 74.89%, Valid: 72.46% Test: 71.36%\n",
      "Epoch: 1606, Loss: 1.2448, Train: 74.86%, Valid: 72.50% Test: 71.40%\n",
      "Epoch: 1607, Loss: 1.2435, Train: 74.97%, Valid: 72.41% Test: 71.12%\n",
      "Epoch: 1608, Loss: 1.2455, Train: 74.91%, Valid: 72.61% Test: 71.20%\n",
      "Epoch: 1609, Loss: 1.2484, Train: 74.85%, Valid: 72.45% Test: 71.47%\n",
      "Epoch: 1610, Loss: 1.2511, Train: 74.89%, Valid: 72.34% Test: 71.09%\n",
      "Epoch: 1611, Loss: 1.2440, Train: 74.91%, Valid: 72.43% Test: 71.14%\n",
      "Epoch: 1612, Loss: 1.2427, Train: 74.91%, Valid: 72.70% Test: 71.43%\n",
      "Epoch: 1613, Loss: 1.2498, Train: 74.82%, Valid: 72.61% Test: 71.48%\n",
      "Epoch: 1614, Loss: 1.2470, Train: 74.92%, Valid: 72.54% Test: 71.08%\n",
      "Epoch: 1615, Loss: 1.2509, Train: 74.92%, Valid: 72.53% Test: 71.24%\n",
      "Epoch: 1616, Loss: 1.2455, Train: 74.93%, Valid: 72.61% Test: 71.45%\n",
      "Epoch: 1617, Loss: 1.2448, Train: 74.97%, Valid: 72.68% Test: 71.35%\n",
      "Epoch: 1618, Loss: 1.2495, Train: 74.99%, Valid: 72.60% Test: 71.34%\n",
      "Epoch: 1619, Loss: 1.2493, Train: 74.84%, Valid: 72.59% Test: 71.61%\n",
      "Epoch: 1620, Loss: 1.2465, Train: 74.86%, Valid: 72.49% Test: 71.16%\n",
      "Epoch: 1621, Loss: 1.2489, Train: 74.92%, Valid: 72.53% Test: 71.11%\n",
      "Epoch: 1622, Loss: 1.2400, Train: 74.94%, Valid: 72.56% Test: 71.46%\n",
      "Epoch: 1623, Loss: 1.2429, Train: 74.99%, Valid: 72.58% Test: 71.31%\n",
      "Epoch: 1624, Loss: 1.2457, Train: 74.95%, Valid: 72.57% Test: 71.29%\n",
      "Epoch: 1625, Loss: 1.2506, Train: 74.94%, Valid: 72.67% Test: 71.33%\n",
      "Epoch: 1626, Loss: 1.2496, Train: 75.00%, Valid: 72.70% Test: 71.45%\n",
      "Epoch: 1627, Loss: 1.2440, Train: 74.91%, Valid: 72.61% Test: 71.46%\n",
      "Epoch: 1628, Loss: 1.2433, Train: 74.91%, Valid: 72.47% Test: 71.16%\n",
      "Epoch: 1629, Loss: 1.2405, Train: 74.91%, Valid: 72.65% Test: 71.37%\n",
      "Epoch: 1630, Loss: 1.2509, Train: 74.96%, Valid: 72.59% Test: 71.45%\n",
      "Epoch: 1631, Loss: 1.2507, Train: 74.86%, Valid: 72.47% Test: 71.21%\n",
      "Epoch: 1632, Loss: 1.2522, Train: 74.94%, Valid: 72.58% Test: 71.47%\n",
      "Epoch: 1633, Loss: 1.2421, Train: 74.96%, Valid: 72.62% Test: 71.29%\n",
      "Epoch: 1634, Loss: 1.2438, Train: 74.93%, Valid: 72.55% Test: 71.39%\n",
      "Epoch: 1635, Loss: 1.2471, Train: 74.84%, Valid: 72.50% Test: 71.49%\n",
      "Epoch: 1636, Loss: 1.2473, Train: 74.89%, Valid: 72.41% Test: 71.27%\n",
      "Epoch: 1637, Loss: 1.2431, Train: 74.89%, Valid: 72.54% Test: 71.42%\n",
      "Epoch: 1638, Loss: 1.2440, Train: 74.89%, Valid: 72.65% Test: 71.66%\n",
      "Epoch: 1639, Loss: 1.2441, Train: 74.92%, Valid: 72.43% Test: 71.16%\n",
      "Epoch: 1640, Loss: 1.2478, Train: 75.00%, Valid: 72.54% Test: 71.20%\n",
      "Epoch: 1641, Loss: 1.2501, Train: 74.93%, Valid: 72.60% Test: 71.38%\n",
      "Epoch: 1642, Loss: 1.2525, Train: 74.89%, Valid: 72.44% Test: 70.92%\n",
      "Epoch: 1643, Loss: 1.2431, Train: 74.95%, Valid: 72.49% Test: 71.16%\n",
      "Epoch: 1644, Loss: 1.2505, Train: 74.84%, Valid: 72.67% Test: 71.66%\n",
      "Epoch: 1645, Loss: 1.2480, Train: 74.94%, Valid: 72.39% Test: 70.80%\n",
      "Epoch: 1646, Loss: 1.2457, Train: 74.89%, Valid: 72.40% Test: 71.00%\n",
      "Epoch: 1647, Loss: 1.2463, Train: 74.85%, Valid: 72.50% Test: 71.47%\n",
      "Epoch: 1648, Loss: 1.2424, Train: 74.99%, Valid: 72.53% Test: 71.23%\n",
      "Epoch: 1649, Loss: 1.2481, Train: 74.88%, Valid: 72.52% Test: 71.35%\n",
      "Epoch: 1650, Loss: 1.2478, Train: 74.94%, Valid: 72.47% Test: 71.32%\n",
      "Epoch: 1651, Loss: 1.2441, Train: 75.03%, Valid: 72.50% Test: 71.03%\n",
      "Epoch: 1652, Loss: 1.2522, Train: 74.81%, Valid: 72.49% Test: 71.58%\n",
      "Epoch: 1653, Loss: 1.2493, Train: 74.77%, Valid: 72.39% Test: 71.35%\n",
      "Epoch: 1654, Loss: 1.2453, Train: 74.93%, Valid: 72.19% Test: 70.52%\n",
      "Epoch: 1655, Loss: 1.2460, Train: 74.92%, Valid: 72.65% Test: 71.65%\n",
      "Epoch: 1656, Loss: 1.2428, Train: 74.86%, Valid: 72.59% Test: 71.61%\n",
      "Epoch: 1657, Loss: 1.2459, Train: 74.96%, Valid: 72.50% Test: 70.99%\n",
      "Epoch: 1658, Loss: 1.2450, Train: 74.98%, Valid: 72.49% Test: 71.29%\n",
      "Epoch: 1659, Loss: 1.2438, Train: 74.82%, Valid: 72.49% Test: 71.61%\n",
      "Epoch: 1660, Loss: 1.2409, Train: 74.98%, Valid: 72.39% Test: 70.94%\n",
      "Epoch: 1661, Loss: 1.2472, Train: 74.97%, Valid: 72.47% Test: 71.17%\n",
      "Epoch: 1662, Loss: 1.2445, Train: 74.92%, Valid: 72.56% Test: 71.65%\n",
      "Epoch: 1663, Loss: 1.2479, Train: 74.88%, Valid: 72.45% Test: 71.24%\n",
      "Epoch: 1664, Loss: 1.2490, Train: 74.94%, Valid: 72.36% Test: 70.96%\n",
      "Epoch: 1665, Loss: 1.2450, Train: 74.90%, Valid: 72.56% Test: 71.54%\n",
      "Epoch: 1666, Loss: 1.2480, Train: 75.01%, Valid: 72.68% Test: 71.41%\n",
      "Epoch: 1667, Loss: 1.2398, Train: 75.03%, Valid: 72.56% Test: 71.43%\n",
      "Epoch: 1668, Loss: 1.2478, Train: 74.94%, Valid: 72.49% Test: 71.46%\n",
      "Epoch: 1669, Loss: 1.2448, Train: 75.01%, Valid: 72.57% Test: 71.37%\n",
      "Epoch: 1670, Loss: 1.2484, Train: 75.04%, Valid: 72.58% Test: 71.59%\n",
      "Epoch: 1671, Loss: 1.2437, Train: 74.94%, Valid: 72.40% Test: 71.30%\n",
      "Epoch: 1672, Loss: 1.2454, Train: 75.00%, Valid: 72.32% Test: 70.85%\n",
      "Epoch: 1673, Loss: 1.2435, Train: 74.90%, Valid: 72.55% Test: 71.39%\n",
      "Epoch: 1674, Loss: 1.2387, Train: 74.89%, Valid: 72.45% Test: 71.23%\n",
      "Epoch: 1675, Loss: 1.2460, Train: 74.97%, Valid: 72.35% Test: 70.82%\n",
      "Epoch: 1676, Loss: 1.2436, Train: 74.89%, Valid: 72.59% Test: 71.50%\n",
      "Epoch: 1677, Loss: 1.2454, Train: 74.90%, Valid: 72.56% Test: 71.41%\n",
      "Epoch: 1678, Loss: 1.2454, Train: 75.01%, Valid: 72.55% Test: 71.13%\n",
      "Epoch: 1679, Loss: 1.2451, Train: 74.88%, Valid: 72.70% Test: 71.59%\n",
      "Epoch: 1680, Loss: 1.2431, Train: 75.05%, Valid: 72.58% Test: 71.18%\n",
      "Epoch: 1681, Loss: 1.2449, Train: 75.02%, Valid: 72.38% Test: 70.88%\n",
      "Epoch: 1682, Loss: 1.2461, Train: 74.96%, Valid: 72.61% Test: 71.36%\n",
      "Epoch: 1683, Loss: 1.2456, Train: 75.05%, Valid: 72.65% Test: 71.44%\n",
      "Epoch: 1684, Loss: 1.2494, Train: 74.93%, Valid: 72.50% Test: 71.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1685, Loss: 1.2434, Train: 74.93%, Valid: 72.40% Test: 70.99%\n",
      "Epoch: 1686, Loss: 1.2433, Train: 75.01%, Valid: 72.44% Test: 71.04%\n",
      "Epoch: 1687, Loss: 1.2467, Train: 74.87%, Valid: 72.56% Test: 71.58%\n",
      "Epoch: 1688, Loss: 1.2481, Train: 75.00%, Valid: 72.65% Test: 71.46%\n",
      "Epoch: 1689, Loss: 1.2430, Train: 75.03%, Valid: 72.58% Test: 71.17%\n",
      "Epoch: 1690, Loss: 1.2428, Train: 74.95%, Valid: 72.60% Test: 71.51%\n",
      "Epoch: 1691, Loss: 1.2491, Train: 75.03%, Valid: 72.61% Test: 71.32%\n",
      "Epoch: 1692, Loss: 1.2463, Train: 75.07%, Valid: 72.54% Test: 71.26%\n",
      "Epoch: 1693, Loss: 1.2426, Train: 74.93%, Valid: 72.60% Test: 71.58%\n",
      "Epoch: 1694, Loss: 1.2450, Train: 75.01%, Valid: 72.48% Test: 71.17%\n",
      "Epoch: 1695, Loss: 1.2426, Train: 74.98%, Valid: 72.63% Test: 71.24%\n",
      "Epoch: 1696, Loss: 1.2351, Train: 74.96%, Valid: 72.60% Test: 71.49%\n",
      "Epoch: 1697, Loss: 1.2494, Train: 75.00%, Valid: 72.53% Test: 71.45%\n",
      "Epoch: 1698, Loss: 1.2437, Train: 75.01%, Valid: 72.40% Test: 71.08%\n",
      "Epoch: 1699, Loss: 1.2383, Train: 75.00%, Valid: 72.52% Test: 71.29%\n",
      "Epoch: 1700, Loss: 1.2412, Train: 74.89%, Valid: 72.64% Test: 71.80%\n",
      "Epoch: 1701, Loss: 1.2513, Train: 75.01%, Valid: 72.62% Test: 71.39%\n",
      "Epoch: 1702, Loss: 1.2454, Train: 75.09%, Valid: 72.51% Test: 70.95%\n",
      "Epoch: 1703, Loss: 1.2426, Train: 74.97%, Valid: 72.53% Test: 71.57%\n",
      "Epoch: 1704, Loss: 1.2428, Train: 75.05%, Valid: 72.67% Test: 71.46%\n",
      "Epoch: 1705, Loss: 1.2433, Train: 75.06%, Valid: 72.49% Test: 71.17%\n",
      "Epoch: 1706, Loss: 1.2518, Train: 75.00%, Valid: 72.63% Test: 71.33%\n",
      "Epoch: 1707, Loss: 1.2373, Train: 74.96%, Valid: 72.63% Test: 71.53%\n",
      "Epoch: 1708, Loss: 1.2379, Train: 75.12%, Valid: 72.61% Test: 71.08%\n",
      "Epoch: 1709, Loss: 1.2378, Train: 75.08%, Valid: 72.56% Test: 71.28%\n",
      "Epoch: 1710, Loss: 1.2405, Train: 74.97%, Valid: 72.54% Test: 71.37%\n",
      "Epoch: 1711, Loss: 1.2404, Train: 74.97%, Valid: 72.58% Test: 71.31%\n",
      "Epoch: 1712, Loss: 1.2409, Train: 74.98%, Valid: 72.63% Test: 71.35%\n",
      "Epoch: 1713, Loss: 1.2393, Train: 75.06%, Valid: 72.62% Test: 71.48%\n",
      "Epoch: 1714, Loss: 1.2400, Train: 75.03%, Valid: 72.54% Test: 71.48%\n",
      "Epoch: 1715, Loss: 1.2382, Train: 75.05%, Valid: 72.58% Test: 71.48%\n",
      "Epoch: 1716, Loss: 1.2466, Train: 74.98%, Valid: 72.51% Test: 71.17%\n",
      "Epoch: 1717, Loss: 1.2507, Train: 75.01%, Valid: 72.50% Test: 70.97%\n",
      "Epoch: 1718, Loss: 1.2472, Train: 74.98%, Valid: 72.75% Test: 71.57%\n",
      "Epoch: 1719, Loss: 1.2379, Train: 75.02%, Valid: 72.57% Test: 71.33%\n",
      "Epoch: 1720, Loss: 1.2397, Train: 75.06%, Valid: 72.44% Test: 70.85%\n",
      "Epoch: 1721, Loss: 1.2451, Train: 74.92%, Valid: 72.60% Test: 71.56%\n",
      "Epoch: 1722, Loss: 1.2422, Train: 74.98%, Valid: 72.59% Test: 71.55%\n",
      "Epoch: 1723, Loss: 1.2437, Train: 75.03%, Valid: 72.49% Test: 71.05%\n",
      "Epoch: 1724, Loss: 1.2431, Train: 75.01%, Valid: 72.57% Test: 71.52%\n",
      "Epoch: 1725, Loss: 1.2426, Train: 75.06%, Valid: 72.62% Test: 71.54%\n",
      "Epoch: 1726, Loss: 1.2485, Train: 75.05%, Valid: 72.59% Test: 71.43%\n",
      "Epoch: 1727, Loss: 1.2443, Train: 75.03%, Valid: 72.71% Test: 71.41%\n",
      "Epoch: 1728, Loss: 1.2454, Train: 75.00%, Valid: 72.48% Test: 71.30%\n",
      "Epoch: 1729, Loss: 1.2518, Train: 74.98%, Valid: 72.45% Test: 70.95%\n",
      "Epoch: 1730, Loss: 1.2381, Train: 75.01%, Valid: 72.45% Test: 71.20%\n",
      "Epoch: 1731, Loss: 1.2438, Train: 75.02%, Valid: 72.62% Test: 71.56%\n",
      "Epoch: 1732, Loss: 1.2380, Train: 75.04%, Valid: 72.61% Test: 71.42%\n",
      "Epoch: 1733, Loss: 1.2497, Train: 75.05%, Valid: 72.63% Test: 71.36%\n",
      "Epoch: 1734, Loss: 1.2474, Train: 75.04%, Valid: 72.40% Test: 71.27%\n",
      "Epoch: 1735, Loss: 1.2427, Train: 75.06%, Valid: 72.59% Test: 71.29%\n",
      "Epoch: 1736, Loss: 1.2456, Train: 75.10%, Valid: 72.38% Test: 71.10%\n",
      "Epoch: 1737, Loss: 1.2408, Train: 74.98%, Valid: 72.57% Test: 71.66%\n",
      "Epoch: 1738, Loss: 1.2501, Train: 75.11%, Valid: 72.61% Test: 71.52%\n",
      "Epoch: 1739, Loss: 1.2441, Train: 75.04%, Valid: 72.55% Test: 71.30%\n",
      "Epoch: 1740, Loss: 1.2442, Train: 75.00%, Valid: 72.63% Test: 71.57%\n",
      "Epoch: 1741, Loss: 1.2351, Train: 75.10%, Valid: 72.65% Test: 71.33%\n",
      "Epoch: 1742, Loss: 1.2400, Train: 75.00%, Valid: 72.62% Test: 71.56%\n",
      "Epoch: 1743, Loss: 1.2467, Train: 75.00%, Valid: 72.52% Test: 71.29%\n",
      "Epoch: 1744, Loss: 1.2429, Train: 75.04%, Valid: 72.42% Test: 71.13%\n",
      "Epoch: 1745, Loss: 1.2353, Train: 74.86%, Valid: 72.49% Test: 71.61%\n",
      "Epoch: 1746, Loss: 1.2461, Train: 75.03%, Valid: 72.49% Test: 71.21%\n",
      "Epoch: 1747, Loss: 1.2447, Train: 75.01%, Valid: 72.66% Test: 71.33%\n",
      "Epoch: 1748, Loss: 1.2401, Train: 75.00%, Valid: 72.65% Test: 71.56%\n",
      "Epoch: 1749, Loss: 1.2401, Train: 75.04%, Valid: 72.41% Test: 71.20%\n",
      "Epoch: 1750, Loss: 1.2401, Train: 75.07%, Valid: 72.58% Test: 71.33%\n",
      "Epoch: 1751, Loss: 1.2483, Train: 74.92%, Valid: 72.50% Test: 71.44%\n",
      "Epoch: 1752, Loss: 1.2430, Train: 75.06%, Valid: 72.56% Test: 71.04%\n",
      "Epoch: 1753, Loss: 1.2464, Train: 75.12%, Valid: 72.67% Test: 71.35%\n",
      "Epoch: 1754, Loss: 1.2490, Train: 75.02%, Valid: 72.62% Test: 71.45%\n",
      "Epoch: 1755, Loss: 1.2473, Train: 75.09%, Valid: 72.51% Test: 71.14%\n",
      "Epoch: 1756, Loss: 1.2509, Train: 75.05%, Valid: 72.57% Test: 71.28%\n",
      "Epoch: 1757, Loss: 1.2430, Train: 74.96%, Valid: 72.65% Test: 71.49%\n",
      "Epoch: 1758, Loss: 1.2503, Train: 75.04%, Valid: 72.56% Test: 71.11%\n",
      "Epoch: 1759, Loss: 1.2423, Train: 75.02%, Valid: 72.48% Test: 71.10%\n",
      "Epoch: 1760, Loss: 1.2389, Train: 74.97%, Valid: 72.53% Test: 71.49%\n",
      "Epoch: 1761, Loss: 1.2476, Train: 75.10%, Valid: 72.53% Test: 71.10%\n",
      "Epoch: 1762, Loss: 1.2472, Train: 75.10%, Valid: 72.50% Test: 71.34%\n",
      "Epoch: 1763, Loss: 1.2518, Train: 74.98%, Valid: 72.49% Test: 71.53%\n",
      "Epoch: 1764, Loss: 1.2357, Train: 75.06%, Valid: 72.46% Test: 71.10%\n",
      "Epoch: 1765, Loss: 1.2393, Train: 75.13%, Valid: 72.52% Test: 71.15%\n",
      "Epoch: 1766, Loss: 1.2432, Train: 74.94%, Valid: 72.51% Test: 71.71%\n",
      "Epoch: 1767, Loss: 1.2426, Train: 75.10%, Valid: 72.43% Test: 71.22%\n",
      "Epoch: 1768, Loss: 1.2377, Train: 75.11%, Valid: 72.38% Test: 70.88%\n",
      "Epoch: 1769, Loss: 1.2448, Train: 74.98%, Valid: 72.53% Test: 71.53%\n",
      "Epoch: 1770, Loss: 1.2408, Train: 74.99%, Valid: 72.58% Test: 71.51%\n",
      "Epoch: 1771, Loss: 1.2392, Train: 75.00%, Valid: 72.52% Test: 71.13%\n",
      "Epoch: 1772, Loss: 1.2432, Train: 75.00%, Valid: 72.56% Test: 71.40%\n",
      "Epoch: 1773, Loss: 1.2379, Train: 75.07%, Valid: 72.58% Test: 71.34%\n",
      "Epoch: 1774, Loss: 1.2456, Train: 75.15%, Valid: 72.62% Test: 71.37%\n",
      "Epoch: 1775, Loss: 1.2444, Train: 74.94%, Valid: 72.51% Test: 71.70%\n",
      "Epoch: 1776, Loss: 1.2448, Train: 75.09%, Valid: 72.42% Test: 70.96%\n",
      "Epoch: 1777, Loss: 1.2431, Train: 75.01%, Valid: 72.62% Test: 71.49%\n",
      "Epoch: 1778, Loss: 1.2411, Train: 74.95%, Valid: 72.58% Test: 71.75%\n",
      "Epoch: 1779, Loss: 1.2400, Train: 75.13%, Valid: 72.54% Test: 71.23%\n",
      "Epoch: 1780, Loss: 1.2380, Train: 74.96%, Valid: 72.34% Test: 70.97%\n",
      "Epoch: 1781, Loss: 1.2408, Train: 74.90%, Valid: 72.65% Test: 71.64%\n",
      "Epoch: 1782, Loss: 1.2383, Train: 75.00%, Valid: 72.56% Test: 71.32%\n",
      "Epoch: 1783, Loss: 1.2521, Train: 75.01%, Valid: 72.31% Test: 70.93%\n",
      "Epoch: 1784, Loss: 1.2447, Train: 75.02%, Valid: 72.44% Test: 71.17%\n",
      "Epoch: 1785, Loss: 1.2392, Train: 75.01%, Valid: 72.68% Test: 71.58%\n",
      "Epoch: 1786, Loss: 1.2427, Train: 74.90%, Valid: 72.53% Test: 71.38%\n",
      "Epoch: 1787, Loss: 1.2498, Train: 75.07%, Valid: 72.32% Test: 70.83%\n",
      "Epoch: 1788, Loss: 1.2432, Train: 75.04%, Valid: 72.34% Test: 70.91%\n",
      "Epoch: 1789, Loss: 1.2546, Train: 74.91%, Valid: 72.67% Test: 71.77%\n",
      "Epoch: 1790, Loss: 1.2417, Train: 75.08%, Valid: 72.55% Test: 70.97%\n",
      "Epoch: 1791, Loss: 1.2417, Train: 75.06%, Valid: 72.54% Test: 71.20%\n",
      "Epoch: 1792, Loss: 1.2466, Train: 74.94%, Valid: 72.51% Test: 71.54%\n",
      "Epoch: 1793, Loss: 1.2416, Train: 75.00%, Valid: 72.43% Test: 71.02%\n",
      "Epoch: 1794, Loss: 1.2448, Train: 74.98%, Valid: 72.51% Test: 71.35%\n",
      "Epoch: 1795, Loss: 1.2412, Train: 75.01%, Valid: 72.54% Test: 71.34%\n",
      "Epoch: 1796, Loss: 1.2433, Train: 75.06%, Valid: 72.49% Test: 71.18%\n",
      "Epoch: 1797, Loss: 1.2497, Train: 75.03%, Valid: 72.71% Test: 71.60%\n",
      "Epoch: 1798, Loss: 1.2394, Train: 75.03%, Valid: 72.54% Test: 71.45%\n",
      "Epoch: 1799, Loss: 1.2396, Train: 75.02%, Valid: 72.21% Test: 70.56%\n",
      "Epoch: 1800, Loss: 1.2433, Train: 75.05%, Valid: 72.46% Test: 71.41%\n",
      "Epoch: 1801, Loss: 1.2368, Train: 75.07%, Valid: 72.59% Test: 71.53%\n",
      "Epoch: 1802, Loss: 1.2444, Train: 75.11%, Valid: 72.61% Test: 71.37%\n",
      "Epoch: 1803, Loss: 1.2418, Train: 75.08%, Valid: 72.71% Test: 71.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1804, Loss: 1.2448, Train: 75.04%, Valid: 72.64% Test: 71.65%\n",
      "Epoch: 1805, Loss: 1.2386, Train: 75.11%, Valid: 72.37% Test: 71.06%\n",
      "Epoch: 1806, Loss: 1.2377, Train: 75.12%, Valid: 72.61% Test: 71.33%\n",
      "Epoch: 1807, Loss: 1.2409, Train: 75.12%, Valid: 72.54% Test: 71.39%\n",
      "Epoch: 1808, Loss: 1.2401, Train: 75.16%, Valid: 72.47% Test: 71.06%\n",
      "Epoch: 1809, Loss: 1.2382, Train: 75.10%, Valid: 72.59% Test: 71.46%\n",
      "Epoch: 1810, Loss: 1.2409, Train: 74.97%, Valid: 72.54% Test: 71.50%\n",
      "Epoch: 1811, Loss: 1.2389, Train: 75.04%, Valid: 72.46% Test: 71.22%\n",
      "Epoch: 1812, Loss: 1.2407, Train: 75.12%, Valid: 72.43% Test: 71.09%\n",
      "Epoch: 1813, Loss: 1.2411, Train: 74.95%, Valid: 72.41% Test: 71.58%\n",
      "Epoch: 1814, Loss: 1.2456, Train: 75.00%, Valid: 72.52% Test: 71.40%\n",
      "Epoch: 1815, Loss: 1.2340, Train: 75.10%, Valid: 72.41% Test: 71.10%\n",
      "Epoch: 1816, Loss: 1.2470, Train: 75.10%, Valid: 72.63% Test: 71.58%\n",
      "Epoch: 1817, Loss: 1.2436, Train: 75.13%, Valid: 72.65% Test: 71.60%\n",
      "Epoch: 1818, Loss: 1.2439, Train: 75.11%, Valid: 72.34% Test: 70.94%\n",
      "Epoch: 1819, Loss: 1.2424, Train: 75.05%, Valid: 72.42% Test: 70.92%\n",
      "Epoch: 1820, Loss: 1.2417, Train: 75.06%, Valid: 72.60% Test: 71.51%\n",
      "Epoch: 1821, Loss: 1.2377, Train: 75.06%, Valid: 72.55% Test: 71.47%\n",
      "Epoch: 1822, Loss: 1.2409, Train: 75.09%, Valid: 72.52% Test: 71.18%\n",
      "Epoch: 1823, Loss: 1.2403, Train: 75.14%, Valid: 72.47% Test: 71.07%\n",
      "Epoch: 1824, Loss: 1.2429, Train: 75.07%, Valid: 72.62% Test: 71.49%\n",
      "Epoch: 1825, Loss: 1.2419, Train: 75.08%, Valid: 72.67% Test: 71.48%\n",
      "Epoch: 1826, Loss: 1.2390, Train: 75.03%, Valid: 72.45% Test: 71.04%\n",
      "Epoch: 1827, Loss: 1.2423, Train: 75.04%, Valid: 72.53% Test: 71.22%\n",
      "Epoch: 1828, Loss: 1.2411, Train: 75.05%, Valid: 72.45% Test: 71.21%\n",
      "Epoch: 1829, Loss: 1.2453, Train: 75.05%, Valid: 72.59% Test: 71.60%\n",
      "Epoch: 1830, Loss: 1.2477, Train: 75.13%, Valid: 72.59% Test: 71.39%\n",
      "Epoch: 1831, Loss: 1.2408, Train: 75.21%, Valid: 72.62% Test: 71.30%\n",
      "Epoch: 1832, Loss: 1.2409, Train: 75.03%, Valid: 72.61% Test: 71.79%\n",
      "Epoch: 1833, Loss: 1.2462, Train: 75.10%, Valid: 72.53% Test: 71.36%\n",
      "Epoch: 1834, Loss: 1.2437, Train: 75.05%, Valid: 72.34% Test: 70.90%\n",
      "Epoch: 1835, Loss: 1.2418, Train: 74.98%, Valid: 72.54% Test: 71.46%\n",
      "Epoch: 1836, Loss: 1.2417, Train: 75.07%, Valid: 72.70% Test: 71.52%\n",
      "Epoch: 1837, Loss: 1.2427, Train: 75.14%, Valid: 72.56% Test: 71.22%\n",
      "Epoch: 1838, Loss: 1.2488, Train: 75.06%, Valid: 72.55% Test: 71.33%\n",
      "Epoch: 1839, Loss: 1.2386, Train: 75.11%, Valid: 72.49% Test: 71.24%\n",
      "Epoch: 1840, Loss: 1.2392, Train: 75.16%, Valid: 72.54% Test: 71.23%\n",
      "Epoch: 1841, Loss: 1.2379, Train: 75.04%, Valid: 72.68% Test: 71.65%\n",
      "Epoch: 1842, Loss: 1.2419, Train: 75.05%, Valid: 72.54% Test: 71.40%\n",
      "Epoch: 1843, Loss: 1.2441, Train: 75.10%, Valid: 72.47% Test: 71.18%\n",
      "Epoch: 1844, Loss: 1.2351, Train: 75.13%, Valid: 72.56% Test: 71.46%\n",
      "Epoch: 1845, Loss: 1.2427, Train: 75.05%, Valid: 72.55% Test: 71.54%\n",
      "Epoch: 1846, Loss: 1.2377, Train: 75.05%, Valid: 72.45% Test: 71.24%\n",
      "Epoch: 1847, Loss: 1.2434, Train: 75.13%, Valid: 72.34% Test: 70.85%\n",
      "Epoch: 1848, Loss: 1.2326, Train: 75.09%, Valid: 72.55% Test: 71.58%\n",
      "Epoch: 1849, Loss: 1.2371, Train: 75.11%, Valid: 72.51% Test: 71.42%\n",
      "Epoch: 1850, Loss: 1.2387, Train: 75.16%, Valid: 72.41% Test: 70.96%\n",
      "Epoch: 1851, Loss: 1.2405, Train: 75.15%, Valid: 72.60% Test: 71.46%\n",
      "Epoch: 1852, Loss: 1.2393, Train: 75.11%, Valid: 72.54% Test: 71.38%\n",
      "Epoch: 1853, Loss: 1.2416, Train: 75.14%, Valid: 72.50% Test: 71.20%\n",
      "Epoch: 1854, Loss: 1.2376, Train: 75.20%, Valid: 72.50% Test: 71.14%\n",
      "Epoch: 1855, Loss: 1.2398, Train: 75.19%, Valid: 72.63% Test: 71.35%\n",
      "Epoch: 1856, Loss: 1.2470, Train: 75.03%, Valid: 72.59% Test: 71.58%\n",
      "Epoch: 1857, Loss: 1.2385, Train: 75.11%, Valid: 72.35% Test: 70.92%\n",
      "Epoch: 1858, Loss: 1.2414, Train: 75.18%, Valid: 72.30% Test: 70.80%\n",
      "Epoch: 1859, Loss: 1.2437, Train: 75.00%, Valid: 72.62% Test: 71.66%\n",
      "Epoch: 1860, Loss: 1.2470, Train: 75.08%, Valid: 72.51% Test: 71.23%\n",
      "Epoch: 1861, Loss: 1.2336, Train: 75.14%, Valid: 72.54% Test: 71.36%\n",
      "Epoch: 1862, Loss: 1.2460, Train: 75.05%, Valid: 72.56% Test: 71.56%\n",
      "Epoch: 1863, Loss: 1.2383, Train: 75.11%, Valid: 72.64% Test: 71.21%\n",
      "Epoch: 1864, Loss: 1.2379, Train: 75.15%, Valid: 72.64% Test: 71.25%\n",
      "Epoch: 1865, Loss: 1.2379, Train: 75.15%, Valid: 72.49% Test: 71.18%\n",
      "Epoch: 1866, Loss: 1.2380, Train: 75.20%, Valid: 72.65% Test: 71.16%\n",
      "Epoch: 1867, Loss: 1.2355, Train: 75.13%, Valid: 72.71% Test: 71.39%\n",
      "Epoch: 1868, Loss: 1.2373, Train: 75.12%, Valid: 72.70% Test: 71.57%\n",
      "Epoch: 1869, Loss: 1.2374, Train: 75.13%, Valid: 72.51% Test: 71.29%\n",
      "Epoch: 1870, Loss: 1.2362, Train: 75.17%, Valid: 72.50% Test: 71.01%\n",
      "Epoch: 1871, Loss: 1.2436, Train: 75.18%, Valid: 72.77% Test: 71.64%\n",
      "Epoch: 1872, Loss: 1.2390, Train: 75.09%, Valid: 72.65% Test: 71.65%\n",
      "Epoch: 1873, Loss: 1.2401, Train: 75.13%, Valid: 72.22% Test: 70.54%\n",
      "Epoch: 1874, Loss: 1.2432, Train: 75.12%, Valid: 72.46% Test: 71.17%\n",
      "Epoch: 1875, Loss: 1.2423, Train: 75.06%, Valid: 72.63% Test: 71.76%\n",
      "Epoch: 1876, Loss: 1.2435, Train: 75.25%, Valid: 72.60% Test: 71.27%\n",
      "Epoch: 1877, Loss: 1.2469, Train: 75.16%, Valid: 72.43% Test: 71.25%\n",
      "Epoch: 1878, Loss: 1.2421, Train: 75.14%, Valid: 72.46% Test: 71.36%\n",
      "Epoch: 1879, Loss: 1.2397, Train: 75.16%, Valid: 72.61% Test: 71.40%\n",
      "Epoch: 1880, Loss: 1.2423, Train: 75.15%, Valid: 72.46% Test: 70.99%\n",
      "Epoch: 1881, Loss: 1.2398, Train: 75.13%, Valid: 72.52% Test: 71.33%\n",
      "Epoch: 1882, Loss: 1.2407, Train: 75.08%, Valid: 72.64% Test: 71.67%\n",
      "Epoch: 1883, Loss: 1.2434, Train: 75.13%, Valid: 72.57% Test: 71.41%\n",
      "Epoch: 1884, Loss: 1.2349, Train: 75.17%, Valid: 72.36% Test: 70.86%\n",
      "Epoch: 1885, Loss: 1.2365, Train: 75.11%, Valid: 72.42% Test: 71.09%\n",
      "Epoch: 1886, Loss: 1.2410, Train: 75.14%, Valid: 72.61% Test: 71.43%\n",
      "Epoch: 1887, Loss: 1.2380, Train: 75.14%, Valid: 72.63% Test: 71.53%\n",
      "Epoch: 1888, Loss: 1.2445, Train: 75.19%, Valid: 72.29% Test: 70.84%\n",
      "Epoch: 1889, Loss: 1.2396, Train: 74.97%, Valid: 72.47% Test: 71.59%\n",
      "Epoch: 1890, Loss: 1.2436, Train: 75.07%, Valid: 72.55% Test: 71.25%\n",
      "Epoch: 1891, Loss: 1.2418, Train: 75.14%, Valid: 72.53% Test: 70.86%\n",
      "Epoch: 1892, Loss: 1.2431, Train: 75.04%, Valid: 72.58% Test: 71.55%\n",
      "Epoch: 1893, Loss: 1.2436, Train: 75.20%, Valid: 72.58% Test: 71.26%\n",
      "Epoch: 1894, Loss: 1.2393, Train: 75.19%, Valid: 72.55% Test: 71.40%\n",
      "Epoch: 1895, Loss: 1.2443, Train: 75.04%, Valid: 72.37% Test: 71.44%\n",
      "Epoch: 1896, Loss: 1.2422, Train: 75.25%, Valid: 72.43% Test: 70.96%\n",
      "Epoch: 1897, Loss: 1.2442, Train: 75.21%, Valid: 72.59% Test: 71.25%\n",
      "Epoch: 1898, Loss: 1.2410, Train: 75.02%, Valid: 72.61% Test: 71.70%\n",
      "Epoch: 1899, Loss: 1.2437, Train: 75.24%, Valid: 72.27% Test: 70.76%\n",
      "Epoch: 1900, Loss: 1.2420, Train: 75.19%, Valid: 72.51% Test: 71.20%\n",
      "Epoch: 1901, Loss: 1.2366, Train: 74.86%, Valid: 72.52% Test: 71.69%\n",
      "Epoch: 1902, Loss: 1.2380, Train: 75.16%, Valid: 72.41% Test: 70.94%\n",
      "Epoch: 1903, Loss: 1.2402, Train: 75.11%, Valid: 72.39% Test: 70.99%\n",
      "Epoch: 1904, Loss: 1.2425, Train: 74.88%, Valid: 72.43% Test: 71.55%\n",
      "Epoch: 1905, Loss: 1.2396, Train: 75.12%, Valid: 72.55% Test: 70.88%\n",
      "Epoch: 1906, Loss: 1.2427, Train: 75.12%, Valid: 72.71% Test: 71.23%\n",
      "Epoch: 1907, Loss: 1.2454, Train: 74.93%, Valid: 72.44% Test: 71.46%\n",
      "Epoch: 1908, Loss: 1.2332, Train: 75.20%, Valid: 72.56% Test: 70.95%\n",
      "Epoch: 1909, Loss: 1.2414, Train: 75.17%, Valid: 72.46% Test: 70.97%\n",
      "Epoch: 1910, Loss: 1.2464, Train: 75.02%, Valid: 72.54% Test: 71.51%\n",
      "Epoch: 1911, Loss: 1.2382, Train: 75.17%, Valid: 72.39% Test: 70.80%\n",
      "Epoch: 1912, Loss: 1.2330, Train: 75.16%, Valid: 72.35% Test: 70.91%\n",
      "Epoch: 1913, Loss: 1.2373, Train: 75.02%, Valid: 72.36% Test: 71.43%\n",
      "Epoch: 1914, Loss: 1.2384, Train: 75.14%, Valid: 72.59% Test: 71.44%\n",
      "Epoch: 1915, Loss: 1.2439, Train: 75.16%, Valid: 72.59% Test: 71.11%\n",
      "Epoch: 1916, Loss: 1.2392, Train: 75.04%, Valid: 72.57% Test: 71.58%\n",
      "Epoch: 1917, Loss: 1.2405, Train: 75.14%, Valid: 72.42% Test: 71.05%\n",
      "Epoch: 1918, Loss: 1.2358, Train: 75.14%, Valid: 72.53% Test: 71.02%\n",
      "Epoch: 1919, Loss: 1.2431, Train: 75.13%, Valid: 72.66% Test: 71.49%\n",
      "Epoch: 1920, Loss: 1.2320, Train: 75.27%, Valid: 72.72% Test: 71.42%\n",
      "Epoch: 1921, Loss: 1.2407, Train: 75.28%, Valid: 72.71% Test: 71.34%\n",
      "Epoch: 1922, Loss: 1.2425, Train: 75.09%, Valid: 72.60% Test: 71.52%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1923, Loss: 1.2350, Train: 75.21%, Valid: 72.73% Test: 71.31%\n",
      "Epoch: 1924, Loss: 1.2403, Train: 75.16%, Valid: 72.64% Test: 71.27%\n",
      "Epoch: 1925, Loss: 1.2462, Train: 75.07%, Valid: 72.55% Test: 71.35%\n",
      "Epoch: 1926, Loss: 1.2427, Train: 75.15%, Valid: 72.31% Test: 70.86%\n",
      "Epoch: 1927, Loss: 1.2435, Train: 75.14%, Valid: 72.69% Test: 71.62%\n",
      "Epoch: 1928, Loss: 1.2397, Train: 75.11%, Valid: 72.61% Test: 71.49%\n",
      "Epoch: 1929, Loss: 1.2388, Train: 75.16%, Valid: 72.29% Test: 70.69%\n",
      "Epoch: 1930, Loss: 1.2344, Train: 75.09%, Valid: 72.54% Test: 71.36%\n",
      "Epoch: 1931, Loss: 1.2400, Train: 75.09%, Valid: 72.56% Test: 71.58%\n",
      "Epoch: 1932, Loss: 1.2392, Train: 75.20%, Valid: 72.48% Test: 70.98%\n",
      "Epoch: 1933, Loss: 1.2416, Train: 75.16%, Valid: 72.69% Test: 71.53%\n",
      "Epoch: 1934, Loss: 1.2394, Train: 75.17%, Valid: 72.60% Test: 71.62%\n",
      "Epoch: 1935, Loss: 1.2310, Train: 75.29%, Valid: 72.48% Test: 71.06%\n",
      "Epoch: 1936, Loss: 1.2376, Train: 75.22%, Valid: 72.52% Test: 71.24%\n",
      "Epoch: 1937, Loss: 1.2413, Train: 74.99%, Valid: 72.52% Test: 71.50%\n",
      "Epoch: 1938, Loss: 1.2356, Train: 75.17%, Valid: 72.47% Test: 71.16%\n",
      "Epoch: 1939, Loss: 1.2370, Train: 75.17%, Valid: 72.49% Test: 71.23%\n",
      "Epoch: 1940, Loss: 1.2414, Train: 75.09%, Valid: 72.52% Test: 71.48%\n",
      "Epoch: 1941, Loss: 1.2388, Train: 75.21%, Valid: 72.58% Test: 71.38%\n",
      "Epoch: 1942, Loss: 1.2373, Train: 75.19%, Valid: 72.51% Test: 71.20%\n",
      "Epoch: 1943, Loss: 1.2384, Train: 75.20%, Valid: 72.70% Test: 71.46%\n",
      "Epoch: 1944, Loss: 1.2308, Train: 75.18%, Valid: 72.67% Test: 71.50%\n",
      "Epoch: 1945, Loss: 1.2398, Train: 75.20%, Valid: 72.59% Test: 71.33%\n",
      "Epoch: 1946, Loss: 1.2443, Train: 75.21%, Valid: 72.67% Test: 71.46%\n",
      "Epoch: 1947, Loss: 1.2398, Train: 75.26%, Valid: 72.61% Test: 71.42%\n",
      "Epoch: 1948, Loss: 1.2399, Train: 75.26%, Valid: 72.52% Test: 71.07%\n",
      "Epoch: 1949, Loss: 1.2391, Train: 75.18%, Valid: 72.75% Test: 71.75%\n",
      "Epoch: 1950, Loss: 1.2363, Train: 75.11%, Valid: 72.66% Test: 71.60%\n",
      "Epoch: 1951, Loss: 1.2414, Train: 75.18%, Valid: 72.37% Test: 70.79%\n",
      "Epoch: 1952, Loss: 1.2393, Train: 75.19%, Valid: 72.67% Test: 71.31%\n",
      "Epoch: 1953, Loss: 1.2344, Train: 75.14%, Valid: 72.66% Test: 71.48%\n",
      "Epoch: 1954, Loss: 1.2397, Train: 75.22%, Valid: 72.66% Test: 71.01%\n",
      "Epoch: 1955, Loss: 1.2392, Train: 75.15%, Valid: 72.60% Test: 71.26%\n",
      "Epoch: 1956, Loss: 1.2374, Train: 75.16%, Valid: 72.65% Test: 71.49%\n",
      "Epoch: 1957, Loss: 1.2382, Train: 75.23%, Valid: 72.64% Test: 71.21%\n",
      "Epoch: 1958, Loss: 1.2397, Train: 75.17%, Valid: 72.63% Test: 71.21%\n",
      "Epoch: 1959, Loss: 1.2372, Train: 75.11%, Valid: 72.68% Test: 71.53%\n",
      "Epoch: 1960, Loss: 1.2361, Train: 75.22%, Valid: 72.76% Test: 71.49%\n",
      "Epoch: 1961, Loss: 1.2411, Train: 75.16%, Valid: 72.62% Test: 71.46%\n",
      "Epoch: 1962, Loss: 1.2341, Train: 75.24%, Valid: 72.54% Test: 71.18%\n",
      "Epoch: 1963, Loss: 1.2413, Train: 75.22%, Valid: 72.66% Test: 71.29%\n",
      "Epoch: 1964, Loss: 1.2408, Train: 75.07%, Valid: 72.70% Test: 71.66%\n",
      "Epoch: 1965, Loss: 1.2386, Train: 75.15%, Valid: 72.57% Test: 71.17%\n",
      "Epoch: 1966, Loss: 1.2425, Train: 75.16%, Valid: 72.60% Test: 71.35%\n",
      "Epoch: 1967, Loss: 1.2346, Train: 75.13%, Valid: 72.67% Test: 71.40%\n",
      "Epoch: 1968, Loss: 1.2406, Train: 75.24%, Valid: 72.40% Test: 70.98%\n",
      "Epoch: 1969, Loss: 1.2443, Train: 75.24%, Valid: 72.56% Test: 71.44%\n",
      "Epoch: 1970, Loss: 1.2340, Train: 75.12%, Valid: 72.60% Test: 71.72%\n",
      "Epoch: 1971, Loss: 1.2429, Train: 75.16%, Valid: 72.22% Test: 70.58%\n",
      "Epoch: 1972, Loss: 1.2386, Train: 75.17%, Valid: 72.45% Test: 71.16%\n",
      "Epoch: 1973, Loss: 1.2350, Train: 75.04%, Valid: 72.62% Test: 71.65%\n",
      "Epoch: 1974, Loss: 1.2383, Train: 75.19%, Valid: 72.50% Test: 71.23%\n",
      "Epoch: 1975, Loss: 1.2384, Train: 75.20%, Valid: 72.67% Test: 71.43%\n",
      "Epoch: 1976, Loss: 1.2400, Train: 75.14%, Valid: 72.68% Test: 71.52%\n",
      "Epoch: 1977, Loss: 1.2381, Train: 75.25%, Valid: 72.63% Test: 71.17%\n",
      "Epoch: 1978, Loss: 1.2334, Train: 75.23%, Valid: 72.69% Test: 71.38%\n",
      "Epoch: 1979, Loss: 1.2361, Train: 75.18%, Valid: 72.64% Test: 71.47%\n",
      "Epoch: 1980, Loss: 1.2365, Train: 75.22%, Valid: 72.46% Test: 71.07%\n",
      "Epoch: 1981, Loss: 1.2321, Train: 75.18%, Valid: 72.68% Test: 71.37%\n",
      "Epoch: 1982, Loss: 1.2405, Train: 75.06%, Valid: 72.69% Test: 71.60%\n",
      "Epoch: 1983, Loss: 1.2330, Train: 75.13%, Valid: 72.61% Test: 71.42%\n",
      "Epoch: 1984, Loss: 1.2425, Train: 75.21%, Valid: 72.39% Test: 70.91%\n",
      "Epoch: 1985, Loss: 1.2411, Train: 75.19%, Valid: 72.70% Test: 71.65%\n",
      "Epoch: 1986, Loss: 1.2416, Train: 75.19%, Valid: 72.69% Test: 71.73%\n",
      "Epoch: 1987, Loss: 1.2408, Train: 75.25%, Valid: 72.52% Test: 71.17%\n",
      "Epoch: 1988, Loss: 1.2419, Train: 75.22%, Valid: 72.60% Test: 71.32%\n",
      "Epoch: 1989, Loss: 1.2357, Train: 75.13%, Valid: 72.76% Test: 71.68%\n",
      "Epoch: 1990, Loss: 1.2348, Train: 75.30%, Valid: 72.65% Test: 71.28%\n",
      "Epoch: 1991, Loss: 1.2375, Train: 75.23%, Valid: 72.74% Test: 71.59%\n",
      "Epoch: 1992, Loss: 1.2429, Train: 75.11%, Valid: 72.54% Test: 71.52%\n",
      "Epoch: 1993, Loss: 1.2386, Train: 75.20%, Valid: 72.51% Test: 71.18%\n",
      "Epoch: 1994, Loss: 1.2376, Train: 75.33%, Valid: 72.72% Test: 71.34%\n",
      "Epoch: 1995, Loss: 1.2391, Train: 75.19%, Valid: 72.76% Test: 71.78%\n",
      "Epoch: 1996, Loss: 1.2341, Train: 75.15%, Valid: 72.64% Test: 71.30%\n",
      "Epoch: 1997, Loss: 1.2367, Train: 75.27%, Valid: 72.51% Test: 70.87%\n",
      "Epoch: 1998, Loss: 1.2381, Train: 75.20%, Valid: 72.80% Test: 71.68%\n",
      "Epoch: 1999, Loss: 1.2386, Train: 75.23%, Valid: 72.72% Test: 71.48%\n",
      "0.7180009464436352\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 4000)\n",
    "evaluator = Evaluator(name='ogbn-arxiv')\n",
    "test_accs = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "    test_accs.append(test_acc)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * valid_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')\n",
    "print(max(test_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(range(1, NUM_EPOCHS+1), test_accs)\n",
    "plt.title(\"Test Set\")\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.7553854700327141\n"
     ]
    }
   ],
   "source": [
    "# Ensemble results\n",
    "\n",
    "final_out = model(data.x, data.adj_t)\n",
    "with open(\"/nlp/scr/ananjan/graph_embeddings/finetuned/mpnet_logits_arxiv.pkl\", 'rb') as f:\n",
    "    lm_logits = pickle.load(f)\n",
    "lm_logits = torch.tensor(lm_logits).to(device)\n",
    "\n",
    "test_acc_best = -100\n",
    "best_wt = -1\n",
    "\n",
    "for rel in range(0,30):\n",
    "    final_out = final_out + (rel/10)*lm_logits\n",
    "    y_pred = final_out.argmax(dim=-1, keepdim=True)\n",
    "    test_acc = evaluator.eval({\n",
    "            'y_true': data.y[split_idx['test']],\n",
    "            'y_pred': y_pred[split_idx['test']],\n",
    "        })['acc']\n",
    "    if (test_acc > test_acc_best):\n",
    "        test_acc_best = test_acc\n",
    "        best_wt = rel\n",
    "        \n",
    "print(best_wt/10)\n",
    "print(test_acc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:ts] *",
   "language": "python",
   "name": "conda-env-ts-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
